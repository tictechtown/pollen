{
  "generatedAt": "2025-12-19T22:22:22.511Z",
  "count": 38,
  "results": [
    {
      "title": "MySQL Performance Blog",
      "url": "https://www.percona.com/blog/feed/",
      "file": "mysql-performance-blog__f4f22b2918.xml",
      "ok": true,
      "bytes": 35582,
      "contentType": "application/rss+xml; charset=UTF-8",
      "expectedFeed": {
        "id": "aHR0cHM6Ly93d3cucGVyY29uYS5jb20vYmxvZy9mZWVkLw",
        "title": "Percona Database Performance Blog",
        "xmlUrl": "https://www.percona.com/blog/feed/",
        "image": "https://www.percona.com/blog/wp-content/uploads/2023/02/cropped-percona-favicon-32x32.png",
        "description": null,
        "lastUpdated": "Fri, 19 Dec 2025 14:05:05 +0000",
        "lastPublishedAt": null
      },
      "expectedArticles": [
        {
          "id": "aHR0cHM6Ly93d3cucGVyY29uYS5jb20vYmxvZy8_cD0xMDQxMTg",
          "title": "Improve Developer Velocity with Kubernetes Databases",
          "description": "Your company has invested heavily in agile development, microservices, and Kubernetes to move faster. Your app teams can spin up a new service in minutes. So why can it still take a week to get a database for it? The bottleneck has shifted. It’s no longer compute; it’s the database. Manual, ticket-based provisioning still dominates, […]",
          "link": "https://www.percona.com/blog/improve-developer-velocity-with-kubernetes-databases/",
          "source": "Percona Database Performance Blog",
          "thumbnail": "https://www.percona.com/blog/wp-content/uploads/2025/12/Improve-Developer-Velocity-with-Kubernetes-200x112.jpg",
          "feedId": "aHR0cHM6Ly93d3cucGVyY29uYS5jb20vYmxvZy9mZWVkLw",
          "seen": false,
          "saved": false,
          "publishedAt": "Fri, 19 Dec 2025 14:05:05 +0000",
          "updatedAt": null
        },
        {
          "id": "aHR0cHM6Ly93d3cucGVyY29uYS5jb20vYmxvZy8_cD0xMDQxNDg",
          "title": "Introducing Percona Load Generator for MongoDB Clusters: The Benchmark Tool That Simulates Your Actual Application",
          "description": "If you have ever tuned a MongoDB cluster that passed every synthetic benchmark with flying colors, only to choke the moment real user traffic hit, you are not alone. For years, database administrators and developers have relied on a standard suite of tools to test MongoDB performance (YCSB, Sysbench, POCDriver and mgodatagen –  just to […]",
          "link": "https://www.percona.com/blog/introducing-percona-load-generator-for-mongodb-clusters-the-benchmark-tool-that-simulates-your-actual-application/",
          "source": "Percona Database Performance Blog",
          "thumbnail": "https://www.percona.com/blog/wp-content/uploads/2025/12/Percona-Load-Generator-for-MongoDB-Clusters-200x86.jpg",
          "feedId": "aHR0cHM6Ly93d3cucGVyY29uYS5jb20vYmxvZy9mZWVkLw",
          "seen": false,
          "saved": false,
          "publishedAt": "Thu, 18 Dec 2025 13:38:13 +0000",
          "updatedAt": null
        }
      ],
      "expectedArticleCount": 20
    },
    {
      "title": "HTMHell Tips &amp; Tricks",
      "url": "https://htmhell.dev/feed_tips.xml",
      "file": "htmhell-tips-tricks__c9d7949f20.xml",
      "ok": true,
      "bytes": 294052,
      "contentType": "application/xml",
      "expectedFeed": {
        "id": "aHR0cHM6Ly9odG1oZWxsLmRldi90aXBz",
        "title": "HTMHell Tips & Tricks",
        "xmlUrl": "https://htmhell.dev/feed_tips.xml",
        "image": null,
        "description": "A collection of HTML tips and tricks.",
        "lastUpdated": "2025-09-11T00:00:00Z",
        "lastPublishedAt": null
      },
      "expectedArticles": [
        {
          "id": "aHR0cHM6Ly9odG1oZWxsLmRldi90aXBzL2Rvd25sb2FkLWxpbmtzLw",
          "title": "Download links",
          "description": null,
          "link": "https://htmhell.dev/tips/download-links/",
          "source": "HTMHell Tips & Tricks",
          "thumbnail": null,
          "feedId": "aHR0cHM6Ly9odG1oZWxsLmRldi90aXBz",
          "seen": false,
          "saved": false,
          "publishedAt": "2021-05-19T00:00:00Z",
          "updatedAt": "2021-05-19T00:00:00Z"
        },
        {
          "id": "aHR0cHM6Ly9odG1oZWxsLmRldi90aXBzL2lmcmFtZS1hY2Nlc3NpYmlsaXR5Lw",
          "title": "iframe accessibility",
          "description": null,
          "link": "https://htmhell.dev/tips/iframe-accessibility/",
          "source": "HTMHell Tips & Tricks",
          "thumbnail": null,
          "feedId": "aHR0cHM6Ly9odG1oZWxsLmRldi90aXBz",
          "seen": false,
          "saved": false,
          "publishedAt": "2021-06-04T00:00:00Z",
          "updatedAt": "2021-06-04T00:00:00Z"
        }
      ],
      "expectedArticleCount": 20
    },
    {
      "title": "SRE WEEKLY",
      "url": "https://sreweekly.com/feed/",
      "file": "sre-weekly__920c2c5c5f.xml",
      "ok": true,
      "bytes": 32048,
      "contentType": "application/rss+xml; charset=UTF-8",
      "expectedFeed": {
        "id": "aHR0cHM6Ly9zcmV3ZWVrbHkuY29tL2ZlZWQv",
        "title": "SRE WEEKLY",
        "xmlUrl": "https://sreweekly.com/feed/",
        "image": "https://sreweekly.com/wp-content/uploads/2015/12/cropped-sreweekly-logo-axes-32x32.png",
        "description": null,
        "lastUpdated": "Mon, 15 Dec 2025 03:31:52 +0000",
        "lastPublishedAt": null
      },
      "expectedArticles": [
        {
          "id": "aHR0cHM6Ly9zcmV3ZWVrbHkuY29tLz9wPTE3MTU",
          "title": "SRE Weekly Issue #501",
          "description": "View on sreweekly.com A message from our sponsor, Depot: “Waiting for a runner” but the runner is online? Depot debugs three cases where symptoms misled engineers. Workflow permissions, Azure authentication, and Dependabot’s security context all caused failures that looked like infrastructure problems. AI and the ironies of automation – Part 1 A thoughtful evaluation of […]",
          "link": "https://sreweekly.com/sre-weekly-issue-501/",
          "source": "SRE WEEKLY",
          "thumbnail": null,
          "feedId": "aHR0cHM6Ly9zcmV3ZWVrbHkuY29tL2ZlZWQv",
          "seen": false,
          "saved": false,
          "publishedAt": "Mon, 15 Dec 2025 03:31:51 +0000",
          "updatedAt": null
        },
        {
          "id": "aHR0cHM6Ly9zcmV3ZWVrbHkuY29tLz9wPTE3MTM",
          "title": "SRE Weekly Issue #500",
          "description": "View on sreweekly.com A message from our sponsor, Depot: Stop hunting through GitHub Actions logs. Depot now offers powerful CI log search across all your repositories and workflows. With smart filtering by timeframe, runner type, and keywords, you’ll have all the information at your fingertips to debug faster. Wow, five hundred issues! I sent the […]",
          "link": "https://sreweekly.com/sre-weekly-issue-500/",
          "source": "SRE WEEKLY",
          "thumbnail": null,
          "feedId": "aHR0cHM6Ly9zcmV3ZWVrbHkuY29tL2ZlZWQv",
          "seen": false,
          "saved": false,
          "publishedAt": "Mon, 08 Dec 2025 02:05:42 +0000",
          "updatedAt": null
        }
      ],
      "expectedArticleCount": 5
    },
    {
      "title": "Of Dollars and Data",
      "url": "https://ofdollarsanddata.com/feed/",
      "file": "of-dollars-and-data__1bf739e66b.xml",
      "ok": true,
      "bytes": 211950,
      "contentType": "application/rss+xml; charset=UTF-8",
      "expectedFeed": {
        "id": "aHR0cHM6Ly9vZmRvbGxhcnNhbmRkYXRhLmNvbS9mZWVkLw",
        "title": "Of Dollars And Data",
        "xmlUrl": "https://ofdollarsanddata.com/feed/",
        "image": "https://ofdollarsanddata.com/wp-content/uploads/2020/06/cropped-small_logo_only-32x32.jpg",
        "description": null,
        "lastUpdated": "Mon, 15 Dec 2025 16:28:59 +0000",
        "lastPublishedAt": null
      },
      "expectedArticles": [
        {
          "id": "aHR0cHM6Ly9vZmRvbGxhcnNhbmRkYXRhLmNvbS8_cD0zMDkzNw",
          "title": "No, the Poverty Line Isn’t $140,000 a Year",
          "description": "A few weeks ago, Michael Green published a post where he argued that the poverty line for a family of four in the U.S. wasn't $32,100 in annual income (as currently claimed by the Department of Health and Human Services), but closer to $140,000 per year.\n\nHe maintains that how poverty was determined historically (based solely on food prices) no longer holds because the costs of other necessities (namely housing, healthcare, and childcare) have gone up considerably. Therefore, a typical family of four needs far more income to participate in society today than they would've needed a few decades ago.\n\nI believe that this thesis is fundamentally correct and the real poverty line is much higher than the $32,100 figure provided by the DHHS. However, how Green goes from this correct diagnosis to a revised $140,000 per year \"poverty line\" is flawed in many ways.\n\nI have no interest in taking apart the $140,000 figure because others have thoroughly debunked it already, and even Green himself revised it down to $94,000 one week later. That alone should illustrate how outlandish his original $140k poverty line estimate was.\n\nHowever, even Green's more reasonable $94,000 poverty line for a family of four is still slightly exaggerated. The problem with this number isn't the data Green uses, but how he applies it.\n\nIronically, Green bashes economists for championing rising home prices and 401(k) balances as signs of improving wealth, but, with similar naiveté, assumes that everyone pays the average price for all their goods and services. But they don't. In the real world, the costs associated with things like childcare and housing vary significantly and can be much lower than the average. \n\nFor example, I know a woman who is unmarried with three children. Her and her boyfriend both work and they each make less than $20 an hour. As a result, their household income is less than $80,000 per year.\n\nAccording to Green, this family would be struggling just trying to keep up with their childcare costs. Is that what happens in practice? No. When their children aren't in school, they stay with the woman's mother. So that hypothetical $32,000 in childcare costs (for two children) goes to $0 (for three children). While not everyone has this luxury, millions do, and a poverty metric that ignores the informal economy overlooks how the working class actually survives.\n\nMore importantly, if she didn't have her mother there, she could consider other relatives to watch her kids or pay someone to watch them for far less than $32,000 per year. Most people aren't isolated economic units. They exist within a broader network of friends and family that can provide real economic value that offsets some of these costs.\n\nI understand that this is just one anecdote, but it exemplifies the logical flaw in Green's argument. He assumes that people will willingly go to work, earn a low wage, and then spend it all on childcare (i.e., pay the average price). No, they won't! If the second earner doesn't make enough, they will stay home and watch the kids. Or they will only work part time (nights/weekends). Or they will find a cheaper childcare arrangement.\n\nThis demonstrates that there's a big difference between the formal market and the informal market, especially for childcare. Green's analysis assumes that everyone pays the sticker price at a licensed daycare center (i.e., the formal market). But in reality, millions of families operate in the informal market, utilizing grandparents, neighbors, or split-shifts to reduce their childcare cost significantly.\n\nThe same logic applies for housing as well. For example, the average price for a one-bedroom apartment in New York City is around $4,000. If we assumed that everyone in NYC paid that price for housing, then it would be easy to argue that lots of people in NYC are in deep poverty.\n\nHowever, if you actually look at the data, the median rent paid for an apartment in NYC is only $1,650 per month across 2.3 million rental units. How is that possible? Because this figure includes rent-stabilized units, rent-controlled units, and public housing units which are much cheaper than market rate apartments. When we use the average market rate, we skew this number upward and exclude over half of NYC's housing stock.\n\nAnd that's just what's in the formal housing market. There are many informal housing arrangements that fly below the radar that are much cheaper as well. For example, one of my wife's friends shares a room in Brooklyn with two other people and only pays $500 a month. While this is a bit extreme, she's living in Brooklyn for only $500 a month! These kinds of housing situations are unlikely to be in the data, but they exist nonetheless.\n\nI understand that the NYC housing market is very different from the rest of the U.S., but it demonstrates that housing options are far more diverse than what \"the average\" suggests. The same goes for childcare.\n\nAs a result, many families can get by on much less than what Green assumes. Does that mean that the poverty line for a family of four is only $32,100? No. It's definitely more than double that.\n\nBut is that really a surprise? If low skilled workers now earn $20 an hour (~$40,000 per year), is it unreasonable to expect people to earn more than that to raise a family of four?  I don't know. Unfortunately, questions like this are more ethical than financial in nature, which isn't my area of expertise.\n\nRegardless of what you believe about the true poverty line, it's fair to say that it's far below $140,000. And Michael Green knows that.\n\nThe real genius of his article was saying something blatantly true and blatantly false at the same time. This is how you maximize engagement and go viral.\n\nWhy does this work? Because it gets those who believe the truth to come out and support you and those who think it's false to come out against you. For example, consider this image I saw on LinkedIn recently:\n\n\n\nThis is incredible engagement bait because it says something true (\"If you can't tip your server, don't go out to eat\") and something false (\"You should tip your server 40%\") at the same time. Max outrage. Max engagement. Rinse. Repeat.\n\nThis is basically what Green did in his original article and it worked. Multiple readers asked me about it, so I felt like I had to respond.\n\nGreen is far smarter than me and I have nothing against him. Even though I disagree with his long-held stance that passive indexing is in a massive bubble, he's a great thinker.\n\nHowever, people are also more complicated than Green assumes. For example, you can run the numbers and declare that someone will run out of money in retirement using the 4% Rule, but they probably won't. In practice, they will cut back as their assets decline. They will change their behavior. They will adapt.\n\nThis explains why so few people actually use the 4% Rule. It's too robotic to fit actual human behavior. However, it's a great convenience for investment nerds like myself and Green. \n\nBut convenience doesn't equal truth, whether we look at the 4% Rule or the poverty line. Thank you for reading.\n\nIf you liked this post, consider signing up for my newsletter.\n\nThis is post 481. Any code I have related to this post can be found here with the same numbering: https://github.com/nmaggiulli/of-dollars-and-data\n\n",
          "link": "https://ofdollarsanddata.com/no-the-poverty-line-isnt-140000-a-year/",
          "source": "Of Dollars And Data",
          "thumbnail": "https://ofdollarsanddata.com/wp-content/uploads/2025/12/tipping_too_much.jpg",
          "feedId": "aHR0cHM6Ly9vZmRvbGxhcnNhbmRkYXRhLmNvbS9mZWVkLw",
          "seen": false,
          "saved": false,
          "publishedAt": "Tue, 16 Dec 2025 12:45:37 +0000",
          "updatedAt": null
        },
        {
          "id": "aHR0cHM6Ly9vZmRvbGxhcnNhbmRkYXRhLmNvbS8_cD0zMDg5OA",
          "title": "My Favorite Investment Writing of 2025",
          "description": "With 2025 coming to an end, it’s time for my annual tradition of gathering my favorite investment writing of the year. I started this tradition in 2017, and have continued it ever since (2018, 2019, 2020, 2021, 2022, 2023, 2024).\n\n2025 was a year of turbulence (in April) and a year of growth. And though AI has infiltrated the writing space like never before, there are still many great human writers doing their thing. With that being said, I present my favorite investment writing of 2025:\n\n \tOn Bubble Watch (Howard Marks)\n\nHoward Marks is one of the best investment writers and thinkers in our industry and this piece (which came out in early 2025) set the stage for many of the bubble discussions that followed throughout the year. While Marks doesn't adamantly claim that everything is in a bubble, he does provide measured evidence illustrating how valuations seem stretched in today's environment. A great read to orient yourself as we go into 2026.\n\n \tWhy be an LP when you can be a GP? (Josh Brown)\n\nWhile Marks was discussing the possibility of a bubble in public markets, Josh Brown penned this wonderful article on what's happening in private markets. Similarly, Josh doesn't claim that private equity is bad or in a huge bubble, but rather highlights what Wall Street has done to get more investors into this historically exclusive asset class. Filled with humor and wit in equal measure, this piece is for anyone who wants to know what's been happening in private markets.\n\n \tAmerica's Housing Paradox, Hiding in Plain Sight (Money With Katie)\n\nThere were a lot of housing posts published in 2025, but this one had the most in-depth research of any I read. Quite simply, Katie Gatti Tassin crushed it here. If you want to know why the U.S. has a housing crisis and why it probably won't be solved anytime soon, read this piece.\n\n \tWhen Will Housing Prices Fall? (Ben Carlson)\n\nEvery year I put a Ben Carlson housing piece on this list because every year he delivers. This year Ben asks, \"When will housing prices fall?\" and then answers the question with solid data and analysis. There's a reason Ben is the best housing writer in our space, and this piece illustrates why. \n\n \tPure Independence (Morgan Housel)\n\nYou can tell when a writer is passionate about a topic and it clearly shows here for Morgan. Not only does he define different forms of independence and why they matter, but he also demonstrates why independence is the key to producing great work. A must read for anyone trying to live life on their own terms.\n\n \tWhy you probably have a low leverage career (and how to create more leverage) (Rick Foerster)\n\nI discovered Rick Foerster rather recently and loved this piece on career leverage. I've written on leverage before, but this guide from Rick is far more detailed and provides a lot more high-leverage options for those looking to transform their career. If you want to understand how to earn more in the future via leverage, this is the piece to read.\n\n \tHow Does the Stock Market Bottom? (Michael Batnick)\n\nEvery time the market crashes, Michael Batnick produces his absolute best work. The calm and collected tone during the high uncertainty back in April was something every investor needed to hear. And while the market turbulence has since passed, this is a good reminder on how the stock market tends to bottom before things get better.\n\n \tWhat Now? An Investor’s To-Do List for Chaotic Markets (Christine Benz)\n\nRight as the market crashed in April, Christine Benz came out with this simple, yet effective reminder on what things to do during a chaotic market. This was not a piece on market timing, but a gentle reminder to have your affairs in order in case things got worse. An evergreen read whether we are experiencing a chaotic market or not.\n\n \tPerspective on Market Downturns (Rubin Miller, CFA)\n\nRubin Miller came out with this wonderful piece one month before the market crashed back in April, but it was timely nonetheless. It reads like a greatest hits of Miller's ideas on volatility, rebalancing, and much more. If you want a broader perspective on managing your portfolio during market downturns, check this one out.\n\n \tInvest Like Buffett (Callie Cox)\n\nShortly after Warren Buffett announced that he was stepping down from Berkshire Hathaway, Callie Cox wrote this great article. Not only was it an ode to Buffett and his legacy, but it provides real-world takeaways on how to invest more like the Oracle of Omaha. Though the advice is deceptively simple, a periodic reminder doesn't hurt. \n\n \tGiving people money helped less than I thought it would (Kelsey Piper)\n\nI love evidence-based financial writing and Kelsey Piper delivers it in this one on the effectiveness of universal basic income (UBI). Historically, I was a fan of UBI, but after reading this piece it seems like the result is less promising than I would've hoped. An incredible read for anyone trying to understand where UBI helps people...and where it doesn't. \n\n \tWho's Getting Rich Off Your Attention (Kyla Scanlon)\n\nThough Kyla Scanlon is more of an economics writer, I had to include her work here because she is writing on the very topics that are impacting markets and our day-to-day lives. This one takes an in-depth look at how companies get rich off of our attention and how that landscape has evolved over the past decade. A must read for anyone trying to understand the impact of social media on our lives.\n\n \tlong degeneracy (jez)\n\nI don't usually read about cryptocurrency and other forms of speculation, but this piece by \"jez\" is simply fantastic. Whether we like it or not, speculation is a large part of the investment space and this post explains why. While I don't agree with everything written here, it's a must read for those who want to know more about the non-traditional world of finance.\n\n \tThe Last Decision by the World's Leading Thinker on Decisions (Jason Zweig)\n\nThis post isn't about investing per se, but it tackles the topics of life, death, and decision-making in an incredible way. Zweig does a great job examining Daniel Kahneman's final decision to end his life and the impact this decision had on Kahneman's friends, family, and extended community.\n\n \tFarewell Friends (Jonathan Clements)\n\nUnfortunately, we lost a legend of financial writing in 2025—Jonathan Clements. Clements was known for his simple, clear communication around money and I enjoyed many of his books. \"Farewell Friends\" was Clements' last blog post. May he rest in peace.\n\n\n\nI hope you enjoyed this year's annual review.\n\nThank you for reading.\n\nIf you liked this post, consider signing up for my newsletter.\n\nThis is post 480. Any code I have related to this post can be found here with the same numbering: https://github.com/nmaggiulli/of-dollars-and-data\n\n",
          "link": "https://ofdollarsanddata.com/my-favorite-investment-writing-of-2025/",
          "source": "Of Dollars And Data",
          "thumbnail": null,
          "feedId": "aHR0cHM6Ly9vZmRvbGxhcnNhbmRkYXRhLmNvbS9mZWVkLw",
          "seen": false,
          "saved": false,
          "publishedAt": "Tue, 09 Dec 2025 12:45:22 +0000",
          "updatedAt": null
        }
      ],
      "expectedArticleCount": 10
    },
    {
      "title": "Facebook Engineering",
      "url": "https://engineering.fb.com/feed/",
      "file": "facebook-engineering__cbcbaf636f.xml",
      "ok": true,
      "bytes": 145778,
      "contentType": "application/rss+xml; charset=UTF-8",
      "expectedFeed": {
        "id": "aHR0cHM6Ly9lbmdpbmVlcmluZy5mYi5jb20vZmVlZC8",
        "title": "Engineering at Meta",
        "xmlUrl": "https://engineering.fb.com/feed/",
        "image": null,
        "description": null,
        "lastUpdated": "Fri, 19 Dec 2025 17:16:56 +0000",
        "lastPublishedAt": null
      },
      "expectedArticles": [
        {
          "id": "aHR0cHM6Ly9lbmdpbmVlcmluZy5mYi5jb20vP3A9MjM0OTY",
          "title": "DrP: Meta’s Root Cause Analysis Platform at Scale",
          "description": "Incident investigation can be a daunting task in today’s digital landscape, where large-scale systems comprise numerous interconnected components and dependencies DrP is a root cause analysis (RCA) platform, designed by Meta, to programmatically automate the investigation process, significantly reducing the mean time to resolve (MTTR) for incidents and alleviating on-call toil Today, DrP is used [...]\nRead More...\nThe post DrP: Meta’s Root Cause Analysis Platform at Scale appeared first on Engineering at Meta.\n",
          "link": "https://engineering.fb.com/2025/12/19/data-infrastructure/drp-metas-root-cause-analysis-platform-at-scale/",
          "source": "Engineering at Meta",
          "thumbnail": "https://engineering.fb.com/wp-content/uploads/2025/12/Meta-DrP-image-1.png",
          "feedId": "aHR0cHM6Ly9lbmdpbmVlcmluZy5mYi5jb20vZmVlZC8",
          "seen": false,
          "saved": false,
          "publishedAt": "Fri, 19 Dec 2025 17:35:13 +0000",
          "updatedAt": null
        },
        {
          "id": "aHR0cHM6Ly9lbmdpbmVlcmluZy5mYi5jb20vP3A9MjM0Nzc",
          "title": "How We Built Meta Ray-Ban Display: From Zero to Polish",
          "description": "We’re going behind the scenes of the Meta Ray-Ban Display, Meta’s most advanced AI glasses yet. In a previous episode we met the team behind the Meta Neural Band, the EMG wristband packaged with the Ray-Ban Display. Now we’re delving into the glasses themselves. Kenan and Emanuel, from Meta’s Wearables org, join Pascal Hartig on [...]\nRead More...\nThe post How We Built Meta Ray-Ban Display: From Zero to Polish appeared first on Engineering at Meta.\n",
          "link": "https://engineering.fb.com/2025/12/17/virtual-reality/meta-ray-ban-display-from-zero-to-polish/",
          "source": "Engineering at Meta",
          "thumbnail": null,
          "feedId": "aHR0cHM6Ly9lbmdpbmVlcmluZy5mYi5jb20vZmVlZC8",
          "seen": false,
          "saved": false,
          "publishedAt": "Wed, 17 Dec 2025 14:00:17 +0000",
          "updatedAt": null
        }
      ],
      "expectedArticleCount": 9
    },
    {
      "title": "Camille Fournier on Medium",
      "url": "https://medium.com/feed/@skamille",
      "file": "camille-fournier-on-medium__df3c3dcb55.xml",
      "ok": true,
      "bytes": 75567,
      "contentType": "text/xml; charset=UTF-8",
      "expectedFeed": {
        "id": "aHR0cHM6Ly9tZWRpdW0uY29tL2ZlZWQvQHNrYW1pbGxl",
        "title": "Stories by Camille Fournier on Medium",
        "xmlUrl": "https://medium.com/feed/@skamille",
        "image": "https://cdn-images-1.medium.com/fit/c/150/150/1*J2fWNTyPbgEhIyvVIjHAXg.jpeg",
        "description": null,
        "lastUpdated": "Fri, 19 Dec 2025 22:12:49 GMT",
        "lastPublishedAt": null
      },
      "expectedArticles": [
        {
          "id": "aHR0cHM6Ly9tZWRpdW0uY29tL3AvYjlhNTkxNjdjMjI2",
          "title": "Revisiting Manager READMEs",
          "description": null,
          "link": "https://skamille.medium.com/revisiting-manager-readmes-b9a59167c226?source=rss-12421a4f856------2",
          "source": "Stories by Camille Fournier on Medium",
          "thumbnail": "https://cdn-images-1.medium.com/max/225/0*8URkz_l2YKxEqADi",
          "feedId": "aHR0cHM6Ly9tZWRpdW0uY29tL2ZlZWQvQHNrYW1pbGxl",
          "seen": false,
          "saved": false,
          "publishedAt": "Sat, 22 Nov 2025 19:02:58 GMT",
          "updatedAt": null
        },
        {
          "id": "aHR0cHM6Ly9tZWRpdW0uY29tL3AvOGM4NmFhMDE3Mjlj",
          "title": "Dude, Where’s My Strategy?",
          "description": null,
          "link": "https://skamille.medium.com/dude-wheres-my-strategy-8c86aa01729c?source=rss-12421a4f856------2",
          "source": "Stories by Camille Fournier on Medium",
          "thumbnail": "https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=8c86aa01729c",
          "feedId": "aHR0cHM6Ly9tZWRpdW0uY29tL2ZlZWQvQHNrYW1pbGxl",
          "seen": false,
          "saved": false,
          "publishedAt": "Thu, 05 Jun 2025 13:16:53 GMT",
          "updatedAt": null
        }
      ],
      "expectedArticleCount": 10
    },
    {
      "title": "Irrational Exuberance",
      "url": "https://lethain.com/feeds.xml",
      "file": "irrational-exuberance__7724ef2ebe.xml",
      "ok": true,
      "bytes": 87909,
      "contentType": "application/xml",
      "expectedFeed": {
        "id": "aHR0cHM6Ly9sZXRoYWluLmNvbS9mZWVkcy54bWw",
        "title": "Irrational Exuberance",
        "xmlUrl": "https://lethain.com/feeds.xml",
        "image": null,
        "description": null,
        "lastUpdated": "Thu, 18 Dec 2025 10:00:00 -0700",
        "lastPublishedAt": null
      },
      "expectedArticles": [
        {
          "id": "aHR0cHM6Ly9sZXRoYWluLmNvbS8yMDI1LWluLXJldmlldy8",
          "title": "2025 in review.",
          "description": "Yet another edition of my annual recap!\nThis year brought my son to kindergarten,\nme to forty and to a new job at Imprint,\nmy fourth book to bookstores,\nand a lot more time in the weeds of developing software.\n\nPreviously:\n2024, 2023, 2022, 2021,\n2020, 2019, 2018, 2017\nGoals\nEvaluating my goals for this year and decade:\n\n\n[Completed]\nWrite at least four good blog posts each year.\nMoving from an orchestration-heavy to leadership-heavy management role,\nGood engineering management is a fad,\nWhat is the competitive advantage of authors in the age of LLMs?,\nFacilitating AI adoption at Imprint\n\n\n[Completed]\nWrite three books about engineering or leadership in 2020s.\nThis year I finished Crafting Engineering Strategy\nwith O’Reilly. This is my third engineering book in the 2020s.\nMore about this in the Writing section below.\n\n\n[Completed]\nDo something substantial and new every year that provides new perspective or deeper practice.\nAfter almost a decade of not submitting a substantial pull request at work,\nI’ve been back in the mix since joining Imprint.\nI’ve submitted a solid handful of real pull requests that implement\nproduction features, and have used Claude Code widely in their creation.\nI’ve missed this a lot, and have learned a bunch about developing software with LLMs.\n\n\n[In progress]\n20+ folks who I’ve managed or meaningfully supported move into VPE or CTO roles at 50+ person or $100M+ valuation companies.\nThis is a decade goal ending in 2029. I previously increased the goal in 2022 from 3-5 to 20.\nIn 2024, the count was at 10.\nThings haven’t moved too much since then, but I’ll refresh next year.\nI think that I’m on track, but I will say that I think getting into these roles is markedly\nharder than it was three years ago. There are just fewer of these roles available recently,\nand they tend to be both more demanding and more difficult than the standard VPE/CTO role\na few years ago.\n\n\nFor backstory on these goals: I originally\nset them in 2019, and then revised them in 2022.\nI’ve come to believe that I should be revising these every year,\nbut also that it’s not that interesting to revise them every year.\nI’ll revise them again in a few years.\nWriting\nI finished my fourth book, Crafting Engineering Strategy,\nand wrote some notes on writing it.\nI’m really excited for this book to be done, because I think it’s been a missing book\nin the industry, and I hope it will change how the industry thinks about “engineering strategy.”\nIn particular, I hope it’ll pull us away from the frequent gripe that “we have no engineering strategy!”\nYou do have an engineering strategy, it’s just not written down yet.\nAs part of finishing this book, I’ve also recognized that\nif I write another book, it will be far into the future.\nAfter publishing four books in six years, I’m booked out,\nand I’m pretty sure I’ve tapped out my last decade’s path of\nwriting books to advance the industry.\nI’ll definitely keep writing, but it’ll be posts focused on the stuff\nI’m concretely working on, without trying to map them into a larger book structure.\n(Last year I mentioned adding The High-Context Triad to a second\nedition of Staff Engineer, which I still plan to do, but I’m not quite sure when.\nProbably in a few years.)\nWork\nI left Carta in May after two years there, and joined Imprint.\nImprint has just been a lot of fun for me. I’ve written a small number of real pull requests\nthat implement meaningful things.\nThat’s something I haven’t done since working at Uber,\nand aligns with my desire to be working in the details again.\nThere’s nothing more energizing to me than getting to solve real, concrete problems,\nand that’s exactly the sort of job Imprint has been for me.\nI just haven’t been spenting time on stuff like implementing internal workflow agents\nor automatically merging Dependabot pull requests in a long time,\nand I missed it.\nIt’s also, after some years spent on making teams more efficient,\nbeen an opportunity to really hire again, which I haven’t gotten to do\nsince my first couple years at Calm.\nIt’s never easy working at a fast growing company,\nbut you do learn a lot, and quite quickly.\nFamily\nMy son entered kindergarten this year. I turned 40.\nMy wife is starting to explore the world of fractional software development,\nand she’s figuring out its rules.\nWe’ve had a fair amount of health issues in the immediate\nand extended family, but altogether everything is going well.\nSpeaking\nI didn’t do much public speaking, although I spoke on\nBook Overflow about Staff Engineer,\nwhich was a fun discussion.\nI also spoke at several private events, and recorded practice runs on YouTube\nof Good engineering management is a fad\nand CTOs must earn the right to specialize.\nThose are very similar talks, where I’ve been iterating on the core\nidea of how engineering managers need to adapt to the current era.\nReading\nIn 2024, I read 27 profession-adjacent books. In 2023, I read 11.\nI’m not quite sure how many I read in 2022, because I put together a\n2019-2022 professional reading recap, but it was about\n50 over four years. This year I didn’t do much professional reading,\nmostly because I was too busy with the new job and polishing my most recent book.\nWhat I did read was:\n\nAI Engineering by Chip Huyen\nRecoding America by Jennifer Pahlka\nFacilitating Software Architecture by Andrew Harmel-Law\nTurning the Flywheel by Jim Collins\n\nIt’s interesting to note the drop in volume, but I feel fine about it.\nI don’t read to hit a goal, I read to learn or understand a particular problem,\nand found myself mostly working on topics that didn’t align well with that\napproach this year.\n\nIf you’ve written something about your year, send it my way!",
          "link": "https://lethain.com/2025-in-review/",
          "source": "Irrational Exuberance",
          "thumbnail": null,
          "feedId": "aHR0cHM6Ly9sZXRoYWluLmNvbS9mZWVkcy54bWw",
          "seen": false,
          "saved": false,
          "publishedAt": "Thu, 18 Dec 2025 10:00:00 -0700",
          "updatedAt": null
        },
        {
          "id": "aHR0cHM6Ly9sZXRoYWluLmNvbS9kZXBlbmRhYm90LWF1dG8tbWVyZ2Uv",
          "title": "Automatically merging dependabot PRs",
          "description": "One of the recurring themes of software development is patching security issues.\nMost repository hosting services have fairly good issue reporting at this point, but many\norganizations still struggle to apply those fixes in a timely fashion.\nThis past week we were discussing how to reduce the overhead of this process,\nand I was curious: can you just auto-merge Github Dependabot pull-requests?\nIt turns out, [the answer is yes], and it works pretty well.\nYou get control over which types of updates (patches, minor updates, major updates, etc) you want\nto auto-merge, and it will also respect your automated checks.\nIf you have great CI/CD that runs blocking linting, typing and tests, then this works\nparticularly well.\nIf you don’t, then, well, this will be an effective mechanism\nto get you to having good linting, typing, and tests afer traversing a small ocean of tears.\nI got this running for about a dozen repositories at work over the past few days,\nbut I’ll show an example of setting up the same mechanism for my blog.\nFirst, add a .github/workflows/dependabot-auto-merge.yml file to your repository\nthat looks like this:\n# Automatically approve and merge Dependabot PRs for minor and patch updates\nname: Dependabot auto-merge\non: pull_request\npermissions:\ncontents: write\npull-requests: write\njobs:\ndependabot:\nruns-on: ubuntu-latest\nif: github.event.pull_request.user.login == 'dependabot[bot]' && github.repository == 'lethain/irrational_hugo'\nsteps:\n- name: Dependabot metadata\nid: metadata\nuses: dependabot/fetch-metadata@v2\nwith:\ngithub-token: \"${{ secrets.GITHUB_TOKEN }}\"\n- name: Approve Dependabot PR\nrun: gh pr review --approve \"$PR_URL\"\nenv:\nPR_URL: ${{ github.event.pull_request.html_url }}\nGH_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n- name: Enable auto-merge for Dependabot PRs\nif: steps.metadata.outputs.update-type == 'version-update:semver-patch' || steps.metadata.outputs.update-type == 'version-update:semver-minor'\nrun: gh pr merge --auto --squash \"$PR_URL\"\nenv:\nPR_URL: ${{ github.event.pull_request.html_url }}\nGH_TOKEN: ${{ secrets.GITHUB_TOKEN }}\nThen go to your repository settings (something like\nhttps://github.com/lethain/irrational_hugo/settings), and enable auto-merging\nfor your repository. This still respects all required branch rules, like required test passes\nor approvals, etc.\n\n\n\nThen make sure you have appropriate status checks for whatever\nlinting, typing and tests you have in your repository.\n\n\n\nThen enable Dependabot (something like https://github.com/lethain/irrational_hugo/settings/security_analysis).\nEven the default settings are just find.\n\n\n\nThen you’re done. The PRs from dependabot will automatically merge going forward.\nThere are lots of nuances here–I already found one issues that automatically merged\ndespite an issue because of a missing test–but ultimately I think that’s valuable pressure\nto improve the testing quality, rather than a reason to avoid, or backtrack, on the approach.",
          "link": "https://lethain.com/dependabot-auto-merge/",
          "source": "Irrational Exuberance",
          "thumbnail": "https://lethain.com/static/blog/2025/dep-automerge.png",
          "feedId": "aHR0cHM6Ly9sZXRoYWluLmNvbS9mZWVkcy54bWw",
          "seen": false,
          "saved": false,
          "publishedAt": "Thu, 18 Dec 2025 08:00:00 -0700",
          "updatedAt": null
        }
      ],
      "expectedArticleCount": 6
    },
    {
      "title": "Ars Technica",
      "url": "https://feeds.arstechnica.com/arstechnica/index",
      "file": "ars-technica__09cc00c55f.xml",
      "ok": true,
      "bytes": 77832,
      "contentType": "text/xml; charset=utf-8",
      "expectedFeed": {
        "id": "aHR0cHM6Ly9mZWVkcy5hcnN0ZWNobmljYS5jb20vYXJzdGVjaG5pY2EvaW5kZXg",
        "title": "Ars Technica - All content",
        "xmlUrl": "https://feeds.arstechnica.com/arstechnica/index",
        "image": "https://cdn.arstechnica.net/wp-content/uploads/2016/10/cropped-ars-logo-512_480-60x60.png",
        "description": null,
        "lastUpdated": "Fri, 19 Dec 2025 22:05:52 +0000",
        "lastPublishedAt": null
      },
      "expectedArticles": [
        {
          "id": "aHR0cHM6Ly9hcnN0ZWNobmljYS5jb20vc2NpZW5jZS8yMDI1LzEyL3RoZS1ldm9sdXRpb24tb2YtZXhwZW5kYWJpbGl0eS13aHktc29tZS1hbnRzLXRyYWRlZC1hcm1vci1mb3ItbnVtYmVycy8",
          "title": "The evolution of expendability: Why some ants traded armor for numbers",
          "description": "Ants with lots of workers tend to put less energy into making them armored.",
          "link": "https://arstechnica.com/science/2025/12/the-evolution-of-expendability-why-some-ants-traded-armor-for-numbers/",
          "source": "Ars Technica - All content",
          "thumbnail": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/GettyImages-2247196489-1152x648.jpg",
          "feedId": "aHR0cHM6Ly9mZWVkcy5hcnN0ZWNobmljYS5jb20vYXJzdGVjaG5pY2EvaW5kZXg",
          "seen": false,
          "saved": false,
          "publishedAt": "Fri, 19 Dec 2025 22:05:52 +0000",
          "updatedAt": null
        },
        {
          "id": "aHR0cHM6Ly9hcnN0ZWNobmljYS5jb20vZ2FtaW5nLzIwMjUvMTIvY2hlYXBlci1sb3dlci1jYXBhY2l0eS1zd2l0Y2gtMi1jYXJ0cmlkZ2VzLWNvdWxkLW1lYW4tZmV3ZXItZ2FtZS1rZXktY2FyZHMv",
          "title": "Switch 2 pub backs off Game Key Cards after leaking lower-cost cartridge options",
          "description": "Inin suggests new low-cost options allowed it to \"recalculate production\" for full cartridge.",
          "link": "https://arstechnica.com/gaming/2025/12/cheaper-lower-capacity-switch-2-cartridges-could-mean-fewer-game-key-cards/",
          "source": "Ars Technica - All content",
          "thumbnail": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/switch2gkc-1152x648-1766176952.png",
          "feedId": "aHR0cHM6Ly9mZWVkcy5hcnN0ZWNobmljYS5jb20vYXJzdGVjaG5pY2EvaW5kZXg",
          "seen": false,
          "saved": false,
          "publishedAt": "Fri, 19 Dec 2025 21:30:08 +0000",
          "updatedAt": null
        }
      ],
      "expectedArticleCount": 20
    },
    {
      "title": "MDN Blog",
      "url": "https://developer.mozilla.org/en-US/blog/rss.xml",
      "file": "mdn-blog__6e471a4484.xml",
      "ok": true,
      "bytes": 47519,
      "contentType": "application/xml",
      "expectedFeed": {
        "id": "aHR0cHM6Ly9kZXZlbG9wZXIubW96aWxsYS5vcmcvZW4tVVMvYmxvZy9yc3MueG1s",
        "title": "MDN Blog",
        "xmlUrl": "https://developer.mozilla.org/en-US/blog/rss.xml",
        "image": "https://developer.mozilla.org/mdn-social-share.png",
        "description": null,
        "lastUpdated": "Fri, 19 Dec 2025 00:41:06 +0000",
        "lastPublishedAt": null
      },
      "expectedArticles": [
        {
          "id": "aHR0cHM6Ly9kZXZlbG9wZXIubW96aWxsYS5vcmcvZW4tVVMvYmxvZy9pbWFnZS1mb3JtYXRzLWNvZGVjcy1jb21wcmVzc2lvbi10b29scy8",
          "title": "Image formats: Codecs and compression tools",
          "description": "Image compression involves countless trade-offs between quality, size, and speed. In this final part of the series, we experiment with codecs, metrics, and tools to find practical ways to balance efficiency and visual fidelity.",
          "link": "https://developer.mozilla.org/en-US/blog/image-formats-codecs-compression-tools/",
          "source": "MDN Blog",
          "thumbnail": "https://developer.mozilla.org/en-US/blog/image-formats-codecs-compression-tools/featured.png",
          "feedId": "aHR0cHM6Ly9kZXZlbG9wZXIubW96aWxsYS5vcmcvZW4tVVMvYmxvZy9yc3MueG1s",
          "seen": false,
          "saved": false,
          "publishedAt": "Wed, 5 Nov 2025 00:00:00 +0000",
          "updatedAt": null
        },
        {
          "id": "aHR0cHM6Ly9kZXZlbG9wZXIubW96aWxsYS5vcmcvZW4tVVMvYmxvZy92aWV3LXRyYW5zaXRpb25zLWJlZ2lubmVyLWd1aWRlLw",
          "title": "A beginner-friendly guide to view transitions in CSS",
          "description": "Learn how to bring smooth, animated navigation to multi-page apps with view transitions. With just one line of CSS, you can enable seamless transitions between pages.\n",
          "link": "https://developer.mozilla.org/en-US/blog/view-transitions-beginner-guide/",
          "source": "MDN Blog",
          "thumbnail": "https://developer.mozilla.org/en-US/blog/view-transitions-beginner-guide/featured.png",
          "feedId": "aHR0cHM6Ly9kZXZlbG9wZXIubW96aWxsYS5vcmcvZW4tVVMvYmxvZy9yc3MueG1s",
          "seen": false,
          "saved": false,
          "publishedAt": "Thu, 9 Oct 2025 00:00:00 +0000",
          "updatedAt": null
        }
      ],
      "expectedArticleCount": 69
    },
    {
      "title": "HTML &amp; CSS Tip of the Week",
      "url": "https://html-css-tip-of-the-week.netlify.app/rss.xml",
      "file": "html-css-tip-of-the-week__0d1c6511c8.xml",
      "ok": true,
      "bytes": 12782,
      "contentType": "application/xml",
      "expectedFeed": {
        "id": "aHR0cHM6Ly9odG1sLWNzcy10aXAtb2YtdGhlLXdlZWsubmV0bGlmeS5hcHAvcnNzLnhtbA",
        "title": "HTML & CSS Tip of the Week",
        "xmlUrl": "https://html-css-tip-of-the-week.netlify.app/rss.xml",
        "image": null,
        "description": null,
        "lastUpdated": null,
        "lastPublishedAt": null
      },
      "expectedArticles": [
        {
          "id": "aHR0cHM6Ly9odG1sLWNzcy10aXAtb2YtdGhlLXdlZWsubmV0bGlmeS5hcHAvdGlwL25lc3RpbmctdGlwcy10cmlja3Mv",
          "title": "A few fun nesting tips & tricks",
          "description": "There are some handy things that you can do with nesting, espcially when you start moving the & placeholder around!",
          "link": "https://html-css-tip-of-the-week.netlify.app/tip/nesting-tips-tricks/",
          "source": "HTML & CSS Tip of the Week",
          "thumbnail": null,
          "feedId": "aHR0cHM6Ly9odG1sLWNzcy10aXAtb2YtdGhlLXdlZWsubmV0bGlmeS5hcHAvcnNzLnhtbA",
          "seen": false,
          "saved": false,
          "publishedAt": "Thu, 02 Oct 2025 00:00:00 GMT",
          "updatedAt": null
        },
        {
          "id": "aHR0cHM6Ly9odG1sLWNzcy10aXAtb2YtdGhlLXdlZWsubmV0bGlmeS5hcHAvdGlwL211dGxpcGxlLWNvcm5lci1yYWRpaS8",
          "title": "One corner, two border radii",
          "description": "Did you know you can control the border radius of both sides of a corner indepenently of one another? It might seem a little strange to do, but you can do some intersting things with it!",
          "link": "https://html-css-tip-of-the-week.netlify.app/tip/mutliple-corner-radii/",
          "source": "HTML & CSS Tip of the Week",
          "thumbnail": null,
          "feedId": "aHR0cHM6Ly9odG1sLWNzcy10aXAtb2YtdGhlLXdlZWsubmV0bGlmeS5hcHAvcnNzLnhtbA",
          "seen": false,
          "saved": false,
          "publishedAt": "Thu, 25 Sep 2025 00:00:00 GMT",
          "updatedAt": null
        }
      ],
      "expectedArticleCount": 31
    },
    {
      "title": "Times Open - Medium",
      "url": "https://open.nytimes.com/feed",
      "file": "times-open-medium__d15fbcdff1.xml",
      "ok": true,
      "bytes": 138999,
      "contentType": "text/xml; charset=UTF-8",
      "expectedFeed": {
        "id": "aHR0cHM6Ly9vcGVuLm55dGltZXMuY29tL2ZlZWQ",
        "title": "NYT Open - Medium",
        "xmlUrl": "https://open.nytimes.com/feed",
        "image": "https://cdn-images-1.medium.com/proxy/1*TGH72Nnw24QL3iV9IOm4VA.png",
        "description": null,
        "lastUpdated": "Fri, 19 Dec 2025 22:27:53 GMT",
        "lastPublishedAt": null
      },
      "expectedArticles": [
        {
          "id": "aHR0cHM6Ly9tZWRpdW0uY29tL3AvNDA1MzMxMzUyMTg5",
          "title": "Designing a Digital New York Times Museum",
          "description": null,
          "link": "https://open.nytimes.com/designing-a-digital-times-museum-for-all-405331352189?source=rss----51e1d1745b32---4",
          "source": "NYT Open - Medium",
          "thumbnail": "https://cdn-images-1.medium.com/max/1024/1*TkpbB5_zR3GSXWYSeqaBQQ.jpeg",
          "feedId": "aHR0cHM6Ly9vcGVuLm55dGltZXMuY29tL2ZlZWQ",
          "seen": false,
          "saved": false,
          "publishedAt": "Wed, 15 Oct 2025 18:30:40 GMT",
          "updatedAt": null
        },
        {
          "id": "aHR0cHM6Ly9tZWRpdW0uY29tL3AvNWYyM2E3YjI0ZmY0",
          "title": "Scaling Subscriptions at The New York Times with Real-Time Causal Machine Learning",
          "description": null,
          "link": "https://open.nytimes.com/scaling-subscriptions-at-the-new-york-times-with-real-time-causal-machine-learning-5f23a7b24ff4?source=rss----51e1d1745b32---4",
          "source": "NYT Open - Medium",
          "thumbnail": "https://cdn-images-1.medium.com/max/1024/1*UITh9uwuoXVxScBnf9JnJQ.gif",
          "feedId": "aHR0cHM6Ly9vcGVuLm55dGltZXMuY29tL2ZlZWQ",
          "seen": false,
          "saved": false,
          "publishedAt": "Fri, 03 Oct 2025 15:19:24 GMT",
          "updatedAt": null
        }
      ],
      "expectedArticleCount": 10
    },
    {
      "title": "Julia Evans",
      "url": "https://jvns.ca/atom.xml",
      "file": "julia-evans__e1299d24fd.xml",
      "ok": true,
      "bytes": 298933,
      "contentType": "application/xml",
      "expectedFeed": {
        "id": "aHR0cDovL2p2bnMuY2E",
        "title": "Julia Evans",
        "xmlUrl": "https://jvns.ca/atom.xml",
        "image": null,
        "description": null,
        "lastUpdated": "2025-11-05T00:00:00+00:00",
        "lastPublishedAt": null
      },
      "expectedArticles": [
        {
          "id": "aHR0cHM6Ly9qdm5zLmNhL2Jsb2cvMjAyNS8xMC8xMC9ub3Rlcy1vbi1zd2l0Y2hpbmctdG8taGVsaXgtZnJvbS12aW0v",
          "title": "Notes on switching to Helix from vim",
          "description": null,
          "link": "https://jvns.ca/blog/2025/10/10/notes-on-switching-to-helix-from-vim/",
          "source": "Julia Evans",
          "thumbnail": "/images/helix-search.png",
          "feedId": "aHR0cDovL2p2bnMuY2E",
          "seen": false,
          "saved": false,
          "publishedAt": "2025-10-10T00:00:00+00:00",
          "updatedAt": "2025-10-10T00:00:00+00:00"
        },
        {
          "id": "aHR0cHM6Ly9qdm5zLmNhL2Jsb2cvMjAyNS8wNi8yNC9uZXctemluZS0tdGhlLXNlY3JldC1ydWxlcy1vZi10aGUtdGVybWluYWwv",
          "title": "New zine: The Secret Rules of the Terminal",
          "description": null,
          "link": "https://jvns.ca/blog/2025/06/24/new-zine--the-secret-rules-of-the-terminal/",
          "source": "Julia Evans",
          "thumbnail": "https://jvns.ca/images/terminal-cover-small.jpg",
          "feedId": "aHR0cDovL2p2bnMuY2E",
          "seen": false,
          "saved": false,
          "publishedAt": "2025-06-26T00:00:00+00:00",
          "updatedAt": "2025-06-26T00:00:00+00:00"
        }
      ],
      "expectedArticleCount": 20
    },
    {
      "title": "Simon Willison's Weblog",
      "url": "https://simonwillison.net/atom/everything/",
      "file": "simon-willison-s-weblog__d1c587ecba.xml",
      "ok": true,
      "bytes": 211880,
      "contentType": "application/xml; charset=utf-8",
      "expectedFeed": {
        "id": "aHR0cDovL3NpbW9ud2lsbGlzb24ubmV0Lw",
        "title": "Simon Willison's Weblog",
        "xmlUrl": "https://simonwillison.net/atom/everything/",
        "image": null,
        "description": null,
        "lastUpdated": "2025-12-19T18:33:41+00:00",
        "lastPublishedAt": null
      },
      "expectedArticles": [
        {
          "id": "aHR0cHM6Ly9zaW1vbndpbGxpc29uLm5ldC8yMDI1L0RlYy8xOS9zYW0tcm9zZS1sbG1zLyNhdG9tLWV2ZXJ5dGhpbmc",
          "title": "Sam Rose explains how LLMs work with a visual essay",
          "description": "Sam Rose explains how LLMs work with a visual essay\nSam Rose is one of my favorite authors of explorable interactive explanations - here's his previous collection.\nSam joined ngrok in September as a developer educator. Here's his first big visual explainer for them, ostensibly about how prompt caching works but it quickly expands to cover tokenization, embeddings, and the basics of the transformer architecture.\nThe result is one of the clearest and most accessible introductions to LLM internals I've seen anywhere.\n\n\n\n    Tags: ai, explorables, generative-ai, llms, sam-rose, tokenization",
          "link": "https://simonwillison.net/2025/Dec/19/sam-rose-llms/#atom-everything",
          "source": "Simon Willison's Weblog",
          "thumbnail": null,
          "feedId": "aHR0cDovL3NpbW9ud2lsbGlzb24ubmV0Lw",
          "seen": false,
          "saved": false,
          "publishedAt": "2025-12-19T18:33:41+00:00",
          "updatedAt": "2025-12-19T18:33:41+00:00"
        },
        {
          "id": "aHR0cHM6Ly9zaW1vbndpbGxpc29uLm5ldC8yMDI1L0RlYy8xOS9pbnRyb2R1Y2luZy1ncHQtNTItY29kZXgvI2F0b20tZXZlcnl0aGluZw",
          "title": "Introducing GPT-5.2-Codex",
          "description": "Introducing GPT-5.2-Codex\nThe latest in OpenAI's Codex family of models (not the same thing as their Codex CLI or Codex Cloud coding agent tools).\n\nGPT‑5.2-Codex is a version of GPT‑5.2⁠ further optimized for agentic coding in Codex, including improvements on long-horizon work through context compaction, stronger performance on large code changes like refactors and migrations, improved performance in Windows environments, and significantly stronger cybersecurity capabilities.\n\nAs with some previous Codex models this one is available via their Codex coding agents now and will be coming to the API \"in the coming weeks\". Unlike previous models there's a new invite-only preview process for vetted cybersecurity professionals for \"more permissive models\".\nI've been very impressed recently with GPT 5.2's ability to tackle multi-hour agentic coding challenges. 5.2 Codex scores 64% on the Terminal-Bench 2.0 benchmark that GPT-5.2 scored 62.2% on. I'm not sure how concrete that 1.8% improvement will be!\nI didn't hack API access together this time (see previous attempts), instead opting to just ask Codex CLI to \"Generate an SVG of a pelican riding a bicycle\" while running the new model (effort medium). Here's the transcript in my new Codex CLI timeline viewer, and here's the pelican it drew:\n\n\n\n    Tags: ai, openai, generative-ai, llms, pelican-riding-a-bicycle, llm-release, codex-cli, gpt-codex",
          "link": "https://simonwillison.net/2025/Dec/19/introducing-gpt-52-codex/#atom-everything",
          "source": "Simon Willison's Weblog",
          "thumbnail": null,
          "feedId": "aHR0cDovL3NpbW9ud2lsbGlzb24ubmV0Lw",
          "seen": false,
          "saved": false,
          "publishedAt": "2025-12-19T05:21:17+00:00",
          "updatedAt": "2025-12-19T05:21:17+00:00"
        }
      ],
      "expectedArticleCount": 30
    },
    {
      "title": "CSS-Tricks",
      "url": "https://css-tricks.com/feed/",
      "file": "css-tricks__609d3f76cb.xml",
      "ok": true,
      "bytes": 250427,
      "contentType": "application/rss+xml; charset=UTF-8",
      "expectedFeed": {
        "id": "aHR0cHM6Ly9jc3MtdHJpY2tzLmNvbS9mZWVkLw",
        "title": "CSS-Tricks",
        "xmlUrl": "https://css-tricks.com/feed/",
        "image": "https://i0.wp.com/css-tricks.com/wp-content/uploads/2021/07/star.png?fit=32%2C32&#038;ssl=1",
        "description": null,
        "lastUpdated": "Fri, 19 Dec 2025 16:08:33 +0000",
        "lastPublishedAt": null
      },
      "expectedArticles": [
        {
          "id": "aHR0cHM6Ly9jc3MtdHJpY2tzLmNvbS8_cD0zOTA2NDA",
          "title": "Masonry Layout is Now grid-lanes",
          "description": "It's settled! A new CSS display property keyword called grid-lanes will trigger a masonry layout mode.\n\nMasonry Layout is Now grid-lanes originally published on CSS-Tricks, which is part of the DigitalOcean family. You should get the newsletter.\n",
          "link": "https://css-tricks.com/masonry-layout-is-now-grid-lanes/",
          "source": "CSS-Tricks",
          "thumbnail": "https://i0.wp.com/css-tricks.com/wp-content/uploads/2025/12/pinterest-layout_y8vjhk.png?resize=1913%2C1463",
          "feedId": "aHR0cHM6Ly9jc3MtdHJpY2tzLmNvbS9mZWVkLw",
          "seen": false,
          "saved": false,
          "publishedAt": "Fri, 19 Dec 2025 16:08:28 +0000",
          "updatedAt": null
        },
        {
          "id": "aHR0cHM6Ly9jc3MtdHJpY2tzLmNvbS8_cD0zOTExNzE",
          "title": "Search CSS-Tricks Raycast Extension",
          "description": "Jelte Lagendijk built a Raycast extension for searching CSS-Tricks articles where you simply type and a get a solid set of real-time results.\n\nSearch CSS-Tricks Raycast Extension originally published on CSS-Tricks, which is part of the DigitalOcean family. You should get the newsletter.\n",
          "link": "https://css-tricks.com/search-css-tricks-raycast-extension/",
          "source": "CSS-Tricks",
          "thumbnail": "https://i0.wp.com/css-tricks.com/wp-content/uploads/2025/12/Screenshot-2025-12-17-at-11.38.48-AM.png?resize=1724%2C1172&#038;ssl=1",
          "feedId": "aHR0cHM6Ly9jc3MtdHJpY2tzLmNvbS9mZWVkLw",
          "seen": false,
          "saved": false,
          "publishedAt": "Thu, 18 Dec 2025 15:34:23 +0000",
          "updatedAt": null
        }
      ],
      "expectedArticleCount": 15
    },
    {
      "title": "High Scalability",
      "url": "https://highscalability.com/rss/",
      "file": "high-scalability__48eff5312d.xml",
      "ok": true,
      "bytes": 909059,
      "contentType": "application/rss+xml; charset=utf-8",
      "expectedFeed": {
        "id": "aHR0cHM6Ly9oaWdoc2NhbGFiaWxpdHkuY29tL3Jzcy8",
        "title": "High Scalability",
        "xmlUrl": "https://highscalability.com/rss/",
        "image": "https://highscalability.com/favicon.png",
        "description": null,
        "lastUpdated": "Thu, 18 Dec 2025 06:30:35 GMT",
        "lastPublishedAt": null
      },
      "expectedArticles": [
        {
          "id": "NjYzYzBmNDRhMmZjZGYwMDAxYmFiODZj",
          "title": "Kafka 101",
          "description": "This is a guest article by Stanislav Kozlovski, an Apache Kafka Committer. If you would like to connect with Stanislav, you can do so on Twitter and LinkedIn.Originally developed in LinkedIn during 2011, Apache Kafka is one of the most popular open-source Apache projects out there.",
          "link": "https://highscalability.com/untitled-2/",
          "source": "High Scalability",
          "thumbnail": "https://highscalability.com/content/images/2024/05/pasted-image-0-2.png",
          "feedId": "aHR0cHM6Ly9oaWdoc2NhbGFiaWxpdHkuY29tL3Jzcy8",
          "seen": false,
          "saved": false,
          "publishedAt": "Thu, 09 May 2024 18:55:21 GMT",
          "updatedAt": null
        },
        {
          "id": "NjYwMjJlM2Y0MmIyODYwMDAxMTZjOTcw",
          "title": "Capturing A Billion Emo(j)i-ons",
          "description": "This blog post was written by Dedeepya Bonthu. This is a repost from her Medium article, approved by the author.In stadiums, sports fans love to express themselves by cheering for their favorite teams, holding up placards and team logos. Emoji’s allow fans at home to rapidly express",
          "link": "https://highscalability.com/capturing-a-billion-emo-j-i-ons/",
          "source": "High Scalability",
          "thumbnail": "https://highscalability.com/content/images/2024/03/1-rSRWALA4XzOdDcn-5vv7Zw.gif",
          "feedId": "aHR0cHM6Ly9oaWdoc2NhbGFiaWxpdHkuY29tL3Jzcy8",
          "seen": false,
          "saved": false,
          "publishedAt": "Tue, 26 Mar 2024 15:32:38 GMT",
          "updatedAt": null
        }
      ],
      "expectedArticleCount": 15
    },
    {
      "title": "RocksDB",
      "url": "https://rocksdb.org/feed.xml",
      "file": "rocksdb__4163416c06.xml",
      "ok": true,
      "bytes": 189577,
      "contentType": "application/xml",
      "expectedFeed": {
        "id": "aHR0cHM6Ly9yb2Nrc2RiLm9yZy9mZWVkLnhtbA",
        "title": "RocksDB",
        "xmlUrl": "https://rocksdb.org/feed.xml",
        "image": null,
        "description": null,
        "lastUpdated": "Tue, 16 Dec 2025 20:39:29 +0000",
        "lastPublishedAt": null
      },
      "expectedArticles": [
        {
          "id": "aHR0cDovL3JvY2tzZGIub3JnL2Jsb2cvMjAyNS8xMC8wOC9wYXJhbGxlbC1jb21wcmVzc2lvbi1yZXZhbXAuaHRtbA",
          "title": "Parallel Compression Revamp: Dramatically Reduced CPU Overhead",
          "description": "The upcoming RocksDB 10.7 release includes a major revamp of parallel compression that dramatically reduces the feature’s CPU overhead by up to 65% while maintaining or improving throughput for compression-heavy workloads. We expect this to broaden the set of workloads that could benefit from parallel compression, especially for bulk SST generation and remote compaction use cases that are less sensitive to CPU responsiveness.\n\nBackground\n\nParallel compression in RocksDB (CompressionOptions::parallel_threads > 1) allows multiple threads to compress different blocks simultaneously during SST file generation, which can significantly improve compaction throughput for workloads where compression is a bottleneck. However, the original implementation had substantial CPU overhead that often outweighed the benefits, limiting its practical adoption.\n\nWhat’s New: A Complete Reimplementation\n\nThe parallel compression framework has been completely rewritten from the ground up in pull request #13910 to address the core inefficiencies:\n\nRing Buffer Architecture\nInstead of separate compression and write queues with complex thread coordination, the new implementation uses a ring buffer of blocks-in-progress that enables efficient work distribution across threads. This bounds working memory while enabling high throughput with minimal cross-thread synchronization.\n\n\n\nWork-Stealing Design\nPreviously, the calling thread could only generate uncompressed blocks, dedicated compression threads could only compress, and a writer thread could only write the SST file to storage. Now, all threads can participate in compression work in a quasi-work-stealing manner, dramatically reducing the need for threads to block waiting for work. While only one thread (the calling thread or “emit thread”) can generate uncompressed SST blocks in the new implementation, feeding compression work to other threads and itself, all other threads are compatible with writing compressed blocks to storage.\n\nAuto-Scaling Thread Management\nThe ring buffer enables another key feature: auto-scaling of active threads based on ring buffer utilization. The framework intelligently wakes up idle worker threads only when there’s sufficient work to justify the overhead, achieving near-maximum throughput while minimizing CPU waste from unnecessary thread wake-ups.\n\nLock-Free Synchronization\nThe entire framework is now lock-free (and wait-free as long as compatible work units are available for each thread), based primarily on atomic operations. To cleanly pack and leverage many data fields into a single atomic value, I’ve developed a new BitFields utility API. This is proving useful for cleaning up the HyperClockCache implementation as well, and will be the topic of a later blog post.\n\nSemaphores are used for lock-free management of idle threads (assuming a lock-free semaphore implementation, which is likely the case with ROCKSDB_USE_STD_SEMAPHORES but that is untrustworthy; see below).\n\nPerformance Improvements\n\nThe results speak for themselves. Here’s a comparison using db_bench fillseq benchmarks with various compression configurations:\n\nZSTD Compression (Default Level)\nNote:\n\n  “throughput” = how quickly a given CPU-bound flush or compaction can complete\n  “CPU increase” = total CPU usage in amount of time that each core was used\n  “PT” = parallel_threads setting.\n\n\nBefore:\n\n  PT=3: ~38% throughput increase for ~73% CPU increase\n  PT=6: No throughput increase for ~70% CPU increase\n\n\nAfter:\n\n  PT=3: ~58% throughput increase for ~25% CPU increase\n  PT=6: ~58% throughput increase for ~28% CPU increase\n\n\nHigh Compression Scenarios\nFor ZSTD compression level 8, the improvements are even more dramatic:\n\nBefore:\n\n  PT=4: 2.6x throughput increase for 139% CPU increase\n  PT=8: 3.6x throughput increase for 135% CPU increase\n\n\nAfter:\n\n  PT=4: 2.8x throughput increase for 114% CPU increase\n  PT=8: 3.7x throughput increase for 116% CPU increase\n\n\nCompression Algorithm Optimizations\n\nAlongside the parallel compression revamp, some optimizations have gone into the underlying compression implementations/integrations. Most notably, LZ4HC received dramatic performance improvements through better reuse of internal data structures between compression calls (detailed in pull request #13805). A small regression in LZ4 performance from that change was fixed in pull request #14017.\n\nWhile ZSTD remains the gold standard for medium-to-high compression ratios in RocksDB, these LZ4HC optimizations make it an increasingly attractive option for read-heavy workloads where LZ4’s faster decompression can provide overall performance benefits.\n\nProduction Ready\n\nWith these efficiency improvements, parallel compression is now considered production-ready. The feature has been thoroughly tested in both unit tests and stress testing, including validation on high-load scenarios with hundreds of concurrent compression jobs and thousands of threads.\n\nSome notes on current limitations:\n\n  Parallel compression is currently incompatible with UserDefinedIndex and with the deprecated decouple_partitioned_filters=false setting\n  Maximum performance is available with -DROCKSDB_USE_STD_SEMAPHORES at compile time, though this is not currently recommended due to reported bugs in some implementations of C++20 semaphores\n\n\nConfiguration Recommendations\n\nThe dramatically reduced CPU overhead means parallel compression is now viable for a broader range of workloads, particularly those using higher compression levels or compression-heavy scenarios like time-series data. However, simply enabling parallel compression could result in more spiky CPU loads for hosts serving live DB data. Parallel compression might be most useful for bulk SST file generation and/or remote compaction workloads because they are less sensitive to CPU responsiveness. In these scenarios there is little danger in setting parallel_threads=8 even with the possibility of over-subscribing CPU cores, though the potentially safer “sweet spot” is typically around parallel_threads=3, depending on compression level, etc.\n\nLimitations and Future\n\nAlthough this offers a great improvement in the implementation of an existing option, we recognize that this setup is suboptimal in a number of ways:\n\n  There is no work sharing / thread pooling for these SST compression/writer threads among compactions in the same process, so not well able to fit the workload to available CPU cores and not able to use other SST file compression work to avoid a worker thread going to sleep.\n  We are not (yet) using a framework that would allow micro-work sharing with things other than SST generation on a set of threads. That would be a good direction for effective sharing of CPU resources without spikes in usage, but might incur intolerable CPU overhead in managing work. With this “hand optimized” and specialized framework, we can at least evaluate such future endeavors against a perhaps ideal framework in terms of parallelizing with minimal overhead.\n\n\nTry It Out\n\nParallel compression revamp will be available in RocksDB 10.7. As always, we recommend testing in your specific environment to determine the optimal configuration for your workload.",
          "link": "http://rocksdb.org/blog/2025/10/08/parallel-compression-revamp.html",
          "source": "RocksDB",
          "thumbnail": "/static/images/parallel-compression/ring-buffer-architecture.svg",
          "feedId": "aHR0cHM6Ly9yb2Nrc2RiLm9yZy9mZWVkLnhtbA",
          "seen": false,
          "saved": false,
          "publishedAt": "Wed, 08 Oct 2025 00:00:00 +0000",
          "updatedAt": null
        },
        {
          "id": "aHR0cDovL3JvY2tzZGIub3JnL2Jsb2cvMjAyNS8wOS8yNS9pby10YWdnaW5nLmh0bWw",
          "title": "IO Activity Tagging",
          "description": "Context\n\nRocksDB performs a variety of IO operations—user reads, background compactions, flushes, database opens, and verification tasks. Treating all these operations the same makes it difficult for file system implementers to optimize performance, prioritize latency-sensitive IOs, and diagnose bottlenecks. To solve that, RocksDB internally tags every IO operation with its activity type using the IOActivity enum. This automatic tagging provides precise context for each IO, enabling file systems to make smarter, context-aware decisions for scheduling, caching, and resource management.\n\nHow Internal IO Tagging Works\nRocksDB automatically assigns an IOActivity tag to each IO operation. This tag is propagated through the storage stack and included in the IO options passed to the file system.\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\nenum class IOActivity : uint8_t {\n    kFlush = 0,                        // IO for flush operations (background write)\n    kCompaction = 1,                   // IO for compaction (background read/write)\n    kDBOpen = 2,                       // IO during database open (read/write)\n    kGet = 3,                          // User Get() read\n    kMultiGet = 4,                     // User MultiGet() read\n    kDBIterator = 5,                   // User iterator read\n    kVerifyDBChecksum = 6,             // Verification: DB checksum\n    kVerifyFileChecksums = 7,          // Verification: file checksums\n    kGetEntity = 8,                    // Entity Get (e.g., wide-column)\n    kMultiGetEntity = 9,               // Entity MultiGet\n    kGetFileChecksumsFromCurrentManifest = 10, // Manifest checksum reads\n    // 0x80–0xFE: Reserved for custom/internal use\n    kUnknown = 0xFF                    // Unknown/unspecified activity\n};\n\n\nAccess IO Tag in File System\nCustom file systems can access the IOActivity tag via the IO options structure provided by RocksDB. This allows them to optimize behavior based on the specific IO activity.\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\nStatus CustomFileSystem::Append(uint64_t offset, const Slice& data, const IOOptions& io_opts, ...) {\n    switch (io_opts.io_activity) {\n        case Env::IOActivity::kGet:\n            // Prioritize or cache user reads\n            break;\n        case Env::IOActivity::kCompaction:\n            // Throttle or deprioritize background compaction IO\n            break;\n        case Env::IOActivity::kDBOpen:\n            // Track or optimize DB open IO\n            break;\n        // ... handle other activities ...\n        default:\n            // Default handling\n            break;\n    }\n}\n\nIO Activity Statistics in RocksDB\nRocksDB provides detailed histograms for IO activities, allowing you to analyze both the aggregate time spent (in microseconds) and the count of IOs for each activity type.\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n// Read Histograms\nFILE_READ_FLUSH_MICROS\nFILE_READ_COMPACTION_MICROS\nFILE_READ_DB_OPEN_MICROS\nFILE_READ_GET_MICROS\nFILE_READ_MULTIGET_MICROS\nFILE_READ_DB_ITERATOR_MICROS\nFILE_READ_VERIFY_DB_CHECKSUM_MICROS\nFILE_READ_VERIFY_FILE_CHECKSUMS_MICROS\n\n// Write Histograms\nFILE_WRITE_FLUSH_MICROS\nFILE_WRITE_COMPACTION_MICROS\nFILE_WRITE_DB_OPEN_MICROS\n\n\nThanks to Maciej Szeszko and Andrew Chang from the RocksDB team for their contributions in expanding and maintaining the IOActivity enum.",
          "link": "http://rocksdb.org/blog/2025/09/25/io-tagging.html",
          "source": "RocksDB",
          "thumbnail": null,
          "feedId": "aHR0cHM6Ly9yb2Nrc2RiLm9yZy9mZWVkLnhtbA",
          "seen": false,
          "saved": false,
          "publishedAt": "Thu, 25 Sep 2025 00:00:00 +0000",
          "updatedAt": null
        }
      ],
      "expectedArticleCount": 10
    },
    {
      "title": "Engineering | Uber Blog",
      "url": "https://www.uber.com/en-US/blog/engineering/rss/",
      "file": "engineering-uber-blog__fb34f4cb48.xml",
      "ok": true,
      "bytes": 11906,
      "contentType": "application/rss+xml",
      "expectedFeed": {
        "id": "aHR0cHM6Ly93d3cudWJlci5jb20vZW4tVVMvYmxvZy9lbmdpbmVlcmluZy9yc3Mv",
        "title": "Engineering | Uber Blog",
        "xmlUrl": "https://www.uber.com/en-US/blog/engineering/rss/",
        "image": null,
        "description": null,
        "lastUpdated": "Fri Dec 19 2025 22:36:24 GMT+0000 (Coordinated Universal Time)",
        "lastPublishedAt": null
      },
      "expectedArticles": [
        {
          "id": "aHR0cHM6Ly93d3cudWJlci5jb20vYmxvZy9wb3dlcmluZy1iaWxsaW9uLXNjYWxlLXZlY3Rvci1zZWFyY2gtd2l0aC1vcGVuc2VhcmNoLw",
          "title": "Powering Billion-Scale Vector Search with OpenSearch",
          "description": "Uber powers billion-scale vector search with OpenSearch. Discover the innovative optimizations we designed to boost search efficiency, scalability, and reliability for massive datasets.\n",
          "link": "https://www.uber.com/blog/powering-billion-scale-vector-search-with-opensearch/",
          "source": "Engineering | Uber Blog",
          "thumbnail": null,
          "feedId": "aHR0cHM6Ly93d3cudWJlci5jb20vZW4tVVMvYmxvZy9lbmdpbmVlcmluZy9yc3Mv",
          "seen": false,
          "saved": false,
          "publishedAt": "2025-12-18 14:00:00",
          "updatedAt": null
        },
        {
          "id": "aHR0cHM6Ly93d3cudWJlci5jb20vYmxvZy9ob3ctdWJlci1pbmRleGVzLXN0cmVhbWluZy1kYXRhLXdpdGgtcHVsbC1iYXNlZC1pbmdlc3Rpb24taW4tb3BlbnNlYXJjaC8",
          "title": "How Uber Indexes Streaming Data with Pull-Based Ingestion in OpenSearch™",
          "description": "Discover how Uber uses OpenSearch™’s streaming ingestion architecture for powerful search, and learn about our contributions to a pull-based ingestion framework in the OpenSearch project.\n",
          "link": "https://www.uber.com/blog/how-uber-indexes-streaming-data-with-pull-based-ingestion-in-opensearch/",
          "source": "Engineering | Uber Blog",
          "thumbnail": null,
          "feedId": "aHR0cHM6Ly93d3cudWJlci5jb20vZW4tVVMvYmxvZy9lbmdpbmVlcmluZy9yc3Mv",
          "seen": false,
          "saved": false,
          "publishedAt": "2025-12-16 14:00:00",
          "updatedAt": null
        }
      ],
      "expectedArticleCount": 17
    },
    {
      "title": "strava-engineering - Medium",
      "url": "https://medium.com/feed/strava-engineering",
      "file": "strava-engineering-medium__07076b2026.xml",
      "ok": true,
      "bytes": 143219,
      "contentType": "text/xml; charset=UTF-8",
      "expectedFeed": {
        "id": "aHR0cHM6Ly9tZWRpdW0uY29tL2ZlZWQvc3RyYXZhLWVuZ2luZWVyaW5n",
        "title": "strava-engineering - Medium",
        "xmlUrl": "https://medium.com/feed/strava-engineering",
        "image": "https://cdn-images-1.medium.com/proxy/1*TGH72Nnw24QL3iV9IOm4VA.png",
        "description": null,
        "lastUpdated": "Fri, 19 Dec 2025 22:17:03 GMT",
        "lastPublishedAt": null
      },
      "expectedArticles": [
        {
          "id": "aHR0cHM6Ly9tZWRpdW0uY29tL3AvN2Y1ODBmNWI0ODQ4",
          "title": "Rain: A key-value store for Strava’s scale",
          "description": null,
          "link": "https://medium.com/strava-engineering/rain-a-key-value-store-for-stravas-scale-7f580f5b4848?source=rss----89d4108ce2a3---4",
          "source": "strava-engineering - Medium",
          "thumbnail": "https://cdn-images-1.medium.com/max/904/1*OZ80K_OVcAp8Opf195cqtw.png",
          "feedId": "aHR0cHM6Ly9tZWRpdW0uY29tL2ZlZWQvc3RyYXZhLWVuZ2luZWVyaW5n",
          "seen": false,
          "saved": false,
          "publishedAt": "Fri, 24 Jan 2025 18:02:11 GMT",
          "updatedAt": null
        },
        {
          "id": "aHR0cHM6Ly9tZWRpdW0uY29tL3AvOWFiMDllZjAxMzgx",
          "title": "Scaling Challenge Leaderboards for Millions of Athletes",
          "description": null,
          "link": "https://medium.com/strava-engineering/scaling-challenge-leaderboards-for-millions-of-athletes-9ab09ef01381?source=rss----89d4108ce2a3---4",
          "source": "strava-engineering - Medium",
          "thumbnail": "https://cdn-images-1.medium.com/max/1024/1*sTekNCekHeM10HHYK99Icg.jpeg",
          "feedId": "aHR0cHM6Ly9tZWRpdW0uY29tL2ZlZWQvc3RyYXZhLWVuZ2luZWVyaW5n",
          "seen": false,
          "saved": false,
          "publishedAt": "Thu, 18 Jan 2024 17:01:41 GMT",
          "updatedAt": null
        }
      ],
      "expectedArticleCount": 10
    },
    {
      "title": "Stories by Pinterest Engineering on Medium",
      "url": "https://medium.com/feed/@Pinterest_Engineering",
      "file": "stories-by-pinterest-engineering-on-medium__83a7c8b616.xml",
      "ok": true,
      "bytes": 204901,
      "contentType": "text/xml; charset=UTF-8",
      "expectedFeed": {
        "id": "aHR0cHM6Ly9tZWRpdW0uY29tL2ZlZWQvQFBpbnRlcmVzdF9FbmdpbmVlcmluZw",
        "title": "Stories by Pinterest Engineering on Medium",
        "xmlUrl": "https://medium.com/feed/@Pinterest_Engineering",
        "image": "https://cdn-images-1.medium.com/fit/c/150/150/1*iAV-apeVpCJ1h6Znt1AzCg.jpeg",
        "description": null,
        "lastUpdated": "Fri, 19 Dec 2025 22:11:59 GMT",
        "lastPublishedAt": null
      },
      "expectedArticles": [
        {
          "id": "aHR0cHM6Ly9tZWRpdW0uY29tL3AvYjg0NjQ4OWUzNThk",
          "title": "LLM-Powered Relevance Assessment for Pinterest Search",
          "description": null,
          "link": "https://medium.com/pinterest-engineering/llm-powered-relevance-assessment-for-pinterest-search-b846489e358d?source=rss-ef81ef829bcb------2",
          "source": "Stories by Pinterest Engineering on Medium",
          "thumbnail": "https://cdn-images-1.medium.com/max/1024/1*ibgqQEssW3lmqg1Qsoq7uw.png",
          "feedId": "aHR0cHM6Ly9tZWRpdW0uY29tL2ZlZWQvQFBpbnRlcmVzdF9FbmdpbmVlcmluZw",
          "seen": false,
          "saved": false,
          "publishedAt": "Wed, 10 Dec 2025 20:02:11 GMT",
          "updatedAt": null
        },
        {
          "id": "aHR0cHM6Ly9tZWRpdW0uY29tL3AvZDVhMTA4ZTAyYWMy",
          "title": "How Pinterest Built a Real‑Time Radar for Violative Content using AI",
          "description": null,
          "link": "https://medium.com/pinterest-engineering/how-pinterest-built-a-real-time-radar-for-violative-content-using-ai-d5a108e02ac2?source=rss-ef81ef829bcb------2",
          "source": "Stories by Pinterest Engineering on Medium",
          "thumbnail": "https://cdn-images-1.medium.com/max/738/1*NhUi6IO44OyZJSSlX8gSaQ.png",
          "feedId": "aHR0cHM6Ly9tZWRpdW0uY29tL2ZlZWQvQFBpbnRlcmVzdF9FbmdpbmVlcmluZw",
          "seen": false,
          "saved": false,
          "publishedAt": "Mon, 08 Dec 2025 17:02:56 GMT",
          "updatedAt": null
        }
      ],
      "expectedArticleCount": 10
    },
    {
      "title": "Netflix TechBlog - Medium",
      "url": "https://netflixtechblog.com/feed",
      "file": "netflix-techblog-medium__cb4c52cb07.xml",
      "ok": true,
      "bytes": 220935,
      "contentType": "text/xml; charset=UTF-8",
      "expectedFeed": {
        "id": "aHR0cHM6Ly9uZXRmbGl4dGVjaGJsb2cuY29tL2ZlZWQ",
        "title": "Netflix TechBlog - Medium",
        "xmlUrl": "https://netflixtechblog.com/feed",
        "image": "https://cdn-images-1.medium.com/proxy/1*TGH72Nnw24QL3iV9IOm4VA.png",
        "description": null,
        "lastUpdated": "Fri, 19 Dec 2025 22:21:13 GMT",
        "lastPublishedAt": null
      },
      "expectedArticles": [
        {
          "id": "aHR0cHM6Ly9tZWRpdW0uY29tL3AvNzNjNjljY2I1OTUz",
          "title": "How Temporal Powers Reliable Cloud Operations at Netflix",
          "description": null,
          "link": "https://netflixtechblog.com/how-temporal-powers-reliable-cloud-operations-at-netflix-73c69ccb5953?source=rss----2615bd06b42e---4",
          "source": "Netflix TechBlog - Medium",
          "thumbnail": "https://cdn-images-1.medium.com/max/1024/1*7sGhc8LhyqQlW9Uiq76TWQ.png",
          "feedId": "aHR0cHM6Ly9uZXRmbGl4dGVjaGJsb2cuY29tL2ZlZWQ",
          "seen": false,
          "saved": false,
          "publishedAt": "Mon, 15 Dec 2025 23:51:59 GMT",
          "updatedAt": null
        },
        {
          "id": "aHR0cHM6Ly9tZWRpdW0uY29tL3AvNDFmMWIwYWQ1Mzcx",
          "title": "Netflix Live Origin",
          "description": null,
          "link": "https://netflixtechblog.com/netflix-live-origin-41f1b0ad5371?source=rss----2615bd06b42e---4",
          "source": "Netflix TechBlog - Medium",
          "thumbnail": "https://cdn-images-1.medium.com/max/1024/1*44sJszKXEHZvSHnEQgYiiw.png",
          "feedId": "aHR0cHM6Ly9uZXRmbGl4dGVjaGJsb2cuY29tL2ZlZWQ",
          "seen": false,
          "saved": false,
          "publishedAt": "Mon, 15 Dec 2025 17:38:16 GMT",
          "updatedAt": null
        }
      ],
      "expectedArticleCount": 10
    },
    {
      "title": "Lyft Engineering — Medium",
      "url": "https://eng.lyft.com/feed",
      "file": "lyft-engineering-medium__0eff42b2ff.xml",
      "ok": true,
      "bytes": 184830,
      "contentType": "text/xml; charset=UTF-8",
      "expectedFeed": {
        "id": "aHR0cHM6Ly9lbmcubHlmdC5jb20vZmVlZA",
        "title": "Lyft Engineering - Medium",
        "xmlUrl": "https://eng.lyft.com/feed",
        "image": "https://cdn-images-1.medium.com/proxy/1*TGH72Nnw24QL3iV9IOm4VA.png",
        "description": null,
        "lastUpdated": "Fri, 19 Dec 2025 22:16:37 GMT",
        "lastPublishedAt": null
      },
      "expectedArticles": [
        {
          "id": "aHR0cHM6Ly9tZWRpdW0uY29tL3AvMWZkOWI0M2NjMDFl",
          "title": "From Python3.8 to Python3.10: Our Journey Through a Memory Leak",
          "description": null,
          "link": "https://eng.lyft.com/from-python3-8-to-python3-10-our-journey-through-a-memory-leak-1fd9b43cc01e?source=rss----25cd379abb8---4",
          "source": "Lyft Engineering - Medium",
          "thumbnail": "https://cdn-images-1.medium.com/max/1024/1*QWBsfrlv7BNM8sZwFAsTfQ.png",
          "feedId": "aHR0cHM6Ly9lbmcubHlmdC5jb20vZmVlZA",
          "seen": false,
          "saved": false,
          "publishedAt": "Mon, 15 Dec 2025 19:31:01 GMT",
          "updatedAt": null
        },
        {
          "id": "aHR0cHM6Ly9tZWRpdW0uY29tL3AvNTQ3ZGU2Yzk1MGUx",
          "title": "LyftLearn Evolution: Rethinking ML Platform Architecture",
          "description": null,
          "link": "https://eng.lyft.com/lyftlearn-evolution-rethinking-ml-platform-architecture-547de6c950e1?source=rss----25cd379abb8---4",
          "source": "Lyft Engineering - Medium",
          "thumbnail": "https://cdn-images-1.medium.com/max/1024/1*-r1saxCbUiFJf47gTbTyXg.png",
          "feedId": "aHR0cHM6Ly9lbmcubHlmdC5jb20vZmVlZA",
          "seen": false,
          "saved": false,
          "publishedAt": "Tue, 18 Nov 2025 18:16:05 GMT",
          "updatedAt": null
        }
      ],
      "expectedArticleCount": 10
    },
    {
      "title": "Blogs on Grafana Labs Blog",
      "url": "https://grafana.com/blog/index.xml",
      "file": "blogs-on-grafana-labs-blog__3d428078f5.xml",
      "ok": true,
      "bytes": 159273,
      "contentType": "text/xml",
      "expectedFeed": {
        "id": "aHR0cHM6Ly9ncmFmYW5hLmNvbS9ibG9nL2luZGV4LnhtbA",
        "title": "Grafana Labs blog on Grafana Labs",
        "xmlUrl": "https://grafana.com/blog/index.xml",
        "image": null,
        "description": null,
        "lastUpdated": null,
        "lastPublishedAt": null
      },
      "expectedArticles": [
        {
          "id": "aHR0cHM6Ly9ncmFmYW5hLmNvbS9ibG9nLzIwMjUvMTIvMTIvaG93LXRvLXVzZS1haS10by1hbmFseXplLWFuZC12aXN1YWxpemUtY2FuLWRhdGEtd2l0aC1ncmFmYW5hLWFzc2lzdGFudC8",
          "title": "How to use AI to analyze and visualize CAN data with Grafana Assistant",
          "description": "Note: A version of this post originally appeared on the CSS Electronics blog. \nMartin Falch, co-owner and head of sales and marketing at CSS Electronics, is an expert on CAN bus data. Martin works closely with end users, typically OEM engineers, across diverse industries, including automotive, maritime, and industrial. He is passionate about data visualization and AI—and he’s been working extensively with Grafana Assistant. \nAt CSS Electronics, we build pro specs and simple-to-use CAN bus data loggers including optional WiFi/LTE/GPS. In short, CAN bus is a protocol used for communicating sensor data within vehicles and machinery, including trucks, cars, ships, and robots.\nOur end users include engineers at automotive and industrial manufacturers (OEMs) who need to monitor assets in the field for R&D, diagnostics, or predictive maintenance. A large share of our users also visualize their data via Grafana dashboards using Amazon Athena or Google BigQuery data sources (see our previous blog post for details).\nIn this blog, we show how Grafana Assistant can be used to easily unleash the power of AI for data analysis and dashboard visualization—directly within Grafana!\nWhy use Grafana Assistant for CAN data analyses?\nOur users face a challenge: They can collect tons of CAN/LIN data using the CANedge, but they have to then explore or visualize data across several devices, thousands of log files, and months (or even years) of data.\nMost of our users are engineers, but they’re not data scientists. And even if they are, statistical data analysis/visualization can be extremely time consuming.\nWhy not use ChatGPT?\nOne solution to this challenge is to use ChatGPT to help analyze the data, which we wrote about in a 2023 article. However, ChatGPT has some practical limitations:\n\n\nLimited to manually uploading small files (e.g. 100 MB CSV)\n\n\nAnalysis results are not easy to share\n\n\nOutputs are “static” (e.g., Python-generated plots)\n\n\nKey features of Grafana Assistant \n\n\nIn practice, our end users typically upload gigabytes (or terabytes) of data to their own AWS, Google Cloud, or Microsoft Azure cloud servers using our devices. Here, the data is auto-processed into Parquet data lakes, which can be queried via Grafana’s Athena/BigQuery data sources. In other words, the complete data lake is easily accessible within Grafana. \nWith the new assistant, Grafana Cloud now enables seamless LLM access to existing data sources that are already in place. This introduces multiple powerful features:\n\nZero set up: If you have already deployed a Grafana integration, you can start prompting your data immediately—no set up required.\nAnalyze terabytes of data: Unlike ChatGPT, you don’t have to limit your analysis to 100 MB of data. The assistant can query your entire data lake out-the-box.\nData exploration: Simply chat your way to powerful data insights and through complex diagnostic analyses—no query language or coding knowledge required.\nDashboard creation: The assistant can create fully customized Grafana dashboards in seconds based on high level prompts, drastically reducing time spent.\nRetain and share insights: Any data insights can be easily summarized into Grafana dashboards, enabling you to navigate the data temporally and share it with your team.\n\nIt’s basically Cursor/Windsurf for your dashboards and data lake.\nHow to start analyzing CAN data with Grafana Assistant \n\n\nIf you have already connected your data source in Grafana Cloud, no further set up is necessary.\nTo start chatting with the assistant, you can open the chat window via the left-menu Assistant tab. Alternatively, you can open the chat panel within a dashboard via the sparkle icon in the upper right corner.\nHowever, to get the best experience, we recommend following these steps:\n\nUse a dashboard template: At CSS we provide various dashboard templates customized for our end users, which include relevant Grafana variable dropdowns. Using templates as the basis for LLM-based dashboard development is highly recommended as it allows dashboard users to subsequently interact with the generated dashboards (e.g. switching between different devices)\nSelect data source as context: Make sure to select the relevant data source in the Grafana Assistant chat window to explicitly tell it what data to work with.\nUse a system prompt: In our documentation we provide a “system prompt” that our users can add as a “rule” within the Grafana Assistant settings. This provides context about the data lake structure, query syntax and more—and significantly improves the results. \n\nExample use cases\nTo showcase how Grafana Assistant can help with data analyses, we’ll use our public data pack, which consists of 1GB of data from a Kia EV6 electric vehicle. Below we highlight example use cases for the LLM:\nExample 1: See what data is available\nFirst, we use the LLM to get an overview of our data lake.\nThis is a useful starting point for exploring a CAN bus data lake as you do not necessarily have a clear overview of what devices, CAN messages, and CAN signals are available. Further, constructing the SQL queries to extract this information is quite complex.\n\n\n\n\nCopy\n\n\n\nPrompt:\nMy data source contains data from a Kia EV6 electric car, recorded with a CANedge CAN bus data logger with device ID 2A896980. The data includes battery data from the EV and GPS/IMU data from a sensor module. I want to know the following:\n1: What tables and columns are available for this device?\n2: What time period does the data span?\n\n\nGrafana Assistant starts analyzing the data via multiple queries, summarizing the results in a tabular form, and in the chat. Notice how the LLM iterates through multiple queries to understand the data structure. You can of course inspect what queries are used to generate each result, ensuring full transparency. The summary provides us with a good starting point for further investigation.\n {\nresponded = true;\nresponse && response.status === 200 ? vimeo_is_up = true : vimeo_is_up = false;\n})\n.catch(error => {\nresponded = true;\n})\"\n>\n\n\n\n\n\n\n\nThere’s supposed to be a video here, but for some reason there isn’t. Either we entered the id wrong (oops!), or Vimeo is down. If it’s the latter, we’d expect they’ll be back up and running soon. In the meantime, check out our blog!\n\n\n\nExample 2: Explore data ad hoc\nIn many cases you’ll want to explore the data directly in the chat window prior to creating actual panels.\nHere, Grafana Assistant runs the relevant queries and produces the output in-chat as text or as plots. We can also prompt the LLM to create a panel that displays speed over time within our dashboard, which Grafana does successfully as shown below.\n\n\n\n\nCopy\n\n\n\nPrompt:\nWhat is the average speed from the CAN2_GnssSpeed message in July 2023? It's in m/s. Please create a panel in this dashboard to visualize the average speed over time\n\n\n {\nresponded = true;\nresponse && response.status === 200 ? vimeo_is_up = true : vimeo_is_up = false;\n})\n.catch(error => {\nresponded = true;\n})\"\n>\n\n\n\n\n\n\n\nThere’s supposed to be a video here, but for some reason there isn’t. Either we entered the id wrong (oops!), or Vimeo is down. If it’s the latter, we’d expect they’ll be back up and running soon. In the meantime, check out our blog!\n\n\n\nExample 3: Create dashboard via a high-level prompt\nAn obvious use case for Grafana Assistant is to create a new dashboard from scratch. In this example we try a minimal-effort prompt—leaving a lot up to the imagination of the LLM.\nThe result is a functional 12-panel dashboard where all SQL queries are as expected (i.e., as per our system prompt guidance). Notice in particular that the LLM proactively identifies available (and relevant) messages/signals. Pretty cool! It’s worth reflecting on how commoditized LLMs + tools have already become. If this was 2022 we’d have been blown away.\nHowever, the dashboard we get is highly inconsistent between re-runs of the same prompt. This is of course to be expected given the open-ended nature of our request. In our view, there’s not much practical value to providing prompts that are this high level if the goal is to create real Grafana dashboards.\n\n\n\n\nCopy\n\n\n\nPrompt:\nMy data source contains data from a Kia EV6 electric car, recorded with a CANedge CAN bus data logger with device ID 2A896980. The data includes battery data from the EV and GPS/IMU data from a sensor module.\nUpdate my dashboard to include panels showing my Kia EV6 battery data and GPS/IMU data.\n\n\n {\nresponded = true;\nresponse && response.status === 200 ? vimeo_is_up = true : vimeo_is_up = false;\n})\n.catch(error => {\nresponded = true;\n})\"\n>\n\n\n\n\n\n\n\nThere’s supposed to be a video here, but for some reason there isn’t. Either we entered the id wrong (oops!), or Vimeo is down. If it’s the latter, we’d expect they’ll be back up and running soon. In the meantime, check out our blog!\n\n\n\nExample 4: Create a dashboard via a detailed prompt\nInstead of using a fairly vague prompt, a much better approach is of course to provide highly detailed guidance, similar to what you would provide a human assistant if they were to design your dashboard. You can find the full detailed prompt here.\nAs you can see, the result looks as intended. And more importantly, when we run this 10x (in new conversations each time), we get a 90%+ consistent dashboard each time.\nYou might argue that writing a prompt like this is also time consuming, but in our experience it is still five to 10 times faster than if we were to construct this dashboard from scratch. For example, notice that many of our message/signal names are approximate, leaving Grafana Assistant to figure out what the exact table and column names are. Further, some of the panels involve semi-complex queries (e.g., the consumed State of Charge and the delta distance traveled), which would require significant SQL expertise to create.\nMost importantly, the prompt specifies no SQL syntax, which is important as 99%+ of our end users have zero SQL experience.\nCheck out the generated dashboard in our public playground.\n {\nresponded = true;\nresponse && response.status === 200 ? vimeo_is_up = true : vimeo_is_up = false;\n})\n.catch(error => {\nresponded = true;\n})\"\n>\n\n\n\n\n\n\n\nThere’s supposed to be a video here, but for some reason there isn’t. Either we entered the id wrong (oops!), or Vimeo is down. If it’s the latter, we’d expect they’ll be back up and running soon. In the meantime, check out our blog!\n\n\n\nOur summary thoughts\nWe spent 20+ hours with Grafana Assistant. Here are our overarching thoughts.\n1: Excellent concept. For users that have already hooked up Grafana to their data, it is extremely simple to start working with the data through the LLM. This ease-of-access is a critical advantage—and the Grafana Assistant UI is great.\n2: A drunk genius. Grafana Assistant can give you that “magical experience” where you sit back and watch it produce an entire Grafana dashboard in one shot according to your specifications. However, in some cases it will produce invalid queries, get stuck or hallucinate—just like all LLMs. Make sure to always review the output.\n3: Visualization vs. analysis. The LLM is able to modify dashboards and execute SQL queries, making it an excellent tool for data visualization and light exploration. However, it is not able to run scripts (in contrast to ChatGPT, for example), making it less suitable for highly complex, multi-step data analysis—at least for now. Such functionality could be a powerful future mode/variation of the assistant.\n4: Huge potential. While the current version has limitations in terms of performance and data source support, we are confident that Grafana Assistant will become an extremely handy tool for data visualization and exploration. In just our one month of testing, Grafana added a ton of improvements to the LLM, so we are excited to see how this tool develops!\nTo learn more and see additional showcases, check out our full Grafana Assistant article!\nGrafana Cloud is the easiest way to get started with metrics, logs, traces, dashboards, and more. We have a generous forever-free tier and plans for every use case. Sign up for free now!",
          "link": "https://grafana.com/blog/2025/12/12/how-to-use-ai-to-analyze-and-visualize-can-data-with-grafana-assistant/",
          "source": "Grafana Labs blog on Grafana Labs",
          "thumbnail": "https://a-us.storyblok.com/f/1022730/800x600/75de30d1ec/can-data-architecture.png/m/",
          "feedId": "aHR0cHM6Ly9ncmFmYW5hLmNvbS9ibG9nL2luZGV4LnhtbA",
          "seen": false,
          "saved": false,
          "publishedAt": "Fri, 12 Dec 2025 00:00:00 +0000",
          "updatedAt": null
        },
        {
          "id": "aHR0cHM6Ly9ncmFmYW5hLmNvbS9ibG9nLzIwMjUvMTIvMTEvZ3JhZmFuYXMtYmlnLXRlbnQtcG9kY2FzdC13ZWxjb21lLXRvLXNlYXNvbi0zLw",
          "title": "‘Grafana’s Big Tent’ podcast: Welcome to season 3!",
          "description": "Sometimes the simplest questions spark the most entertaining rabbit holes. Questions like: “Can you monitor a candle without starting a fire?” or “Should your robot boat have redundancy, or just a twin?” \nToday, we’re excited to kick off season 3 of “Grafana’s Big Tent” — the award-winning podcast about the people, community, tools, and tech shaping observability — to answer these pressing questions (and more). \nWe launched “Grafana’s Big Tent” in 2022 to spark fun, open conversations across the observability community. The show embodies and celebrates our “big tent” philosophy — the belief that you should be able to access your data anywhere, and use the observability tools and strategies that work best for you. Most importantly, the podcast has resonated with the open source community, with more than 30,000 downloads across 120+ countries. \nIn the first episode of season 3, you’ll hear a live recording from GrafanaCON 2025 in Seattle, featuring hosts Mat Ryer, Principal Software Engineer at Grafana Labs, and Tom Wilkie, Grafana Labs CTO. The topic? Homelabs gone wild, adventures in tinkering, and IoT wins and fails. \nOur hosts are joined by Ivana Huckova, Staff Software Engineer at Grafana Labs; Andrew McCalip, Head of Research and Development at Varda Space Industries (and builder of an autonomous drone-ship); and Brad Fitzpatrick, Chief Engineer at Tailscale, creator of LiveJournal, and former member of the Go team. \nThe group discuss everything from a self-righting boat to dog happiness monitoring (version 2 pending) and a “magic wand” wishlist for Grafana. Oh, and we learn why switching between pounds and kilos mid-sentence is a dangerous maritime practice.\nYou can watch the full episode in the YouTube video below, or listen on Spotify or Apple Podcasts.\n\nNote: The following are highlights from episode 1, season 3 of “Grafana’s Big Tent” podcast. The transcript below has been edited for length and clarity.\nFirst tinkers: from ZX Spectrums to 5,000-lb garage surprises\nMat Ryer: My dad was into computers really early, so we had a ZX Spectrum at home. That’s where I learned BASIC first. I loved it — you could make things happen in this little universe. I’ve been hooked ever since. I kind of miss when tech used to be rubbish; now everything’s shiny and just works.\nBrad Fitzpatrick: We had a bootleg Apple II my dad made from stolen parts and a stolen ROM. He taught me to program when I was like five or six, and I kind of haven’t stopped since.\nAndrew McCalip:  I sort of shocked my parents when I was 14 — I brought home this old CNC machine, a 5,000-pound monstrosity, and parked it in the garage. That was the start of my hardware career… and there’s basically always been a CNC around since.\nIvana Huckova: I joined Grafana as a frontend engineer, so naturally my onboarding project was a little IoT monitoring solution. My manager Dan mailed me an ESP32 board in an envelope, with all the sensors. That really sparked everything — since then I’ve built monitoring for my sourdough starter, my avocado plant, my standing desk, and I once tried to build a dog happiness monitoring solution. That one failed, so it’s on the list for version two.\nUseful 3D printing: beyond trinkets\nTom Wilkie: I saw on your profile you’ve got a 3D printer. What have you actually been using it for?\nBrad: My kids wanted one for Christmas, then lost interest after about a day… so now I have a 3D printer. At this point, half our house is plastic. I’ve printed baby-proofing corner guards, a Wi-Fi mount. We had this bathtub with a tiny one-inch gap at the back where everything fell and you couldn’t reach it, so I printed a shelf that clicks together and fills it. Now nothing falls down there.\nTom: You’re the first person I’ve asked who didn’t just say ‘I printed parts for more printers.’\nBrad: Oh no, I love CAD. Making useful stuff is the fun part.\nTom (to Andrew): But you’ve got a real 3D printer… or rather a CNC, right?\nAndrew: Yeah, a 17,000-pound Haas CNC. You can actually pay people to move something that big on 18-wheelers. I think of it as a metal compiler — metal goes in, parts come out. It’s super-satisfying.\nIoT wins (and one smoky fail)\nIvana: With my plant monitoring, I learned more than from any blog post — how much water they need, how much sun, what the light looks like over the day. I was terrible at taking care of plants, but after wiring all this up I actually became good at it. One of my biggest failed projects was candle monitoring. I wanted to watch the PM particles when you blow a candle out, and I also wanted to know if I’d left a candle burning after leaving the apartment. The idea was that if it was still on, I could remotely shut it down. So I built a system where a wooden lid would drop on the candle. During testing, the lid… caught fire. I did at least learn that you shouldn’t mess with fire when you’re outside your apartment.\nTom: My laser cutter is in the garage for exactly that reason — not in my office. Also, it smells terrible.\nIvana: And as for dog happiness v1 — my dog is very hairy. Double-coated, very long hair. I tried using a heart rate monitor on him, but if you just strap a sensor onto a lot of fur, it’s not very reliable. I also put a little camera on him, and every time his heart rate went up, it took a photo. The results were mostly hair, feet, and pavement. So I need a better heart rate sensor, or a different camera placement. I’m not abandoning the idea — version 2 is definitely on the list for a future Grafana hackathon.\nTom: I have five 3D printers in my office. I dread monitoring the air in there. I am made of microplastics now.\nThe ocean robot: ballast, barnacles, and “redundancy”\nTom: I want to ask about your ocean-going drone ship. How are you going to handle terrible weather? What happens when it inevitably capsizes?\nAndrew: Good question. If you’re not careful, things in the ocean don’t stay upright. So we gave the boat a really deep keel with a big lead ballast. If it flips over, the idea is it self-rights. We actually wrote a whole Python script to model the hydrodynamics and buoyancy, then tested it in water a few times — it works great.\nBrad: Did you model the keel breaking?\nAndrew: We have two models: the strong keel and the fast keel. Priority one, since we’re mechanical people more than software people, was ‘Make sure it doesn’t flip over.’ Priority two was ‘turn it off and back on again.’\nTom: Do you have a secondary backup control system?\nAndrew: No. No backup. There was a big philosophical debate about redundancy. Is anything truly redundant? In the end we decided the easiest redundancy is: make a second boat. So we test, test, test, and when we’re happy, we ship it.\nTom: And when it fails in the ocean, how do you get to it to reboot it?\nAndrew: We don’t. We’ll tell Twitter, ‘It was last seen at this latitude/longitude. If anybody finds it, please tow it back to Los Angeles.’ It’ll just be out there floating around.\nTom: Does it have a name? And why is it not Boaty McBoatface?\nAndrew: Boaty McBoatface was a strong contender, but it’s kind of taken. It’s called Bob, after the Bobiverse books — sci-fi about a sentient spacecraft that makes copies of itself and explores the universe. It’s poetic, and also a pun.\nParting words\nIt wouldn’t be Big Tent without a nod to history.\nBrad: LiveJournal was like Twitter in 1998. The first client was a Windows app with a single input bar across the bottom of your screen. You typed, hit Enter, and it posted. No paragraphs — hitting Enter just posted it. Somehow it ended up with millions of users. In the opening scene of that Facebook movie, the actor playing Zuckerberg is actually on LiveJournal. That’s my little movie cameo, via software.\nTom: I don’t think anything I’ve written has ever been in a movie.\nMat: What a flex.\n“Grafana’s Big Tent” podcast wants to hear from you. If you have a great story to share, want to join the conversation, or have any feedback, please contact the Big Tent team at bigtent@grafana.com.",
          "link": "https://grafana.com/blog/2025/12/11/grafanas-big-tent-podcast-welcome-to-season-3/",
          "source": "Grafana Labs blog on Grafana Labs",
          "thumbnail": null,
          "feedId": "aHR0cHM6Ly9ncmFmYW5hLmNvbS9ibG9nL2luZGV4LnhtbA",
          "seen": false,
          "saved": false,
          "publishedAt": "Thu, 11 Dec 2025 00:00:00 +0000",
          "updatedAt": null
        }
      ],
      "expectedArticleCount": 10
    },
    {
      "title": "Code as Craft - Code as Craft",
      "url": "https://codeascraft.com/feed/",
      "file": "code-as-craft-code-as-craft__d642675b32.xml",
      "ok": true,
      "bytes": 517847,
      "contentType": "text/xml;charset=UTF-8",
      "expectedFeed": {
        "id": "aHR0cHM6Ly9jb2RlYXNjcmFmdC5jb20vZmVlZC8",
        "title": "Etsy Engineering | Code as Craft",
        "xmlUrl": "https://codeascraft.com/feed/",
        "image": "https://etsy.com/images/blogs/code_as_craft/cac_logo_lavender.png",
        "description": null,
        "lastUpdated": "Fri, 19 Dec 2025 17:21:10 -0500",
        "lastPublishedAt": null
      },
      "expectedArticles": [
        {
          "id": "aHR0cHM6Ly93d3cuZXRzeS5jb20vY29kZWFzY3JhZnQvcmVkdWNpbmctZXhwZXJpbWVudC1kdXJhdGlvbi13aXRoLXByZWRpY3RlZC1jb250cm9sLXZhcmlhdGVzP3V0bV9zb3VyY2U9T3BlbkdyYXBoJnV0bV9tZWRpdW09UGFnZVRvb2xzJnV0bV9jYW1wYWlnbj1TaGFyZQ",
          "title": "Reducing experiment duration with predicted control variates",
          "description": "In 2021, we published a blog post titled “Increasing experimentation accuracy and speed by using control variates,” describing how we reduce the variance of metrics using CUPED in our experimentation platform. This is a follow-up on how CUPED has evolved at Etsy since then. Spoiler – It’s changed a lot, decreasing our average experiment duration by 3 days!\nEtsy’s mission is to Keep Commerce Human. To achieve this, we need to understand the impact each change to our platform has on our buyers' and sellers' experience. Whether that involves changing the color of the “Buy Now” button on the Etsy app or updating elements of how our algorithms rank search results, we leverage large-scale online experimentation to iterate on and improve the things we build.\nHowever, running an experiment can be a long process. From design and setup to running the experiment and analyzing results, the entire experimentation process can take weeks to months. Experiments must run long enough to collect sufficient data for the results to be statistically significant – ensuring we can confidently attribute observed changes to the treatment, rather than random chance. On the other hand, being able to learn from an experiment quickly is a crucial step in the product development lifecycle, enabling faster improvements to Etsy. Fortunately, there are tools to reduce experiment runtime. CUPED is one of them! Variance reduction techniques like CUPED can help reduce the time to run an experiment, shortening the overall experimentation lifecycle and time to learning, as visualized below.\n\n\n\nA recap of CUPED\nCUPED is a variance reduction technique that estimates experiment outcomes with greater speed and accuracy compared to a direct comparison between control and treatment groups. In 2021, Etsy implemented CUPED (Controlled-Experiment Using Pre-Experiment Data) for key metrics like Conversion Rate (the percentage of visitors that make a purchase). \nCUPED leverages historical visitor data collected before the experiment begins — for example, the number of purchases in the week prior to the experiment – to explain some natural variation in the outcome metric. The pre-experiment factors are used as covariates in a linear regression model to remove some of the “noise” that is not attributable to the treatment. By accounting for this variation, CUPED reduces the variance of the treatment effect estimator, increasing statistical power and improving sensitivity without introducing bias.\nThe CUPED correction can be conceptualized as:\n\n\n\nThe CUPED-adjusted metric will have a smaller variance than the original metric, as visualized below, providing more precise estimates of a mean or treatment effect.\n\n\n\nSample size, power, and variance are all related. Holding everything else unchanged, the smaller the variance of a metric, the smaller the sample size required to reach a desired power. Since we can reduce the variance of our metric by applying CUPED, we can achieve the same amount of power with a smaller sample size. In practice, a smaller sample size corresponds to a shorter experiment duration. \nEtsy’s initial implementation of CUPED yielded an average variance reduction of 7% across all experiments, with some experiments achieving up to 30% variance reduction. Experiments that used CUPED-adjusted metrics in decision-making yielded a decision about 1 day earlier, on average. However, we’re always iterating to improve our buyers’ and sellers’ experience on Etsy, and we knew we could do even better. Enter: CUPAC.\nLeveling up further with CUPAC\nDuring our research and implementation of CUPED in 2020, scientists at DoorDash published a blog post describing a novel statistical method, building on CUPED, called Control Using Predictions as Covariate, or “CUPAC.” \nWhen performing CUPAC, the pre-experiment data is first input into a non-linear machine learning model that captures more complex relationships than a linear model. The non-linear model is trained to predict the outcome metric of interest – for example, if an experiment is measuring the observed Conversion Rate, the model would predict Conversion Rate. The prediction more effectively captures the impact of pre-experiment behaviors on our experimental outcomes than the raw pre-experiment data because it captures complex relationships in the data that linear regression alone cannot. The prediction is then used as an “ML-based covariate” in a linear regression to perform the CUPED correction: \n\n\n\nThe CUPAC-adjusted outcome has an even smaller variance than the CUPED-adjusted outcome, as visualized below.\n\n\n\nEmpirically, our CUPAC-adjusted metrics showed even lower variance than CUPED. Our initial prototype demonstrated that CUPAC produced an adjusted metric with an additional 10% smaller variance when compared to our original CUPED estimator. Despite the added complexity, these results justified incorporating CUPAC into our experimentation pipeline. We hypothesized it would cut average experiment duration by an additional day, enabling teams to run more experiments and ship changes to Etsy faster.\nTraining and implementation\nThe first step was to train the CUPAC models to predict the ML-based covariate. We identified over 100 pre-experiment features, increasing from 3 features in CUPED, to capture more behavior prior to the experiment. Using these features, we iteratively trained and tuned the models in Vertex AI. Hyperparameters were optimized on a validation dataset to maximize the median correlation between the model’s predictions and the observed in-experiment metrics across experiments.\nInitially we trained XGBoost, a popular gradient boosted tree model, but then found LightGBM, a similar non-linear, tree-based model, was better suited to predict the covariate. When testing the models at scale with billions of predictions, LightGBM demonstrated both rapid training and prediction times, along with strong validation results.\nOnce the models were trained, our next challenge was to implement them at scale. Our experimentation pipeline runs batch jobs for hundreds of experiments each day. From our original implementation, we had an Airflow DAG (directed acyclic graph) to orchestrate the CUPED variance reduction pipeline, as visualized below:\n\n\n\nWe evolved this pipeline to support CUPAC by adding a batch prediction step to produce the ML-based covariate.\n\n\n\nIn the above CUPAC pipeline, we perform the following steps: \n\nCalculate pre-experiment features and in-experiment data using BigQuery SQL jobs.\nPredict ML-based covariates with our trained LightGBM models via parallel Dataflow jobs using the pre-experiment features.\nPerform variance reduction with a Spark job that fits a linear regression model between the ML-based covariates and in-experiment data, creating the CUPAC-adjusted metrics.\nApply statistical t-tests using the CUPAC-adjusted metric to calculate the treatment effect, p-value, and power of the experiment.\n\nImpact: Shortening average experiment duration by 3 days\nWe measured success through variance reduction. Variance reduction is the percent change between the:\n\nVariance of the metric without CUPAC, and\nVariance of the CUPAC-adjusted metric. \n\nThe original CUPED implementation showed 7% variance reduction, reducing overall experiment duration by almost 1 day, on average. After implementing CUPAC, we observed an average of 27% variance reduction, nearly 4x as much variance reduction, when compared to CUPED, exceeding our early research estimates.\n\n\n\nThe additional variance reduction shortens our average experiment duration by almost 3 days. This means a 10-day experiment could conclude in only 7 days due to the ability to reach power on a smaller sample size with CUPAC. These marginal time savings allow many teams to run 10 or more additional experiments each year. That translates to more opportunities to test and faster insights into how we can deliver the best experience for our community of millions of sellers and buyers. \nNotably, there was a substantial spread in variance reduction among different metrics and experiments, ranging from 2% to 77%. In the chart below, each blue bar displays the percent variance reduction for a sampled metric on an experiment. \n\n\n\nThe large range is expected because variance reduction can be influenced by several factors, such as metric definition, data accessibility, experimental design, and market characteristics. These factors impact how predictive the pre-experiment data is of the outcome metric, resulting in the degree of variance reduction. For example, two common experimentation metrics are Mean Visits and Purchase Rate. In the e-commerce setting, an individual's visit behavior will almost always be more stable over time than their purchasing behavior. This implies that pre-experiment data is more correlated with in-experiment data for a visit-related metric than for a purchase-related metric. Therefore, CUPAC is more effective at reducing variance in a metric like Mean Visits than in a metric like Purchase Rate.\nWhat’s next?\nAligned with Etsy’s culture of experimentation, we’ll continue to evolve our pipeline to be nimble and flexible based on the needs of the teams that use them. \nOne challenge we face is that teams use metrics curated to specific parts of the Etsy experience – like search, recommendations, seller features, etc. – to make decisions on their experiment results. However, our CUPAC models take significant time to train and maintain for each metric, consequently limiting the number of CUPAC-adjusted metrics we can develop. While we continue to grow CUPAC use, we also encourage teams to continue to use CUPED, which is more scalable and has lower maintenance costs. To account for this, we plan to increase the flexibility of CUPED to more metrics by automatically collecting pre-experiment data based on the metric definition to reduce noise. In tandem with our work on CUPAC, this CUPED expansion will enable teams across Etsy to benefit from variance reduction across all their team-specific metrics, not just a select few.\nDespite the success of CUPED and CUPAC thus far, there remains a need to explore additional variance reduction techniques for the current metrics that leverage CUPAC. In 2024, we released research findings exploring a novel approach: Variance reduction combining pre-experiment and in-experiment data. As we look to generalize our variance reduction architecture, we expect that incorporating such techniques will continue to strengthen our experimentation platform and enable product teams to iterate more quickly.\nLastly, it is important to recognize that applying variance reduction in practice can be a never-ending race to squeeze the most noise out of these estimators. In our experience, the craft lies in finding the sweet spot between variance reduction, implementation cost, and the impact on experimentation velocity. That intersection is context-dependent and what makes experimentation code as craft.\nWe hope our experience inspires you to try out variance reduction techniques and determine which one is best suited to your needs!\nAcknowledgements\nThank you to Alexander Tank and Stephane Shao for their work on initial research and implementation of CUPAC. Thanks to Pablo Crespo for his research into extending our CUPAC models with more predictive features. And, thanks to Julie Beckley, Kevin Gaan, and Mary Hu for supporting and prioritizing this project. \nReferences\nA. Deng, Y. Xu, R. Kohavi, T. Walker (2013). Improving the sensitivity of online controlled experiments by utilizing pre-experiment data.\nJ. Li (2020). Improving Experimental Power through Control Using Predictions as Covariate (CUPAC).",
          "link": "https://www.etsy.com/codeascraft/reducing-experiment-duration-with-predicted-control-variates?utm_source=OpenGraph&utm_medium=PageTools&utm_campaign=Share",
          "source": "Etsy Engineering | Code as Craft",
          "thumbnail": "https://i.etsystatic.com/inv/508bdd/7485804299/inv_fullxfull.7485804299_5dhtrbg7.jpg?version=0",
          "feedId": "aHR0cHM6Ly9jb2RlYXNjcmFmdC5jb20vZmVlZC8",
          "seen": false,
          "saved": false,
          "publishedAt": "Tue, 25 Nov 2025 11:28:26 -0500",
          "updatedAt": null
        },
        {
          "id": "aHR0cHM6Ly93d3cuZXRzeS5jb20vY29kZWFzY3JhZnQvc2VhcmNoLXByZWZldGNoaW5nLXBlcmZvcm1hbmNlP3V0bV9zb3VyY2U9T3BlbkdyYXBoJnV0bV9tZWRpdW09UGFnZVRvb2xzJnV0bV9jYW1wYWlnbj1TaGFyZQ",
          "title": "Improving performance by prefetching product pages from Etsy Search",
          "description": "Rarely are there opportunities for big, bold, game-changing improvements in web performance. The Speculation Rules API (SRA) is a recent browser development that offers just such an opportunity. This post details a joint effort between the search and the web performance teams at Etsy to implement SRA on Etsy search pages and drastically improve the performance of product listing pages with some metrics seeing 20-24% improvements and some dropping all the way to 0ms values.\nPrefetching Options\nThere are two main ways to predictively fetch resources for the next page:\n\n allows us to instruct the browser to download a resource we believe we'll need soon. The resource can be anything, like a static asset or an HTML page.  \nSpeculation Rules API (SRA) is a recently updated browser API which allows for a JSON definition to dictate what page A wants to do with page B. The \"do\"-ing can be either prefetching (just download the HTML) or prerendering (load the page, including its static assets, and render it completely). The prerendering happens in a new browser process and page B is ready to be swapped with the current page A instantaneously when the user navigates to B.\n\nWhile implementing full prerendering is likely to yield more impressive performance improvements, it is a bigger and riskier investment, mostly related to the side effects of executing the JavaScript on the target page B. Starting with prefetching is a good first step into exploring SRA.\nThe benefits of using SRA over link prefetch will become evident further in the article but the topline highlights include: a simpler API to define what is prefetched (via a CSS selector rather than do-it-yourself bespoke JavaScript), convenient utilities to define when, as well as where (memory and HTTP cache) prefetching happens, and a built-in upgrade path to full on prerendering.\nImplementing Speculation Rules\nThe Search team at Etsy recently ran an A/B experiment to use the Speculation Rules API to prefetch the listing page when hovering over organic listing cards on the desktop search page on Chromium browsers. To do this, we added a new  tag to the search page with JSON that defines how we want the prefetching to work, like so:\n\n{\n  \"prefetch\": [{\n    \"where\": {\n        \"and\": [\n          {\n            \"href_matches\": \"/{*/}?listing/*\"\n          },\n          {\n            \"selector_matches\": \"[data-sr-prefetch='1']\"\n          }\n        ]\n    },\n    \"eagerness\": \"moderate\"\n  }]\n}\n\nThis instructs the browser to download the HTML for a listing page when:\n\nthe user hovers over a link to a listing page for 200 milliseconds (defined by the “moderate” eagerness property), and   \nthe link has a data-sr-prefetch attribute\n\nThe data attribute allows us to more precisely opt in pages that are eligible for prefetching. \nLessons learned\nIn terms of changes to the page’s code, the implementation of SRA was straightforward. As such, we spent most of our time testing that everything was working as expected and that our systems and analytics were not inadvertently affected. And we found some surprises along the way, related to all the little details modern web pages use (such as cookies, redirects, new tabs).\nAllow us to share a few lessons in prefetching...\nTwo ways to prefetch\nAs mentioned earlier, prefetching can happen one of two ways:  or speculative prefetch (the one using SRA). So what sets them apart?\nThey do work mostly the same, except that the speculative prefetch caches the page in both memory and the HTTP cache. The  only uses the HTTP cache and merely downloads the specified resource.\nThis makes the SRA way of prefetching more advantageous than the  prefetch because of the memory cache.\nTwo speculative prefetches only\nWe also discovered the number of prefetched pages that are kept in memory is restricted to two. When you prefetch a third page, the first one is evicted from the memory cache. The HTTP cache still works as usual. So again, the SRA prefetching is preferable to the  prefetch due to the difference in caching we just described.\nIt’s helpful while debugging to be aware of the eviction of the prefetched page from memory. But rest assured, the downloaded page is still cached locally.\nEagerness\nWhile  advises the browser to load a resource as soon as it sees the  in the DOM, the speculative prefetch is more nuanced, offering eager, immediate, conservative and moderate loading. We selected moderate eagerness, which prefetches after the user has hovered over a link for 200ms.\nExploring our options we found that the immediate eagerness would trigger a significantly larger number of prefetches (since it executes immediately and prefetches all eligible pages), and we wanted to avoid creating new server requests for listing cards with a low likelihood of being clicked. However, the immediate eagerness setting could be worth considering if the cost of additional requests is very low. The conservative eagerness executes on pointer or touch down, providing a very small head start over normal browser behavior and therefore greatly reducing the potential benefits of prefetching. Conservative eagerness may only be suitable for a use case in which it is necessary to avoid unused prefetches altogether.\nNote that eager and immediate were synonyms in the initial SRA implementation, but that is changing. Keep an eye on the official docs for updates.\nSpeculations and new browser tabs\nInitially, SRA launched without the ability to prerender pages that open in new tabs, as Etsy listings do. This option was added later, but only for values _blank of the target attribute of the link elements, not named target attributes such as the ones that Etsy uses, for example .\nFortunately, the target restriction doesn't apply to prefetching, so for SRA prefetching (unlike SRA prerendering) there's no problem, regardless of whether or how you specify a target at all. For developers who may be considering moving from prefetching to prerendering, this distinction is something to bear in mind. \n5-minute rule\nBecause of the complex nature of listing pages, Etsy's HTML pages are non-cacheable. However, the speculative prefetch keeps the prefetched pages cached in memory for five minutes. This was a helpful learning, as there would be no point of using speculative prefetches at all if they expire immediately. After five minutes, the normal caching rules apply, set via HTTP headers such as Max-age or Expires.\nGiven that only two pages are currently kept in memory cache and all others expire because they are non-cacheable, the benefits are greatly reduced when, for example, a person hovers over 3 links and eventually clicks the first one which leads to a page that's already expired from the prefetch memory (and HTTP!) cache.\nTo aid with the two-page restriction, one strategy we devised is to make our pages cacheable for five minutes when we detect a prefetch request. Such requests are identifiable because the browser sends Sec-Purpose: prefetch HTTP header when prefetching. This helps preserve downloaded pages that would’ve otherwise expired from both memory and HTTP cache.\nVideo links and shadow DOM\nOften, listings on Etsy include product videos, which start to play on the search results page when a user hovers their mouse over them. In these cases, prefetching doesn't work: the mouse hover is effectively \"swallowed,\" disappearing into the shadow DOM of the browser's video player. One workaround is to overlay a div on top of the video for 200ms to let the hover register in the DOM. Then, after the 200ms has elapsed, remove the extra div to let the browser video controls (e.g., on right click) work as usual. You can find a demonstration of this technique here.\nCookies\nIf a page sets cookies, prefetching it will set those cookies as well (as demonstrated here). This is something to be aware of, as the prefetch may end up being unused. This may confuse your application (and/or analytics) to thinking a page has been visited where in reality it was not.\nAgain, you can use Sec-Purpose: prefetch HTTP header to detect prefetch requests and avoid setting the cookie as part of the prefetching process.\nRedirects\nIf the link to the page being prefetched goes through a redirect, the actual page after the redirect is still being prefetched. Let’s say you have a sequence that looks like this:\nLink on Page A -> redirect -> Page B \nHere the browser follows the redirect during prefetching and still caches Page B. When the user then clicks the link on page A leading to Page B, the browser follows the usual process of going through the redirect. Normal HTTP cache rules still apply, meaning that if the redirect is cached, it won’t need to be requested again.\nSo, even though redirects are a bad performance practice, if you need to do them, they do not affect prefetching as long as you set appropriate caching headers.\nMutating hrefs\nSometimes the href attributes of  elements get modified by JavaScript on mouse hover. This does not play well with prefetching. Imagine you have:\nFollow me\n… which changes on hover to:\nFollow me\nWhen the user hovers over the link, the browser starts working on prefetching link.html but realizes that the link to that page is no longer in the DOM and abandons the process. So the page is not prefetched even if ?source=footer doesn’t change the target page in any way other than reporting analytics. The browser has no way of knowing this and considers the two as separate pages.\nAdditionally, the failed attempt at prefetching link.html counts in the “two speculations only” rule and evicts the older speculative load from the memory cache. For best results, avoid modifying links on hover.\nAnalytics and Event Logging\nThis is the elephant in the room. Many sites on the web today were built in a world where prefetching did not exist. So there is one big assumption: that a page load is always initiated by the user and the load can be counted as such – either server-side during page construction or client-side by JavaScript after the page is loaded (or, as it often happens, a combination of the two). With prefetching, this assumption is no longer true. A page constructed on the server-side and downloaded by the browser does not necessarily mean the page has been seen (and therefore its JavaScript has been executed). This can result in a number of miscalculations when it comes to analytics.\nLuckily, browser APIs such as the Sec-Purpose HTTP header and JavaScript APIs (document.prerendering and prerenderingchange event) allow us to tell prerender requests from user-generated ones, as well as when a prerendered page is \"activated\" (when the user actually sees a prefetched page). For prefetches, Performance Resource Timing’s deliveryType method of navigational-prefetch can be used for the purposes of analytics.\nWe (and our analytics partners) found this to be the hardest part: ironing out the required analytics updates so that numbers remain true after implementing speculation rules. In our particular use case, we intentionally pursued a strategy of prefetching the destination page instead of prerendering it, meaning that no assets would be loaded and JavaScript would not execute on our prefetches. This gave us a relatively simple way to handle the accuracy of our analytics.\nA foundational piece of our analytics is event logging. For example, in the controller of the listing page we log a view_listing event that contains key information such as the listing ID, user ID, etc. This informs not only our site analytics, but also our search training pipeline, recently viewed listing data for users, and more. We ended up creating a system to cache the payload of all events within a request to avoid firing those events during prefetches. We were then able to move that event logging to the destination page’s JavaScript bundle, deferring them until after page “activation” and mitigating the impact of prefetching on our analytics.\nResults\nWe were thrilled with the performance results of the prefetching experiment. We saw a 20-24% improvement in many performance metrics we care about: TTFB, DOMContentLoaded, FCP, LCP. \n\nThe 75th percentile time to first byte (TTFB) on the listing page improved by 23.6%   \nWe saw similar improvements throughout the request: First Contentful Paint -20.7%, Largest Contentful Paint -21.1%, DOMContentLoaded -20.4%, and Page Load -10.6%\n\nIn the cumulative distribution function below, we see the control of our experiment (no speculation rules prefetches) in blue, and the treatment (speculation rules prefetches) in orange, with the treatment dramatically faster than the control at every percentile. Remarkably, about 40% of eligible browsers saw their TTFB drop nearly to zero:\n\n\n\nWe saw small but detectable improvements in some business metrics, which is promising given that listing page views come from many sources, only some of which are search results. As we implement more prefetching in more places, we hypothesize that the numbers will further improve.\nWhen people approach SRA implementation they may be worrying about unused prefetches and resource waste. In our experiment we saw a ratio of about 14:1 for the number of prefetches requested to subsequently activated pages (i.e., about 1 in 14 prefetch requests was navigated to by the user).\nWe’re encouraged by these results, and are looking forward to new opportunities to improve performance across additional surfaces.\nOpportunities to iterate and expand\nOne clear opportunity is to try implementing prefetching on other pages beyond Search. Shoppers end up on product listing pages from various other referral surfaces: shop pages, our SEO-optimized landing pages, home page, etc. Prefetching could improve performance on these surfaces, leading to a better experience for Etsy buyers. \nAnother opportunity is to consider upgrading our prefetching to prerendering in the future. This would be a significant change to client-side JavaScript code operating during prefetches. However (and it's hard to contain the excitement about this!) Chrome is working on prerender-until-script update, which means prerendering stops at the first . Even if you have  high up in the  of your page and prerendering halts early, the browser will still download page resources (scripts, styles, images, fonts) and have them ready. \nFor our use case, enabling prerender-until-script would mean that frontend performance metrics downstream of TTFB, such as First/Largest Contentful Paint, would likely see even larger improvements, and users would be able to interact with the listing page even earlier. This would further reduce friction for users when browsing on Etsy, letting them spend less time watching web pages load and more time engaging directly with our sellers’ amazing inventory of items. \nAcknowledgements\nImplementing SRA was truly a cross-team effort, not only by the search front-end and web performance teams but also people from infrastructure, analytics, ranking, and recommendations. Special thanks to Paul Calvano from our Web Performance team, Diana Sanchez Urban from Search Experience Web, and Eileen Toomer from the Visits team! This project also benefited from input from members of Recommendations and Listing Page teams, as well as members of our internal Architecture Advisory Group.",
          "link": "https://www.etsy.com/codeascraft/search-prefetching-performance?utm_source=OpenGraph&utm_medium=PageTools&utm_campaign=Share",
          "source": "Etsy Engineering | Code as Craft",
          "thumbnail": "https://i.etsystatic.com/inv/f69a53/7378031331/inv_fullxfull.7378031331_hfrpx3ex.jpg?version=0",
          "feedId": "aHR0cHM6Ly9jb2RlYXNjcmFmdC5jb20vZmVlZC8",
          "seen": false,
          "saved": false,
          "publishedAt": "Wed, 29 Oct 2025 13:14:09 -0400",
          "updatedAt": null
        }
      ],
      "expectedArticleCount": 20
    },
    {
      "title": "Discord Blog",
      "url": "https://discord.com/blog/rss.xml",
      "file": "discord-blog__8ede55fdfc.xml",
      "ok": true,
      "bytes": 78554,
      "contentType": "application/rss+xml",
      "expectedFeed": {
        "id": "aHR0cHM6Ly9kaXNjb3JkLmNvbS9ibG9nL3Jzcy54bWw",
        "title": "Discord Blog",
        "xmlUrl": "https://discord.com/blog/rss.xml",
        "image": null,
        "description": null,
        "lastUpdated": "Fri, 19 Dec 2025 10:39:32 GMT",
        "lastPublishedAt": null
      },
      "expectedArticles": [
        {
          "id": "aHR0cHM6Ly9kaXNjb3JkLmNvbS9ibG9nL2JlZ2lubmVycy1ndWlkZS10by1jdXN0b20tZW1vamlz",
          "title": "How to Make and Use Custom Emoji on Discord",
          "description": "Emojis on Discord are special — you can make a little picture out of almost any symbol, in-joke, or bizarre late-night inspiration.",
          "link": "https://discord.com/blog/beginners-guide-to-custom-emojis",
          "source": "Discord Blog",
          "thumbnail": "https://cdn.prod.website-files.com/5f9072399b2640f14d6a2bf4/63603f76620d3470d9bd3f1f_2022_EmojiSurvey_HEADER_2%20(1).png",
          "feedId": "aHR0cHM6Ly9kaXNjb3JkLmNvbS9ibG9nL3Jzcy54bWw",
          "seen": false,
          "saved": false,
          "publishedAt": "Fri, 12 Dec 2025 00:00:00 GMT",
          "updatedAt": null
        },
        {
          "id": "aHR0cHM6Ly9kaXNjb3JkLmNvbS9ibG9nL2Rpc2NvcmQtcGF0Y2gtbm90ZXMtZGVjZW1iZXItOC0yMDI1",
          "title": "Discord Patch Notes: December 8, 2025",
          "description": "Check out the finer details of the more technical fixes implemented into Discord recently.",
          "link": "https://discord.com/blog/discord-patch-notes-december-8-2025",
          "source": "Discord Blog",
          "thumbnail": "https://cdn.prod.website-files.com/5f9072399b2640f14d6a2bf4/683a385e31ae16bd173ee8d9_image2.png",
          "feedId": "aHR0cHM6Ly9kaXNjb3JkLmNvbS9ibG9nL3Jzcy54bWw",
          "seen": false,
          "saved": false,
          "publishedAt": "Mon, 08 Dec 2025 00:00:00 GMT",
          "updatedAt": null
        }
      ],
      "expectedArticleCount": 100
    },
    {
      "title": "AWS Official Blog",
      "url": "https://aws.amazon.com/blogs/aws/feed/",
      "file": "aws-official-blog__e64af89c6f.xml",
      "ok": true,
      "bytes": 299117,
      "contentType": "application/rss+xml;charset=UTF-8",
      "expectedFeed": {
        "id": "aHR0cHM6Ly9hd3MuYW1hem9uLmNvbS9ibG9ncy9hd3MvZmVlZC8",
        "title": "AWS News Blog",
        "xmlUrl": "https://aws.amazon.com/blogs/aws/feed/",
        "image": null,
        "description": null,
        "lastUpdated": "Fri, 19 Dec 2025 20:56:36 +0000",
        "lastPublishedAt": null
      },
      "expectedArticles": [
        {
          "id": "OWQ4MTBmZDAyN2MxMmVjMTcyZjU0OTAwNWZlN2M0YTE4MDZkNzgyYw",
          "title": "AWS Weekly Roundup: Amazon ECS, Amazon CloudWatch, Amazon Cognito and more (December 15, 2025)",
          "description": "Can you believe it? We’re nearly at the end of 2025. And what a year it’s been! From re:Invent recap events, to AWS Summits, AWS Innovate, AWS re:Inforce, Community Days, and DevDays and, recently, adding that cherry on the cake, re:Invent 2025, we have lived through a year filled with exciting moments and technology advancements […]",
          "link": "https://aws.amazon.com/blogs/aws/aws-weekly-roundup-amazon-ecs-amazon-cloudwatch-amazon-cognito-and-more-december-15-2025/",
          "source": "AWS News Blog",
          "thumbnail": null,
          "feedId": "aHR0cHM6Ly9hd3MuYW1hem9uLmNvbS9ibG9ncy9hd3MvZmVlZC8",
          "seen": false,
          "saved": false,
          "publishedAt": "Mon, 15 Dec 2025 16:42:05 +0000",
          "updatedAt": null
        },
        {
          "id": "NTdlMmZjYTA5NWQxYjlkNTliZGQ3YzgxOWExMGI2ZTg1NzIzMzA0Yg",
          "title": "AWS Weekly Roundup: AWS re:Invent keynote recap, on-demand videos, and more (December 8, 2025)",
          "description": "The week after AWS re:Invent builds on the excitement and energy of the event and is a good time to learn more and understand how the recent announcements can help you solve your challenges and unlock new opportunities. As usual, we have you covered with our top announcements of AWS re:Invent 2025 that you can […]",
          "link": "https://aws.amazon.com/blogs/aws/aws-weekly-roundup-aws-reinvent-keynote-recap-on-demand-videos-and-more-december-8-2025/",
          "source": "AWS News Blog",
          "thumbnail": "https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/12/08/2025-news-nowgobuild-1.png",
          "feedId": "aHR0cHM6Ly9hd3MuYW1hem9uLmNvbS9ibG9ncy9hd3MvZmVlZC8",
          "seen": false,
          "saved": false,
          "publishedAt": "Mon, 08 Dec 2025 17:05:29 +0000",
          "updatedAt": null
        }
      ],
      "expectedArticleCount": 20
    },
    {
      "title": "Auth0 Blog",
      "url": "https://auth0.com/blog/rss.xml",
      "file": "auth0-blog__9e6678051b.xml",
      "ok": true,
      "bytes": 8075,
      "contentType": "text/xml",
      "expectedFeed": {
        "id": "aHR0cHM6Ly9hdXRoMC5jb20vYmxvZy9yc3MueG1s",
        "title": "Auth0 Blog",
        "xmlUrl": "https://auth0.com/blog/rss.xml",
        "image": null,
        "description": null,
        "lastUpdated": "Fri, 19 Dec 2025 22:21:55 GMT",
        "lastPublishedAt": null
      },
      "expectedArticles": [
        {
          "id": "aHR0cHM6Ly9hdXRoMC5jb20vYmxvZy9tY3Atc3RyZWFtYWJsZS1odHRwLw",
          "title": "Why MCP’s Move Away from Server-Sent Events Simplifies Security",
          "description": "Discover why the Model Context Protocol (MCP) deprecated Server-Sent Events (SSE) for Streamable HTTP and how this shift enables stronger authentication, standard CORS policies, and secure session management.",
          "link": "https://auth0.com/blog/mcp-streamable-http/",
          "source": "Auth0 Blog",
          "thumbnail": "https://images.ctfassets.net/23aumh6u8s0i/7o34vTMAB9Hip3pa48DEYR/3062348c26a40199c1ebc0a847734d23/MCP_and_Auth0.jpg",
          "feedId": "aHR0cHM6Ly9hdXRoMC5jb20vYmxvZy9yc3MueG1s",
          "seen": false,
          "saved": false,
          "publishedAt": "Fri, 19 Dec 2025 00:00:00 GMT",
          "updatedAt": null
        },
        {
          "id": "aHR0cHM6Ly9hdXRoMC5jb20vYmxvZy9haS1hc3Npc3RhbnQtbGFuZ2dyYXBoLW5leHRqcy1zbGFjay1naXRodWIv",
          "title": "Build an AI Assistant with LangGraph, Next.js, and Auth0 Connected Accounts",
          "description": "Learn how to build a tool-calling AI agent using LangGraph, Next.js, and Auth0. Integrate GitHub and Slack tools using Connected Accounts for Token Vault.",
          "link": "https://auth0.com/blog/ai-assistant-langgraph-nextjs-slack-github/",
          "source": "Auth0 Blog",
          "thumbnail": "https://images.ctfassets.net/23aumh6u8s0i/1JJsVYc1hPjkP7zSaH0EF8/961afac75b2ce3699620596c08646227/hero.jpg",
          "feedId": "aHR0cHM6Ly9hdXRoMC5jb20vYmxvZy9yc3MueG1s",
          "seen": false,
          "saved": false,
          "publishedAt": "Fri, 19 Dec 2025 00:00:00 GMT",
          "updatedAt": null
        }
      ],
      "expectedArticleCount": 10
    },
    {
      "title": "Airbnb Engineering &amp; Data Science — Medium",
      "url": "https://medium.com/feed/airbnb-engineering",
      "file": "airbnb-engineering-data-science-medium__2bd5f0250d.xml",
      "ok": true,
      "bytes": 162879,
      "contentType": "text/xml; charset=UTF-8",
      "expectedFeed": {
        "id": "aHR0cHM6Ly9tZWRpdW0uY29tL2ZlZWQvYWlyYm5iLWVuZ2luZWVyaW5n",
        "title": "The Airbnb Tech Blog - Medium",
        "xmlUrl": "https://medium.com/feed/airbnb-engineering",
        "image": "https://cdn-images-1.medium.com/proxy/1*TGH72Nnw24QL3iV9IOm4VA.png",
        "description": null,
        "lastUpdated": "Fri, 19 Dec 2025 22:18:26 GMT",
        "lastPublishedAt": null
      },
      "expectedArticles": [
        {
          "id": "aHR0cHM6Ly9tZWRpdW0uY29tL3AvMzBiMzgwZjEyYmQ2",
          "title": "GraphQL Data Mocking at Scale with LLMs and @generateMock",
          "description": null,
          "link": "https://medium.com/airbnb-engineering/graphql-data-mocking-at-scale-with-llms-and-generatemock-30b380f12bd6?source=rss----53c7c27702d5---4",
          "source": "The Airbnb Tech Blog - Medium",
          "thumbnail": "https://cdn-images-1.medium.com/max/1024/1*wHF0IXmtHzIfzv-IZh_CKA.jpeg",
          "feedId": "aHR0cHM6Ly9tZWRpdW0uY29tL2ZlZWQvYWlyYm5iLWVuZ2luZWVyaW5n",
          "seen": false,
          "saved": false,
          "publishedAt": "Thu, 30 Oct 2025 17:01:54 GMT",
          "updatedAt": null
        },
        {
          "id": "aHR0cHM6Ly9tZWRpdW0uY29tL3AvMjkzNjI3NjRlNWMy",
          "title": "From Static Rate Limiting to Adaptive Traffic Management in Airbnb’s Key-Value Store",
          "description": null,
          "link": "https://medium.com/airbnb-engineering/from-static-rate-limiting-to-adaptive-traffic-management-in-airbnbs-key-value-store-29362764e5c2?source=rss----53c7c27702d5---4",
          "source": "The Airbnb Tech Blog - Medium",
          "thumbnail": "https://cdn-images-1.medium.com/max/1024/1*kBx_8QLd7El4TZ2nrouYUw.jpeg",
          "feedId": "aHR0cHM6Ly9tZWRpdW0uY29tL2ZlZWQvYWlyYm5iLWVuZ2luZWVyaW5n",
          "seen": false,
          "saved": false,
          "publishedAt": "Thu, 09 Oct 2025 16:01:55 GMT",
          "updatedAt": null
        }
      ],
      "expectedArticleCount": 10
    },
    {
      "title": "Crunchbase News",
      "url": "https://news.crunchbase.com/feed/",
      "file": "crunchbase-news__8188438a3f.xml",
      "ok": true,
      "bytes": 93943,
      "contentType": "application/rss+xml; charset=UTF-8",
      "expectedFeed": {
        "id": "aHR0cHM6Ly9uZXdzLmNydW5jaGJhc2UuY29tL2ZlZWQv",
        "title": "Crunchbase News",
        "xmlUrl": "https://news.crunchbase.com/feed/",
        "image": "https://news.crunchbase.com/wp-content/uploads/cb_news_favicon-150x150.png",
        "description": null,
        "lastUpdated": "Fri, 19 Dec 2025 19:28:33 +0000",
        "lastPublishedAt": null
      },
      "expectedArticles": [
        {
          "id": "aHR0cHM6Ly9uZXdzLmNydW5jaGJhc2UuY29tLz9wPTkyOTUx",
          "title": "The Week’s 10 Biggest Funding Rounds: Security And Energy Deals Top The List",
          "description": "Perennial megaround raiser Databricks was the top funding recipient by far this week, securing a fresh $4 billion in Series L funding (yes, that is a thing) at a $134 billion valuation. Next on the list were a data security platform and a nuclear microreactor company.",
          "link": "https://news.crunchbase.com/venture/biggest-funding-rounds-databricks-cyera/",
          "source": "Crunchbase News",
          "thumbnail": "https://news.crunchbase.com/wp-content/uploads/Top_10_.jpeg",
          "feedId": "aHR0cHM6Ly9uZXdzLmNydW5jaGJhc2UuY29tL2ZlZWQv",
          "seen": false,
          "saved": false,
          "publishedAt": "Fri, 19 Dec 2025 19:28:33 +0000",
          "updatedAt": null
        },
        {
          "id": "aHR0cHM6Ly9uZXdzLmNydW5jaGJhc2UuY29tLz9wPTkyOTMy",
          "title": "These Startups Went From Zero To Unicorn In Under 3 Years",
          "description": "Forty-six companies founded in the past three years both held or obtained unicorn status in 2025 and raised fresh funding, per Crunchbase data. Collectively, they pulled in nearly $39 billion in new investment this year. Predictably, it’s an AI-centric group.",
          "link": "https://news.crunchbase.com/startups/funding-zero-to-unicorn-ai-robotics-eoy-2025/",
          "source": "Crunchbase News",
          "thumbnail": "https://news.crunchbase.com/wp-content/uploads/Unicorn-1.jpg",
          "feedId": "aHR0cHM6Ly9uZXdzLmNydW5jaGJhc2UuY29tL2ZlZWQv",
          "seen": false,
          "saved": false,
          "publishedAt": "Fri, 19 Dec 2025 12:00:28 +0000",
          "updatedAt": null
        }
      ],
      "expectedArticleCount": 10
    },
    {
      "title": "The GitHub Blog",
      "url": "https://github.blog/feed/",
      "file": "the-github-blog__d070c82cd8.xml",
      "ok": true,
      "bytes": 160559,
      "contentType": "application/rss+xml; charset=UTF-8",
      "expectedFeed": {
        "id": "aHR0cHM6Ly9naXRodWIuYmxvZy9mZWVkLw",
        "title": "The GitHub Blog",
        "xmlUrl": "https://github.blog/feed/",
        "image": "https://github.blog/wp-content/uploads/2019/01/cropped-github-favicon-512.png?fit=32%2C32",
        "description": null,
        "lastUpdated": "Fri, 12 Dec 2025 20:43:39 +0000",
        "lastPublishedAt": null
      },
      "expectedArticles": [
        {
          "id": "aHR0cHM6Ly9naXRodWIuYmxvZy8_cD05MjgyNg",
          "title": "The future of AI-powered software optimization (and how it can help your team)",
          "description": "We envision the future of AI-enabled tooling to look like near-effortless engineering for sustainability. We call it Continuous Efficiency.\nThe post The future of AI-powered software optimization (and how it can help your team) appeared first on The GitHub Blog.\n",
          "link": "https://github.blog/news-insights/policy-news-and-insights/the-future-of-ai-powered-software-optimization-and-how-it-can-help-your-team/",
          "source": "The GitHub Blog",
          "thumbnail": "https://github.blog/wp-content/uploads/2025/12/image1_c8a727.png?resize=1024%2C320",
          "feedId": "aHR0cHM6Ly9naXRodWIuYmxvZy9mZWVkLw",
          "seen": false,
          "saved": false,
          "publishedAt": "Fri, 12 Dec 2025 20:43:37 +0000",
          "updatedAt": null
        },
        {
          "id": "aHR0cHM6Ly9naXRodWIuYmxvZy8_cD05Mjc2Mg",
          "title": "Let’s talk about GitHub Actions",
          "description": "A look at how we rebuilt GitHub Actions’ core architecture and shipped long-requested upgrades to improve performance, workflow flexibility, reliability, and everyday developer experience.\nThe post Let’s talk about GitHub Actions appeared first on The GitHub Blog.\n",
          "link": "https://github.blog/news-insights/product-news/lets-talk-about-github-actions/",
          "source": "The GitHub Blog",
          "thumbnail": null,
          "feedId": "aHR0cHM6Ly9naXRodWIuYmxvZy9mZWVkLw",
          "seen": false,
          "saved": false,
          "publishedAt": "Thu, 11 Dec 2025 17:40:52 +0000",
          "updatedAt": null
        }
      ],
      "expectedArticleCount": 10
    },
    {
      "title": "UX Movement",
      "url": "https://uxmovement.com/feed/",
      "file": "ux-movement__3d6d456229.xml",
      "ok": true,
      "bytes": 7429,
      "contentType": "application/rss+xml; charset=UTF-8",
      "expectedFeed": {
        "id": "aHR0cHM6Ly91eG1vdmVtZW50LmNvbS9mZWVkLw",
        "title": "UX Movement",
        "xmlUrl": "https://uxmovement.com/feed/",
        "image": "https://uxmovement.com/wp-content/uploads/2019/02/cropped-uxmovement-site-icon-32x32.png",
        "description": null,
        "lastUpdated": "Wed, 19 Mar 2025 15:27:48 +0000",
        "lastPublishedAt": null
      },
      "expectedArticles": [
        {
          "id": "aHR0cHM6Ly91eG1vdmVtZW50LmNvbS8_cD0zMzIyNQ",
          "title": "How to Group Your Sidebar Items for Better Findability",
          "description": "When a sidebar contains many items, grouping is necessary to help users find them faster. However, most designers don’t group their sidebar items and force users to scan an entire list. This results in slow navigation times and poor findability. Grouping improves findability by enabling users to spot a group and scan the items in […]\nThe post How to Group Your Sidebar Items for Better Findability first appeared on UX Movement.",
          "link": "https://uxmovement.com/navigation/how-to-group-your-sidebar-items-for-better-findability/",
          "source": "UX Movement",
          "thumbnail": null,
          "feedId": "aHR0cHM6Ly91eG1vdmVtZW50LmNvbS9mZWVkLw",
          "seen": false,
          "saved": false,
          "publishedAt": "Wed, 19 Mar 2025 15:27:48 +0000",
          "updatedAt": null
        },
        {
          "id": "aHR0cHM6Ly91eG1vdmVtZW50LmNvbS8_cD0zMzIyMQ",
          "title": "How to Make Any Sidebar Menu Easier to Scan",
          "description": "How easy to scan is your sidebar menu? If you haven’t optimized the spacing, users will likely spend more time navigating and finding items. Balancing the spacing in the sidebar can help users navigate faster and easier. A typical mistake designers make is adding too much or not enough space. Both can make scanning for […]\nThe post How to Make Any Sidebar Menu Easier to Scan first appeared on UX Movement.",
          "link": "https://uxmovement.com/navigation/how-to-make-any-sidebar-menu-easier-to-scan/",
          "source": "UX Movement",
          "thumbnail": null,
          "feedId": "aHR0cHM6Ly91eG1vdmVtZW50LmNvbS9mZWVkLw",
          "seen": false,
          "saved": false,
          "publishedAt": "Wed, 19 Mar 2025 15:24:10 +0000",
          "updatedAt": null
        }
      ],
      "expectedArticleCount": 5
    },
    {
      "title": "Martin Fowler",
      "url": "https://martinfowler.com/feed.atom",
      "file": "martin-fowler__e9a6101142.xml",
      "ok": true,
      "bytes": 79278,
      "contentType": "application/atom+xml",
      "expectedFeed": {
        "id": "aHR0cHM6Ly9tYXJ0aW5mb3dsZXIuY29tL2ZlZWQuYXRvbQ",
        "title": "Martin Fowler",
        "xmlUrl": "https://martinfowler.com/feed.atom",
        "image": null,
        "description": "Master feed of news and updates from martinfowler.com",
        "lastUpdated": "2025-12-16T10:14:00-05:00",
        "lastPublishedAt": null
      },
      "expectedArticles": [
        {
          "id": "aHR0cHM6Ly9tYXJ0aW5mb3dsZXIuY29tL2ZyYWdtZW50cy8yMDI1LTEyLTE2Lmh0bWw",
          "title": "Fragments: December 16",
          "description": null,
          "link": "https://martinfowler.com/fragments/2025-12-16.html",
          "source": "Martin Fowler",
          "thumbnail": "https://martinfowler.com/fragments/2025/gitanjali-mainframe.png",
          "feedId": "aHR0cHM6Ly9tYXJ0aW5mb3dsZXIuY29tL2ZlZWQuYXRvbQ",
          "seen": false,
          "saved": false,
          "publishedAt": "2025-12-16T10:14:00-05:00",
          "updatedAt": "2025-12-16T10:14:00-05:00"
        },
        {
          "id": "aHR0cHM6Ly9tYXJ0aW5mb3dsZXIuY29tL2FydGljbGVzL3dyaXRpbmctZnJhZ21lbnRzLmh0bWw",
          "title": "Writing Fragments",
          "description": null,
          "link": "https://martinfowler.com/articles/writing-fragments.html",
          "source": "Martin Fowler",
          "thumbnail": null,
          "feedId": "aHR0cHM6Ly9tYXJ0aW5mb3dsZXIuY29tL2ZlZWQuYXRvbQ",
          "seen": false,
          "saved": false,
          "publishedAt": "2025-12-16T10:06:00-05:00",
          "updatedAt": "2025-12-16T10:06:00-05:00"
        }
      ],
      "expectedArticleCount": 30
    },
    {
      "title": "Google Developers Blog",
      "url": "https://developers.googleblog.com/feeds/posts/default",
      "file": "google-developers-blog__10db7a627c.xml",
      "ok": true,
      "bytes": 15011,
      "contentType": "application/rss+xml; charset=utf-8",
      "expectedFeed": {
        "id": "aHR0cHM6Ly9kZXZlbG9wZXJzLmdvb2dsZWJsb2cuY29tL2ZlZWRzL3Bvc3RzL2RlZmF1bHQ",
        "title": "Google Developers Blog",
        "xmlUrl": "https://developers.googleblog.com/feeds/posts/default",
        "image": null,
        "description": null,
        "lastUpdated": "Fri, 19 Dec 2025 22:22:20 +0000",
        "lastPublishedAt": null
      },
      "expectedArticles": [
        {
          "id": "aHR0cHM6Ly9kZXZlbG9wZXJzLmdvb2dsZWJsb2cuY29tL3JlYWwtd29ybGQtYWdlbnQtZXhhbXBsZXMtd2l0aC1nZW1pbmktMy8",
          "title": "Real-World Agent Examples with Gemini 3",
          "description": "Gemini 3 is powering the next generation of reliable, production-ready AI agents. This post highlights 6 open-source framework collaborations (ADK, Agno, Browser Use, Eigent, Letta, mem0), demonstrating practical agentic workflows for tasks like deep search, multi-agent systems, browser and enterprise automation, and stateful agents with advanced memory. Clone the examples and start building today.",
          "link": "https://developers.googleblog.com/real-world-agent-examples-with-gemini-3/",
          "source": "Google Developers Blog",
          "thumbnail": null,
          "feedId": "aHR0cHM6Ly9kZXZlbG9wZXJzLmdvb2dsZWJsb2cuY29tL2ZlZWRzL3Bvc3RzL2RlZmF1bHQ",
          "seen": false,
          "saved": false,
          "publishedAt": null,
          "updatedAt": null
        },
        {
          "id": "aHR0cHM6Ly9kZXZlbG9wZXJzLmdvb2dsZWJsb2cuY29tL2NvbmR1Y3Rvci1pbnRyb2R1Y2luZy1jb250ZXh0LWRyaXZlbi1kZXZlbG9wbWVudC1mb3ItZ2VtaW5pLWNsaS8",
          "title": "Conductor: Introducing context-driven development for Gemini CLI",
          "description": "Conductor is a new Gemini CLI extension that promotes context-driven development. It shifts project context from chat logs to persistent Markdown files for formal specs and plans, ensuring AI agents adhere to project goals, style, and tech stack. This structured workflow is great for \"brownfield\" projects and teams, allowing for safe iteration and consistent code contributions while keeping the human developer in control.",
          "link": "https://developers.googleblog.com/conductor-introducing-context-driven-development-for-gemini-cli/",
          "source": "Google Developers Blog",
          "thumbnail": null,
          "feedId": "aHR0cHM6Ly9kZXZlbG9wZXJzLmdvb2dsZWJsb2cuY29tL2ZlZWRzL3Bvc3RzL2RlZmF1bHQ",
          "seen": false,
          "saved": false,
          "publishedAt": null,
          "updatedAt": null
        }
      ],
      "expectedArticleCount": 20
    },
    {
      "title": "Android Developers Blog",
      "url": "https://android-developers.blogspot.com/atom.xml",
      "file": "android-developers-blog__c4b24e3d9f.xml",
      "ok": true,
      "bytes": 1562789,
      "contentType": "application/atom+xml; charset=UTF-8",
      "expectedFeed": {
        "id": "dGFnOmJsb2dnZXIuY29tLDE5OTk6YmxvZy02NzU1NzA5NjQzMDQ0OTQ3MTc5",
        "title": "Android Developers Blog",
        "xmlUrl": "https://android-developers.blogspot.com/atom.xml",
        "image": null,
        "description": "The official Android Developers blog covering the latest news on app development tools, platform updates, training, and documentation for developers across every Android device.",
        "lastUpdated": "2025-12-19T14:00:00.133-08:00",
        "lastPublishedAt": null
      },
      "expectedArticles": [
        {
          "id": "dGFnOmJsb2dnZXIuY29tLDE5OTk6YmxvZy02NzU1NzA5NjQzMDQ0OTQ3MTc5LnBvc3QtMjc0MzQxMjExNTM5OTEyNTA0Ng",
          "title": "Media3 1.9.0 - What’s new",
          "description": null,
          "link": "https://android-developers.blogspot.com/atom.xml",
          "source": "Android Developers Blog",
          "thumbnail": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjUMVg00srjTLgh0s2Qc3SgvVpuVUdpzG0jIKkSSI62wa_yafiPGNTskbi87cxNUdHLGRu4KdvO5j82H5gXahXPMGxqOlkad6Kz3b9XMGHNucy2cTCsMclNJf8X_J48BV3CImRg9XwrvnVwlegI1zeS4jl4U5ViJ5xRmqiiZYt-cKMJf6mi0rUDrEiosWc/s1600/Android_Evergreen_Blogger_Banner_AI_WebandApp.png",
          "feedId": "dGFnOmJsb2dnZXIuY29tLDE5OTk6YmxvZy02NzU1NzA5NjQzMDQ0OTQ3MTc5",
          "seen": false,
          "saved": false,
          "publishedAt": "2025-12-19T14:00:00.000-08:00",
          "updatedAt": "2025-12-19T14:00:00.124-08:00"
        },
        {
          "id": "dGFnOmJsb2dnZXIuY29tLDE5OTk6YmxvZy02NzU1NzA5NjQzMDQ0OTQ3MTc5LnBvc3QtNzk1MTU0OTgxNDU2NDM2NjcyOQ",
          "title": "Goodbye Mobile Only, Hello Adaptive: Three essential updates from 2025 for building adaptive apps",
          "description": null,
          "link": "https://android-developers.blogspot.com/atom.xml",
          "source": "Android Developers Blog",
          "thumbnail": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgFFPBX2aEy-BimBic-IaoVAZ7rxlSVic8wsgRsremTvpkH0fc2WlXx0GBj_fUFZYwnFTRiLjD6mYincdLsFxTE0fWoI-1WJxQYdaHXC00LSg48apySI-0oakfL9EI5IXDqUWivLBXzKQZXRuhCjMxCKMfOW8CLsu_KYcEpjXIKe-wLsF_uCfuPEni58Tc/s1600/Android%20adaptives%20festivity%2001-%20Meta.png",
          "feedId": "dGFnOmJsb2dnZXIuY29tLDE5OTk6YmxvZy02NzU1NzA5NjQzMDQ0OTQ3MTc5",
          "seen": false,
          "saved": false,
          "publishedAt": "2025-12-19T09:00:00.000-08:00",
          "updatedAt": "2025-12-19T09:00:00.118-08:00"
        }
      ],
      "expectedArticleCount": 25
    },
    {
      "title": "I Love Typography",
      "url": "https://feeds.feedburner.com/ILoveTypography",
      "file": "i-love-typography__0a22a867d9.xml",
      "ok": true,
      "bytes": 8777,
      "contentType": "text/xml; charset=utf-8",
      "expectedFeed": {
        "id": "aHR0cHM6Ly9mZWVkcy5mZWVkYnVybmVyLmNvbS9JTG92ZVR5cG9ncmFwaHk",
        "title": "I Love Typography Ltd",
        "xmlUrl": "https://feeds.feedburner.com/ILoveTypography",
        "image": "https://ilovetypography.com/NEW_BLOG/wp-content/uploads/2025/08/Vector.svg",
        "description": null,
        "lastUpdated": "Fri, 19 Dec 2025 04:41:40 +0000",
        "lastPublishedAt": null
      },
      "expectedArticles": [
        {
          "id": "aHR0cHM6Ly9pbG92ZXR5cG9ncmFwaHkuY29tLz9wPTUwNzI0",
          "title": "10 Must-have Typefaces for 2026",
          "description": "Read the book, Typographic Firsts\nHow quickly a year passes. Our Must-Have Fonts for 2025 list was our most popular ever, but our must-have fonts for 2026 list aims to set the bar even higher. Finding the best typefaces among thousands can be pretty daunting! So, to make things easier, we’ve curated a list of outstanding must-have […]\nThe post 10 Must-have Typefaces for 2026 appeared first on I Love Typography Ltd.\n",
          "link": "https://ilovetypography.com/2025/12/19/10-must-have-fonts-for-2026/",
          "source": "I Love Typography Ltd",
          "thumbnail": null,
          "feedId": "aHR0cHM6Ly9mZWVkcy5mZWVkYnVybmVyLmNvbS9JTG92ZVR5cG9ncmFwaHk",
          "seen": false,
          "saved": false,
          "publishedAt": "Fri, 19 Dec 2025 04:00:44 +0000",
          "updatedAt": null
        },
        {
          "id": "aHR0cHM6Ly9pbG92ZXR5cG9ncmFwaHkuY29tLz9wPTUwNzM5",
          "title": "Steven Heller’s Font of the Year: Fillmore",
          "description": "Read the book, Typographic Firsts\nIn my past Font of the Month columns, I admitted to extreme fixation for ‘stencilism’ and avaricious hoarding of stencil type and lettering specimens. There is a je ne sais quoi about them that, perhaps, reminds me of some primal life event. I don’t judge stencils on aesthetics per se […]\nThe post Steven Heller’s Font of the Year: Fillmore appeared first on I Love Typography Ltd.\n",
          "link": "https://ilovetypography.com/2025/12/03/steven-hellers-font-of-the-year-fillmore/",
          "source": "I Love Typography Ltd",
          "thumbnail": null,
          "feedId": "aHR0cHM6Ly9mZWVkcy5mZWVkYnVybmVyLmNvbS9JTG92ZVR5cG9ncmFwaHk",
          "seen": false,
          "saved": false,
          "publishedAt": "Wed, 03 Dec 2025 04:00:40 +0000",
          "updatedAt": null
        }
      ],
      "expectedArticleCount": 7
    },
    {
      "title": "MIT News - Computer Science and Artificial Intelligence Laboratory (CSAIL)",
      "url": "https://web.mit.edu/newsoffice/topic/mitcomputers-rss.xml",
      "file": "mit-news-computer-science-and-artificial-intelligence-labora__52cdae1b7d.xml",
      "ok": true,
      "bytes": 560443,
      "contentType": "application/rss+xml; charset=utf-8",
      "expectedFeed": {
        "id": "aHR0cHM6Ly93ZWIubWl0LmVkdS9uZXdzb2ZmaWNlL3RvcGljL21pdGNvbXB1dGVycy1yc3MueG1s",
        "title": "MIT News - Computer Science and Artificial Intelligence Laboratory (CSAIL)",
        "xmlUrl": "https://web.mit.edu/newsoffice/topic/mitcomputers-rss.xml",
        "image": null,
        "description": null,
        "lastUpdated": "Fri, 12 Dec 2025 05:00:00 +0000",
        "lastPublishedAt": null
      },
      "expectedArticles": [
        {
          "id": "aHR0cHM6Ly9uZXdzLm1pdC5lZHUvMjAyNS9ndWlkZWQtbGVhcm5pbmctbGV0cy11bnRyYWluYWJsZS1uZXVyYWwtbmV0d29ya3MtcmVhbGl6ZS10aGVpci1wb3RlbnRpYWwtMTIxOA",
          "title": "Guided learning lets “untrainable” neural networks realize their potential",
          "description": "CSAIL researchers find even “untrainable” neural nets can learn effectively when guided by another network’s built-in biases using their guidance method.",
          "link": "https://news.mit.edu/2025/guided-learning-lets-untrainable-neural-networks-realize-their-potential-1218",
          "source": "MIT News - Computer Science and Artificial Intelligence Laboratory (CSAIL)",
          "thumbnail": "https://news.mit.edu/sites/default/files/styles/news_article__cover_image__original/public/images/202512/mit-csail-Untrainable-networks.jpg?itok=_xsMAwVf",
          "feedId": "aHR0cHM6Ly93ZWIubWl0LmVkdS9uZXdzb2ZmaWNlL3RvcGljL21pdGNvbXB1dGVycy1yc3MueG1s",
          "seen": false,
          "saved": false,
          "publishedAt": "Thu, 18 Dec 2025 16:20:00 -0500",
          "updatedAt": null
        },
        {
          "id": "aHR0cHM6Ly9uZXdzLm1pdC5lZHUvMjAyNS9uZXctd2F5LXRvLWluY3JlYXNlLWxhcmdlLWxhbmd1YWdlLW1vZGVsLWNhcGFiaWxpdGllcy0xMjE3",
          "title": "A new way to increase the capabilities of large language models",
          "description": "MIT-IBM Watson AI Lab researchers developed an expressive architecture that provides better state tracking and sequential reasoning in LLMs over long texts.",
          "link": "https://news.mit.edu/2025/new-way-to-increase-large-language-model-capabilities-1217",
          "source": "MIT News - Computer Science and Artificial Intelligence Laboratory (CSAIL)",
          "thumbnail": "https://news.mit.edu/sites/default/files/styles/news_article__cover_image__original/public/images/202512/mit-watson-cats-in-a-box.jpg?itok=ytH_wQHS",
          "feedId": "aHR0cHM6Ly93ZWIubWl0LmVkdS9uZXdzb2ZmaWNlL3RvcGljL21pdGNvbXB1dGVycy1yc3MueG1s",
          "seen": false,
          "saved": false,
          "publishedAt": "Wed, 17 Dec 2025 23:10:00 -0500",
          "updatedAt": null
        }
      ],
      "expectedArticleCount": 50
    },
    {
      "title": "The Next Web",
      "url": "https://thenextweb.com/feed/",
      "file": "the-next-web__90aa17c353.xml",
      "ok": true,
      "bytes": 19622,
      "contentType": "application/xml",
      "expectedFeed": {
        "id": "aHR0cHM6Ly90aGVuZXh0d2ViLmNvbS9mZWVkLw",
        "title": "The Next Web",
        "xmlUrl": "https://thenextweb.com/feed/",
        "image": null,
        "description": null,
        "lastUpdated": "Fri, 19 Dec 2025 05:59:13 +0000",
        "lastPublishedAt": null
      },
      "expectedArticles": [
        {
          "id": "VGhlTmV4dFdlYj0xNDE1MDUy",
          "title": "Letter from the Editor-in-Chief",
          "description": "Not long ago, like many of you, I read what I feared might be The Next Web’s final article. In late September, TNW’s co-founder announced that the tech conference and news site would be winding down, no more events, no new stories. It felt like the end of an era; the news hit hard. Yet, just a few weeks ago, a twist arrived: the tech platform Tekpon acquired 100% of TNW’s media and events brand from the Financial Times, ensuring that this nearly two-decade legacy will continue to thrive. While, myself, trying to read people’s opinions on this topic, I…This story continues at The Next Web",
          "link": "https://thenextweb.com/news/letter-from-the-editor-in-chief",
          "source": "The Next Web",
          "thumbnail": "https://img-cdn.tnwcdn.com/image?fit=796%2C417&url=https%3A%2F%2Fcdn0.tnwcdn.com%2Fwp-content%2Fblogs.dir%2F1%2Ffiles%2F2025%2F12%2FTNW-new-Editor-in-Chief.png&signature=ace3fe9752016fc238ce587e6d510da3",
          "feedId": "aHR0cHM6Ly90aGVuZXh0d2ViLmNvbS9mZWVkLw",
          "seen": false,
          "saved": false,
          "publishedAt": "Tue, 16 Dec 2025 20:31:00 +0000",
          "updatedAt": null
        },
        {
          "id": "VGhlTmV4dFdlYj0xNDE1MDMz",
          "title": "Is ChatGPT’s New Shopping Research Solving a Problem, or Creating One?",
          "description": "When OpenAI announced its new shopping search capabilities, I took the news with a grain of salt (perhaps the whole shaker). For the past decade, we have watched the slow evolution of traditional search engines. What began as tools for pure information discovery gradually morphed into ecosystems dominated by SEO-optimized content and sponsored results. My initial fear with ChatGPT’s update was simple: Are we seeing the beginning of a similar shift? Is the purity of the “reasoning engine” being diluted by the necessity of commerce? After testing the new shopping integration, the results suggest that we are at a pivotal…This story continues at The Next Web",
          "link": "https://thenextweb.com/news/is-chatgpts-new-shopping-research-solving-a-problem-or-creating-one",
          "source": "The Next Web",
          "thumbnail": "https://img-cdn.tnwcdn.com/image?fit=796%2C417&url=https%3A%2F%2Fcdn0.tnwcdn.com%2Fwp-content%2Fblogs.dir%2F1%2Ffiles%2F2025%2F12%2FChatGPTs-New-Shopping-Research.png&signature=2eeed9ea07926978f9ba07860cb02621",
          "feedId": "aHR0cHM6Ly90aGVuZXh0d2ViLmNvbS9mZWVkLw",
          "seen": false,
          "saved": false,
          "publishedAt": "Thu, 11 Dec 2025 22:37:55 +0000",
          "updatedAt": null
        }
      ],
      "expectedArticleCount": 10
    },
    {
      "title": "TechCrunch",
      "url": "https://techcrunch.com/feed/",
      "file": "techcrunch__2ef05e3145.xml",
      "ok": true,
      "bytes": 18790,
      "contentType": "application/rss+xml; charset=UTF-8",
      "expectedFeed": {
        "id": "aHR0cHM6Ly90ZWNoY3J1bmNoLmNvbS9mZWVkLw",
        "title": "TechCrunch",
        "xmlUrl": "https://techcrunch.com/feed/",
        "image": "https://techcrunch.com/wp-content/uploads/2015/02/cropped-cropped-favicon-gradient.png?w=32",
        "description": null,
        "lastUpdated": "Fri, 19 Dec 2025 22:19:55 +0000",
        "lastPublishedAt": null
      },
      "expectedArticles": [
        {
          "id": "aHR0cHM6Ly90ZWNoY3J1bmNoLmNvbS8_cD0zMDc4MDEx",
          "title": "Former Patagonia CEO Rose Marcario resigns from Rivian’s board",
          "description": "Marcario joined the board in 2021, and will maintain her position as chair overseeing the Rivian Foundation, which made its first grants last year.",
          "link": "https://techcrunch.com/2025/12/19/former-patagonia-ceo-rose-marcario-resigns-from-rivians-board/",
          "source": "TechCrunch",
          "thumbnail": null,
          "feedId": "aHR0cHM6Ly90ZWNoY3J1bmNoLmNvbS9mZWVkLw",
          "seen": false,
          "saved": false,
          "publishedAt": "Fri, 19 Dec 2025 22:13:34 +0000",
          "updatedAt": null
        },
        {
          "id": "aHR0cHM6Ly90ZWNoY3J1bmNoLmNvbS8_cD0zMDc3ODc4",
          "title": "Where are investors placing their bets next year? AI, AI, AI.",
          "description": "Investors at TechCrunch Disrupt explained their focus on artificial intelligence and offered advice to founders on how to stand out in a crowded AI field.",
          "link": "https://techcrunch.com/2025/12/19/where-are-investors-placing-their-bets-next-year-ai-ai-ai/",
          "source": "TechCrunch",
          "thumbnail": null,
          "feedId": "aHR0cHM6Ly90ZWNoY3J1bmNoLmNvbS9mZWVkLw",
          "seen": false,
          "saved": false,
          "publishedAt": "Fri, 19 Dec 2025 22:00:00 +0000",
          "updatedAt": null
        }
      ],
      "expectedArticleCount": 20
    },
    {
      "title": "The Verge -  All Posts",
      "url": "https://www.theverge.com/rss/index.xml",
      "file": "the-verge-all-posts__e8d31cec28.xml",
      "ok": true,
      "bytes": 150162,
      "contentType": "application/xml; charset=UTF-8",
      "expectedFeed": {
        "id": "aHR0cHM6Ly93d3cudGhldmVyZ2UuY29tL3Jzcy9pbmRleC54bWw",
        "title": "The Verge",
        "xmlUrl": "https://www.theverge.com/rss/index.xml",
        "image": "https://platform.theverge.com/wp-content/uploads/sites/2/2025/01/verge-rss-large_80b47e.png?w=150&h=150&crop=1",
        "description": "The Verge is about technology and how it makes us feel. Founded in 2011, we offer our audience everything from breaking news to reviews to award-winning features and investigations, on our site, in video, and in podcasts.",
        "lastUpdated": "2025-12-19T21:48:50+00:00",
        "lastPublishedAt": null
      },
      "expectedArticles": [
        {
          "id": "aHR0cHM6Ly93d3cudGhldmVyZ2UuY29tLz9wPTg0MzA3OQ",
          "title": "We found 80 stocking stuffers under $100 that are actually useful",
          "description": "Let’s face it, it’s easy to fixate on the big gifts that crowd around the Christmas tree. However, we’d argue that the true treasures are the small, useful, and thoughtful gifts tucked within stockings. That’s why, for this guide, we’ve pooled together a bunch of tried-and-tested gadgets and goods to help bolster someone’s everyday carry […]",
          "link": "https://www.theverge.com/gadgets/843079/best-stocking-stuffers-christmas-ideas-2025",
          "source": "The Verge",
          "thumbnail": "https://platform.theverge.com/wp-content/uploads/sites/2/chorus/uploads/chorus_asset/file/22461382/vpavic_4547_20210421_0058.jpg?quality=90&#038;strip=all&#038;crop=0,0,100,100",
          "feedId": "aHR0cHM6Ly93d3cudGhldmVyZ2UuY29tL3Jzcy9pbmRleC54bWw",
          "seen": false,
          "saved": false,
          "publishedAt": "2025-12-19T16:48:09-05:00",
          "updatedAt": "2025-12-19T16:48:50-05:00"
        },
        {
          "id": "aHR0cHM6Ly93d3cudGhldmVyZ2UuY29tLz9wPTg0ODQzNQ",
          "title": "ChatGPT will now let you pick how nice it is",
          "description": "OpenAI will now give you the ability to dial up - or down - ChatGPT's warmth and enthusiasm. An update rolling out on Friday gives you the option to choose whether you want \"more\" or \"less\" of these personality traits, or stick with the default. There are also options to tweak how often ChatGPT uses […]",
          "link": "https://www.theverge.com/news/848435/openai-chatgpt-characteristics-update-warmth-enthusiasm",
          "source": "The Verge",
          "thumbnail": "https://platform.theverge.com/wp-content/uploads/sites/2/2025/09/STK414_AI_CVIRGINIA_I__0011_9.png?quality=90&#038;strip=all&#038;crop=0,0,100,100",
          "feedId": "aHR0cHM6Ly93d3cudGhldmVyZ2UuY29tL3Jzcy9pbmRleC54bWw",
          "seen": false,
          "saved": false,
          "publishedAt": "2025-12-19T16:28:08-05:00",
          "updatedAt": "2025-12-19T16:28:08-05:00"
        }
      ],
      "expectedArticleCount": 10
    }
  ]
}
