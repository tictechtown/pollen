<?xml version="1.0" encoding="UTF-8"?><rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0" xmlns:cc="http://cyber.law.harvard.edu/rss/creativeCommonsRssModule.html">
    <channel>
        <title><![CDATA[strava-engineering - Medium]]></title>
        <description><![CDATA[Engineers building the home for your active life. - Medium]]></description>
        <link>https://medium.com/strava-engineering?source=rss----89d4108ce2a3---4</link>
        <image>
            <url>https://cdn-images-1.medium.com/proxy/1*TGH72Nnw24QL3iV9IOm4VA.png</url>
            <title>strava-engineering - Medium</title>
            <link>https://medium.com/strava-engineering?source=rss----89d4108ce2a3---4</link>
        </image>
        <generator>Medium</generator>
        <lastBuildDate>Fri, 19 Dec 2025 22:17:03 GMT</lastBuildDate>
        <atom:link href="https://medium.com/feed/strava-engineering" rel="self" type="application/rss+xml"/>
        <webMaster><![CDATA[yourfriends@medium.com]]></webMaster>
        <atom:link href="http://medium.superfeedr.com" rel="hub"/>
        <item>
            <title><![CDATA[Rain: A key-value store for Strava‚Äôs scale]]></title>
            <link>https://medium.com/strava-engineering/rain-a-key-value-store-for-stravas-scale-7f580f5b4848?source=rss----89d4108ce2a3---4</link>
            <guid isPermaLink="false">https://medium.com/p/7f580f5b4848</guid>
            <category><![CDATA[maps]]></category>
            <category><![CDATA[spark]]></category>
            <category><![CDATA[key-value-store]]></category>
            <category><![CDATA[caching]]></category>
            <dc:creator><![CDATA[Derick Yang]]></dc:creator>
            <pubDate>Fri, 24 Jan 2025 18:02:11 GMT</pubDate>
            <atom:updated>2025-01-31T19:37:19.788Z</atom:updated>
            <content:encoded><![CDATA[<figure><img alt="" src="https://cdn-images-1.medium.com/max/904/1*OZ80K_OVcAp8Opf195cqtw.png" /><figcaption>Much of our heatmaps are built on batch data outputs stored in¬†Rain</figcaption></figure><p>At Strava, we love maps‚Ää‚Äî‚Ääsome of our most loved features are nestled on map surfaces. My team, the Geo team, is focused on building and improving these products. On the Geo and <a href="https://metro.strava.com/">Metro</a> teams, we tend to work with large datasets: aggregations of open source map data via <a href="https://www.openstreetmap.org/">OpenStreetMaps</a>, GPS data points from uploaded activities, third-party datasets for properties like elevation, and beyond. This aggregated dataset eventually turns into Geo features we know and love, like the <a href="https://www.strava.com/maps/global-heatmap">global heatmap</a>, <a href="https://metro.strava.com/">Strava Metro</a>, the <a href="https://support.strava.com/hc/en-us/articles/216918387-Routes-on-Web">routing product</a>, <a href="https://communityhub.strava.com/insider-journal-9/how-to-use-suggested-routes-1498">route suggestions</a>, elevation profiles, and points of interest. We perform these data aggregations in a rather hefty data pipeline, run on a regular cadence to ensure we‚Äôre serving up-to-date geo¬†data.</p><p>One of the Geo team‚Äôs key challenges is <strong>efficiently serving large, immutable (write-once, read-many) datasets</strong> produced by our pipeline. This is particularly hard for compute-intensive use cases like routing,¬†where:</p><ol><li><strong>Write-Optimized vs. Read-Optimized Conflict</strong>: Traditional read-optimized data stores struggle with large batch writes without impacting read performance or introducing significant operational complexity.</li><li><strong>Cost Constraints</strong>: Storing rarely accessed datasets in production databases can be prohibitively expensive‚Ää‚Äî‚Ääespecially for projects like <strong>Strava Metro</strong>, which are accessed sporadically.</li><li><strong>Schema Complexity</strong>: Defining schemas externally from the service that uses them can be costly and inflexible for developers.</li></ol><p><strong>Previously</strong></p><p>Our previous solution to large writes used a combination of datastores: <a href="https://github.com/linkedin/PalDB">PalDB</a> and <a href="https://cassandra.apache.org/_/index.html">Cassandra</a>.</p><p>PalDB is a binary data format ideal for small datasets. The <a href="https://github.com/linkedin/PalDB">README</a> states that it is optimized for ‚Äúside data‚Äù, relatively small datasets you read ‚Äúin passing‚Äù on your service. PalDB is unideal, however, for larger datasets. In our case, since each service deployment required downloading the key-value file from <a href="https://aws.amazon.com/pm/serv-s3/">S3</a>, our deployments were taking upwards of twenty minutes. Slow deployment hindered rapid iteration for developers. Additionally, the collection of PalDB files occupies a hefty amount of memory on every service instance. For an important service like <a href="https://medium.com/strava-engineering/introducing-routemaster-ccecbb47be86">Routemaster</a> at Strava, this means we end up duplicating the data <em>in memory</em> across potentially dozens of server instances.</p><p>Cassandra is advertised as a write-heavy datastore and it can be an effective solution for batch data outputs. Though Strava does still use it as storage for some batch datastores, we can run into problems when we‚Äôre replacing the full dataset on a regular cadence. In our experience, Cassandra writes from Spark require babysitting to ensure we don‚Äôt hit throttling/network/connection limits. Since our builds are full replacements incorporating worldwide changes to the <a href="https://www.openstreetmap.org/">OpenStreetMaps</a> source, this can cause high load to a production datastore.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*CH2xJUpxng75PkCx" /></figure><p><strong>Introducing Rain</strong></p><p>We embarked on a journey to improve our immutable batch data updates by creating a new service that acts as a key-value store for any dataset generated in <a href="https://spark.apache.org/">Spark</a>. We call this service Rain, because it distributes data from the cloud onto client services.</p><p>At its core, Rain behaves analogously to the cache in your operating system, except on a distributed systems level. Just as the OS loads file blocks into cache, Rain loads subsets of your Spark-output dataset on S3 (‚Äúthe filesystem‚Äù) into Redis (‚Äúthe L1/L2 cache‚Äù). Client services retrieve the datasets via a rich client that calls a service. In code, Rain has three primary components: a Spark writer API, a library for reads, and a Thrift service, shown¬†below:</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/830/0*Lnz-DwaitdDPKOKr" /></figure><p>What does this structure enable? First, it allows us to tap into the power of Spark distributed write, which is optimized for <a href="https://parquet.apache.org/">Parquet</a> outputs. Second, it allows us to perform immutable data hot swap by simply changing the reference path for the dataset, which is provided through an admin interface. Third, it helps us save on data costs by using a LRU (least recently used) Redis cache and using a single distributed datastore rather than a duplicated in-memory store on each service instance.</p><p><strong>Writing a Rain¬†table</strong></p><p>Strava uses Apache Spark to run our data pipelines and write Rain tables. For datasets we update regularly, we typically schedule refreshes with <a href="https://airflow.apache.org/">Apache Airflow</a>. We output the data of a fully refreshed table to a clean prefix in S3 and update a file representing a pointer to the table data to point at this new¬†prefix.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*fiK0gdwSolybheCs" /></figure><p>Rain is responsible for regularly checking if this reference data pointer has been updated to point to new table data. At the Rain service level, we use a <a href="https://github.com/ben-manes/caffeine">Caffeine</a> cache to expire the pointer pointing to the old dataset. This enables us to replace the immutable dataset in the background, <em>without redeploying any component of the system</em>. The table pointer update is simply an API call to the Rain server. The server then updates the pointer. When Caffeine expires the pointer at the old dataset, Rain will start reading data from the new¬†dataset.</p><p><strong>Polymorphism</strong></p><p>Key/value pairs in a Rain table can consist of any arbitrary <a href="https://github.com/EsotericSoftware/kryo">Kryo-serializable</a> case classes. This means that services can be responsible for defining their own schemas, without involving a database administrator. We write, store, and transfer data using a byte array format, and clients define the key/value types and ensure they are Kryo serializable. The Spark client and client server reader handle object serialization and deserialization, respectively.</p><p>The client library is responsible for deserializing the byte array results that Rain returns into types that the client can¬†use.</p><p>How do we perform schema changes on a Rain table? A schema change generally requires a service deployment, so simply naming and using a new Rain table and redeploying the service will¬†suffice.</p><p><strong>Partitioning</strong></p><p>‚ÄúWriting a Rain table‚Äù is simply writing homogeneously sized Parquet files in S3, where the schema for the Parquet data is a key-value tuple. We use the basic Spark parquet write API to perform this operation. To write these homogeneously-sized files, we need to assign a partitioner in Spark to conduct a `.repartition` operation.</p><p>We partition by key, using either a hash partitioner against the key, or a range partitioner based on a predefined Ordering of the key. Hash partitioning distributes the keys evenly across all partitions based on a hash function. Range partitioning ensures that keys ‚Äúclose‚Äù to each other based on the ordering are on the same partition. Hash partitioning offers a guarantee of minimized skew, while range partitioning has cache locality benefits for certain read patterns on the read side, which can reduce the number of read¬†queries.</p><p>For some datasets, range partitioning makes more sense because the data is often loaded in ranges. For example, routing edges in Strava‚Äôs <a href="https://www.strava.com/routes/new">routebuilder</a>, which are keyed by ID, have IDs close together <a href="https://medium.com/strava-engineering/strava-metro-scaling-aligned-edges-ffb2379e77dc">when close together geographically</a>. This makes the routing edges dataset a good candidate for range partitioning. The flip side of this is that certain keys may be ‚Äúhotter‚Äù than others at read time. The performance penalty of a hot key, however, is fairly minimal with a cache store like¬†Redis.</p><p>The Spark write client and the Rain read client need to use the same partitioner to be in sync. For hash-partitioned tables, this is fairly straightforward‚Äìwe use the default hash partitioner in Spark. However, for range-partitioned tables, we need to write a separate index that the read client loads to tell the Rain server in which partition to search for a key. Since deserialization happens on the client via the rich Rain client library, computing the ordering also needs to happen on the client. That adds one more responsibility when registering classes with the Rain client library: it has to define an ordering for the¬†keys.</p><p><strong>Reading</strong></p><p>Reading from Rain is fairly straightforward. The client library takes the object key, serializes it into bytes, and makes a request to the Rain service to look up in Redis/S3. If the key is found in Redis, we return it. If not, we load the file from S3 that contains that key. The data is returned in byte array format, and again the Rain client deserializes the bytes into an object that makes sense for the calling¬†service.</p><p>Internally, there are a few bookkeeping constructs to ensure good performance for concurrent reads. If there are concurrent requests for the same key, we use <a href="https://twitter.github.io/finagle/guide/PartitionAwareClient.html">ThriftMux consistent hashing</a> to make sure that we only load the S3 file into Redis once. Consistent hashing ensures that only one service instance is responsible for loading the S3 file associated with a key. We use a singleton <a href="https://github.com/ben-manes/caffeine">Caffeine cache</a> on individual service instances to maintain a record of which requests to S3 are currently being made. Conveniently, an AsyncCaffeineCache implicitly provides a clean locking mechanism for our file¬†loads.</p><p>We do bookkeeping on Rain server so we can lazily refresh full immutable tables.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*BS9NBFR56XdEteup" /></figure><p><strong>The Cache</strong></p><p>There are several levels to the cache in Rain. S3 is the slowest read, followed by Redis, followed by Caffeine cache directly on the service client. We ideally want to have as much data as possible as close to the service client as possible, but, of course, we operate in a world with limited resources. Each service has its own SLA and resourcing requirements. Rain is designed to be flexible to each of these constraints.</p><p>As with any caching system, heterogeneity in read patterns on Rain helps provide good performance. The ideal distribution of data stored in a Rain table will have both frequently accessed and infrequently accessed data. Data stored in ordered and partitioned tables helps increase diversity of access SLAs, since partitions in an ordered table will be accessed less frequently. For example, routing data on roads where it is currently nighttime (and therefore not many users) does not need to be cached. Another example: we generally should not need to cache satellite imagery of zoomed-in parts of the ocean (and we expect that data to be evicted first), whereas it would make sense to store in cache an image of Central Park. Variation of SLAs on data retrieval within a cache reduces the amount of cache evictions.</p><p>Basically, we can happily exceed the storage size of the cache as long as we don‚Äôt have high-usage data filling the whole cache and causing eviction¬†churn.</p><p><strong>Local mode</strong></p><p>Rain unlocks the ability to run local servers against production datasets. We can set up local runs of service instances to point at a Rain server. Practically, this means we can avoid loading the entirety of a dataset into memory for local runs, meaning local service instances come up much more¬†quickly.</p><p>When running in local mode, Strava engineers can pick and choose which Rain tables they want to load from the remote Rain service, and which Rain tables they want to interact with directly. We introduced a Rain table mode to use Caffeine for local caching only. One use case of this mode is when developers are locally iterating on a job that outputs to a Rain table. The developer can write to the Rain table locally in a Spark run and read it locally without having to productionalize their dataset. On the Geo team, we use these local Spark runs to output data specific to a certain region of the world, which is helpful for QA when developing new features.</p><p><strong>Admin UI</strong></p><p>Of course, with a tool like Rain, it‚Äôs important to have visibility into what datasets are being used. It‚Äôs important to investigate cache metrics and understand data access patterns for certain datasets. We built an internal UI for this that lets us perform immutable table refreshes, investigate access patterns, warm our Redis cache, and clean up our Redis¬†cache.</p><p>Below is a screenshot from the admin UI which shows a distribution of the access times of keys by table in¬†Redis.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*IroSLixfuyBoFFPv" /></figure><p><strong>Cons</strong></p><p>One downside we‚Äôve seen is an increase in cross-AZ network usage, but the increased spend there is offset by the savings from service memory reduction. We had budgeted for small increases in latency, but we soon discovered that Rain and Redis reads caused little to no latency bump in client service responses.</p><p>Another downside we found was a challenging migration from synchronous data retrieval to Future-based asynchronous retrieval of Rain table data. Finagle Thrift client responses are always asynchronous, whereas PalDB calls are always synchronous, so our move to Rain meant that several workflows needed to be refactored to use Futures. This required a bit of thread pool tuning and a better understanding of concurrency control on client services. Some algorithms (e.g. A* graph search) that inherently require a large number of serial steps, each needing a data lookup, are inherently hard to¬†migrate.</p><p>Provisioning a large Redis cluster has a cost, too. By our calculations, this is still offset by our savings on cloud computing cost.</p><p><strong>Conclusion</strong></p><p>Rain is still young, but so far, we‚Äôve seen quite a lot of improvements:</p><ul><li>We‚Äôve seen faster iteration time on deployments (from 20 minutes to 1 minute deploy time) and enabled local mode for large datasets. We hope that Rain simplifies development going forward when considering caching solutions at¬†Strava.</li><li>We reduced the memory footprint of some of our largest services by orders of magnitude.</li><li>We saved tens of thousands of dollars in EC2 computing costs.</li><li>We‚Äôve enabled immutable table refresh in the background</li><li>We‚Äôve enabled distributed write for immutable datasets from¬†Spark</li></ul><p>Overall, Rain is a big step forward in the way that Strava can serve large datasets. The biggest benefit we get from Rain is that it lets us serve terabyte-scale Spark-derived datasets at low latency. This is huge for our product roadmap, and I‚Äôm excited to see what we‚Äôll do with¬†it.</p><p>Interested in joining Strava? See the <a href="https://www.strava.com/careers">careers¬†page</a>.</p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=7f580f5b4848" width="1" height="1" alt=""><hr><p><a href="https://medium.com/strava-engineering/rain-a-key-value-store-for-stravas-scale-7f580f5b4848">Rain: A key-value store for Strava‚Äôs scale</a> was originally published in <a href="https://medium.com/strava-engineering">strava-engineering</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Scaling Challenge Leaderboards for Millions of Athletes]]></title>
            <link>https://medium.com/strava-engineering/scaling-challenge-leaderboards-for-millions-of-athletes-9ab09ef01381?source=rss----89d4108ce2a3---4</link>
            <guid isPermaLink="false">https://medium.com/p/9ab09ef01381</guid>
            <category><![CDATA[system-design-concepts]]></category>
            <category><![CDATA[programming]]></category>
            <category><![CDATA[sql]]></category>
            <category><![CDATA[scalability]]></category>
            <category><![CDATA[relational-databases]]></category>
            <dc:creator><![CDATA[Mike Kasberg]]></dc:creator>
            <pubDate>Thu, 18 Jan 2024 17:01:41 GMT</pubDate>
            <atom:updated>2024-01-18T17:01:40.788Z</atom:updated>
            <content:encoded><![CDATA[<p><a href="https://www.strava.com/challenges">Strava challenges</a> offer a fun way for athletes to compete against themselves and others! Back in 2020, our legacy challenge leaderboard system was running into bottlenecks and scalability problems on a regular basis, and we often found ourselves putting out fires to keep the system stable. In late 2020 and early 2021, I worked on a project to replace the old leaderboard system with a new one that could handle a much larger number of athletes competing in challenges. This blog post is about that project. I drafted most of this post when the project wrapped up in 2021, but didn‚Äôt get it published before I went on paternity leave‚Ää‚Äî‚Ääand then I forgot about it. I think the project was interesting and worth sharing, so I‚Äôm glad I finally remembered my draft (three years later ü´£) and found some time to put in the finishing touches and get it published! Enjoy!</p><figure><img alt="A group of cyclists on a gravel ride" src="https://cdn-images-1.medium.com/max/1024/1*sTekNCekHeM10HHYK99Icg.jpeg" /></figure><p>In January 2020, Strava‚Äôs monthly 5K running challenge attracted more than half a million participants for the first time. This was a big milestone, <strong>doubling</strong> the participation from just a year earlier when we had only a little more than 250,000 participants in the January 2019 5K challenge. But we weren‚Äôt done growing! Just 5 months later, our challenge participants <strong>doubled again</strong> and we broke <strong>1 million participants</strong> in a monthly challenge for the first time with the May 2020 5K, where 1.2 million Strava athletes participated! In less than a year and a half, the number of athletes participating in Strava‚Äôs monthly challenges had quadrupled.</p><p>As you can imagine, the increase in challenge participation came with a significant increase in load on our systems. In particular, we were beginning to approach the limits of what our existing challenge leaderboard system could handle. If the number of challenge athletes participating in our monthly challenges were to double again, our challenge leaderboard system wouldn‚Äôt handle it well. We needed to do something to improve the way our leaderboard system scaled with more challenge participants.</p><h3>The Old Leaderboard System</h3><p>Strava‚Äôs existing challenge leaderboard system wasn‚Äôt necessarily designed poorly, but it also wasn‚Äôt designed for the scale we‚Äôre currently operating at. The original challenge leaderboard implementation was designed about 8 years earlier, in 2013. It met Strava‚Äôs needs when it was designed, and operated pretty well for more than 8¬†years.</p><p>The original challenge leaderboard system was implemented primarily using <a href="https://redis.io/">Redis</a>. Specifically, the leaderboard made use of Redis‚Äôs <a href="https://redis.io/topics/data-types#sorted-sets">sorted sets</a>. This is a pretty well-known use case, and there‚Äôs plenty of documentation available online about how you might implement a leaderboard using a Redis sorted set. There‚Äôs a good chance that some of the other online leaderboards you might be familiar with are using a Redis sorted set in the background. But in addition to using Redis sorted sets (which can scale well accessed in an efficient manner), the leaderboard system also made use of less efficient storage and data access patterns in Redis, and these less efficient access patterns ultimately led to the inability of the system to handle more athletes.</p><p>As the old leaderboard system scaled up to more than a million athletes, limits to the scalability of the system became clear. Due to some inefficient data access patterns in our code (that worked fine at a smaller scale), we began running into scalability problems somewhat regularly. One of the inefficient data access patterns we discovered in our old leaderboards code involved the use of a redis hash to store data related to an athlete‚Äôs leaderboard entry. We discovered old code that would call <a href="https://redis.io/commands/HGETALL">HGETALL</a> on a hash that contained <em>all</em> leaderboard members for a given challenge. HGETALL is an O(N) operation, so the performance got significantly worse as more athletes joined our challenges.</p><p>One of the most memorable incidents was a problem related to the inefficient HGETALL operation that happened near the beginning of the month (either on the first of the month or on the first weekend of the month). With about a million athletes signed up to compete in our monthly 5k challenge, tens or even hundreds of thousands of athletes would complete the challenge on the same day. And when an athlete completed the challenge, we would send them an email with some of their challenge stats. This email, triggered when any athlete completed a challenge, was one of the code paths to the inefficient HGETALL operation. So if too many athletes completed the challenge at approximately the same time, it could overwhelm the CPU on our Redis instance and cause Redis queries to fail. This was bad because it not only caused the query for the challenge completion email to fail (which was processed in the background and could be retried), but also caused other queries to fail. For example, queries made by athletes trying to view the leaderboard on strava.com or in our app might also fail. Thus, if too many athletes completed a challenge at roughly the same time (like when hundreds of thousands of athletes go run a 5K on a beautiful Saturday morning), it could cause parts of strava.com to become temporarily unavailable. Of course, as software engineers, it‚Äôs our responsibility to improve the system so this can‚Äôt¬†happen.</p><p>Besides our immediate performance and reliability concerns, we also had a small wishlist of other improvements we could make to our challenge leaderboard system. The original leaderboard system was designed to be ephemeral. That is, all of the data stored in the leaderboard was also stored in more durable databases within our system. If Redis crashed and we lost our leaderboard data, we‚Äôd be able to re-compute the entire leaderboard in a relatively short amount of time. Well, that <em>was</em> true when we had tens of thousands of athletes on our challenge leaderboards. It‚Äôs no longer true with more than a million athletes on a single leaderboard. While a leaderboard with under a hundred-thousand athletes could be regenerated in about an hour, a leaderboard with a million or more athletes might take more than a day to rebuild. To mitigate the risk of losing our leaderboard data, we wanted to store leaderboards in something more durable than Redis. (It‚Äôs also possible to make Redis more fault-tolerant with replication and backups, but that too requires engineering effort and we weighed this against other solutions.)</p><p>In addition to our concerns about our ability to recover leaderboard data after data loss, we were also thinking about the long-term storage of leaderboard data. Strava challenge leaderboards are different from many other online leaderboards in that once the challenge is over, the leaderboard is in a more-or-less permanent state. Old leaderboard data won‚Äôt be accessed nearly as frequently as current leaderboard data, but we still want to be able to efficiently query old leaderboards so they‚Äôre fast when an athlete views them. Redis is an in-memory data store, and while its sorted sets make a lot of sense for a leaderboard that receives many updates, they make less sense for leaderboards that are infrequently modified and infrequently accessed. In particular, there‚Äôs no reason a leaderboard from 2014 needs to be in memory instead of on a disk, and using a traditional disk-based database would be preferable for many reasons including storage cost and ease of¬†backup.</p><p>So, our old challenge leaderboard system had scalability problems that we knew we needed to address. We could do several in-place fixes or upgrades to make the old system work much better, and we considered doing so. But we were also looking ahead to the future. We were well into the process of migrating our old monolithic Rails application to a <a href="https://medium.com/strava-engineering/mesos-at-strava-5ac98d00dacf">service oriented architecture</a>, and we already had a service for challenges. Ideally, our new leaderboard solution would not only address the scalability issues in our old system, but would also be a step in the direction of a more service-oriented approach.</p><h3>Gauntlet</h3><p>Gauntlet is Strava‚Äôs new challenge back-end service (named after <a href="https://en.wikipedia.org/wiki/Gauntlet_(glove)#%22Throw_down_the_gauntlet%22">throwing down the gauntlet</a>). Actually, it isn‚Äôt terribly new anymore‚Ää‚Äî‚Ääit‚Äôs been operating in production since September 2019 when it powered <a href="https://www.strava.com/challenges/the-escape-plan">The Escape Plan</a> (Strava‚Äôs first ‚Äústreak‚Äù challenge). And we‚Äôve written about components related to Gauntlet on this blog before. Mindy and Zack have written about a service to store rich activity data (<a href="https://medium.com/strava-engineering/a-richer-activity-part-1-58b6ce4bde6a">Part 1</a>, <a href="https://medium.com/strava-engineering/a-richer-activity-part-2-f0987c538a1f">Part 2</a>), and Gauntlet is a client of that service. And our intern Clara (now a full-time employee!) wrote about <a href="https://medium.com/strava-engineering/scala-practices-that-powered-streak-challenges-64a61f400397">working on Gauntlet</a> last summer. Gauntlet has already provided big improvements to Strava‚Äôs challenge ecosystem. Aside from introducing streak challenges, Gauntlet allows us to run challenges for any type of activity (old challenges only worked for runs and rides). Gauntlet also allows us to run challenges where activities that aren‚Äôt publicly visible can count toward the challenge badge. And of course, gauntlet scales much better than our old challenge implementation did, so challenges with a million or more athletes aren‚Äôt a¬†problem!</p><p>But Gauntlet had always been limited because it didn‚Äôt support leaderboards. When we started building Gauntlet in 2019, we wanted first and foremost to experiment with new types of challenges. We experimented with non-traditional formats like streak challenges and challenges that allow a wider variety of activity types, making it easier for more athletes on Strava to participate. Our experiments with Gauntlet were successful, but it was time to double down on our investment and make Gauntlet better so it could serve as a foundational service for <em>all</em> challenges on Strava. Leaderboards are the heart and soul of challenges on Strava, and they create the competition that motivates many of us to get out and move. Adding leaderboard functionality to Gauntlet would not only make Gauntlet-powered challenges better, it would also let us use Gauntlet to power challenges that were powered by our legacy challenge service <em>specifically because they need leaderboards</em>. By designing a new, efficient leaderboard system for Gauntlet, we could stop using our old, inefficient leaderboards and improve the reliability of our¬†system.</p><h3>Designing a Leaderboard Solution</h3><p>We considered a very wide variety of possible approaches to implement leaderboards on Gauntlet. We spent several months (not full-time) brainstorming different ideas, researching them, and prototyping some things. We considered solutions that used Redis sorted sets, similar to our previous approach. We considered solutions that use a relatively new statistical data structure called a <a href="https://github.com/tdunning/t-digest">t-digest</a>. We briefly considered other non-traditional data stores that might be well suited for this purpose. And we considered solutions that use a traditional MySQL data store, like we‚Äôre familiar with from so many other parts of our application. When comparing different approaches, scalability was one of our main concerns. In particular, we wanted to ensure that our system would scale sub-linearly (less than O(N)) with the number of athletes on a leaderboard so that our new system wouldn‚Äôt encounter performance problems as our challenge participation continued to¬†grow.</p><p>When designing a system like this, it‚Äôs important to consider how the system will be used. We understood our use cases pretty well. Our leaderboard system needed¬†to:</p><ul><li>Add an athlete to the leaderboard when they join a challenge.</li><li>Remove the athlete from the leaderboard when they leave a challenge.</li><li>Update an athlete‚Äôs ‚Äúscore‚Äù when they upload new activities.</li><li>Display the first leaderboard page¬†quickly.</li><li>Efficiently page through the leaderboard.</li><li>Efficiently determine an athlete‚Äôs rank, given their¬†score.</li></ul><p>Redis seemed to fit the bill pretty well, but we weren‚Äôt confident about our ability to handle data recovery with Redis and we also didn‚Äôt want to use Redis for long-term storage of challenges that had ended‚Ää‚Äî‚Ääwhich still need accurate leaderboards but receive much less traffic than active challenges. If we wanted to use Redis, we‚Äôd need to design some way to export data to another data store either continuously or after the challenge has ended. So we didn‚Äôt rule out Redis as an option, but we weighed these factors in our decision.</p><p>MySQL was also an appealing option. Many of our engineers are very familiar with it, and our foundation (ops) team is also familiar with it. It‚Äôs a good solution for long-term storage at the scale we need, and handles <em>almost</em> all of our use cases very well. Traditional SQL databases like MySQL are good at performing CRUD operations while keeping a data set ordered (e.g. by using an index). The one problematic use case for MySQL is efficiently determining an athlete‚Äôs rank. (More on that below.) Ultimately, we determined that MySQL fit our needs best and was also a system we were very comfortable with. (We know the system well, we have engineers who are experts with it, and we understand its failure modes and limitations and how to work around¬†them.)</p><h3>Querying Rank from MySQL Efficiently</h3><p>When we need to determine an athlete‚Äôs rank, we already know the athlete‚Äôs score (their distance in a distance-based challenge or speed in a speed-based challenge). So we need to query our database to get the rank of that particular score. Querying for the ‚Äúrank‚Äù of a ‚Äúscore‚Äù is really just counting the number of entries (rows) ahead of that score on the leaderboard. The MySQL query might look something like¬†this:</p><pre>SELECT count(*) FROM leaderboards WHERE challenge_id = ? AND score &gt; ?</pre><p>We can make this query more efficient by using an index on (<strong>challenge_id</strong>, <strong>score</strong>). When that index exists, MySQL will use it to avoid the need to sort the data each time it performs the query. Great! But there‚Äôs still a problem that can make this query pretty inefficient. Even when using the index, MySQL will perform this query by counting scores that match the where clause. This will be very fast for the athletes near the top of the leaderboard, where it will only need to count a few rows. But for athletes near the bottom of the leaderboard, it will need to count <em>most of the rows in the leaderboard</em>. In other words, this query scales as O(N) with the number of athletes on the leaderboard, and we‚Äôre looking for better performance than that! We need to improve the performance of this query if we‚Äôre going to use this method at¬†scale.</p><p>But there are some tricks we can use to make the performance better! One simple technique that could work well is to ‚Äúcache‚Äù the score at specific ranks. For example, every 1,000 ranks, we could store what the score is for that rank. So we know the score for rank 1,000, rank 2,000, and so on. When we need to look up the rank for any score, we first look up the rank for the worst cached score that‚Äôs better than ours. That looks like¬†this:</p><pre>SELECT score, rank FROM leaderboard_cache WHERE challenge_id = ? AND score &gt; ?<br>ORDER BY score ASC LIMIT 1</pre><p>After finding that rank, we can query the full leaderboards table for the rank of the exact score we care about, but we can avoid counting records up to our cached score‚Ää‚Äî‚Ääwe already know the rank of that score. That query looks something like¬†this:</p><pre>SELECT count(*) FROM leaderboards<br>WHERE challenge_id = ? AND score &lt; ? AND score &gt; ?</pre><p>In other words, we count the (small number of) records between the cached score and the exact score we want to look up, and add that count to the cached rank to get the exact rank. It‚Äôs an O(log N) operation to find <em>which</em> rows to count (using the index), and an O(N) operation to actually count them. But we know we won‚Äôt count more than 1,000 rows, so the O(N) part is actually bounded by O(1,000), so we can treat it as constant time! The cache lookup is also an O(log N) operation, so our complete rank lookup can be performed in O(log N) time for a leaderboard with N athletes. Using this approach lets us use the MySQL option with sub-linear performance for all of our data access¬†methods!</p><p>Of course, there‚Äôs some additional complexity when we update information in the leaderboards table. We not only need to update the leaderboards table itself, but we also need to update the leaderboard_cache table so it remains accurate. Without going into too much detail, we do this process in batches for efficiency. When we get a batch of leaderboard updates, we calculate the changes to our cached ranks for the batch. For example, if we‚Äôve cached rank 1,000 with a score of 8,000m (distance), and 3 athletes in the batch have done better than that score, we know that the cached rank for the score of 8,000m should now be 1,003. Thus, when we process a batch of updates, we update each of our cache rows at most once. When necessary, we perform an additional rebalancing step to keep our caches spaced roughly how we want them, but we allow plenty of variance here so this doesn‚Äôt happen too often. And we can tune the system by adjusting our cache spacing, batch size, and rebalancing operation.</p><h3>Rollout</h3><p>When we release big changes (or even small changes) at Strava, we like to do so in a way that‚Äôs as safe and controlled as possible. This leaderboard upgrade was no exception, and we used a dark launch to roll this out. Strava has a mature ‚Äúfeature switches‚Äù platform that helps us control access to different code paths and perform dark launches. In this case, we enabled leaderboard writes to our new leaderboards backend on a per-challenge basis, and enabled database writes on several production challenges before the leaderboard was visible anywhere. This allowed us to make sure our backend could take a full volume of writes for many concurrently running challenges before we ever rendered any leaderboard data to the front-end. When we were ready, we used our feature switches to enable the leaderboard front-end for select internal users on our team while we put the finishing touches on things to wrap up development. This allowed us to get early feedback from our product owners and internal users on a live version of the product before athletes could see¬†it.</p><p>Our internal rollout was a success, and we began enabling our new Gauntlet-powered leaderboards on some athlete-visible challenges in February, 2021. You might not have even noticed the rollout‚Ää‚Äî‚Ääthis was primarily a backend change, so the new leaderboards look very similar to the old ones on the web and identical to the old ones in our mobile apps. They have essentially the same functionality as our old leaderboards, but the new ones are much faster, and work on a wider variety of challenge configurations!</p><h3>Results</h3><p>It‚Äôs hard to overstate the performance impact of the new leaderboard system. In one test, the old leaderboard system took more than 40 seconds to load the United States country leaderboard for a monthly running challenge. By contrast, a roughly-equivalent monthly running challenge on the new leaderboard system loaded the equivalent United States country leaderboard in under 250ms. On average, the response time of the new system (in blue on the graph below) is more than ten times faster than the response time of the old system (in green). (Note the log scale on the¬†graph.)</p><figure><img alt="A graph comparing the response time of the old and new challenge leaderboard systems" src="https://cdn-images-1.medium.com/max/1024/0*gXEanKNKGduviMiQ" /><figcaption>Mean Leaderboard Response Time (ms); Green: Old, Blue:¬†New</figcaption></figure><p>When a website or mobile app page takes more than ten seconds to load, it feels broken, so the performance improvements we‚Äôve made to our leaderboards make our website and app better in a meaningful way, even though we don‚Äôt necessarily expect a lot of people to notice when something simply works faster. In addition to the performance gains, our new leaderboards are an investment in our Gauntlet backend service as a platform to power challenges at Strava, and should help us continue to build new and exciting challenge features well into the¬†future!</p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=9ab09ef01381" width="1" height="1" alt=""><hr><p><a href="https://medium.com/strava-engineering/scaling-challenge-leaderboards-for-millions-of-athletes-9ab09ef01381">Scaling Challenge Leaderboards for Millions of Athletes</a> was originally published in <a href="https://medium.com/strava-engineering">strava-engineering</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[AN EVENTFUL SUMMER AT STRAVA]]></title>
            <link>https://medium.com/strava-engineering/an-eventful-summer-at-strava-5692882e5f4f?source=rss----89d4108ce2a3---4</link>
            <guid isPermaLink="false">https://medium.com/p/5692882e5f4f</guid>
            <category><![CDATA[software-engineering]]></category>
            <category><![CDATA[data-platforms]]></category>
            <category><![CDATA[data-engineering]]></category>
            <dc:creator><![CDATA[Bisman Sodhi]]></dc:creator>
            <pubDate>Mon, 08 Jan 2024 20:19:46 GMT</pubDate>
            <atom:updated>2024-01-08T20:19:46.882Z</atom:updated>
            <content:encoded><![CDATA[<p>Hi my name is Bisman and I studied Computer Science at University of California, Santa Barbara. During summer of 2022, I had the most amazing experience working as a Software Engineer Intern on Strava‚Äôs Data Platform Team. In the first fews weeks, I learned the tools my team uses and then spent the rest of the time working on my¬†project.</p><h3>TRACKING BAD¬†EVENTS</h3><p>For my major summer project, I created a data pipeline that pulls user behavior data out of external storage and persists it in our data warehouse. Strava uses a service called <a href="https://snowplow.io">Snowplow</a> to collect this user behavior data, like loading a club page or uploading a profile photo. Sometimes, this data fails to match the schema that we‚Äôve set, and a piece of data that fails this schema validation is called a bad event. Previously, these bad events were temporarily stored in an Elastic Search. Persisting this data in <a href="https://www.snowflake.com/en/">Snowflake</a>, our data warehouse, makes it accessible to a wider audience. It also makes it easier to incorporate the bad events data with other services used at¬†Strava.</p><p>To start my project, I created a directed acyclic graph in <a href="https://airflow.apache.org">Apache Airflow</a>, a scheduling framework, using python that extracts bad events data from the <a href="https://aws.amazon.com/s3/">S3</a>, AWS‚Äôs storage service, buckets on a daily cadence. This data was stored as gzip files on S3 which I decompressed and stored the data as JSON blobs. As I was working with billions of rows of data, it was important to maintain data integrity and take measures in case data failed to load from S3. Therefore, I loaded data into a staging table in Snowflake. The staging table ensured that if loading from S3 failed, the production table would remain untouched. This data was then loaded into the production table free of any partial data. After all the data was loaded into the production table, I created six view tables because there were six different types of bad events stored in the production table.</p><p>I collaborated with our stakeholders‚Ää‚Äî‚Äädata analysts‚Ää‚Äî‚Ääthroughout this process to craft tables based on their inputs. Since the JSON information in each of the bad events data contained different schemas, I extracted unique information from each type. I chose to materialize them as SQL view tables to reduce redundancy of data and decrease latency to query the data. After data was aggregated in the appropriate tables, I created a dashboard on Tableau that creates visuals on the number of bad events and displays important metrics. I collaborated with all members of my team throughout my project to discuss timelines, progress, road blocks, and next¬†steps.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/465/0*ZoeX3C7NaP2wOOOf" /><figcaption>Visual representation of the¬†pipeline</figcaption></figure><h3>TRACKING GOOD ‚ÄòEVENTS‚Äô, TOO</h3><p>My internship was not all about bad events. There were plenty of opportunities to enjoy good events like JAMS and my team‚Äôs offsite meet up in the San Francisco office.</p><p>JAMS is Strava‚Äôs week-long hackathon. Everyone at Strava enthusiastically participates at JAMS and creates features that range from super useful for the app to something just for fun. It was an incredible experience where I worked with engineers and interns across different teams to integrate Spotify to Strava. The other interns and I would hop on a zoom call together and try to debug scala code, which I also learnt during JAMS! I also created a database to store an athlete‚Äôs information, the activity during which they played a song, and a list of songs they have played so¬†far.</p><p>Although this internship was fully remote, my team organized a week long offsite meeting at the San Francisco office. The Strava office is beautiful and exactly how you would imagine it‚Ää‚Äî‚Ääindoor gym, a room full of bikes and too many snacks and coffee flavors. During this time, my team and I worked in the mornings, then spent the afternoons making wood boards as a team building exercise, and later enjoying dinner together.</p><p>This internship was an intense and rewarding experience filled with opportunities to learn skills beyond my project guidelines, develop non-technical skills and learn about how my team‚Äôs work supports¬†Strava.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/465/0*H7cMF8yaZALykpSc" /><figcaption>Great events</figcaption></figure><h3>Acknowledgement</h3><p>Thank you to my manager, Kau, for guiding throughout my internship, trusting me to lead the discussions with our stakeholder, giving me opportunities beyond programming to grow and setting me up for¬†success.</p><p>Thank you Alaena for mentoring me, reviewing my code, providing me clarity on the project, and always being there to guide¬†me.</p><p>Shoutout to the rest of the team‚Ää‚Äî‚ÄäDaniel, Eric, Alex and Stephen for making my internship a memorable experience, reviewing my PRs, answering all my questions on Slack and Zoom, and for all the wonderful memories during the team‚Äôs offsite meet up in San Francisco.</p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=5692882e5f4f" width="1" height="1" alt=""><hr><p><a href="https://medium.com/strava-engineering/an-eventful-summer-at-strava-5692882e5f4f">AN EVENTFUL SUMMER AT STRAVA</a> was originally published in <a href="https://medium.com/strava-engineering">strava-engineering</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Amazing Summer on ML Team, Search + Recommendation]]></title>
            <link>https://medium.com/strava-engineering/amazing-summer-on-ml-team-search-recommendation-308223bb2b75?source=rss----89d4108ce2a3---4</link>
            <guid isPermaLink="false">https://medium.com/p/308223bb2b75</guid>
            <category><![CDATA[search]]></category>
            <category><![CDATA[maching-learning]]></category>
            <category><![CDATA[recommendations]]></category>
            <dc:creator><![CDATA[Shuyi Li]]></dc:creator>
            <pubDate>Wed, 08 Nov 2023 01:24:23 GMT</pubDate>
            <atom:updated>2023-11-08T01:24:23.882Z</atom:updated>
            <content:encoded><![CDATA[<p>First and foremost, I express my gratitude for stopping by my corner of the internet! I trust that the content that follows will provide valuable insights and prove beneficial to individuals interested in the Machine Learning Engineer(MLE) internship opportunity at Strava or just general ML¬†work.</p><blockquote><strong>About me</strong></blockquote><p>Greetings from Shuyi! Currently a fifth-year Ph.D. candidate in Statistics at ASU, I am thrilled to be embarking on an MLE Internship at Strava, Pearl in¬†Ocean!</p><p>Despite my passion for hiking and frequent search for routes, I hadn‚Äôt yet come across the Strava App (a missed opportunity indeed). Serendipitously stumbling upon Strava while exploring intern positions, I delved into research, instantly captivated by what this company has to offer. The resoundingly positive reviews and the enthusiasm radiating from Strava‚Äôs employees heightened my eagerness to dive into this Strava experience. Here marks the commencement of my summer¬†journey!</p><blockquote><strong>About ML¬†team</strong></blockquote><p>The team‚Äôs mission revolves around providing machine learning-driven functionalities and expanding the scope of personalized interactions within Strava‚Äôs ecosystem. The ML team has successfully introduced an array of remarkable features, exemplified by the following:</p><ul><li>Route Photos (with Geo¬†Team)</li><li>Suggested Follows (with Growth¬†Team)</li><li>Challenge Recommendation (with Events¬†Team)</li><li>and more</li></ul><blockquote><strong>About My¬†Project</strong></blockquote><p>Referred to as the ‚ÄúPost <strong>Search</strong> and <strong>Recommendation</strong> Prototyping,‚Äù this constitutes a crucial technological advancement for the future of the Strava App. Allow me to provide a separate introduction for¬†each.</p><blockquote><strong><em>Search</em></strong></blockquote><p>Delivering<strong> </strong>Strava‚Äôs <strong>relevant and high-quality content based on the user‚Äôs queries, ex: ‚ÄòWhat‚Äôs the scenic route in Bay Area‚Äô</strong>. Which would be very useful¬†to:</p><ul><li><strong>Help users find</strong> applicable interesting information and relevant content which are hard to find¬†before;</li><li>Analyze query to <strong>understand user¬†needs</strong></li></ul><p>Within the Strava App, posts play a pivotal role, enabling us to share glimpses of our daily lives, undiscovered trails, and breathtaking views, while fostering interactions with fellow users. Consequently, we leverage all post data(&gt;4 million) for our prototyping project, with the potential for a comparable search mechanism to extend to elements like the ‚ÄúClub search bar,‚Äù ‚ÄúRoute search bar,‚Äù and¬†beyond.</p><p><strong><em>Architecture(Prototyping)</em></strong></p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*NOXtfh_sQYE-Retp0X-lYw.png" /></figure><p>In essence, the search approach involves the extraction and conversion of each post into a numerical vector, alongside the conversion of the user‚Äôs search query or question into a vector as well. Subsequently, all the vectors are compared using a ‚Äúmatching engine‚Äù via a distance metric. It is important to note that the proximity between two vectors indicates a closer alignment in meaning. Through this process, we can effectively identify content that is relevant to the given search¬†query.</p><ol><li>Choose Embedding/Natural Language Processing(NLP) model paragraph -&gt; numerical embeddings, ‚ÄòI love Strava!‚Äô ‚Üí [1, 2,¬†9];</li><li>Construct Vector Database(DB)‚Ää‚Äî‚ÄäVertex AI matching engine of Google Cloud Platform(GCP);</li><li>Given the search query(‚Äòwhere is the best route for San Francisco‚Äô), the post which is highly relevant to the query would be retrieved by Vector DB in real-time.</li></ol><blockquote><strong><em>Recommendation</em></strong></blockquote><p>If a user tells us explicitly he/she is interested in skiing and hiking, and is interested in finding peers to explore new trails together, are we able to <strong>connect the relevant clubs, posts, and routes to this user</strong>? By providing unbounded recommendations, we aim¬†to:</p><ul><li>Improve <strong>new user experience</strong>;</li><li><strong>Increase engagement</strong>, especially engagement between 2 users with no connection;</li><li><strong>Inspire creators</strong> to amplify their posting frequency by providing increased exposure through recommendations. This conclusion is based on the hypothesis that creators would be inclined to post more if they receive a greater number of clicks, kudos, or comments from non-connected users.</li></ul><p>We use the posts data(100000 in 2023 after filtering) for the prototyping project but a similar recommendation mechanism can also be applied ‚ÄúPost curation/ranking‚Äù, ‚ÄúClub recommendation‚Äù, ‚ÄúRoute description/recommendation‚Äù and¬†more.</p><p><strong><em>Architecture(Prototyping)</em></strong></p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*TynQMwlux2KIS6HoQb1v8Q.png" /></figure><p>In summary, the key idea is to extract and convert each post to a vector and convert the user‚Äôs explicit inputs/preferences to a vector. All the vectors then can be compared within the same domain via a distance metric, i.e. the closer the two vectors are, the closer meaning they carry. This way we are able to find relevant content with respect to the user interests. The diagram above shows the components of this prototyping project.</p><ol><li>Choose Embedding Model word/post -&gt; numerical embeddings, ‚ÄòI love Strava!‚Äô ‚Üí [1, 2,‚Ä¶,¬†9]</li><li>Classify posts(100000 posts here for demo), obtain top representation for each cluster/topic</li><li>Recommend post based on preferred activities(hike/run/etc.) or goals(‚ÄúTrack my activities and workouts‚Äù) via ‚ÄúNew Reg Intent¬†Survey‚Äù</li></ol><blockquote><strong>Team Offsite</strong></blockquote><p>Embark on a scenic journey along the ‚ÄúVista Trail‚Äù(<strong>picked by Strava </strong><a href="https://www.strava.com/routes/3116741709062223292">https://www.strava.com/routes/3116741709062223292</a>), accompanied by the ML + Data Platform Engineer Team. The adventure continues with an engaging exploration of each team member‚Äôs enneagram type, followed by an exciting round of Axe Throwing‚Ää‚Äî‚Ääa truly unique experience!</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*r7hDnkbDtNDbs7jCBFWRPw.jpeg" /><figcaption>hike ML+Data Platform¬†Team</figcaption></figure><p><strong>Big Shoutouts:</strong></p><p>I want to shout out to my manager &amp; mentor Lucinda, teammate Shuyun, Dan, Jun, and PM Dustin! Lucinda‚Äôs unwavering commitment to guiding me through challenges and keeping me aligned as a MLE has been invaluable. Her wealth of knowledge shines through, and she consistently addresses my inquiries with patience. The team‚Äôs responsiveness and eagerness to aid me in various capacities, such as integrating GCP with SnowFlake, restructuring backfill logic, and comprehending business intricacies while infusing domain expertise, has been truly remarkable. Their guidance has streamlined everything, and I‚Äôm profoundly thankful for the wealth of insights they‚Äôve¬†shared.</p><p>Furthermore, I‚Äôve gained valuable perspectives from engineers spanning different teams, including Analytics, Data Platform, and Search. Their generous assistance in familiarizing me with their services, along with the time they‚Äôve taken to connect and elucidate their projects‚Äô contributions to Strava‚Äôs overarching goals, has been immensely enriching.</p><p>TO BE CONTINUED</p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=308223bb2b75" width="1" height="1" alt=""><hr><p><a href="https://medium.com/strava-engineering/amazing-summer-on-ml-team-search-recommendation-308223bb2b75">Amazing Summer on ML Team, Search + Recommendation</a> was originally published in <a href="https://medium.com/strava-engineering">strava-engineering</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Ac(count)ing for Scale]]></title>
            <link>https://medium.com/strava-engineering/ac-count-ing-for-scale-becf9c27b104?source=rss----89d4108ce2a3---4</link>
            <guid isPermaLink="false">https://medium.com/p/becf9c27b104</guid>
            <category><![CDATA[open-source]]></category>
            <category><![CDATA[scale]]></category>
            <category><![CDATA[strava]]></category>
            <category><![CDATA[api]]></category>
            <dc:creator><![CDATA[Anjali Merchant]]></dc:creator>
            <pubDate>Wed, 26 Apr 2023 18:23:14 GMT</pubDate>
            <atom:updated>2023-04-27T13:06:12.236Z</atom:updated>
            <content:encoded><![CDATA[<p>Tens of thousands of<a href="https://www.strava.com/apps"> API applications</a> interact with Strava‚Äôs publicly available API, from small projects whose only users are the developers who created them to larger partners like Garmin, Zwift, Wahoo, or Peloton, who upload thousands of activities to Strava daily on our athletes‚Äô behalf. Recently the API &amp; Platform team undertook a project to redefine the way that Strava supports API applications and allows them to interact with Strava data (read more about the updated Developer program¬†<a href="https://communityhub.strava.com/t5/strava-insider-journal/introducing-strava-s-updated-developer-program/ba-p/9061">here</a>).</p><p>As part of the effort to redefine the management of API applications, a main requirement of the project asked that we be able to assign and enforce a limit to the number of athletes who are allowed to authorize an application on their behalf, what we called an application‚Äôs athleteCapacity. On creation of a new application, the default athleteCapacity is a single athlete‚Ää‚Äî‚Ääthe application owner. Developers can subsequently apply to have their limits increased.</p><p>In order to enforce the assigned athleteCapacity we needed to know how many athletes had authorized any given API application to read and write data to their Strava account, what we termed as an application‚Äôs connectedAthletesCount. When a new athlete attempts to authorize an application on their behalf (as pictured below), we wanted to be able to ascertain whether the authorization would cause the connectedAthletesCount to exceed its athleteCapacity.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/994/1*spYlSooXcMqvFbRpxORYjg.png" /><figcaption>The prompt shown to an athlete to request their permission to authorize an external application to connect to Strava on their behalf. We planned to perform the check of an application‚Äôs `connectedAthletesCount` against its `athleteCapacity` on click of ‚ÄúAuthorize‚Äù.</figcaption></figure><p>If authorization would cause the application to exceed its athleteCapacity, we would prevent the athlete from authorizing. Otherwise we would allow authorization to proceed. Our use of the <a href="https://developers.strava.com/docs/authentication/">OAuth2.0 standard</a> for external access to our API gave us an easy proxy for determining the connectedAthletesCount. As part of the OAuth flow, an external application receives an access and refresh token after an athlete has authorized it to connect to Strava. The application must use its short-lived access token to obtain and modify Strava resources, and its refresh token to obtain a new access token when the current one expires. Since each application only ever has a single refresh token per athlete, we intended to compute the connectedAthletesCount for an application by counting the number of unique athlete IDs that had refresh tokens associated with a given application.</p><h4><strong>The Challenge</strong></h4><p>While we often think of counting as elementary, providing accurate counts at scale can be technically challenging. We store refresh tokens in a table in a SQL database. Counting N rows from a SQL table is at least as expensive as reading N rows with an index and becomes increasingly untenable as the number of rows to read and count grows. Some of Strava‚Äôs largest API partners have connectedAthletesCountsthat are in the millions, so computing the count on the fly in response to every potential athlete oAuth event would be a no¬†go.</p><h4><strong>Possible Solutions</strong></h4><p>We knew that we would need to store the denormalized connectedAthletesCountfor each application to keep reads cheap. We explored two possible approaches for what this would look like from a technical perspective, both of which would leverage existing Kafka pub-sub architecture in Strava‚Äôs backend and rely on a new consumer to asynchronously respond to refresh token creation or deletion¬†events.</p><p><strong>Approach One: Maintain our own denormalized counter<br></strong>In this approach, a consumer of refresh token creation or deletion events would increment or decrement a counter in a data store, keeping it up to date. Kafka‚Äôs <a href="https://medium.com/@andy.bryant/processing-guarantees-in-kafka-12dd2e30be0e">processing guarantees</a> would be important in this approach; because our counter would be ‚Äúlive‚Äù, processing a message multiple times or failing to process it at all would result in inaccuracies in the count that would grow over time. ‚ÄúExactly once‚Äù processing is hard to achieve, however, so we‚Äôd have to process our messages with ‚Äúat least once‚Äù processing rather than ‚Äúat most once‚Äù processing, the latter of which does not guarantee delivery. To avoid the possibility of double counting if messages were to ever be replayed‚Ää‚Äî‚Ääas they can be with ‚Äúat least once‚Äù processing‚Ää‚Äî‚Ääwe could partition the stream of token events by application. As order is guaranteed within the partition, we could then store the offset of the last message processed for that application next to its count in our data store. When processing a new message we could compare the offset of the incoming message with that of which was stored, and only increment or decrement the count if the incoming offset were¬†greater.</p><p><strong>Approach Two: Recompute the count probabilistically based on the known </strong><strong>connectedAthletesCount<br></strong>Processing guarantees would matter less in the alternative approach we considered. Instead of incrementing or decrementing a counter, the consumer of token events would rerun our expensive count query of refresh tokens probabilistically: if the connectedAthletesCount for an application were beyond some defined threshold, we would become less likely to recompute the count the larger the count became. Anytime we‚Äôd re-run the count, we‚Äôd replace the value of the connectedAthletesCountin a data¬†store.</p><p>Probabilistic counting would mitigate against the increasing cost of count queries as the number of rows to count increased. Fewer expensive queries, however, would come at the expense of accuracy, as the count would more likely be stale for applications with a larger connectedAthletesCount. For our use case, however, this would not be too critical; we determined that we cared more about maintaining a fresher count for smaller applications so that we could more accurately enforce their athleteCapacity. Applications with the largest connectedAthletesCount, on the other hand, would have the most permissive limits, making stale values less important.</p><h4><strong>Decision Time</strong></h4><p>As we compared the two approaches, we also considered what backfilling a baseline count for all of Strava‚Äôs API applications would entail. Maintaining a denormalized counter would necessitate a more complex backfilling approach, as we‚Äôd need to snapshot the count at a known point in time and write that total to a database. We‚Äôd then have to play future events to it to capture any token events that occurred during the duration of the computation and the write. Adopting the probabilistic approach, on the other hand, would require a much simpler approach; if the deployed consumer were to receive an event for an application that lacked a connectedAthletesCount, it could compute the count irrespective of the application‚Äôs size.</p><p>Given the relative simplicity of the implementation of the probabilistic approach over maintaining our own denormalized counter, we decided to give it a try, so long as we were able to optimize the performance of the count query for our largest applications.</p><h4><strong>Implementation and¬†rollout</strong></h4><p>Our first order of business, then, was to ensure that our count query would be performant; otherwise we would have to abandon the denormalized approach in favor of maintaining our own¬†counter.</p><p>To assess query performance, we made a copy of the database that holds the refresh tokens table, as we wanted to avoid running our tests of long-running queries on a critically important live production database. To our copy we added new covering indexes that we hoped would be leveraged by and improve the performance of the count query that the consumer would initiate probabilistically in response to refresh token creation or deletion events. Running some test queries on a few of our largest applications revealed a query execution time of ~16 seconds with the new¬†indexes.</p><p>Although 16 seconds was at least an order of magnitude slower than most SQL queries performed at Strava, we had several reasons to think that the probabilistic approach would still be tenable. The fact that the potentially slow count query would occur asynchronous to the refresh token creation or deletion processes themselves would be critical; as these events would be initiated by an athlete end user, a long running query would make for a poor UX were the count computation synchronous. Also important was the fact that by using the default MySQL<a href="https://dev.mysql.com/doc/refman/8.0/en/innodb-transaction-isolation-levels.html"> transaction isolation level</a>, ‚Äúrepeatable read‚Äù, our count query would not lock the queried rows for other database sessions, a key requirement on a table so central to Strava‚Äôs functioning. Finally, while we were unsure of the consequences of running a count query like this while serving other authentication traffic, we planned to leverage instrumentation and tuning parameters (detailed below) that together would allow us to modulate the frequency of counts as we sought to balance database load and freshness of the connectedAthletesCount.</p><p>With increased confidence in our approach, we then added a Kafka producer to emit events on refresh token creation and deletion as well as a Kafka consumer to read the stream of events. During event processing, the consumer fetches the application to which the event pertains, probabilistically performs the count query, and finally updates the application‚Äôs connectedAthletesCount. The code snippet below illustrates the logic we put in place to determine whether to perform the recount; bolded are configurable protections that gave us greater control over the¬†rollout:</p><pre>def shouldCount(application: Application): Boolean = {<br>  if (<strong>enabledApplicationIds</strong>.contains(application.id)) {         <br>    application.connectedAthletesCount match {<br>      case None =&gt; true<br>      case Some(count) if count &lt; <strong>largeApplicationSize </strong>=&gt; true<br>      case Some(count) =&gt; random.nextInt(count / <br>      <strong>connectedCountUpdateRatio</strong>) == 0<br>    }<br>  } else {<br>     false<br>  }<br>}</pre><ul><li>The use of a parameter called enabledApplicationIds enabled us to initially gate recomputation to only applications that we specified, allowing us to test our code on a variety of application sizes in production before turning it on all for all applications.</li><li>For any of our enabledApplications, if the connectedAthletesCountwas not set, we automatically computed the count so that we‚Äôd have a value going forward (described above).</li><li>We added a configurable variable called largeApplicationSize; any application with a connectedAthletesCountsmaller than this value always has its count recomputed. Counts at this size and below are inexpensive enough to perform every time a token event occurs and also ensure that the connectedAthletesCountfor the applications whose limits we care more about enforcing are up-to-date.</li><li>connectedCountUpdateRatio, another configurable variable, allowed us to fine tune the probability of recounting. With a connectedCountUpdateRatioof 10 and a connectedAthletesCountof 10,000, for example, we generate a random number between 0 and 1,000 when we called nextInt(10000 / 10). A 1/1,000 chance of obtaining a 0 translates to a 1/1,000 chance that we recompute the count. To make the probability of recomputing the count more or less likely, we could increase or decrease the connectedCountUpdateRatio.</li></ul><p>We also added instrumentation to our code so that we‚Äôd have visibility into the latency of our handler and the rates of computes, no-ops, and errors amongst other metrics. Monitoring of our metrics and logs revealed that the initial deployment to production and tests using the enabledApplicationIds parameter failed with timeouts in the server‚Äôs connection to the database‚Ää‚Äî‚Ääan unsurprising result in retrospect, given that we expected the longest count query to take ~16 seconds, much longer than the default timeout threshold. After bumping the timeout, we were excited to see the connectedAthletesCountproperty populated for the applications that we had specified in enabledApplicationIds on our internal applications admin UI; our consumer was¬†working!</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*nmCSfNahJSq63wFC" /><figcaption>Display of the `connectedAthletesCount` on an internal applications management UI.</figcaption></figure><p>When we removed the enabledApplicationIds parameter to allow for computation for all applications, we turned to fine-tuning the connectedCountUpdateRatio.Out of an abundance of caution we had set the initial ratio value to be small, resulting in an absurdly low frequency of recomputes and prolonged data staleness for applications with a connectedAthletesCountgreater than the largeApplicationSize. To derive a more appropriate connectedCountUpdateRatio, we estimated how often we wanted these more expensive recomputes to happen for an application of a particular size, looked at approximately how often token events were received for such applications in a given period of time, worked backwards to arrive at a suitable ratio, and made the correspoding changes.</p><p>Continued monitoring of database metrics throughout the rollout and tuning process allayed our concerns about our count query having a negative impact on load and ability to serve other traffic; we didn‚Äôt see any significant changes to server latency or database CPU. We then moved on to the final steps of the task, which entailed building out fullstack functionality for comparing and enforcing an application‚Äôs connectedAthletesCountagainst its athleteCapacity limit during authorization events.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*EA2tzmowqNxkzNiP7x_7XQ.png" /><figcaption>The page rendered during the authorization process if the authorization event will cause an application‚Äôs `connectedAthletesCount` to exceed its¬†limit.</figcaption></figure><h4>Conclusion</h4><p>Denormalization is one way to address the inefficiency of performing on-the-fly counts at scale in a SQL database. To compute and store a denormalized connectedAthletesCounton API applications at Strava, the API &amp; Platform team weighed two different approaches that captured trade-offs between accuracy and implementation complexity. In our use case, the fact that larger applications tended to have the most permissive limits to their athleteCapacity meant that stale counts for our largest applications were less important. The use of tuning parameters enabled us to toe the line between data freshness and database performance. Engineers facing similar counting challenges will have to weigh the importance of these trade-offs for their own use¬†case.</p><p><em>Huge thanks and kudos to </em><a href="https://medium.com/u/17a8a0567f8d"><em>Jeff Pollard</em></a><em>, Yudi Fu, and Collin Neuhaus for their contributions to solution design and implementation.</em></p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=becf9c27b104" width="1" height="1" alt=""><hr><p><a href="https://medium.com/strava-engineering/ac-count-ing-for-scale-becf9c27b104">Ac(count)ing for Scale</a> was originally published in <a href="https://medium.com/strava-engineering">strava-engineering</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Searching for Success at Strava]]></title>
            <link>https://medium.com/strava-engineering/searching-for-success-at-strava-22b9bf205dbf?source=rss----89d4108ce2a3---4</link>
            <guid isPermaLink="false">https://medium.com/p/22b9bf205dbf</guid>
            <category><![CDATA[react]]></category>
            <category><![CDATA[micro-frontends]]></category>
            <dc:creator><![CDATA[Navika Budhraja]]></dc:creator>
            <pubDate>Tue, 15 Nov 2022 17:01:28 GMT</pubDate>
            <atom:updated>2022-11-15T17:01:27.905Z</atom:updated>
            <content:encoded><![CDATA[<figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*Np_T-JQZydJba0vDsPNoQQ.jpeg" /><figcaption>Me and my mentors Patrick &amp;¬†Nomnoms</figcaption></figure><h4>Introduction</h4><p>Hi, my name is Navika Budhraja and I‚Äôm a rising senior at UC San Diego studying Computer Science. This summer I was a web-frontend engineering intern on the Athlete Services team and consequently, got to learn a lot about how to develop athlete-facing products!</p><p>During my internship, I worked with 3 other interns, Emily (Server), Sahil (iOS), and Ryan(Android), on a project to add filtering and searching logic to athlete‚Äôs saved routes, which in my case, meant working on the My Routes page on the¬†web.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*j7VXl9wbLYR1tqg5" /><figcaption>‚ÄúOld‚Äù My Routes that I would be improving</figcaption></figure><p>Like the paths of many Strava routes, adding this feature on the web was not going to be a straightforward process. As you may already know, Strava is currently in the process of moving code out of their Ruby on Rails monolith called Active to React-based frontends. Since the code for the current My Routes page lives in active, I was also tasked with migrating the page from active to a React <a href="https://medium.com/strava-engineering/strava-web-microfrontends-79e9586c0222">microfrontend</a> before adding filtering/search logic.</p><p>üò±‚Ä¶My Face exactly when I first read my project description, especially with super rusty React skills and no conception of what a microfrontend was (was it like a tiny frontend or like a craft, hipster frontend sort of like a microbrew?). However, what I came to learn is that when you work in an incredibly supportive and encouraging environment, the process of rolling out a requested feature in just 12 weeks with no experience isn‚Äôt actually as daunting as it¬†sounds.</p><p>In the spirit of the Warriors winning the championship earlier this summer (Yes, I am still riding the high), I will break down these past 12 weeks in terms of quarters of a basketball game!</p><h4>First Quarter: Onboarding &amp;¬†Jams</h4><p>Although I wanted to jump in and start working on a project right away, I first had to get acclimated to a new code base, actually 2 new code bases: active (the monolith) and web (the monorepo where my microfrontend will¬†live).</p><p>By fixing some minor bugs on the website, I learned some integral lessons about all things web dev at Strava. Some of the most important takeaways being: always make sure to squash your commits, even if you don‚Äôt like birds canaries are your friend (a.k.a use them thoroughly for testing and don‚Äôt break a page like I once did), and Coffeescript and Haml are the best programming languages to ever exist‚Ä¶just kidding!</p><p>Now that I was feeling a bit more acclimated to Strava‚Äôs web platform, it was time to brush up on those React skills I mentioned earlier. Luckily, this need for a React refresher coincided perfectly with JAMS week, where I was able to jam with a few web-engineers on revamping the monthly stats visualizations in React on the Training Calendar page. Just from observing, asking questions, and experimenting during JAMS, I was able to have a nice introduction on all-things React prior to jumping into the¬†project.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*DD9iAMeXvqevWKxA" /><figcaption>A statistics visualization I crafted up in React for¬†JAMS</figcaption></figure><h4>Second Quarter: Rails-React Migration</h4><p>After onboarding, I was surprised at how quickly this migration went, as I was able to set up and <a href="https://indepth.dev/posts/1173/webpack-5-module-federation-a-game-changer-in-javascript-architecture">federate</a> my microfrontend, put it behind a feature flag, and start developing React components seamlessly, further demonstrating the ease of developing on a microfrontend as opposed to active. Migrating the page was by far one of my favorite parts of the project, as I thoroughly enjoyed bringing to life Figma designs on the frontend and would enthusiastically send little video updates to my mentor Patrick whenever I would add new UI elements to my microfrontend, like this one¬†below!</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*Svxyzwrp3c7BS2wzJjPh4w.gif" /><figcaption>Any early-stage version of the filtering menu‚Äôs¬†UI</figcaption></figure><p>Through this process, I felt myself getting more comfortable with more advanced topics in React like using states, hooks, and contexts, which made some of the nitty-gritty aspects of the site easier to implement as I went¬†along.</p><h4>Third Quarter: GraphQL Integration &amp; Frontend Bug¬†Bash</h4><p>Now that I had all of the UI in place, it was now time to make things functional! Since we were migrating the page out of active, in order to bring data and functionality to the page, we needed to hit a GraphQL endpoint as opposed to an endpoint on an active. Although making calls to a GraphQL endpoint was something completely new to me, pair-programming sessions with Patrick, extensive documentation reading, and conversations with server engineers made the process quite straightforward. I enjoyed the process of integrating my UI with the backend, especially when I finally got to remove placeholder elements with real user data and started to implement filtering and search¬†logic!</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*VT2bKXB8QfiBinri" /><figcaption>Route Tiles populated with my routes¬†data</figcaption></figure><p>During this time, I also participated in the July Frontend Bug Bash, a two-day period dedicated to fixing any lingering bugs on the web. The not so subtle bug bash leaderboard ignited my competitive spirit, as I bashed 5 different bugs and in classic intern fashion accidentally created a bug in the process of fixing one, which was a learning process in and of¬†itself.</p><h4>Fourth Quarter: Finishing Touches, Testing, &amp;¬†Demos</h4><p>Throughout the development process, I developed a bit of a bad habit of leaving little TODO comments in my code for minor changes that I would eventually come back to. Luckily, near the end, I had the time to go through all of my React components and fix up every little TODO in my own little personal project bug bash. With some extra time I had left during my internship, I also wrote some UI tests in Jest to ensure I didn‚Äôt miss any further bugs. In the last few weeks of my internship, I got to demo my work to both the Athlete Services Team and the Frontend Guild, which was super exciting and made me proud of the work I was able to complete during my short time here at¬†Strava.</p><h4>Overtime</h4><p>Since the internship was remote, I was able to split time between San Diego and the Bay Area. When I returned to the Bay, I started going to the SF-Office periodically and got to meet some amazing people in the process! Whether it was pair-programming with my mentor Patrick and unofficial Strava mascot Nomnoms, going on boba runs with other interns, or covering a wide-range of topics during Wednesday lunches (some of my favorites included musical festivals, the lack of school buses in the Bay Area, and supersonic aircrafts), I genuinely enjoyed each and every interaction I had with everyone at Strava, which made me feel really excited to be a part of the community!</p><p>In conclusion, this summer, I helped build some new features, worked with newer languages/tech, and broke a few minor things here and there in the process, all of which helped me grow both as an engineer and a person this¬†summer!</p><p>This was one of my most fun summers to date and I can safely say that working at Strava contributed more to my overall happiness this summer than the Warriors winning the championship!</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*6l961ngYBynWwCB-" /><figcaption>(Boba w/ Patrick, Emily, Yuwen, and¬†Suds!)</figcaption></figure><h4>Acknowledgements</h4><p>Thank you to my mentor Patrick and manager Kelsey for welcoming me into the Strava community and making this internship flow so smoothly!</p><p>Shout out to Alex Kirillov and Emily Zimmerman for reviewing the multitude of PRs I had for my project and giving the best feedback!</p><p>Lastly, special thanks to Emily, Ryan, and Sahil for being amazing collaborators and more importantly, good friends throughout this¬†process!</p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=22b9bf205dbf" width="1" height="1" alt=""><hr><p><a href="https://medium.com/strava-engineering/searching-for-success-at-strava-22b9bf205dbf">Searching for Success at Strava</a> was originally published in <a href="https://medium.com/strava-engineering">strava-engineering</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Dependency Injection, MVP, and the all reliable Android Studio IDE.]]></title>
            <link>https://medium.com/strava-engineering/dependency-injection-mvp-and-the-all-reliable-android-studio-ide-9e47a6c8743b?source=rss----89d4108ce2a3---4</link>
            <guid isPermaLink="false">https://medium.com/p/9e47a6c8743b</guid>
            <category><![CDATA[android]]></category>
            <category><![CDATA[internships]]></category>
            <category><![CDATA[kotlin]]></category>
            <category><![CDATA[strava]]></category>
            <category><![CDATA[dependency-injection]]></category>
            <dc:creator><![CDATA[Aleksei Bingham]]></dc:creator>
            <pubDate>Tue, 08 Nov 2022 17:02:36 GMT</pubDate>
            <atom:updated>2022-11-08T17:02:35.942Z</atom:updated>
            <content:encoded><![CDATA[<p>First and foremost, thanks for visiting my little slice of the internet! I hope the following is both insightful and comedic as I plan to @inject well constructed jokes throughout this¬†post.</p><h3><strong>Introduction</strong></h3><p>Hello! My name is Aleksei and at the time of writing this I‚Äôm a rising Senior perusing a Bachelors of Science in Computer Science at the Rochester Institute of Technology. Specifically, I‚Äôm focusing on Programming Languages and Tools, a cluster of courses offered by the Golisano College of Computing and Information Sciences at RIT. Clusters are courses that supplement the core Computer Science curriculum allowing students to dive deeper into the topics that spark their interests the most. Below you will find the courses I have and will be taking from this¬†cluster.</p><p>CSCI-742 Compiler Construction (Completed)</p><p>CSCI-541 Programming Skills in Haskell (Fall¬†2022)</p><p>CSCI-541 Systems Programming in Rust (Spring¬†2023)</p><p>As you can probably tell, I have a love for languages. But don‚Äôt be mistaken, computer programming languages are not the only type of languages I enjoy studying. While at RIT I also studied Russian, the language that was <strong>almost</strong> my native tongue. While my future schedule doesn‚Äôt support taking more Russian courses I have continued to study the language on my own¬†time.</p><p>Outside of academics, I‚Äôm a passionate endurance athlete who trains to compete throughout three seasons: cross country, indoor, and outdoor track &amp; field. I primarily race the 3K, 5K, and 8K and plan to continue my love for racing outside of college out on the roads running the 15K, half, and the marathon.</p><p>Enough about me, let‚Äôs switch over to talking about the heart of this blog post. The reason why I decided to spend a summer at¬†Strava.</p><h3>Why Strava?</h3><p>It goes without saying, I <strong>love</strong> to run. I competed in cross-country, indoor, and outdoor track and field all of high-school and planned to do the same in college. Surprisingly, I didn‚Äôt use Strava throughout high-school. In fact, I don‚Äôt think I knew of Strava‚Äôs existence in the first place. It wasn‚Äôt until I arrived on campus that my new teammates would bug me to install Strava so I could join the team group. It was from that moment on that I was¬†hooked.</p><p>There was something special about seeing my teammates‚Äôs activities on Strava. Whether I was finishing up a brutal workout or just jogging around the neighborhood I always had something to share on Strava and so did my teammates. Strava provided a feeling of camaraderie and I knew I wanted to be apart of¬†it.</p><p>I vividly remember reading other intern blog posts from previous years. The team activities, company mission, and passion for the product showed through each and every medium post I stumbled across. It was for that reason that I had dreamed of landing an internship at Strava before graduation and ultimately would apply as an Android Engineer Intern during the Fall of 2021. In fact, I still have the activities leading up to my offer letter on¬†Strava!</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*kZCsRcaFCatDP65M38uRTg.png" /></figure><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*yXbElK0unO9OSUnzc7OU9A.png" /></figure><h3>Growth Team</h3><p>With a couple of weeks until the start of my internship I learned that I would be placed on the growth team. The growth team is all about experimentation in which product managers, designers, and engineers collaborate to drive user retention and subscription purchases. Specifically, I was going to be working on the subscription acquisition team inside growth where the primary goal is to encourage users to subscribe for all of Strava‚Äôs awesome features.</p><h3>The First¬†Week</h3><p>Throughout my first week I spent the majority of my time learning Kotlin, Android Studio, and basic Android Development all the while meeting my new teammates. With the help of my remarkable mentor, <strong>Faraz</strong>, I was able to hack together the following path of execution:</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*ai7Gsz630smqi1gohYFYYw.png" /></figure><p>Unfortunately, I only had a single thread to work with and many of these procedures were blocking operations</p><pre>@Target(Dagger.Dependency, RxJava.Dependency and MVP.Design_Pattern)</pre><p>so needless to say, learning all of this happened over the course of my internship.</p><p>While I don‚Äôt have the time (or energy) to write about everything I did throughout this internship. I will be highlighting the project that I worked on in significant detail.</p><h3>My Summer¬†Project</h3><p>Shortly after my ramp-up period my manager disclosed my summer project with me. I had been assigned to bring student plans to Android. Previously, student plans was only accessible on our <a href="https://www.strava.com/student?origin=website_footer">website</a>. However, a significant portion of our athletes are also accessing Strava through our iOS and Android apps. Without including student plans on mobile we are potentially missing out on thousands if not millions of athletes.</p><p>At first glance, the project seemed trivial with just a few UI changes and a single backend API call. Keep in mind, my previous Android experience is practically nonexistent despite having published some (horrendous) apps that I am too embarrassed to share here. Needless to say I was feeling quite confident.</p><p>After a design review with our team‚Äôs phenomenal UI/UX designer (huge shoutout to <strong>Grace Kim. </strong>I will never understand how you come up with these designs) I was given a portion of the overall design and this is what it looked¬†like:</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*Ncp6bb3pUHUww101r0hH2g.png" /></figure><h3>Settings View</h3><p>Prior to seeing the code firsthand, I had assumed the settings view would be a simple activity with a vertical linear layout using a reusable custom component responsible for rendering each setting option. However, The most interesting part of the settings view was learning how wrong my intuition really was. Instead, I learned all about Android‚Äôs Preference hierarchy, the preferred method for building setting¬†layouts.</p><p>For example, the XML below using <a href="https://developer.android.com/guide/topics/ui/settings">Preferences</a> renders the settings view on the Android device that¬†follows.</p><pre>&lt;PreferenceScreen<br>    xmlns:app=&quot;http://schemas.android.com/apk/res-auto&quot;&gt;<br><br>    &lt;SwitchPreferenceCompat<br>        app:key=&quot;notifications&quot;<br>        app:title=&quot;Enable message notifications&quot;/&gt;<br><br>    &lt;Preference<br>        app:key=&quot;feedback&quot;<br>        app:title=&quot;Send feedback&quot;<br>        app:summary=&quot;Report technical issues or suggest new features&quot;/&gt;<br><br>&lt;/PreferenceScreen&gt;</pre><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*gaM_HYrSepyAguzMSr0k5Q.png" /></figure><p>Easy right? All we need to do is add a single &lt;Preference¬†... /&gt; tag, put in the correct text and off we go¬†üöÄ!</p><p>Not so fast‚Ä¶ If you recall, the design document shows a ‚ÄúNew‚Äù icon, text highlighted in Strava orange, and a dismiss button in the top right to remove it from the view permanently when tapped. These little customizations are not easy to do, if not impossible, with the built in Preference. Instead, we need¬†to</p><ol><li>Design a standalone layout file for the specific preference containing the ‚ÄúNew‚Äù notification, dismiss button, text, and additional styling.</li><li>Write a custom class that extends the Android Preference class to inflate the layout file we created in part¬†one.</li><li>Get reference to the specific items in the layout file such as the ‚ÄúNew‚Äù notification and write public methods to modify its visibility outside of the¬†class.</li><li>Get reference to the entire custom preference and set an<br>onClickListener {¬†‚Ä¶ } to open a dialog containing the student plan information when it‚Äôs¬†tapped!</li></ol><p>But before all of that we still need to create another layout file for our new dialog fragment that will appear as a pop-up when the user clicks our new setting preference. The class that will be responsible for displaying the pop-up will be referred to as the StudentPlanDialog for future reference.</p><h3>Implicit Intents</h3><p>The Strava Android code-base is neatly organized across several unique modules. In fact, some of these modules can live on its own as a standalone application serving as a testament to how well organized the project is. However, this comes with its own issues as you will later¬†read.</p><p>As I started to work on the StudentPlanDialog class it made the most sense to store its implementation inside the subscriptions module as student plans will make most of its appearance around the checkout section of the app. But of course, student plans also appears in settings so we will need to reference the StudentPlanDialog from the settings module. At this point I was unsure about how the importing would work across multiple modules so instead I did what any intern would do. I pretend everything is going to be fine and continued onward until the compiler inevitably rejects my¬†code.</p><p>As I‚Äôm wiring up the StudentPlanDialog to appear when the user clicks our new settings option I get this lovely error message from inside Android¬†Studio</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/777/1*RCY0-jq8DlqT6psiMpmUKw.png" /></figure><p>It was here that I realized I cannot access the class‚Äôs public methods without adding the subscriptions module as a <strong>dependency</strong> to the settings¬†module.</p><p>At the time this didn‚Äôt feel like a good solution but I went ahead and added the dependency regardless. Shortly after, I grabbed some Java with Gradle for a quick sync-up and before I knew it the JVM was interpreting my byte-code to perfection! In other-words, my feature was working! Although, I did notice a new change appeared in my git diff for the settings.gradle file‚Ä¶</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/392/1*WrVAJwIJ5tp6JtaURjfaag.png" /></figure><p>Seeing a change to the Gradle file made my heart sink. After-all, making modifications to any Gradle configurations as an intern isn‚Äôt a wonderful feeling, it‚Äôs actually quite terrifying. After a few slack messages and reading some articles online I came to the conclusion that my solution was horrible and here‚Äôs¬†why.</p><p>Prior to adding subscriptions as a dependency, this is what a (heavily) simplified version of Strava‚Äôs dependency tree could look¬†like:</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*BZT7qiCUggWj8mM42j0_iQ.png" /></figure><p>Here, in order to run the <strong>Strava Android App</strong> we first must build the <strong>Activity</strong>, <strong>Feed</strong>, <strong>Subscriptions</strong>, and <strong>Settings</strong> modules. But, in order to build the <strong>Activity</strong> module we first need to build the <strong>Activity Recording</strong> and <strong>Activity Upload</strong> modules and so fourth. However, After adding subscriptions as a dependency to the settings module our tree transforms into the following one:</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*p0_h1CE_hXiMmZ39u6Znvw.png" /></figure><p>Now, in order to run anything related to settings we first need to build and compile the entire subscriptions module. If you think about it, settings has practically nothing to do with purchasing a Strava subscription. In fact, we just slowed down the build time of the project by preventing the compiler from parallelizing these build tasks. To work around this there are two primary methods to pick from: Create a new student plan module or use implicit¬†intents!</p><p>For student plans, it didn‚Äôt make much sense to create a brand new module as it would only contain a handful of views and a couple kotlin classes. Not to mention, modules are expensive to create and should be thought of as standalone portions of the app. Instead, I created an implicit intent which can be thought of as a broadcast message and setup an intent filter to catch this broadcast and use an activity inside the subscriptions module to handle it. This allowed me to open the pop-up dialog from inside the settings module even though it‚Äôs located inside the subscriptions module.</p><p>After proofreading the previous paragraph I realized it can be rather confusing to someone who doesn‚Äôt know anything about Android development. Hence, I decided to create a stunning and intuitive diagram to better illustrate implicit intents (take notes <strong>Grace</strong>). This also served as a wonderful time sink on a Friday afternoon.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*Lj_D3jzkAnffZXr4OM9jXA.png" /></figure><p>Implicit intents can be thought of as a request often used for cross app communication. Explicit intents on the other-hand explicitly define who is handling the message by providing the specific Activity as a required argument. Hence, explicit intents do not need an intent filter to resolve who is handling what type of intent as it was already made explicit!</p><p>Without implicit intents, every app that wants to access the photo gallery would need to write the logic themselves. Of course this sounds ridiculous and instead we should somehow use the already built photo gallery app to do this. Implicit intents provide the path of communication between the two applications much like an API. Best of all, they can also live in a single application and communicate across the application‚Äôs modules. In my project, I used implicit intents to communicate across the settings and subscription modules without needing to modify their dependencies.</p><p>To further emphasize implicit intents, here‚Äôs a code snippet that initiates a phone call from inside any Android application:</p><pre>val callIntent: Intent = Uri.parse(&quot;tel:5551234&quot;).let { number -&gt;<br>    Intent(Intent.ACTION_DIAL, number)<br>}</pre><p>Here callIntent can be started using startActivity(...) and will initiate a phone call to the given number 555-1234 using the default dialer app. If you‚Äôre lucky enough Big Bird might just pick¬†up.</p><p>However, implicit intents alone will only allow us to open the pop-up dialog. If we wish to also access business logic across the two modules then we will need to use¬†Dagger.</p><h3>Feature Switches and Dependency Injection</h3><h4>@GET(‚Äústrava/feature-switches‚Äù)</h4><p>Feature switches are an essential Strava server side service that both web and mobile clients rely on. Imagine you wish to release a brand new feature but are hesitant to release it to all of your users. Maybe you only want 30% of your users to have access to it or maybe you would like a particular age group to see it. Feature switches control what features are available to a particular client. Every user who logs into Strava whether it be on web or mobile receives a list of available features specific to¬†them.</p><p>With that being said, student plans needed to be placed behind a feature switch for experimentation purposes. To accomplish this, all I needed to do¬†was</p><ol><li>Add student plans as a new feature switch on the¬†backend</li><li>Create a StudentPlanHelper class that would encapsulate the business logic needed to check if the feature flag was enabled or not (and some additional strava¬†magic)</li><li>Set all student plan user interface elements to be invisible by¬†default</li><li>Reference the StudentPlanHelper during setup to conditionally render the student plan¬†UI</li></ol><p>As easy as it sounds don‚Äôt be fooled, there was yet another hidden road-bump patiently waiting ahead. Recall that the majority of the student plan work resides in the subscription module including the StudentPlanHelper logic. It would be bad practice to copy and paste the StudentPlanHelper logic into both modules separately but we know from experience that if we try to access it inside the settings module we will get the following error</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/933/1*wt3qM6l5y30_Z813c_xQPg.png" /></figure><p>and this would defeat the entire implicit intent workaround, what a shame! Luckily, the brilliant Strava engineers have already solved this problem by using a well known design pattern known as dependency injection.</p><h4>Dependency Injection</h4><p>Dependency injection is a design pattern often used without knowing it. Simply put, a class‚Äôs dependencies are any other classes that it relies on. Dependency injection is when we construct all of these dependencies ahead-of time and pass it into another classes constructor. Let‚Äôs look at a simple example <strong>without</strong> using dependency injection.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*jMjg4LpiM8vA1sRiRuoA3Q.png" /></figure><p>Notice how the <strong>Strava</strong> class constructs its own dependencies at the time of its own creation. Not only is object instantiation expensive but it leaves <strong>Strava</strong> tightly coupled with <strong>WebApp</strong>, <strong>iOSApp</strong>, and <strong>AndroidApp</strong>. If <strong>Strava</strong> wanted to add another dependency such as <strong>WatchOS</strong> or modify an existing one such as <strong>iOSApp. </strong>We would have to directly modify <strong>Strava‚Äô</strong>s implementation to support those changes. This also makes unit testing a disaster because we cannot mock the dependencies <strong>Strava</strong> is using as we don‚Äôt get to pass them in during¬†runtime.</p><p>Now, let‚Äôs look at an example using dependency injection:</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*16GTbUP9BXFa4qp-mmn6Nw.png" /></figure><p>In order to build the <strong>Strava</strong> class it requires three dependencies: <strong>WebApp</strong>, <strong>iOSApp</strong>, and <strong>AndroidApp</strong>. Inside the main function we create each dependency manually and pass them in all at once to the <strong>Strava</strong> class to construct it. However, this is very verbose and with large and complex class structures it can become hard to follow and maintain.</p><h4><strong>Introducing Dagger</strong></h4><p>Dagger is a dependency injection framework that can generate code to remove the verbosity from the example above and much, much more. Dagger manages dependency graphs much like Gradle except these are not Android Studio modules rather classes. The following is a simple example using Dagger and Dagger Annotations to clean up the example from¬†above:</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*qDjv5xODPr2oM8FaAxkzBg.png" /></figure><p>When compiling the project Dagger uses the annotations @Component and @Inject to generate code that resembles a dependency graph. Dagger also generates class files for us to use such as DaggerStravaComponent that uses the generated code to implement the StravaComponent interface! Using Dagger, Dagger‚Äôs @Binds annotation, and an interface representing the business logic of the StudentPlanHelper. I was able to provide its implementation across different modules all without adding any dependencies üòé.</p><p>But even after all that, there was still one more design pattern that I needed to become comfortable with in order to fully implement student¬†plans.</p><h4>Model View Presenter</h4><p>The Model View Presenter (MVP) is a design pattern commonly used in Android Development. When developing Android apps for the first time it‚Äôs tempting to write both the business logic and view logic inside a single Android activity. However, this makes unit testing more of a nightmare than it already is. After countless videos and articles about MVP I just couldn‚Äôt grasp how Strava was implementing it until I spoke with a different Android engineer. Within a matter of minutes I finally understood the design pattern and was able to build my views using it (thank you <strong>Maria</strong> <strong>Botross </strong>üôå). In fact, I felt confident enough to explain it¬†here!</p><p>The generic MVP is made-up of three (hopefully obvious) components: The model, view, and presenter. The Android environment changes things slightly and instead we have an Activity, Model, View Delegate, and Presenter.</p><p><strong>Activity</strong>: Handles initial setup such as creating a view delegate and binding itself to a presenter as well as routing to other activities. For the sake of simplicity the following example will not showcase activity¬†routing.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*AvdGfP_h1SWg4y7_g7qPRQ.png" /></figure><p><strong>Model</strong>: Contains objects that represent the possible view events and view states during the lifetime of the host activity. These objects are passed between the view delegate and presenter to initiate business logic such as an API call or make UI changes. These objects can also contain data that can be later extracted and used (thanks¬†Kotlin).</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*MkSkxcwqBsOVe0k0JIJ7mA.png" /></figure><p><strong>View Delegate</strong>: Initializes the view and establishes view events such as click listeners. When an event occurs such as a button click, the view delegate will send a view event to the presenter to do some business logic. Then, the view delegate will receive a state events from the presenter that tells it how to update the¬†view.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*IjmdXmHfPBEZUHb6hx7QeA.png" /></figure><p><strong>Presenter</strong>: Responds to view events from the view delegate and handles them appropriately. After handling the view event, the presenter will send back a state event for the view delegate to¬†handle.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*GMOwhes4Y_jlR56DTu1H0Q.png" /></figure><p>Combining these four components makes for highly testable applications and often leads to very easy to read code. At Strava, MVP is used practically everywhere. However, this forced me to get out of my comfort zone and ultimately made me a better Android engineer. After using MVP for an extended period of time it‚Äôs hard to imagine writing an app without¬†it.</p><h4>Ok I lied¬†‚Ä¶</h4><p>I said I wasn‚Äôt going to talk about anything unrelated to my project but I just <strong>had</strong> to talk about Strava Jams. For those who (somehow) don‚Äôt know, Strava Jams is a kick-ass week long event were everyone groups up into teams across the company and hacks together whatever they want! What makes the event so exciting is that your project can be totally unrelated to the app and can be completed in solo fashion üòé or with a team üèÉ‚Äç‚ôÇÔ∏è üö¥ üèÉ‚Äç‚ôÄÔ∏è üö¥ üèÉüö¥ üèÉ‚Äç‚ôÄÔ∏è¬†. Whether you wanna learn Jetpack Compose or build an internal tool the week is yours to decide! Best of all, Strava Jams ends in style with each individual and team presenting their work (if they so choose of course), earning awesome awards, and potentially advancing their feature into production for millions to enjoy. With that being said, let‚Äôs dive into what I worked on during Jams¬†week.</p><h4>#Jams-Breathe</h4><p>Both the Jams project and Jams team was assembled by a talented product analytics intern, <strong>Malhar Khandare</strong>! Our team consisted of other interns and full-time members on iOS, Web, Server, and myself on Android paired with a previously mentioned full-time Android engineer, Maria. Malhar‚Äôs proposal was to bring mediation to the app as a brand new activity that lives within the recording screen. Without going into the details this was a <strong>very</strong> daunting task. To put it simply, the recording screen is one of the most complicated portions of the code-base and I had no clue where to¬†begin.</p><p>On day one of Jams week I reached out to Faraz for advice and he recommended that I reach out to the Strava engineer who has extensively worked on the recording module, <strong>Dave Rozsnyai</strong>. Without hesitation, Dave was more than happy to schedule a quick 1:1 over zoom. After the meeting I had a general idea of where my code changes needed to live and, more importantly, what portions of the code I should stay away from. It‚Äôs short meetings like this that prove time and time again to be invaluable to us¬†interns.</p><p>However, even after receiving advice I continued to find myself struggling throughout all of day two while trying to implement a subset of the feature. I decided to switch gears and implement the feature into a standalone app to help break the problem down into more manageable pieces. This helped me understand all of the moving parts and gave me the confidence that I could bring it into¬†Strava.</p><p>For the remaining portion of Jams week I paired up Maria. After several days of rewarding yet frustrating bugs and complications the feature was fully implemented. I even had enough time to write my own animation manager to elegantly render rich animations such as the levitating person and countdown timer (that you will see shortly). These animations were not in the initial design created by Malhar so needless to say it was a fun surprise to share with my team hours before our presentation.</p><p>As I‚Äôm writing these last couple of paragraphs I realize today is my last day and I only have a couple of hours until I need to submit this post. So, here‚Äôs a bunch of gifs and images to showcase our amazing Jams¬†feature!</p><h4>Navigating to the New Meditate¬†Activity</h4><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*8SfvSdHFQvEj057-bnbaLg.gif" /></figure><h4>Starting and Ending the Meditate¬†Activity</h4><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*gswU1Gqd1wj0mro7P_4vMA.gif" /></figure><h4>Starting, Pausing, and Resuming the Meditate¬†Activity</h4><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*CPxF5XoeRcb_DZnjh8YxUg.gif" /></figure><h4><strong>Still Image of Meditate¬†Activity</strong></h4><figure><img alt="" src="https://cdn-images-1.medium.com/max/934/1*NTvP-zB_r9w0ct83ux28fw.png" /></figure><p>As you can imagine, Jams week was an absolute blast for both my teammates and myself. I cannot thank my entire team enough for making this feature come to life during our live demo. Maybe one day meditation will arrive on¬†Strava.</p><h4>Closing Thoughts</h4><p>The Strava internship exceeded my expectations, especially for a remote internship. Outside of my project I had the opportunity to meet some amazing members from Strava‚Äôs management team including Michael Horvath‚Ää‚Äî‚ÄäCEO &amp; Co-Founder and Claude Jones‚Ää‚Äî‚ÄäVP of Engineering. I also spent a significant amount of time chatting with other interns and the talent team. At times it felt surreal to be surrounded with other individuals who are also striving to be their best in whatever they choose. In fact, and it started to grow on me. I ended up dusting off my road bike, purchasing a cycling jersey, and hit the roads nearly everyday for a ride. I don‚Äôt think I could‚Äôve picked a better way to spend my last summer as a college student. It has been a pleasure working with everyone this summer and it wouldn‚Äôt be possible without my amazing manager, <strong>Amy Sheinhait.</strong></p><p>Thank you for a wonderful internship experience <a href="https://medium.com/u/e7266b4a0593">Strava</a>,¬†kudos!</p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=9e47a6c8743b" width="1" height="1" alt=""><hr><p><a href="https://medium.com/strava-engineering/dependency-injection-mvp-and-the-all-reliable-android-studio-ide-9e47a6c8743b">Dependency Injection, MVP, and the all reliable Android Studio IDE.</a> was originally published in <a href="https://medium.com/strava-engineering">strava-engineering</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[A Taste of Pakora]]></title>
            <link>https://medium.com/strava-engineering/a-taste-of-pakora-cf3b5de261ec?source=rss----89d4108ce2a3---4</link>
            <guid isPermaLink="false">https://medium.com/p/cf3b5de261ec</guid>
            <category><![CDATA[software-development]]></category>
            <category><![CDATA[graphql]]></category>
            <category><![CDATA[microservices]]></category>
            <category><![CDATA[api]]></category>
            <category><![CDATA[internships]]></category>
            <dc:creator><![CDATA[Avery Dunn]]></dc:creator>
            <pubDate>Tue, 01 Nov 2022 16:02:01 GMT</pubDate>
            <atom:updated>2022-11-01T16:02:00.335Z</atom:updated>
            <content:encoded><![CDATA[<p>My name is Avery Dunn and I am a rising master‚Äôs student at Washington University in St. Louis studying computer science. For the past 12 weeks, I have been a software engineering intern on the API &amp; Platform pod of the Foundation team. I am an active Strava user and have been for approximately 3 years with my favorite activity being running. Some other activities I enjoy are playing the piano, reading novels, or skiing (more of a luxury rather than a hobby). My internship at Strava has been a wonderful experience to help me learn, grow, and develop into becoming a more well-rounded, conscientious software engineer. Whether it was working with a recent hire or seasoned ‚ÄúStravioli,‚Äù the positive and ambitious company culture shined brightly throughout the course of the¬†summer.</p><h4>In Transition From a Monolithic to Microservice Architecture</h4><p>Strava currently maintains a code monolith‚Äìa huge Ruby on Rails codebase that controls the user interface, business logic, and database access. For a growing company like Strava and the continuous development of ideas being made into new features, a code monolith doesn‚Äôt make for a great developer experience. Trying to parse through a massive codebase and making sure that all the moving parts are in order so that a typo that was somehow glossed over can successfully be changed makes me a little dizzy, personally. The developers at Strava thought so too, and decided to embark on a transition from the Ruby on Rails singular software application to Scala microservices.</p><p>Over the course of my internship, I gained insight into the process of restructuring a singular software application into Scala microservices and the benefits of that result. Scala microservices can be thought of as modules that work together but separately. They encourage diversification of teams such that each team has less of a dependence on one another like they would for a monolithic codebase.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/720/0*iLho1kht4Aiuy3lC" /><figcaption>Figure 1: Comparison of a monolithic codebase architecture versus distributed code among microservices (<a href="https://sterling.com/microservices-vs-monolithic/">Kumar</a>)</figcaption></figure><p>Spreading the code functionality across teams in the form of microservices makes for a far better developer experience. With Scala microservices, developers need only talk to a small group of individuals for help and occasionally discuss high-level concerns among a broader group, which keeps projects contained and promotes efficiency. This individualization of teams working on Scala microservices also falls directly in line with how the API is evolving: from a REST API to a GraphQL¬†API.</p><h4>Acronyms Explained</h4><p>The mention of API applications might leave you wondering: what is an API? API stands for Application Programming Interface, which really doesn‚Äôt do a whole lot for understanding what it actually does. An API is like a bridge between two different islands, where the cars, people, or bikes crossing the bridge are the data packets being exchanged among two software systems. An API is essentially how we retrieve¬†data.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/491/0*5cChIv503mpzyPZm" /><figcaption>Figure 2: The retrieval and delivery of data is managed through an API which acts as the intermediary between the client and server¬†(<a href="https://www.sqlshack.com/create-rest-apis-in-python-using-flask/">Das</a>)</figcaption></figure><p>Strava athletes, companies, and partners access Strava data through the API. Much like the structure of a bridge, the structure of an API can vary. A GraphQL API and a REST API are two different architectures. Strava is restructuring their internal API to replace the REST API functionality with GraphQL architecture. This restructure includes differences in how data is fetched and retrieved which are shown¬†below:</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*_seRz5mIqCJPCsXH5P7hVw.png" /></figure><p>As shown by the requests above, while REST is the standardized API architecture, GraphQL has many benefits when it comes to having an efficient way to fetch data. The REST API requires two requests in order to retrieve the nested information, whereas the GraphQL request requires a single query to fetch all associated data. Part of my project involved building out GraphQL resolvers, which are the relayers of information so to speak. To build off our existing example, these resolvers could metaphorically be the tollgates on either side of the bridge between our two islands. These resolvers were built out as the foundation for a new feature called application notes.</p><h4>What is¬†Pakora?</h4><p>Pakora is a popular Indian appetizer but I came to know it as one of the Scala microservices at Strava, using a play on the word appetizer to indicate apps, i.e. API applications. Pakora is a new microservice introduced as part of the effort to transition from a code monolith and it is the service that houses all of the API application data. <a href="https://www.strava.com/apps">API applications</a> are the means by which athletes, companies, and partners can interact with Strava data, via the <a href="https://developers.strava.com/docs/reference/">Strava API</a>. Companies like Garmin, Peloton, FitBit, and hundreds more have API applications as a means to exchange information with Strava. I became familiar with this experience of how an athlete or company gains access to this data in the first place: creating an application. An application includes a name, a description, associated club, and other useful information all stored within a MySQL database table. The Scala microservice Pakora interacts with all of this data associated with applications.</p><h4>Do We Need to Take¬†Notes?</h4><p>The details of my project included building out endpoints to create a new feature for these API applications: application notes. Application notes will allow administrators (people who work at Strava) with the appropriate permissions to document important information to have all in one place. Use cases for application notes might be explaining why an application needs a higher rate limit (number of requests over a specific time interval) or documenting an update. These are things to take note of and can be displayed on the admin applications frontend page along with the details of an application. The notes themselves are stored within a table located in a MySQL database and the backend Scala service Pakora directly accesses this data by leveraging the Slick library. The Thrift server has endpoints used to retrieve this data, and finally, the GraphQL server speaks to the Thrift endpoints to actually get this data to an end¬†user.</p><h4>End-to-End</h4><p>After having completed the new notes feature and implementing the backend Thrift and GraphQL endpoints, I transitioned to working in the frontend. The monolith codebase uses haml files for some of the frontend pages that currently exist at Strava. Haml is a markup language that is not widely used. In the transition to a new architecture, these haml files are soon to be replaced by React microfrontends. Microfrontends, similar to microservices, are like modules that make up only a small portion of the frontend, used within a container that puts it all together. The way I became familiar with microfrontends is by React-ifying the current haml files that make up the API applications admin page. This microfrontend will replace the current user interface in the code monolith and it creates a space where administrators can view and manage API applications. Administrators can search applications by the application id or by the owner id. These applications can be viewed, edited, and deleted. The new notes feature in the backend is added in the frontend as well, where administrators can document anything important. Being able to build out the backend endpoints and use them in the frontend was such a gratifying experience and a new discovery of what I enjoy which I can look for in the¬†future.</p><h4>Closing Thoughts</h4><p>Throughout the course of my internship, I was encouraged and inspired by the commitment and positivity of the people at Strava. Whether it was running the Strava Mile or watching an impressive Jams presentation, I was overcome with how the people at Strava truly encourage connection. Having and maintaining connections with others requires vulnerability, which can be daunting, but ultimately drives success. I am extremely grateful for getting to spend my summer at Strava, especially with the mentorship of Collin Neuhaus, Anjali Merchant, Yudi Fu, Alayna Richmond and the rest of the Foundation team. Not only have I gained technical skills over the summer, but also have new role models in the people that I worked¬†with.</p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=cf3b5de261ec" width="1" height="1" alt=""><hr><p><a href="https://medium.com/strava-engineering/a-taste-of-pakora-cf3b5de261ec">A Taste of Pakora</a> was originally published in <a href="https://medium.com/strava-engineering">strava-engineering</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Personal Heatmaps]]></title>
            <link>https://medium.com/strava-engineering/personal-heatmaps-f51d15a0db2b?source=rss----89d4108ce2a3---4</link>
            <guid isPermaLink="false">https://medium.com/p/f51d15a0db2b</guid>
            <category><![CDATA[strava]]></category>
            <category><![CDATA[engineering]]></category>
            <category><![CDATA[running]]></category>
            <category><![CDATA[cycling]]></category>
            <category><![CDATA[gis]]></category>
            <dc:creator><![CDATA[J Evans]]></dc:creator>
            <pubDate>Fri, 28 Oct 2022 21:15:46 GMT</pubDate>
            <atom:updated>2025-07-04T06:43:13.595Z</atom:updated>
            <content:encoded><![CDATA[<p>This post discusses the algorithm behind Personal Heatmap, one of Strava‚Äôs most acclaimed subscriber features.</p><h4>Product Overview</h4><p>The Personal Heatmap feature has been around in some form since 2015, but we gave it a major overhaul in 2020. For those unfamiliar, the heatmap is an aggregated view of an athlete‚Äôs GPS-enabled activities on Strava. Activity data is rendered onto a map according to path traversal frequency; the more an athlete runs on a road, the brighter‚Ää‚Äî‚Ääi.e. ‚Äúhotter‚Äù‚Ää‚Äî‚Ääthat road shows up on the map. The result is a beautiful color gradient displaying the intricate web of past activities, unique to each¬†athlete.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/934/1*20g3cqcMKj395_MuowUc_Q.jpeg" /></figure><p>The Personal Heatmap is displayed on an interactive world map, also known as a <a href="https://wiki.openstreetmap.org/wiki/Slippy_map">slippy map</a>. Athletes can seamlessly zoom in and out or pan around to arbitrary views of the map, and their activity heat stays displayed the entire time. To enable this, we must provide a scheme for rendering and serving subsections of the world map on the fly. Enter map¬†tiling.</p><h3>Mercator Projection &amp; Map¬†Tiling</h3><p>Map tiling is the practice of subdividing a map into many discrete images that can be stitched together and rendered as a single image in real-time during map navigation. The first step in choosing a tiling scheme is picking what world map to use. Enter, the <strong>Mercator Projection</strong>, the most commonly used projection of Earth as a flat, rectangular surface. We use this projection in all of our mapping products, including heatmaps.</p><iframe src="https://cdn.embedly.com/widgets/media.html?src=https%3A%2F%2Fgiphy.com%2Fembed%2F7rg17FyGJdZ7N8dvZa%2Ftwitter%2Fiframe&amp;display_name=Giphy&amp;url=https%3A%2F%2Fgiphy.com%2Fgifs%2F7rg17FyGJdZ7N8dvZa&amp;image=https%3A%2F%2Fmedia1.giphy.com%2Fmedia%2F7rg17FyGJdZ7N8dvZa%2Fgiphy.gif%3Fcid%3D790b76116dc6c84cb445b381cec6e31aaaf1692548644dd8%26rid%3Dgiphy.gif%26ct%3Dg&amp;key=a19fcc184b9711e1b4764040d3dc5c07&amp;type=text%2Fhtml&amp;schema=giphy" width="435" height="435" frameborder="0" scrolling="no"><a href="https://medium.com/media/d9e120d13950dd0f1bb4ee14108aa9a9/href">https://medium.com/media/d9e120d13950dd0f1bb4ee14108aa9a9/href</a></iframe><p>Now, imagine a grid overlaying the Mercator projection. Each grid section is known as a <strong>tile</strong>, a pixel image with resolution 256x256. Every tile has an associated <strong>zoom level</strong>, and tiles are defined recursively according to this zoom level. A tile at a given zoom level can be subdivided into four equal sized tiles at a next<strong> </strong>zoom level. For example, Zoom level 0 displays the entire planet in a single 256x256 pixel image. Zoom level 1 displays the world in four 256x256 pixel images. The recursion continues until Zoom level 20, at which point the 256x256 pixel image displays an area roughly the size of a¬†house.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*wtNOrK2_ztb8U-c-5hTbBg.png" /><figcaption>This table approximates of the landmass covered by tiles at each of the 21 zoom¬†levels</figcaption></figure><p>We use a schema introduced by Google Maps to uniquely identify each tile with an &lt;x, y&gt; coordinate and associated zoom level. Moving forward, we‚Äôll refer to zoom levels as &lt;x,y,z&gt; tuples. Use this <a href="https://www.maptiler.com/google-maps-coordinates-tile-bounds-projection/#11/-122.43/37.77">online tool</a> to get familiar with the standard.</p><p>So, how do we transform an athlete‚Äôs activity data into this¬†map?</p><h3>Generating Map &amp; Heat¬†Images</h3><p>There are two components to a Personal Heatmap, the map image and the activity heat data overlaying that image. We will call the latter the heat¬†images.</p><h3>Generating Map¬†Images</h3><p>Instead of generating map images ourselves, we rely on Mapbox. They‚Äôve done a fantastic job providing beautiful, accurate, and well-designed map images for all of our mapping products. Their map images adhere to the <a href="https://docs.mapbox.com/data/tilesets/guides/vector-tiles-standards/">Mapbox Vector Tile specification</a>, a standard that enables efficient, high-resolution, client-side renderings of map displays.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*VkYCb8lMBCybrCiJDJKgBg.jpeg" /></figure><h3>Generating Heat¬†Images</h3><p>The activity ‚Äúheat‚Äù is what makes this experience unique to each athlete. Here‚Äôs how we create heat¬†images:</p><ol><li>Enumerate all activities for an¬†athlete</li><li>For each activity, produce a list of tiled<strong> activity segments. </strong>(We‚Äôll define¬†below)</li><li>Aggregate these lists of tile activity segments into a dictionary, where the key is a tile and the value is the list of tile activity segments that traverse the¬†tile.</li><li>For each tile in this dictionary, sum the tile activity segments and render a 256x256 resolution <strong>raster image</strong> of the heat for the¬†tile.</li></ol><h4>Step 1: Enumerate all activities</h4><p>We store each uploaded activity as a list of &lt;latitude, longitude&gt; points. For any athlete, we fetch this set of lists of &lt;lat, lng&gt;¬†points.</p><pre>case class Point(latitude: Double, longitude: Double)<br>val athleteActivities: Set[List[Point]] = fetchActivities(athleteId)</pre><h4>Step 2: Produce Tile Activity¬†Segments</h4><p>Once we‚Äôve fetched an athletes activities, we transform them into <strong>ActivitySegments</strong>¬†. An<strong> </strong>ActivitySegment is a data structure representing the portion of an activity that traverses a tile. Specifically, the ActivitySegment is a <strong>list of pixels traversed by the segment of an activity in a given¬†tile</strong>.</p><p>Consider a simplified tiling scheme with four zoom levels and a single activity. In this scheme, tiles are images with 10x10 pixel resolution.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*XKrSDMyPbu0tXSdqmNrh4A.png" /></figure><p>Now we focus on the activity in zoom level 2, taking care to annotate each tile with the &lt;x,y,z&gt; tile coordinates.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/691/1*taZrE1G3mPNPIVUhEhMARA.png" /><figcaption>projection at zoom level¬†2</figcaption></figure><p>The activity traverses seven of the 16 tiles. Thus, there are seven ActivitySegments for this activity at zoom level 2 of this projection; one for each traversed tile. Each ActivitySegment encodes a list of pixels and associated tile. Let‚Äôs drive this home by focusing on tile &lt;0,0,2&gt; as a 10x10 pixel¬†image.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/501/1*b3e6N3S8ZDxSa-c-o1DIVg.png" /><figcaption>Pixels in a 10x10 resolution image for activity segment that traverses tile¬†&lt;0,0,2&gt;</figcaption></figure><p>Tile &lt;0,0,2&gt; contains the beginning and ending segments of the activity. The shaded-in pixels constitute the list of pixels for the this ActivitySegment.</p><pre>ActivitySegment(<br>  Tile(0,0,2),<br>  List(<br>    Pixel(2,3), Pixel(3,3), Pixel(4,3), Pixel(5,3),<br>    Pixel(6,3), Pixel(7,3), Pixel(8,3), Pixel(9,2),<br>    Pixel(9,2), Pixel(2,5), Pixel(2,6), Pixel(2,7),<br>    Pixel(2,8), Pixel(3,8), Pixel(3,9)<br>  )<br>)</pre><p>We repeat this process for each activity, for every tile traversed by those activities, for multiple zoom¬†levels.</p><h4>Step 3: Aggregate Activity¬†Segments</h4><p>Once we‚Äôve repeated step 2 for every activity, we organize the ActivtySegments into a dictionary, keyed by tile. Consider the following scenario of an athlete that has completed four activities:</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*xkv4FoRCDsL1WyPxaXtEyw.png" /></figure><p>Focusing on zoom level 2 again, we can group ActivitySegments by on¬†tile.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/769/1*8qLS1g0E5MgzveFLy6z2pw.png" /><figcaption>ActivitySegments grouped by tile for tile &lt;0,0,2&gt; and tile¬†&lt;3,1,2&gt;</figcaption></figure><p>Tile &lt;0,0,2&gt; has two associated ActivitySegments, one from activity 1 and one from activity 2. Meanwhile, tile &lt;3,1,2&gt; has three associated ActivitySegments, one for activity 2, activity 3, and activity 4. Here, we‚Äôve only shown two mappings, but with the entire mapping, we can quickly determine two things about the¬†athlete:</p><ol><li>All tiles traversed during the athlete‚Äôs activities</li><li>All pixels <em>within</em> the tiles traversed by the¬†athlete</li></ol><p>Moreover, we can use this dictionary to count how many times an athlete has traversed any given pixel in a given tile. We have everything we need to render heat¬†images.</p><h4>Step 4: Render raster¬†images</h4><p>With the tile dictionary, we can calculate a traversal frequency for each pixel in a tile. Upon request, we loop through each pixel of a tile, counting how many ActivitySegments for the given tile include the pixel. After looping through and counting the traversal frequency for each pixel, we can color the pixels on a gradient. Below is an example of tile &lt;3,1,2&gt; from the projection described above.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*2vMLaRpiqDk8QJCTT8070w.png" /><figcaption>tile &lt;x=3,y=1,zoom=2&gt;</figcaption></figure><p>Pixels that aren‚Äôt traversed aren‚Äôt shaded in; pixels traversed fewer times are shaded in darker; pixels traversed more often are shaded in brighter.</p><h3>Putting it All¬†Together</h3><p>An athlete opens the <a href="https://strava.com/athlete/heatmap">Heatmap feature</a> in the Strava mobile app.¬†The map in view is tiled, and this set of tiles get passed down two request paths in parallel:</p><ol><li>Requests to Mapbox servers for vector tile map¬†images</li><li>Requests to our own server for the raster tile heat¬†images</li></ol><p>Once both sets of requests complete, the client overlays the raster images of an Athlete‚Äôs heat atop the vector tiles and presto! You have a¬†heatmap.</p><h3>Future Improvements</h3><p>We‚Äôre happy with the heatmaps product, but there‚Äôs always room for improvement. In a future release, we would consider rendering heat using vector images instead of raster images for a few¬†reasons:</p><ol><li>The resolution of raster images is static. Unfortunately, they look pixelated the more you zoom in. In contrast, vector tile resolution resizes, so they remain sharp regardless of the zoom¬†level.</li><li>As mentioned previously, Mapbox serves our map images in a vector format. Serving heat as vector images would provide consistency between our map and heat image¬†layers.</li><li>Vector image files size are typically smaller then raster file sizes, so data transfer from server to client is reduced when using vector tiles. This can make a significant difference when operating at Strava‚Äôs¬†scale.</li></ol><figure><img alt="" src="https://cdn-images-1.medium.com/max/300/1*pKkYgWLJE966HE5Qp1P1GQ.gif" /></figure><p>Thanks for reading! Subscribe to Strava if you want to explore your own personal heatmap, and be sure to check out our other engineering blog¬†posts.</p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=f51d15a0db2b" width="1" height="1" alt=""><hr><p><a href="https://medium.com/strava-engineering/personal-heatmaps-f51d15a0db2b">Personal Heatmaps</a> was originally published in <a href="https://medium.com/strava-engineering">strava-engineering</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Opportunity Arises From the Most Unexpected]]></title>
            <link>https://medium.com/strava-engineering/opportunity-arises-from-the-most-unexpected-614e9e13dcb9?source=rss----89d4108ce2a3---4</link>
            <guid isPermaLink="false">https://medium.com/p/614e9e13dcb9</guid>
            <category><![CDATA[route]]></category>
            <category><![CDATA[kotlin]]></category>
            <category><![CDATA[internships]]></category>
            <category><![CDATA[engineering]]></category>
            <category><![CDATA[strava]]></category>
            <dc:creator><![CDATA[Ryan Paragas]]></dc:creator>
            <pubDate>Tue, 25 Oct 2022 16:01:27 GMT</pubDate>
            <atom:updated>2023-01-17T16:41:49.296Z</atom:updated>
            <content:encoded><![CDATA[<p><strong>About Me:<br></strong>Hey there! My name is Ryan, and I come from an unconventional background. I am not like most interns from the group in 2022. I‚Äôve dropped out of college 3 times, worked in different fields for about 10 years, then transitioned into a bootcamp. Now working with Strava, they have set the expectation of what it should be like working in a professional environment.</p><p><strong>My Experience at Strava:<br></strong>Strava has been nothing but a wonderful experience. The weekly events they hosted to really engage the interns are motivational. The weekly AMAs were definitely my favorite of all the intern events. We got to meet the leaders of Strava and get to know them personally. The person I was most inspired by was Claude Jones. Claude also came from an unconventional background. He is a self taught programmer and worked his was up to VP of Engineering, leads motivational talks, and writes his own children books. From him I‚Äôve learned that even if I don‚Äôt come from a university, then I‚Äôll be able to make it in this field. So long as I continue to develop¬†myself.</p><iframe src="https://cdn.embedly.com/widgets/media.html?src=https%3A%2F%2Ftenor.com%2Fembed%2F13758139&amp;display_name=Tenor&amp;url=https%3A%2F%2Ftenor.com%2Fview%2Fnerd-sponge-bob-studying-serious-study-hard-gif-13758139&amp;image=https%3A%2F%2Fc.tenor.com%2Fcu2Gonk18tEAAAAC%2Fnerd-sponge-bob.gif&amp;key=a19fcc184b9711e1b4764040d3dc5c07&amp;type=text%2Fhtml&amp;schema=tenor" width="600" height="400" frameborder="0" scrolling="no"><a href="https://medium.com/media/adf714e44d6915dfd4229f36178d2c49/href">https://medium.com/media/adf714e44d6915dfd4229f36178d2c49/href</a></iframe><p>Aside from all the events we got to participate in, the support from my team, mentors, and managers provided for me was a whole new experience. I was given the chance to learn so much, and that definitely did not go to¬†waste.</p><p><strong>The Project:<br></strong>I am on the Athlete Services Team, and my team‚Äôs project was to create filters for the Saved Routes. The designs wanted us to be able to filter by sport, key word, distance, elevation, whether the route is starred or not, and who it is created¬†by.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/745/1*hiniXmtEL_oziMEMbLjD9A.png" /></figure><p><strong>Development:<br></strong>Creating this feature sounds easy right? Get the state of the filters, save it to the sheet, and apply it to the query. Yes, but there is more to it. The routes presenter and all of its associated classes are huge. So the android team wants to start refactoring that class into separate presenters, view delegates, and filter factories. Which I had the pleasure to start. In all honesty, I am really happy that I got to start my own presenter and it associated classes. I got the chance to learn how to link all the classes, inflate the views, and manage the logic between all of Saved Routes and the main presenter.</p><p>All of this is very new to me since I‚Äôve never seen a project of this scale and I‚Äôve never really programmed in Kotlin before. There was so much to process in such a little amount of time that I started to get overwhelmed and really doubted my ability to pull off this project. But the guidance and reassurance from my mentors and manager, Jason, really helped me take a deep breathe and knick away at it one piece at a¬†time.</p><iframe src="https://cdn.embedly.com/widgets/media.html?src=https%3A%2F%2Ftenor.com%2Fembed%2F18408194&amp;display_name=Tenor&amp;url=https%3A%2F%2Ftenor.com%2Fview%2Fmunchlax-meditate-meditation-breath-breathing-gif-18408194&amp;image=https%3A%2F%2Fc.tenor.com%2FZhH5rXOvFoMAAAAd%2Fmunchlax-meditate.gif&amp;key=a19fcc184b9711e1b4764040d3dc5c07&amp;type=text%2Fhtml&amp;schema=tenor" width="600" height="400" frameborder="0" scrolling="no"><a href="https://medium.com/media/7c05ff889a883efbe4f539bf32b70e27/href">https://medium.com/media/7c05ff889a883efbe4f539bf32b70e27/href</a></iframe><p><strong>This is Strava, and Strava is Awesome:<br></strong>I really didn‚Äôt want this blog post to be heavily focused on my project, but more about my time and experiences here at Strava. Just recently, I was talking to my fellow intern, Navika, and we talked about what we really want out of a career and what values do we want to align ourselves when selecting a company to work for. And Strava hits all of them for me. Strava has fostered an environment of just pure support. The collective mindset of wanting to better ourselves and each other, and that is what I want out of a professional environment. So that one day, I could be the person on the other end helping new software engineers.</p><p><strong>Big Shoutouts:<br></strong>I want to shout out my mentors Artem, Jeremy, and Pierre. Artem being my assigned mentor has helped me get on my feet as a programmer. He is extremely knowledgable and has answered every question with patience. Jeremy was another android developer who has moved on from Strava. But during his time still here and during my internship, he helped me with the refactoring of the saved routes logic. His guidance really helped make it manageable on top of teaching me how it all works. I greatly appreciate all the knowledge he‚Äôs passed on to me. Pierre is one of our Android guild leaders and my interim mentor while Artem was out on FTO. Pierre‚Äôs reviews on my code really forced me to think differently about how I need to code. Simply thinking about how business logic should be¬†written.</p><p>I‚Äôd also like to shoutout my fellow interns on my team. The fellow interns being Sahil, Emily, Navika, and Yuwen. We got together every week since the start of our internship just to casually talk. They made the camaraderie feel real. It can be hard when you are working solely from home and really feel the connections between people. But this group of individuals definitely made it feel real. Having gone through this internship with these people really made me feel less lost compared to the first few¬†weeks!</p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=614e9e13dcb9" width="1" height="1" alt=""><hr><p><a href="https://medium.com/strava-engineering/opportunity-arises-from-the-most-unexpected-614e9e13dcb9">Opportunity Arises From the Most Unexpected</a> was originally published in <a href="https://medium.com/strava-engineering">strava-engineering</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>]]></content:encoded>
        </item>
    </channel>
</rss>