<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Google Developers Blog</title><link>https://developers.googleblog.com/rss/</link><description>Updates on changes and additions to the Google Developers Blog.</description><atom:link href="https://developers.googleblog.com/feeds/posts/default/" rel="self"/><language>en-us</language><lastBuildDate>Fri, 19 Dec 2025 22:22:20 +0000</lastBuildDate><item><title>Real-World Agent Examples with Gemini 3</title><link>https://developers.googleblog.com/real-world-agent-examples-with-gemini-3/</link><description>Gemini 3 is powering the next generation of reliable, production-ready AI agents. This post highlights 6 open-source framework collaborations (ADK, Agno, Browser Use, Eigent, Letta, mem0), demonstrating practical agentic workflows for tasks like deep search, multi-agent systems, browser and enterprise automation, and stateful agents with advanced memory. Clone the examples and start building today.</description><guid>https://developers.googleblog.com/real-world-agent-examples-with-gemini-3/</guid></item><item><title>Conductor: Introducing context-driven development for Gemini CLI</title><link>https://developers.googleblog.com/conductor-introducing-context-driven-development-for-gemini-cli/</link><description>Conductor is a new Gemini CLI extension that promotes context-driven development. It shifts project context from chat logs to persistent Markdown files for formal specs and plans, ensuring AI agents adhere to project goals, style, and tech stack. This structured workflow is great for "brownfield" projects and teams, allowing for safe iteration and consistent code contributions while keeping the human developer in control.</description><guid>https://developers.googleblog.com/conductor-introducing-context-driven-development-for-gemini-cli/</guid></item><item><title>Gemini 3 Flash is now available in Gemini CLI</title><link>https://developers.googleblog.com/gemini-3-flash-is-now-available-in-gemini-cli/</link><description>Gemini 3 Flash is now available in Gemini CLI. It delivers Pro-grade coding performance with low latency and a lower cost, matching Gemini 3 Pro's SWE-bench Verified score of 76%. It significantly outperforms 2.5 Pro, improving auto-routing and agentic coding. It's ideal for high-frequency development tasks, handling complex code generation, large context windows (like processing 1,000 comment pull requests), and generating load-testing scripts quickly and reliably.</description><guid>https://developers.googleblog.com/gemini-3-flash-is-now-available-in-gemini-cli/</guid></item><item><title>Introducing Agent Development Kit for TypeScript: Build AI Agents with the Power of a Code-First Approach</title><link>https://developers.googleblog.com/introducing-agent-development-kit-for-typescript-build-ai-agents-with-the-power-of-a-code-first-approach/</link><description>Introducing the Agent Development Kit (ADK) for TypeScript, an open-source framework for building complex, multi-agent AI systems with a code-first approach. Developers can define agent logic in TypeScript, applying traditional software development best practices (version control, testing). ADK offers end-to-end type safety, modularity, and deployment-agnostic functionality, leveraging the familiar TypeScript/JavaScript ecosystem.</description><guid>https://developers.googleblog.com/introducing-agent-development-kit-for-typescript-build-ai-agents-with-the-power-of-a-code-first-approach/</guid></item><item><title>Developerâ€™s guide to multi-agent patterns in ADK</title><link>https://developers.googleblog.com/developers-guide-to-multi-agent-patterns-in-adk/</link><description>Learn how to build modular and reliable agentic applications using 8 effective multi-agent design patterns with the Agent Development Kit (ADK).</description><guid>https://developers.googleblog.com/developers-guide-to-multi-agent-patterns-in-adk/</guid></item><item><title>Introducing A2UI: An open project for agent-driven interfaces</title><link>https://developers.googleblog.com/introducing-a2ui-an-open-project-for-agent-driven-interfaces/</link><description>A2UI is an open-source project for agent-driven, cross-platform, and generative UI. It provides a secure, declarative data format for agents to compose bespoke interfaces from a trusted component catalog, allowing for native styling and incremental updates. Designed for the multi-agent mesh (A2A), it offers a framework-agnostic solution to safely render remote agent UIs, with integrations in AG UI, Flutter's GenUI SDK, Opal, and Gemini Enterprise.</description><guid>https://developers.googleblog.com/introducing-a2ui-an-open-project-for-agent-driven-interfaces/</guid></item><item><title>Building agents with the ADK and the new Interactions API</title><link>https://developers.googleblog.com/building-agents-with-the-adk-and-the-new-interactions-api/</link><description>The new Gemini Interactions API enables stateful, multi-turn AI agent workflows, providing a single interface for raw models and the Gemini Deep Research Agent. It can be integrated with existing ADK systems as a superior inference engine with simplified state management, or used as a transparent remote A2A agent via InteractionsApiTransport, allowing seamless expansion of multi-agent systems with minimal refactoring.</description><guid>https://developers.googleblog.com/building-agents-with-the-adk-and-the-new-interactions-api/</guid></item><item><title>Pick up exactly where you left off with Session Management in Gemini CLI</title><link>https://developers.googleblog.com/pick-up-exactly-where-you-left-off-with-session-management-in-gemini-cli/</link><description>Gemini CLI's new automatic **Session Management** (v0.20.0+) saves your conversation history, tool outputs, and reasoning, providing project-specific context. Resume easily using the **Interactive Session Browser** (`/resume`) or command-line flags (`--resume`). This feature ensures you never lose your work state, capturing prompts, tool execution details, and usage stats. Customize history with cleanup policies in `settings.json`.</description><guid>https://developers.googleblog.com/pick-up-exactly-where-you-left-off-with-session-management-in-gemini-cli/</guid></item><item><title>Don't Trust, Verify: Building End-to-End Confidential Applications on Google Cloud</title><link>https://developers.googleblog.com/dont-trust-verify-building-end-to-end-confidential-applications-on-google-cloud/</link><description>Google Cloud enables end-to-end confidential applications, protecting sensitive data 'in-use' with hardware isolation. The solution combines Confidential Space (TEE/attestation), Oak Functions (private sandbox), and Oak Session (attested end-to-end encryption for scale). This framework anchors user trust in open-source components, proving confidentiality for sensitive workloads like proprietary GenAI models, even when running behind untrusted load balancers.</description><guid>https://developers.googleblog.com/dont-trust-verify-building-end-to-end-confidential-applications-on-google-cloud/</guid></item><item><title>MediaTek NPU and LiteRT: Powering the next generation of on-device AI</title><link>https://developers.googleblog.com/mediatek-npu-and-litert-powering-the-next-generation-of-on-device-ai/</link><description>LiteRT and MediaTek are announcing the new LiteRT NeuroPilot Accelerator. This is a ground-up successor for the TFLite NeuroPilot delegate, bringing seamless deployment experience, state-of-the-art LLM support, and advanced performance to millions of devices worldwide.</description><guid>https://developers.googleblog.com/mediatek-npu-and-litert-powering-the-next-generation-of-on-device-ai/</guid></item><item><title>Architecting efficient context-aware multi-agent framework for production</title><link>https://developers.googleblog.com/architecting-efficient-context-aware-multi-agent-framework-for-production/</link><description>ADK introduces **Context Engineering** to scale AI agents beyond large context windows. It treats context as a compiled view over a tiered, stateful system (**Session, Memory, Artifacts**). This architecture uses explicit processors for transformation, enables efficient compaction and caching, and allows for strict, scoped context handoffs in multi-agent workflows to ensure reliability and cost-effectiveness in production.</description><guid>https://developers.googleblog.com/architecting-efficient-context-aware-multi-agent-framework-for-production/</guid></item><item><title>Announcing the Data Commons Gemini CLI extension</title><link>https://developers.googleblog.com/announcing-the-data-commons-gemini-cli-extension/</link><description>The new Data Commons extension for the Gemini CLI makes accessing public data easier. It allows users to ask complex, natural-language questions to query Data Commons' public datasets, grounding LLM responses in authoritative sources to reduce AI hallucinations. Data Commons is an organized library of public data from sources like the UN and World Bank. The extension enables instant data analysis, exploration, and integration with other data-related extensions.</description><guid>https://developers.googleblog.com/announcing-the-data-commons-gemini-cli-extension/</guid></item><item><title>New Gemini API updates for Gemini 3</title><link>https://developers.googleblog.com/new-gemini-api-updates-for-gemini-3/</link><description>Gemini 3 is available via API with updates for developers: new `thinking_level` for depth control, `media_resolution` for multimodal processing, and enforced `Thought Signatures` for agentic workflows, especially with function calling and image generation. It also introduces combining Google Search/URL Grounding with Structured Outputs and new usage-based pricing for Grounding. Best practices, like using default temperature, are advised for optimal results.</description><guid>https://developers.googleblog.com/new-gemini-api-updates-for-gemini-3/</guid></item><item><title>Unlocking Peak Performance on Qualcomm NPU with LiteRT</title><link>https://developers.googleblog.com/unlocking-peak-performance-on-qualcomm-npu-with-litert/</link><description>LiteRT's new Qualcomm AI Engine Direct (QNN) Accelerator unlocks dedicated NPU power for on-device GenAI on Android. It offers a unified mobile deployment workflow, SOTA performance (up to 100x speedup over CPU), and full model delegation. This enables smooth, real-time AI experiences, with FastVLM-0.5B achieving over 11,000 tokens/sec prefill on Snapdragon 8 Elite Gen 5 NPU.</description><guid>https://developers.googleblog.com/unlocking-peak-performance-on-qualcomm-npu-with-litert/</guid></item><item><title>Build with Google Antigravity, our new agentic development platform</title><link>https://developers.googleblog.com/build-with-google-antigravity-our-new-agentic-development-platform/</link><description>Introducing Google Antigravity, a new agentic development platform for orchestrating code. It combines an AI-powered Editor View with a Manager Surface to deploy agents that autonomously plan, execute, and verify complex tasks across your editor, terminal, and browser. Agents communicate progress via Artifacts (screenshots, recordings) for easy verification. Available now in public preview.</description><guid>https://developers.googleblog.com/build-with-google-antigravity-our-new-agentic-development-platform/</guid></item><item><title>Building AI Agents with Google Gemini 3 and Open Source Frameworks</title><link>https://developers.googleblog.com/building-ai-agents-with-google-gemini-3-and-open-source-frameworks/</link><description>Gemini 3 Pro Preview is introduced as a powerful, agentic model for complex, (semi)-autonomous workflows. New agentic features include `thinking_level` for reasoning control, Stateful Tool Use via Thought Signatures, and `media_resolution` for multimodal fidelity. It has Day 0 support for open-source frameworks like LangChain, AI SDK, LlamaIndex, Pydantic AI, and n8n. Best practices include simplifying prompts and keeping temperature at 1.0.</description><guid>https://developers.googleblog.com/building-ai-agents-with-google-gemini-3-and-open-source-frameworks/</guid></item><item><title>Building with Gemini 3 in Jules</title><link>https://developers.googleblog.com/jules-gemini-3/</link><description>Jules, an always-on, multi-step software development agent, now features Gemini 3, offering clearer reasoning and better reliability. Recent improvements include parallel CLI runs, a stable API, and safer Git handling. Upcoming features include directory attachment without GitHub and automatic PR creation. Jules aims to reduce software writing overhead so developers can focus on building.</description><guid>https://developers.googleblog.com/jules-gemini-3/</guid></item><item><title>Building production AI on Google Cloud TPUs with JAX</title><link>https://developers.googleblog.com/building-production-ai-on-google-cloud-tpus-with-jax/</link><description>The JAX AI Stack is a modular, industrial-grade, end-to-end machine learning platform built on the core JAX library, co-designed with Cloud TPUs. It features key components like JAX, Flax, Optax, and Orbax for foundational model development, plus an extended ecosystem for the full ML lifecycle and production. This integration provides a powerful, scalable foundation for AI development, delivering significant performance advantages.</description><guid>https://developers.googleblog.com/building-production-ai-on-google-cloud-tpus-with-jax/</guid></item><item><title>5 things to try with Gemini 3 Pro in Gemini CLI</title><link>https://developers.googleblog.com/5-things-to-try-with-gemini-3-pro-in-gemini-cli/</link><description>Gemini 3 Pro is now integrated into Gemini CLI, unlocking state-of-the-art reasoning, agentic coding, and advanced tool use for enhanced developer productivity. It's available now for Google AI Ultra and paid Gemini API key subscribers (upgrade CLI to 0.16.x). Features include generating 3D apps and code from visual sketches, running complex shell commands, creating documentation, and debugging live Cloud Run services.</description><guid>https://developers.googleblog.com/5-things-to-try-with-gemini-3-pro-in-gemini-cli/</guid></item><item><title>Google Colab is Coming to VS Code</title><link>https://developers.googleblog.com/google-colab-is-coming-to-vs-code/</link><description>Google Colab has launched an official VS Code extension, bridging the gap between the popular code editor and the AI/ML platform. The extension combines VS Code's powerful development environment with Colab's seamless access to high-powered runtimes (GPUs/TPUs), allowing users to connect local notebooks to Colab. This aims to meet developers where they are and brings the best of both worlds.</description><guid>https://developers.googleblog.com/google-colab-is-coming-to-vs-code/</guid></item></channel></rss>