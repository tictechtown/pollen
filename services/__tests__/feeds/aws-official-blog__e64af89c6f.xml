<?xml version="1.0" encoding="UTF-8" standalone="no"?><rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:slash="http://purl.org/rss/1.0/modules/slash/" xmlns:sy="http://purl.org/rss/1.0/modules/syndication/" xmlns:wfw="http://wellformedweb.org/CommentAPI/" version="2.0">

<channel>
	<title>AWS News Blog</title>
	<atom:link href="https://aws.amazon.com/blogs/aws/feed/" rel="self" type="application/rss+xml"/>
	<link>https://aws.amazon.com/blogs/aws/</link>
	<description>Announcements, Updates, and Launches</description>
	<lastBuildDate>Fri, 19 Dec 2025 20:56:36 +0000</lastBuildDate>
	<language>en-US</language>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	
	<item>
		<title>AWS Weekly Roundup: Amazon ECS, Amazon CloudWatch, Amazon Cognito and more (December 15, 2025)</title>
		<link>https://aws.amazon.com/blogs/aws/aws-weekly-roundup-amazon-ecs-amazon-cloudwatch-amazon-cognito-and-more-december-15-2025/</link>
					
		
		<dc:creator><![CDATA[Matheus Guimaraes]]></dc:creator>
		<pubDate>Mon, 15 Dec 2025 16:42:05 +0000</pubDate>
				<category><![CDATA[News]]></category>
		<category><![CDATA[Week in Review]]></category>
		<guid isPermaLink="false">9d810fd027c12ec172f549005fe7c4a1806d782c</guid>

					<description>Can you believe it? We’re nearly at the end of 2025. And what a year it’s been! From re:Invent recap events, to AWS Summits, AWS Innovate, AWS re:Inforce, Community Days, and DevDays and, recently, adding that cherry on the cake, re:Invent 2025, we have lived through a year filled with exciting moments and technology advancements […]</description>
										<content:encoded>&lt;p&gt;Can you believe it? We’re nearly at the end of 2025. And what a year it’s been! From re:Invent recap events, to AWS Summits, AWS Innovate, AWS re:Inforce, Community Days, and DevDays and, recently, adding that cherry on the cake, re:Invent 2025, we have lived through a year filled with exciting moments and technology advancements which continue to shape our new modern world.&lt;/p&gt; 
&lt;p&gt;Speaking of re:Invent, if you haven’t caught up yet on all the new releases and announcements (and there were plenty of exciting launches across every area), be sure to check out our curated post highlighting the &lt;a href="https://aws.amazon.com/blogs/aws/top-announcements-of-aws-reinvent-2025?trk=ac97e39c-d115-4d4a-b3fe-c695e0c9a7ee&amp;amp;sc_channel=el"&gt;top announcements from AWS re:Invent 2025&lt;/a&gt;. We’ve organized all the key releases into easy-to-navigate categories and included links so you can dive deeper into anything that sparks your interest.&lt;/p&gt; 
&lt;p&gt;While the year may be wrapping up, our teams are still busy working on things that you have either asked for as customers or that we pro-actively create to make your lives easier. Last week had quite a few interesting releases as usual, so let’s look at a few that I think could be useful for many of you out there.&lt;/p&gt; 
&lt;p&gt;&lt;span style="text-decoration: underline"&gt;&lt;strong&gt;Last week’s launches&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://aws.amazon.com/about-aws/whats-new/2025/12/amazon-workspaces-secure-browser-web-content-filtering/?trk=ac97e39c-d115-4d4a-b3fe-c695e0c9a7ee&amp;amp;sc_channel=el"&gt;Amazon WorkSpaces Secure Browser introduces Web Content Filtering&lt;/a&gt; – Organizations can now control web access through category-based filtering across 25+ predefined categories, granular URL policies, and integrated compliance logging. The feature works alongside existing Chrome policies and integrates with Session Logger for enhanced monitoring and is available at no additional cost in 10 AWS Regions with pay-as-you-go pricing.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://aws.amazon.com/about-aws/whats-new/2025/12/amazon-aurora-dsql-cluster-creation-in-seconds/?trk=ac97e39c-d115-4d4a-b3fe-c695e0c9a7ee&amp;amp;sc_channel=el"&gt;Amazon Aurora DSQL now supports cluster creation in seconds&lt;/a&gt;&amp;nbsp;– Developers can now instantly provision Aurora DSQL databases with setup time reduced from minutes to seconds, enabling rapid prototyping through the integrated AWS console query editor or AI-powered development via the Aurora DSQL Model Context Protocol server. Available at no additional cost in all AWS Regions where Aurora DSQL is offered, with AWS Free Tier access available.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://aws.amazon.com/about-aws/whats-new/2025/12/amazon-aurora-postgresql-integration-kiro-powers/?trk=ac97e39c-d115-4d4a-b3fe-c695e0c9a7ee&amp;amp;sc_channel=el"&gt;Amazon Aurora PostgreSQL now supports integration with Kiro powers&lt;/a&gt; – Developers can now accelerate Aurora PostgreSQL application development using AI-assisted coding through Kiro powers, a repository of pre-packaged Model Context Protocol servers. The Aurora PostgreSQL integration provides direct database connectivity for queries, schema management, and cluster operations, dynamically loading relevant context as developers work. Available for one-click installation in Kiro IDE across all AWS Regions.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://aws.amazon.com/about-aws/whats-new/2025/12/amazon-ecs-custom-container-stop-signals-fargate/?trk=ac97e39c-d115-4d4a-b3fe-c695e0c9a7ee&amp;amp;sc_channel=el"&gt;Amazon ECS now supports custom container stop signals on AWS Fargate&lt;/a&gt;&amp;nbsp;– Fargate tasks now honor the stop signal configured in container images, enabling graceful shutdowns for containers that rely on signals like SIGQUIT or SIGINT instead of the default SIGTERM. The ECS container agent reads the STOPSIGNAL instruction from OCI-compliant images and sends the appropriate signal during task termination. Available at no additional cost across all AWS Regions.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://aws.amazon.com/about-aws/whats-new/2025/12/amazon-cloudwatch-sdk-json-cbor-protocols/?trk=ac97e39c-d115-4d4a-b3fe-c695e0c9a7ee&amp;amp;sc_channel=el"&gt;Amazon CloudWatch SDK supports optimized JSON, CBOR protocols&lt;/a&gt;&amp;nbsp;– CloudWatch SDK now defaults to JSON and CBOR protocols, delivering lower latency, reduced payload sizes, and decreased client-side CPU and memory usage compared to the traditional AWS Query protocol. Available at no additional cost across all AWS Regions and SDK language variants.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://aws.amazon.com/about-aws/whats-new/2025/12/amazon-cognito-identity-pools-private-connectivity-aws-privatelink/?trk=ac97e39c-d115-4d4a-b3fe-c695e0c9a7ee&amp;amp;sc_channel=el"&gt;Amazon Cognito identity pools now support private connectivity with AWS PrivateLink&lt;/a&gt; – Organizations can now securely exchange federated identities for temporary AWS credentials through private VPC connections, eliminating the need to route authentication traffic over the public internet. Available in all AWS Regions where Cognito identity pools are supported, except AWS China (Beijing) and AWS GovCloud (US) Regions.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://aws.amazon.com/about-aws/whats-new/2025/12/application-migration-service-ipv6?trk=ac97e39c-d115-4d4a-b3fe-c695e0c9a7ee&amp;amp;sc_channel=el"&gt;AWS Application Migration Service supports IPv6&lt;/a&gt;&amp;nbsp;– Organizations can now migrate applications using IPv6 addressing through dual-stack service endpoints that support both IPv4 and IPv6 communications. During replication, testing, and cutover phases, you can use IPv4, IPv6, or dual-stack configurations to launch servers in your target environment. Available at no additional cost in all AWS Regions that support MGN and EC2 dual-stack endpoints.&lt;/p&gt; 
&lt;p&gt;And that’s it for the AWS News Blog Weekly Roundup…not just for this week, but for 2025! We’ll be taking a break and returning in January to continue bringing you the latest AWS releases and updates.&lt;/p&gt; 
&lt;p&gt;As we close out 2025, it’s remarkable to look back at just how much has changed since the beginning of year. From groundbreaking AI capabilities to transformative infrastructure innovations, AWS has delivered an incredible year of releases that have reshaped what’s possible in the cloud. Throughout it all, the AWS News Blog has been right here with you every week with our Weekly Roundup series, helping you stay informed and ready to take advantage of each new opportunity as it arrived. We’re grateful you’ve joined us on this journey, and we can’t wait to continue bringing you the latest AWS innovations when we return in January 2026.&lt;/p&gt; 
&lt;p&gt;Until then, happy building, and here’s to an even more exciting year ahead!&lt;/p&gt; 
&lt;a href="https://link.codingmatheus.com/linkedin"&gt;Matheus Guimaraes | @codingmatheus&lt;/a&gt;</content:encoded>
					
					
			
		
		
			</item>
		<item>
		<title>AWS Weekly Roundup: AWS re:Invent keynote recap, on-demand videos, and more (December 8, 2025)</title>
		<link>https://aws.amazon.com/blogs/aws/aws-weekly-roundup-aws-reinvent-keynote-recap-on-demand-videos-and-more-december-8-2025/</link>
					
		
		<dc:creator><![CDATA[Donnie Prakoso]]></dc:creator>
		<pubDate>Mon, 08 Dec 2025 17:05:29 +0000</pubDate>
				<category><![CDATA[Amazon Bedrock]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[AWS re:Invent]]></category>
		<category><![CDATA[Events]]></category>
		<category><![CDATA[News]]></category>
		<category><![CDATA[Security, Identity, & Compliance]]></category>
		<category><![CDATA[Week in Review]]></category>
		<guid isPermaLink="false">57e2fca095d1b9d59bdd7c819a10b6e85723304b</guid>

					<description>The week after AWS re:Invent builds on the excitement and energy of the event and is a good time to learn more and understand how the recent announcements can help you solve your challenges and unlock new opportunities. As usual, we have you covered with our top announcements of AWS re:Invent 2025 that you can […]</description>
										<content:encoded>&lt;p&gt;The week after AWS re:Invent builds on the excitement and energy of the event and is a good time to learn more and understand how the recent announcements can help you solve your challenges and unlock new opportunities. As usual, we have you covered with our &lt;a href="https://aws.amazon.com/blogs/aws/top-announcements-of-aws-reinvent-2025/?trk=c4ea046f-18ad-4d23-a1ac-cdd1267f942c&amp;amp;sc_channel=el"&gt;top announcements of AWS re:Invent 2025&lt;/a&gt; that you can learn all about here.&lt;/p&gt; 
&lt;p&gt;For me, one moment stood out above all the technical announcements: watching &lt;a href="https://builder.aws.com/community/heroes/RaphaelQuisumbing?trk=c4ea046f-18ad-4d23-a1ac-cdd1267f942c&amp;amp;sc_channel=el"&gt;Rafi (Raphael Francis Quisumbing)&lt;/a&gt; from the Philippines receive the Now Go Build Award from &lt;a href="https://www.allthingsdistributed.com/"&gt;Werner Vogels&lt;/a&gt;. Rafi has been an AWS Hero since 2015 and co-lead of &lt;a href="https://www.facebook.com/groups/AWSUGPH/"&gt;AWS User Group Philippines&lt;/a&gt; since 2013. His dedication to building communities and empowering developers across the region embodies what this award represents. You can read more about Rafi on &lt;a href="https://thekernel.news/#:~:text=Winner%20of%20the%202025%20Now%20Go%20Build%20Award%3A%20Raphael%20Quisumbing"&gt;The Kernel&lt;/a&gt;. Congrats, Rafi!&lt;/p&gt; 
&lt;p&gt;&lt;img loading="lazy" class="aligncenter size-full wp-image-102608" style="border: 1px solid black;padding: 3px" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/12/08/2025-news-nowgobuild-1.png" alt="" width="1830" height="1142"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="text-decoration: underline"&gt;&lt;strong&gt;The keynote recap: Agents, renaissance, and the developer’s role&lt;br&gt;&lt;/strong&gt;&lt;/span&gt;This year’s AWS re:Invent keynotes painted a clear picture of where we’re headed.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=q3Sb9PemsSo"&gt;&lt;strong&gt;Matt Garman&lt;/strong&gt;&amp;nbsp;&lt;/a&gt;emphasized that developers are “the heart of AWS” and that “freedom to invent” remains AWS’s core mission after 20 years. He focused on AI agents as the next inflection point: “AI assistants are starting to give way to AI agents that can perform tasks and automate on your behalf. This is where we’re starting to see material business returns from your AI investments.”&lt;/p&gt; 
&lt;p&gt;&lt;iframe loading="lazy" title="AWS re:Invent 2025 - Keynote with CEO Matt Garman" width="500" height="281" src="https://www.youtube-nocookie.com/embed/q3Sb9PemsSo?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen sandbox="allow-scripts allow-same-origin"&gt;&lt;/iframe&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=prVdCIHlipg"&gt;&lt;strong&gt;Swami Sivasubramanian&lt;/strong&gt;&lt;/a&gt;&amp;nbsp;highlighted the transformative moment we’re in: “For the first time in history, we can describe what we want to accomplish in natural language, and agents generate the plan. They write the code, call the necessary tools, and execute the complete solution.” AWS is building production-ready infrastructure that’s secure, reliable, and scalable—purpose-built for the non-deterministic nature of agents.&lt;/p&gt; 
&lt;p&gt;&lt;iframe loading="lazy" title="AWS re:Invent 2025 - Keynote with Dr. Swami Sivasubramanian" width="500" height="281" src="https://www.youtube-nocookie.com/embed/prVdCIHlipg?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen sandbox="allow-scripts allow-same-origin"&gt;&lt;/iframe&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=JeUpUK0nhC0"&gt;&lt;strong&gt;Peter DeSantis and Dave Brown&lt;/strong&gt;&lt;/a&gt;&amp;nbsp;reinforced that the core attributes AWS has obsessed over for 20 years—security, availability, performance, elasticity, cost, and agility—are more important than ever in the AI era. Dave Brown showcased Graviton and AWS’s custom silicon innovations that deliver these attributes at scale.&lt;/p&gt; 
&lt;p&gt;&lt;iframe loading="lazy" title="AWS re:Invent 2025 - Keynote with Peter DeSantis and Dave Brown" width="500" height="281" src="https://www.youtube-nocookie.com/embed/JeUpUK0nhC0?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen sandbox="allow-scripts allow-same-origin"&gt;&lt;/iframe&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=3Y1G9najGiI"&gt;&lt;strong&gt;Werner Vogels&lt;/strong&gt;&lt;/a&gt;&amp;nbsp;delivered his final keynote after 14 years, introducing the concept of the “renaissance developer”—someone who is curious, thinks in systems, and communicates effectively. His message about AI and developer evolution resonated: “Will AI take my job? Maybe. Will AI make me obsolete? Absolutely not… if you evolve.” He emphasized that developers must be owners: “The work is yours, not that of the tools. You build it, you own it.”&lt;/p&gt; 
&lt;p&gt;&lt;iframe loading="lazy" title="AWS re:Invent 2025 - Keynote with Dr. Werner Vogels" width="500" height="281" src="https://www.youtube-nocookie.com/embed/3Y1G9najGiI?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen sandbox="allow-scripts allow-same-origin"&gt;&lt;/iframe&gt;&lt;/p&gt; 
&lt;p&gt;You can also watch from keynotes, innovation talks to breakout sessions and more in the &lt;a href="https://reinvent.awsevents.com/on-demand/?trk=c4ea046f-18ad-4d23-a1ac-cdd1267f942c&amp;amp;sc_channel=el"&gt;on-demand video page&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Innovations Talks&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://youtu.be/L_Q7LPB5HcA"&gt;Harnessing analytics for humans and AI (INV201)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://youtu.be/D0UkoghAVM0"&gt;AI agents in action: Architecting the future of applications (INV202)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://youtu.be/qHvm3oFmRls"&gt;The agent-enabled workplace: Transforming businesses with AI (INV203)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://youtu.be/tqHCjUSRKxc"&gt;Build and scale AI: from reliable agents to transformative systems (INV204)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://youtu.be/A8BYnqiHfeA"&gt;Reinventing software development with AI agents (INV205)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://youtu.be/2_Ev5YCO2Ik"&gt;Unlocking possibilities with AWS Compute (INV207)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://youtu.be/MBvyZENChk0"&gt;Databases made effortless so agents and developers can change the world (INV208)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://youtu.be/_Wi_4I40bqQ"&gt;The next frontier: Building the agentic future of Financial Services (INV209)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://youtu.be/pIiZupnNpPM"&gt;Infrastructure for the impossible: Turning public sector barriers into breakthroughs (INV210)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://youtu.be/zj44evAY_AA"&gt;Behind the curtain: How Amazon’s AI innovations are powered by AWS (INV211)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://youtu.be/6b1Ho9hr8-0"&gt;Migrate, modernize, and move your business into the AI era (INV212)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://youtu.be/RkdPAFJEPSA"&gt;The power of cloud network innovation (INV213)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://youtu.be/q3ZRbCTnB3U"&gt;Intelligent security: Protection at scale from development to production (INV214)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://youtu.be/beWO7h7Ut44"&gt;AWS storage beyond data boundaries: Building the data foundation (INV215)&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;table&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Breakout sessions — Topics&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Breakout sessions — Segments&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td valign="top"&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://www.youtube.com/playlist?list=PL2yQDdvlhXf8hzMmCGt2F--Oa6rF2rktF&amp;amp;trk=c4ea046f-18ad-4d23-a1ac-cdd1267f942c"&gt;Analytics&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://www.youtube.com/playlist?list=PL2yQDdvlhXf9m3loOlzEtdpobt-85B04t&amp;amp;trk=c4ea046f-18ad-4d23-a1ac-cdd1267f942c"&gt;Application Integration&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://www.youtube.com/playlist?list=PL2yQDdvlhXf9t-nSD6dYTv-szvZxsBeh0&amp;amp;trk=c4ea046f-18ad-4d23-a1ac-cdd1267f942c"&gt;Architecture&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://www.youtube.com/playlist?list=PL2yQDdvlhXf-UqnINCmXu-dDZJm_B3bbJ" data-sk="tooltip_parent"&gt;Artificial Intelligence&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://www.youtube.com/playlist?list=PL2yQDdvlhXf-H-1ygVzXLcZifTGGIreNK&amp;amp;trk=c4ea046f-18ad-4d23-a1ac-cdd1267f942c"&gt;Business Applications&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://www.youtube.com/playlist?list=PL2yQDdvlhXf8fUGVeljVNpQwugV7XBZRt" data-sk="tooltip_parent"&gt;Cloud Operations&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://www.youtube.com/playlist?list=PL2yQDdvlhXf_0uJ0iFTpJ6zhvGpSl-jsy" data-sk="tooltip_parent"&gt;Compute&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://www.youtube.com/playlist?list=PL2yQDdvlhXf9l1y_VZAm0vG2hproZMtip" data-sk="tooltip_parent"&gt;Database&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://www.youtube.com/playlist?list=PL2yQDdvlhXf8HawFRm2kL9935mQmLyGy1" data-sk="tooltip_parent"&gt;Developer Tools&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://www.youtube.com/playlist?list=PL2yQDdvlhXf_5JZDW_n_p6sGrZpWzPK-3&amp;amp;trk=c4ea046f-18ad-4d23-a1ac-cdd1267f942c"&gt;End-User Computing&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://www.youtube.com/playlist?list=PL2yQDdvlhXf9Vml7a6_rh4BNrLTTU0euv" data-sk="tooltip_parent"&gt;Hybrid Cloud &amp;amp; Multi Cloud&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://www.youtube.com/playlist?list=PL2yQDdvlhXf_LuBI1bIWPHQi88G6QR6KM" data-sk="tooltip_parent"&gt;Industry Solutions&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://www.youtube.com/playlist?list=PL2yQDdvlhXf8Kb_IJfMCw7CA630dbJL7a" data-sk="tooltip_parent"&gt;Migration &amp;amp; Modernization&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://www.youtube.com/playlist?list=PL2yQDdvlhXf8-QA1Hi5D-W2vRdc3h7FpK" data-sk="tooltip_parent"&gt;Networking &amp;amp; Content Delivery&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://www.youtube.com/playlist?list=PL2yQDdvlhXf-a5wgEXBveQkE0MpHprsQt&amp;amp;trk=c4ea046f-18ad-4d23-a1ac-cdd1267f942c"&gt;Open Source&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://www.youtube.com/playlist?list=PL2yQDdvlhXf_1rHZpRPA6MDUBv_OKz6Qk&amp;amp;trk=c4ea046f-18ad-4d23-a1ac-cdd1267f942c"&gt;Security &amp;amp; Identity&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://www.youtube.com/playlist?list=PL2yQDdvlhXf-Gzj7psv0r9d1u9_yYAGus&amp;amp;trk=c4ea046f-18ad-4d23-a1ac-cdd1267f942c"&gt;Serverless &amp;amp; Containers&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=Tj3SHEE0pcI&amp;amp;list=PL2yQDdvlhXf8sqGuKk7yatvGdCbkIH_qM"&gt;Storage&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/td&gt; 
   &lt;td valign="top"&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://www.youtube.com/playlist?list=PL2yQDdvlhXf-SZMaPAmK7huvDT6GBF18B" data-sk="tooltip_parent"&gt;Developer Community&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://www.youtube.com/playlist?list=PL2yQDdvlhXf_NqSnDKx7Hbb9FrNQKmxg7&amp;amp;trk=direct"&gt;Digital Native Business&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://www.youtube.com/playlist?list=PL2yQDdvlhXf_NqSnDKx7Hbb9FrNQKmxg7&amp;amp;trk=direct"&gt;Enterprise&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://www.youtube.com/playlist?list=PL2yQDdvlhXf9BqAa6B07Xia-qmR23RHaJ&amp;amp;trk=direct"&gt;Independent Software Vendor&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://www.youtube.com/playlist?list=PL2yQDdvlhXf_bh3ol1Obzb3P8n6BQENH9&amp;amp;trk=direct"&gt;New to AWS&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://www.youtube.com/playlist?list=PL2yQDdvlhXf9iOBmyb15YPGkoMK1hAX_x&amp;amp;trk=direct" data-sk="tooltip_parent"&gt;Partner Enablement&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://www.youtube.com/playlist?list=PL2yQDdvlhXf-W_5uNnQaCqUaXJHt37Luo&amp;amp;trk=direct"&gt;Public Sector&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://www.youtube.com/playlist?list=PL2yQDdvlhXf9MBvsGS5rB-X7CMvG21ib-&amp;amp;trk=direct"&gt;Senior Leaders&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://www.youtube.com/playlist?list=PL2yQDdvlhXf_Chz_eS8KUdzzbuACSV0CE&amp;amp;trk=direct"&gt;Small &amp;amp; Medium Business&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://www.youtube.com/playlist?list=PL2yQDdvlhXf-yRZ2GBW1PJzz5cneMld9Z&amp;amp;trk=direct"&gt;Startup&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;span style="text-decoration: underline"&gt;&lt;strong&gt;Last week’s launches&lt;br&gt;&lt;/strong&gt;&lt;/span&gt;Here are the launches that caught my attention not yet covered in our &lt;a href="https://aws.amazon.com/blogs/aws/top-announcements-of-aws-reinvent-2025/?trk=c4ea046f-18ad-4d23-a1ac-cdd1267f942c&amp;amp;sc_channel=el"&gt;top announcements of AWS re:Invent 2025&lt;/a&gt; post:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://kiro.dev/blog/introducing-kiro-autonomous-agent/?trk=c4ea046f-18ad-4d23-a1ac-cdd1267f942c&amp;amp;sc_channel=el"&gt;Kiro Autonomous Agent&lt;/a&gt; – Building on Kiro’s general availability in November with team features, AWS introduced an autonomous agent that maintains awareness across sessions, learns from pull requests and feedback, and handles bug triage and code coverage improvements spanning multiple repositories. “Orders of magnitude more efficient” than first-generation AI coding tools, Matt Garman said. Kiro is now Amazon’s standard AI development environment company-wide.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.aws.amazon.com/bedrock/latest/userguide/kb-multimodal.html?trk=c4ea046f-18ad-4d23-a1ac-cdd1267f942c&amp;amp;sc_channel=el"&gt;Multimodal Retrieval for Bedrock Knowledge Bases (GA)&lt;/a&gt; – Build AI-powered search and question-answering applications that work across text, images, audio, and video files. Developers can now ingest multimodal content with full control of parsing, chunking, embedding, and vector storage options, then send text or image queries to retrieve relevant segments across all media types.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.aws.amazon.com/interconnect/latest/userguide/what-is.html?trk=c4ea046f-18ad-4d23-a1ac-cdd1267f942c&amp;amp;sc_channel=el"&gt;AWS Interconnect – Multicloud (Preview)&lt;/a&gt; – Quickly establish private, secure, high-speed network connections with dedicated bandwidth and built-in resiliency between Amazon VPCs and other cloud environments. Starting in preview with Google Cloud as the first launch partner, with Microsoft Azure support coming in 2026.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;See &lt;a href="https://aws.amazon.com/new/?trk=769a1a2b-8c19-4976-9c45-b6b1226c7d20&amp;amp;sc_channel=el"&gt;AWS What’s New&lt;/a&gt; for more launch news that I haven’t covered here.&amp;nbsp;That’s all for this week. Check back next Monday for another Weekly Roundup!&lt;/p&gt; 
&lt;p&gt;Happy building!&lt;/p&gt; 
&lt;p&gt;— &lt;a href="https://www.linkedin.com/in/donnieprakoso"&gt;Donnie&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;This post is part of our&amp;nbsp;&lt;a href="https://aws.amazon.com/blogs/aws/tag/week-in-review/"&gt;Weekly Roundup&amp;nbsp;series&lt;/a&gt;. Check back each week for a quick roundup of interesting news and announcements from AWS!&lt;/em&gt;&lt;/p&gt;</content:encoded>
					
					
			
		
		
			</item>
		<item>
		<title>Amazon Bedrock adds reinforcement ﬁne-tuning simplifying how developers build smarter, more accurate AI models</title>
		<link>https://aws.amazon.com/blogs/aws/improve-model-accuracy-with-reinforcement-fine-tuning-in-amazon-bedrock/</link>
					
		
		<dc:creator><![CDATA[Donnie Prakoso]]></dc:creator>
		<pubDate>Wed, 03 Dec 2025 16:08:14 +0000</pubDate>
				<category><![CDATA[Amazon Bedrock]]></category>
		<category><![CDATA[Amazon Machine Learning]]></category>
		<category><![CDATA[Announcements]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[AWS re:Invent]]></category>
		<category><![CDATA[Events]]></category>
		<category><![CDATA[Launch]]></category>
		<category><![CDATA[News]]></category>
		<category><![CDATA[Serverless]]></category>
		<guid isPermaLink="false">2486b201ef69be04589b658d6d9d7d6521813fda</guid>

					<description>Amazon Bedrock now supports reinforcement fine-tuning delivering 66% accuracy gains on average over base models.</description>
										<content:encoded>&lt;p&gt;Organizations face a challenging trade-off when adapting AI models to their specific business needs: settle for generic models that produce average results, or tackle the complexity and expense of advanced model customization. Traditional approaches force a choice between poor performance with smaller models or the high costs of deploying larger model variants and managing complex infrastructure. Reinforcement fine-tuning is an advanced technique that trains models using feedback instead of massive labeled datasets, but implementing it typically requires specialized ML expertise, complicated infrastructure, and significant investment—with no guarantee of achieving the accuracy needed for specific use cases.&lt;/p&gt; 
&lt;p&gt;Today, we’re announcing reinforcement fine-tuning in &lt;a href="https://aws.amazon.com/bedrock/?trk=c4ea046f-18ad-4d23-a1ac-cdd1267f942c&amp;amp;sc_channel=el"&gt;Amazon Bedrock&lt;/a&gt;, a new &lt;a href="https://aws.amazon.com/bedrock/customize/?trk=c4ea046f-18ad-4d23-a1ac-cdd1267f942c&amp;amp;sc_channel=el"&gt;model customization&lt;/a&gt; capability that creates smarter, more cost-effective models that learn from feedback and deliver higher-quality outputs for specific business needs. Reinforcement fine-tuning uses a feedback-driven approach where models improve iteratively based on reward signals, delivering 66% accuracy gains on average over base models.&lt;/p&gt; 
&lt;p&gt;Amazon Bedrock automates the reinforcement fine-tuning workflow, making this advanced model customization technique accessible to everyday developers without requiring deep &lt;a href="https://aws.amazon.com/ai/machine-learning/"&gt;machine learning (ML)&lt;/a&gt; expertise or large labeled datasets.&lt;/p&gt; 
&lt;p&gt;&lt;span style="text-decoration: underline"&gt;&lt;strong&gt;How reinforcement fine-tuning works&lt;br&gt; &lt;/strong&gt;&lt;/span&gt;Reinforcement fine-tuning is built on top of &lt;a href="https://aws.amazon.com/what-is/reinforcement-learning/?trk=c4ea046f-18ad-4d23-a1ac-cdd1267f942c&amp;amp;sc_channel=el"&gt;reinforcement learning&lt;/a&gt; principles to address a common challenge: getting models to consistently produce outputs that align with business requirements and user preferences.&lt;/p&gt; 
&lt;p&gt;While traditional fine-tuning requires large, labeled datasets and expensive human annotation, reinforcement fine-tuning takes a different approach. Instead of learning from fixed examples, it uses reward functions to evaluate and judge which responses are considered good for particular business use cases. This teaches models to understand what makes a quality response without requiring massive amounts of pre-labeled training data, making advanced model customization in Amazon Bedrock more accessible and cost-effective.&lt;/p&gt; 
&lt;p&gt;Here are the benefits of using reinforcement fine-tuning in Amazon Bedrock:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Ease of use&lt;/strong&gt; – Amazon Bedrock automates much of the complexity, making reinforcement fine-tuning more accessible to developers building AI applications. Models can be trained using existing API logs in Amazon Bedrock or by uploading datasets as training data, eliminating the need for labeled datasets or infrastructure setup.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Better model performance&lt;/strong&gt; – Reinforcement fine-tuning improves model accuracy by 66% on average over base models, enabling optimization for price and performance by training smaller, faster, and more efficient model variants. This works with &lt;a href="https://aws.amazon.com/nova/?trk=c4ea046f-18ad-4d23-a1ac-cdd1267f942c&amp;amp;sc_channel=el"&gt;Amazon Nova 2 Lite&lt;/a&gt; model, improving quality and price performance for specific business needs, with support for additional models coming soon.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Security – &lt;/strong&gt;Data remains within the secure AWS environment throughout the entire customization process, mitigating security and compliance concerns.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The capability supports two complementary approaches to provide flexibility for optimizing models:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Reinforcement Learning with Verifiable Rewards (RLVR)&lt;/strong&gt; uses rule-based graders for objective tasks like code generation or math reasoning.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Reinforcement Learning from AI Feedback (RLAIF)&lt;/strong&gt; employs AI-based judges for subjective tasks like instruction following or content moderation.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style="text-decoration: underline"&gt;&lt;strong&gt;Getting started with reinforcement fine-tuning in Amazon Bedrock&lt;/strong&gt;&lt;/span&gt;&lt;br&gt; Let’s walk through creating a reinforcement fine-tuning job.&lt;/p&gt; 
&lt;p&gt;First, I access the &lt;a href="https://console.aws.amazon.com/bedrock/?trk=c4ea046f-18ad-4d23-a1ac-cdd1267f942c&amp;amp;sc_channel=el"&gt;Amazon Bedrock console&lt;/a&gt;. Then, I navigate to the &lt;strong&gt;Custom models&lt;/strong&gt; page. I choose &lt;strong&gt;Create&lt;/strong&gt; and then choose &lt;strong&gt;Reinforcement fine-tuning job&lt;/strong&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;img loading="lazy" class="aligncenter wp-image-102279 size-full" style="border: 1px solid black;padding: 3px" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/28/2025-news-bedrock-rev-3-1.png" alt="" width="1440" height="917"&gt;&lt;/p&gt; 
&lt;p&gt;I start by entering the name of this customization job and then select my base model. At launch, reinforcement fine-tuning supports &lt;a href="https://aws.amazon.com/nova/?trk=c4ea046f-18ad-4d23-a1ac-cdd1267f942c&amp;amp;sc_channel=el"&gt;Amazon Nova 2 Lite&lt;/a&gt;, with support for additional models coming soon.&lt;/p&gt; 
&lt;p&gt;&lt;img loading="lazy" class="aligncenter size-full wp-image-101326" style="border: 1px solid black;padding: 3px" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/18/2025-news-bedrock-rl-2-0.png" alt="" width="1146" height="607"&gt;&lt;/p&gt; 
&lt;p&gt;Next, I need to provide training data. I can use my stored invocation logs directly, eliminating the need to upload separate datasets. I can also upload new JSONL files or select existing datasets from &lt;a href="https://aws.amazon.com/s3/?trk=c4ea046f-18ad-4d23-a1ac-cdd1267f942c&amp;amp;sc_channel=el"&gt;Amazon Simple Storage Service (Amazon S3)&lt;/a&gt;. Reinforcement fine-tuning automatically validates my training dataset and supports the OpenAI Chat Completions data format. If I provide invocation logs in the Amazon Bedrock &lt;a href="https://docs.aws.amazon.com/bedrock/latest/APIReference/API_runtime_InvokeModel.html"&gt;invoke&lt;/a&gt; or &lt;a href="https://docs.aws.amazon.com/bedrock/latest/APIReference/API_runtime_Converse.html"&gt;converse&lt;/a&gt; format, Amazon Bedrock automatically converts them to the Chat Completions format.&lt;/p&gt; 
&lt;p&gt;&lt;img loading="lazy" class="aligncenter wp-image-102280 size-full" style="border: 1px solid black;padding: 3px" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/28/2025-news-bedrock-rev-3-2.png" alt="" width="1337" height="381"&gt;&lt;/p&gt; 
&lt;p&gt;The reward function setup is where I define what constitutes a good response. I have two options here. For objective tasks, I can select &lt;strong&gt;Custom code&lt;/strong&gt; and write custom Python code that gets executed through &lt;a href="https://aws.amazon.com/lambda/?trk=c4ea046f-18ad-4d23-a1ac-cdd1267f942c&amp;amp;sc_channel=el"&gt;AWS Lambda&lt;/a&gt; functions. For more subjective evaluations, I can select &lt;strong&gt;Model as judge&lt;/strong&gt; to use &lt;a href="https://aws.amazon.com/what-is/foundation-models/?trk=c4ea046f-18ad-4d23-a1ac-cdd1267f942c&amp;amp;sc_channel=el"&gt;foundation models (FMs)&lt;/a&gt; as judges by providing evaluation instructions.&lt;/p&gt; 
&lt;p&gt;Here, I select &lt;strong&gt;Custom code&lt;/strong&gt;, and I create a new Lambda function or use an existing one as a reward function. I can start with one of the provided templates and customize it for my specific needs.&lt;/p&gt; 
&lt;p&gt;&lt;img loading="lazy" class="aligncenter wp-image-102281 size-full" style="border: 1px solid black;padding: 3px" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/28/2025-news-bedrock-rev-3-3.png" alt="" width="1440" height="474"&gt;&lt;/p&gt; 
&lt;p&gt;I can optionally modify default hyperparameters like learning rate, batch size, and epochs.&lt;/p&gt; 
&lt;p&gt;&lt;img loading="lazy" class="aligncenter wp-image-102282 size-full" style="border: 1px solid black;padding: 3px" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/28/2025-news-bedrock-rev-3-4.png" alt="" width="1334" height="1133"&gt;&lt;/p&gt; 
&lt;p&gt;For enhanced security, I can configure virtual private cloud (VPC) settings and &lt;a href="https://aws.amazon.com/kms/"&gt;AWS Key Management Service (AWS KMS)&lt;/a&gt; encryption to meet my organization’s compliance requirements. Then, I choose &lt;strong&gt;Create&lt;/strong&gt; to start the model customization job.&lt;/p&gt; 
&lt;p&gt;&lt;img loading="lazy" class="aligncenter wp-image-102284 size-full" style="border: 1px solid black;padding: 3px" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/28/2025-news-bedrock-rev-3-6.png" alt="" width="1264" height="882"&gt;&lt;/p&gt; 
&lt;p&gt;During the training process, I can monitor real-time metrics to understand how the model is learning. The training metrics dashboard shows key performance indicators including reward scores, loss curves, and accuracy improvements over time. These metrics help me understand whether the model is converging properly and if the reward function is effectively guiding the learning process.&lt;/p&gt; 
&lt;p&gt;&lt;img loading="lazy" class="aligncenter size-full wp-image-102206" style="border: 1px solid black;padding: 3px" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/27/2025-news-bedrock-rev-4.png" alt="" width="2207" height="2279"&gt;&lt;/p&gt; 
&lt;p&gt;When the reinforcement fine-tuning job is completed, I can see the final job status on the &lt;strong&gt;Model details&lt;/strong&gt; page.&lt;/p&gt; 
&lt;p&gt;&lt;img loading="lazy" class="aligncenter size-full wp-image-102207" style="border: 1px solid black;padding: 3px" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/27/2025-news-bedrock-rev-3.png" alt="" width="2194" height="1388"&gt;&lt;/p&gt; 
&lt;p&gt;Once the job is completed, I can deploy the model with a single click. I select &lt;strong&gt;Set up inference&lt;/strong&gt;, then choose &lt;strong&gt;Deploy for on-demand&lt;/strong&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;img loading="lazy" class="aligncenter size-full wp-image-102208" style="border: 1px solid black;padding: 3px" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/27/2025-news-bedrock-rev-5.png" alt="" width="2224" height="957"&gt;&lt;/p&gt; 
&lt;p&gt;Here, I provide a few details for my model.&lt;/p&gt; 
&lt;p&gt;&lt;img loading="lazy" class="aligncenter size-full wp-image-102209" style="border: 1px solid black;padding: 3px" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/27/2025-news-bedrock-rev-6.png" alt="" width="2659" height="1269"&gt;&lt;/p&gt; 
&lt;p&gt;After deployment, I can quickly evaluate the model’s performance using the Amazon Bedrock playground. This helps me to test the fine-tuned model with sample prompts and compare its responses against the base model to validate the improvements. I select &lt;strong&gt;Test in playground.&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img loading="lazy" class="aligncenter size-full wp-image-102210" style="border: 1px solid black;padding: 3px" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/27/2025-news-bedrock-rev-7.png" alt="" width="2166" height="1102"&gt;&lt;/p&gt; 
&lt;p&gt;The playground provides an intuitive interface for rapid testing and iteration, helping me confirm that the model meets my quality requirements before integrating it into production applications.&lt;/p&gt; 
&lt;p&gt;&lt;img loading="lazy" class="aligncenter size-full wp-image-102211" style="border: 1px solid black;padding: 3px" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/27/2025-news-bedrock-rev-8.png" alt="" width="2783" height="1628"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="text-decoration: underline"&gt;&lt;strong&gt;Interactive demo&lt;/strong&gt;&lt;/span&gt;&lt;br&gt; Learn more by navigating an interactive demo of &lt;a href="https://aws.storylane.io/share/2wbkrcppkxdr"&gt;Amazon Bedrock reinforcement fine-tuning&lt;/a&gt; in action.&lt;/p&gt; 
&lt;p&gt;&lt;img loading="lazy" class="aligncenter wp-image-102214 size-full" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/27/2025-news-bedrock-rev-9.png" alt="" width="1798" height="967"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="text-decoration: underline"&gt;&lt;strong&gt;Additional things to know&lt;/strong&gt;&lt;/span&gt;&lt;br&gt; Here are key points to note:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Templates — &lt;/strong&gt;There are seven ready-to-use reward function templates covering common use cases for both objective and subjective tasks.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Pricing — &lt;/strong&gt;To learn more about pricing, refer to the &lt;a href="https://aws.amazon.com/bedrock/pricing/?trk=c4ea046f-18ad-4d23-a1ac-cdd1267f942c&amp;amp;sc_channel=el"&gt;Amazon Bedrock pricing page&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Security —&lt;/strong&gt; Training data and custom models remain private and aren’t used to improve FMs for public use. It supports VPC and AWS KMS encryption for enhanced security.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Get started with reinforcement fine-tuning by visiting the &lt;a href="https://docs.aws.amazon.com/bedrock/latest/userguide/reinforcement-fine-tuning.html"&gt;reinforcement fine-tuning documentation&lt;/a&gt; and by accessing the &lt;a href="https://console.aws.amazon.com/bedrock?trk=c4ea046f-18ad-4d23-a1ac-cdd1267f942c&amp;amp;sc_channel=el"&gt;Amazon Bedrock console&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Happy building!&lt;br&gt; — &lt;a href="https://www.linkedin.com/in/donnieprakoso"&gt;Donnie&lt;/a&gt;&lt;/p&gt;</content:encoded>
					
					
			
		
		
			</item>
		<item>
		<title>New serverless customization in Amazon SageMaker AI accelerates model fine-tuning</title>
		<link>https://aws.amazon.com/blogs/aws/new-serverless-customization-in-amazon-sagemaker-ai-accelerates-model-fine-tuning/</link>
					
		
		<dc:creator><![CDATA[Channy Yun (윤석찬)]]></dc:creator>
		<pubDate>Wed, 03 Dec 2025 16:08:03 +0000</pubDate>
				<category><![CDATA[Amazon SageMaker AI]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[AWS re:Invent]]></category>
		<category><![CDATA[Launch]]></category>
		<category><![CDATA[News]]></category>
		<guid isPermaLink="false">0b635cd80fc1e2e121b5c1787d777aa9194694bb</guid>

					<description>Accelerate AI model development with new training features that enable rapid recovery from failures and automatic scaling based on resource availability.</description>
										<content:encoded>&lt;p&gt;Today, I’m happy to announce new serverless customization in &lt;a href="https://aws.amazon.com/sagemaker/ai/?trk=769a1a2b-8c19-4976-9c45-b6b1226c7d20&amp;amp;sc_channel=el"&gt;Amazon SageMaker AI&lt;/a&gt; for popular AI models, such as &lt;a href="https://aws.amazon.com/ai/generative-ai/nova/?trk=769a1a2b-8c19-4976-9c45-b6b1226c7d20&amp;amp;sc_channel=el"&gt;Amazon Nova&lt;/a&gt;, &lt;a href="https://aws.amazon.com/bedrock/deepseek/?trk=769a1a2b-8c19-4976-9c45-b6b1226c7d20&amp;amp;sc_channel=el"&gt;DeepSeek&lt;/a&gt;, &lt;a href="https://aws.amazon.com/bedrock/openai/?trk=769a1a2b-8c19-4976-9c45-b6b1226c7d20&amp;amp;sc_channel=el"&gt;GPT-OSS&lt;/a&gt;, &lt;a href="https://aws.amazon.com/bedrock/meta/?trk=769a1a2b-8c19-4976-9c45-b6b1226c7d20&amp;amp;sc_channel=el"&gt;Llama&lt;/a&gt;, and &lt;a href="https://aws.amazon.com/bedrock/qwen/?trk=769a1a2b-8c19-4976-9c45-b6b1226c7d20&amp;amp;sc_channel=el"&gt;Qwen&lt;/a&gt;. The new customization capability provides an easy-to-use interface for the latest fine-tuning techniques like reinforcement learning, so you can accelerate the AI model customization process from months to days.&lt;/p&gt; 
&lt;p&gt;With a few clicks, you can seamlessly select a model and customization technique, and handle model evaluation and deployment—all entirely serverless so you can focus on model tuning rather than managing infrastructure. When you choose serverless customization, SageMaker AI automatically selects and provisions the appropriate compute resources based on the model and data size.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;u&gt;Getting started with serverless model customization&lt;/u&gt;&lt;/strong&gt;&lt;br&gt; You can get started customizing models in &lt;a href="https://aws.amazon.com/sagemaker/ai/studio/?trk=769a1a2b-8c19-4976-9c45-b6b1226c7d20&amp;amp;sc_channel=el"&gt;Amazon SageMaker Studio&lt;/a&gt;. Choose &lt;strong&gt;Models&lt;/strong&gt; in the left navigation pane and check out your favorite AI models to be customized.&lt;/p&gt; 
&lt;p&gt;&lt;img loading="lazy" class="aligncenter size-full wp-image-101130" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/17/2025-sagemaker-ai-custom-model-1-models.jpg" alt="" width="2560" height="1393" data-wp-editing="1"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Customize with UI&lt;/strong&gt;&lt;br&gt; You can customize AI models in a only few clicks. In the &lt;strong&gt;Customize model&lt;/strong&gt; dropdown list for a specific model such as &lt;strong&gt;Meta Llama 3.1 8B Instruct&lt;/strong&gt;, choose &lt;strong&gt;Customize with UI&lt;/strong&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;img loading="lazy" class="aligncenter wp-image-101777 size-full" style="width: 90%" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/24/2025-sagemaker-ai-custom-model-2-with-ui.jpg" alt="" width="1989" height="2560"&gt;&lt;/p&gt; 
&lt;p&gt;You can select a customization technique used to adapt the base model to your use case. SageMaker AI supports &lt;strong&gt;Supervised Fine-Tuning&lt;/strong&gt; and the latest model customization techniques including &lt;strong&gt;Direct Preference Optimization&lt;/strong&gt;, &lt;strong&gt;Reinforcement Learning from Verifiable Rewards (RLVR)&lt;/strong&gt;, and &lt;strong&gt;Reinforcement Learning from AI Feedback (RLAIF)&lt;/strong&gt;. Each technique optimizes models in different ways, with selection influenced by factors such as dataset size and quality, available computational resources, task at hand, desired accuracy levels, and deployment constraints.&lt;/p&gt; 
&lt;p&gt;Upload or select a training dataset to match the format required by the customization technique selected. Use the values of batch size, learning rate, and number of epochs recommended by the technique selected. You can conﬁgure advanced settings such as hyperparameters, a newly introduced serverless MLﬂow application for experiment tracking, and network and storage volume encryption. Choose &lt;strong&gt;Submit&lt;/strong&gt; to get started on your model training job.&lt;/p&gt; 
&lt;p&gt;After your training job is complete, you can see the models you created in the &lt;strong&gt;My Models&lt;/strong&gt; tab. Choose &lt;strong&gt;View details&lt;/strong&gt; in one of your models.&lt;/p&gt; 
&lt;p&gt;&lt;img loading="lazy" class="aligncenter wp-image-101144 size-full" style="width: 90%" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/17/2025-sagemaker-ai-custom-model-3-with-ui-1.jpg" alt="" width="2076" height="1396"&gt;&lt;/p&gt; 
&lt;p&gt;By choosing &lt;strong&gt;Continue customization&lt;/strong&gt;, you can continue to customize your model by adjusting hyperparameters or training with different techniques. By choosing &lt;strong&gt;Evaluate&lt;/strong&gt;, you can evaluate your customized model to see how it performs compared to the base model.&lt;/p&gt; 
&lt;p&gt;When you complete both jobs, you can choose either the &lt;strong&gt;SageMaker&lt;/strong&gt; or &lt;strong&gt;Bedrock&lt;/strong&gt; in the &lt;strong&gt;Deploy&lt;/strong&gt; dropdown list to deploy your model.&lt;/p&gt; 
&lt;p&gt;&lt;img loading="lazy" class="aligncenter wp-image-101778 size-full" style="width: 90%" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/24/2025-sagemaker-ai-custom-model-4-with-ui-1-1.jpg" alt="" width="2040" height="1460"&gt;&lt;/p&gt; 
&lt;p&gt;You can choose &lt;a href="https://aws.amazon.com/bedrock/?trk=769a1a2b-8c19-4976-9c45-b6b1226c7d20&amp;amp;sc_channel=el"&gt;Amazon Bedrock&lt;/a&gt; for serverless inference. Choose &lt;strong&gt;Bedrock&lt;/strong&gt; and the model name to deploy the model into Amazon Bedrock. To find your deployed models, choose &lt;strong&gt;Imported models&lt;/strong&gt; in the &lt;a href="https://console.aws.amazon.com/bedrock?trk=769a1a2b-8c19-4976-9c45-b6b1226c7d20&amp;amp;sc_channel=el"&gt;Bedrock console&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;img loading="lazy" class="aligncenter wp-image-101781 size-full" style="border: solid 1px #ccc" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/24/2025-sagemaker-ai-custom-model-5-with-ui-deploy-bedrock.jpg" alt="" width="2392" height="1050"&gt;&lt;/p&gt; 
&lt;p&gt;You can also deploy your model to a SageMaker AI inference endpoint if you want to control your deployment resources such as an instance type and instance count. After the SageMaker AI deployment is &lt;strong&gt;In service&lt;/strong&gt;, you can use this endpoint to perform inference. In the &lt;strong&gt;Playground&lt;/strong&gt; tab, you can test your customized model with a single prompt or chat mode.&lt;/p&gt; 
&lt;p&gt;&lt;img loading="lazy" class="aligncenter wp-image-101444 size-full" style="width: 90%" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/19/2025-sagemaker-ai-custom-model-6-with-ui-1.jpg" alt="" width="2230" height="2014"&gt;&lt;/p&gt; 
&lt;p&gt;With the serverless MLﬂow capability, you can automatically log all critical experiment metrics without modifying code and access rich visualizations for further analysis.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Customize with code&lt;/strong&gt;&lt;br&gt; When you choose customizing with code, you can see a sample notebook to fine-tune or deploy AI models. If you want to edit the sample notebook, open it in JupyterLab. Alternatively, you can deploy the model immediately by choosing &lt;strong&gt;Deploy&lt;/strong&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;img loading="lazy" class="aligncenter wp-image-101784 size-full" style="width: 90%" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/24/2025-sagemaker-ai-custom-model-3-with-code-1-tune-1.jpg" alt="" width="2278" height="1446"&gt;&lt;/p&gt; 
&lt;p&gt;You can choose the Amazon Bedrock or SageMaker AI endpoint by selecting the deployment resources either from &lt;a href="https://aws.amazon.com/sagemaker/ai/deploy/?trk=769a1a2b-8c19-4976-9c45-b6b1226c7d20&amp;amp;sc_channel=el"&gt;Amazon SageMaker Inference&lt;/a&gt; or &lt;a href="https://aws.amazon.com/sagemaker/ai/hyperpod/?trk=769a1a2b-8c19-4976-9c45-b6b1226c7d20&amp;amp;sc_channel=el"&gt;Amazon SageMaker Hyperpod&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;img loading="lazy" class="aligncenter size-full wp-image-101160" style="width: 90%" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/17/2025-sagemaker-ai-custom-model-3-with-code-2-deploy.jpg" alt="" width="2220" height="1262"&gt;&lt;/p&gt; 
&lt;p&gt;When you choose &lt;strong&gt;Deploy&lt;/strong&gt; on the bottom right of the page, it will be redirected back to the model detail page. After the SageMaker AI deployment is in service, you can use this endpoint to perform inference.&lt;/p&gt; 
&lt;p&gt;Okay, you’ve seen how to streamline the model customization in the SageMaker AI. You can now choose your favorite way. To learn more, visit the &lt;a href="https://docs.aws.amazon.com/sagemaker/latest/dg/whatis.html?trk=769a1a2b-8c19-4976-9c45-b6b1226c7d20&amp;amp;sc_channel=el"&gt;Amazon SageMaker AI Developer Guide&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;u&gt;Now available&lt;/u&gt;&lt;/strong&gt;&lt;br&gt; &lt;a href="https://aws.amazon.com/sagemaker/ai/model-customization/?trk=769a1a2b-8c19-4976-9c45-b6b1226c7d20&amp;amp;sc_channel=el"&gt;New serverless AI model customization&lt;/a&gt; in Amazon SageMaker AI is now available in US East (N. Virginia), US West (Oregon), Asia Pacific (Tokyo), and Europe (Ireland) Regions. You only pay for the tokens processed during training and inference. To learn more details, visit &lt;a href="https://aws.amazon.com/sagemaker/ai/pricing/?trk=769a1a2b-8c19-4976-9c45-b6b1226c7d20&amp;amp;sc_channel=el"&gt;Amazon SageMaker AI pricing page&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Give it a try in &lt;a href="https://console.aws.amazon.com/sagemaker?trk=769a1a2b-8c19-4976-9c45-b6b1226c7d20&amp;amp;sc_channel=el"&gt;Amazon SageMaker Studio&lt;/a&gt; and send feedback to &lt;a href="https://repost.aws/tags/TAT80swPyVRPKPcA0rsJYPuA/amazon-sagemaker?trk=769a1a2b-8c19-4976-9c45-b6b1226c7d20&amp;amp;sc_channel=el"&gt;AWS re:Post for SageMaker&lt;/a&gt; or through your usual AWS Support contacts.&lt;/p&gt; 
&lt;p&gt;— &lt;a href="https://linkedin.com/in/channy"&gt;Channy&lt;/a&gt;&lt;/p&gt;</content:encoded>
					
					
			
		
		
			</item>
		<item>
		<title>Introducing checkpointless and elastic training on Amazon SageMaker HyperPod</title>
		<link>https://aws.amazon.com/blogs/aws/introducing-checkpointless-and-elastic-training-on-amazon-sagemaker-hyperpod/</link>
					
		
		<dc:creator><![CDATA[Channy Yun (윤석찬)]]></dc:creator>
		<pubDate>Wed, 03 Dec 2025 16:07:52 +0000</pubDate>
				<category><![CDATA[Amazon SageMaker HyperPod]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[AWS re:Invent]]></category>
		<category><![CDATA[Launch]]></category>
		<category><![CDATA[News]]></category>
		<guid isPermaLink="false">83b49fb2eb3a1369a9b66fabd94b4cdcacabc446</guid>

					<description>Accelerate AI model development with new training features that enable instant recovery from failures and automatic scaling based on resource availability.</description>
										<content:encoded>&lt;p&gt;Today, we’re announcing two new AI model training features within &lt;a href="https://aws.amazon.com/sagemaker/ai/hyperpod/"&gt;Amazon SageMaker HyperPod&lt;/a&gt;: checkpointless training, an approach that mitigates the need for traditional checkpoint-based recovery by enabling peer-to-peer state recovery, and elastic training, enabling AI workloads to automatically scale based on resource availability.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Checkpointless training&lt;/strong&gt; – Checkpointless training eliminates disruptive checkpoint-restart cycles, maintaining forward training momentum despite failures, reducing recovery time from hours to minutes. Accelerate your AI model development, reclaim days from development timelines, and confidently scale training workflows to thousands of AI accelerators.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Elastic training&amp;nbsp;&lt;/strong&gt; – Elastic training maximizes cluster utilization as training workloads automatically expand to use idle capacity as it becomes available, and contract to yield resources as higher-priority workloads like inference volumes peak. Save hours of engineering time per week spent reconfiguring training jobs based on compute availability.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Rather than spending time managing training infrastructure, these new training techniques mean that your team can concentrate entirely on enhancing model performance, ultimately getting your AI models to market faster. By eliminating the traditional checkpoint dependencies and fully utilizing available capacity, you can significantly reduce model training completion times.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;u&gt;Checkpointless training: How it works&lt;/u&gt;&lt;/strong&gt;&lt;br&gt; Traditional checkpoint-based recovery has these sequential job stages: 1) job termination and restart, 2) process discovery and network setup, 3) checkpoint retrieval, 4) data loader initialization, and 5) training loop resumption. When failures occur, each stage can become a bottleneck and training recovery can take up to an hour on self-managed training clusters. The entire cluster must wait for every single stage to complete before training can resume. This can lead to the entire training cluster sitting idle during recovery operations, which increases costs and extends the time to market.&lt;/p&gt; 
&lt;p&gt;Checkpointless training removes this bottleneck entirely by maintaining continuous model state preservation across the training cluster. When failures occur, the system instantly recovers by using healthy peers, avoiding the need for a checkpoint-based recovery that requires restarting the entire job. As a result, checkpointless training enables fault recovery in minutes.&lt;/p&gt; 
&lt;p&gt;&lt;img loading="lazy" class="aligncenter size-full wp-image-101253" style="width: 90%" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/18/2025-sageamker-hyperpod-checkpointless-training.gif" alt="" width="800" height="592"&gt;&lt;/p&gt; 
&lt;p&gt;Checkpointless training is designed for incremental adoption and built on four core components that work together: 1) collective communications initialization optimizations, 2) memory-mapped data loading that enables caching, 3) in-process recovery, and 4) checkpointless peer-to-peer state replication. These components are orchestrated through the &lt;a href="https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-eks-operator.html"&gt;HyperPod training operator&lt;/a&gt; that is used to launch the job. Each component optimizes a specific step in the recovery process, and together they enable automatic detection and recovery of infrastructure faults in minutes with zero manual intervention, even with thousands of AI accelerators. You can progressively enable each of these features as your training scales.&lt;/p&gt; 
&lt;p&gt;The latest &lt;a href="https://aws.amazon.com/nova/"&gt;Amazon Nova&lt;/a&gt; models were trained using this technology on tens of thousands of accelerators. Additionally, based on internal studies on cluster sizes ranging between 16 GPUs to over 2,000 GPUs, checkpointless training showcased significant improvements in recovery times, reducing downtime by over 80% compared to traditional checkpoint-based recovery.&lt;/p&gt; 
&lt;p&gt;To learn more, visit &lt;a href="https://github.com/aws/sagemaker-hyperpod-checkpointless-training" target="_blank" rel="noopener"&gt;checkpointless training GitHub page&lt;/a&gt; for implementation and &lt;a href="https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-eks-checkpointless.html"&gt;HyperPod Checkpointless Training&lt;/a&gt; in the Amazon SageMaker AI Developer Guide.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;u&gt;Elastic training: How it works&lt;/u&gt;&lt;/strong&gt;&lt;br&gt; On clusters that run different types of modern AI workloads, accelerator availability can change continuously throughout the day as short-duration training runs complete, inference spikes occur and subside, or resources free up from completed experiments. Despite this dynamic availability of AI accelerators, traditional training workloads remain locked into their initial compute allocation, unable to take advantage of idle accelerators without manual intervention. This rigidity leaves valuable GPU capacity unused and prevents organizations from maximizing their infrastructure investment.&lt;/p&gt; 
&lt;p&gt;&lt;img loading="lazy" class="size-full wp-image-101255 alignright" style="width: 50%" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/18/2025-sageamker-hyperpod-elastic-training.gif" alt="" width="400" height="437"&gt;Elastic training transforms how training workloads interact with cluster resources. Training jobs can automatically scale up to utilize available accelerators and gracefully contract when resources are needed elsewhere, all while maintaining training quality.&lt;/p&gt; 
&lt;p&gt;Workload elasticity is enabled through the HyperPod training operator that orchestrates scaling decisions through integration with the Kubernetes control plane and resource scheduler. It continuously monitors cluster state through three primary channels: pod lifecycle events, node availability changes, and resource scheduler priority signals. This comprehensive monitoring enables near-instantaneous detection of scaling opportunities, whether from newly available resources or requests from higher-priority workloads.&lt;/p&gt; 
&lt;p&gt;The scaling mechanism relies on adding and removing data parallel replicas. When additional compute resources become available, new data parallel replicas join the training job, accelerating throughput. Conversely, during scale-down events (for example, when a higher-priority workload requests resources), the system scales down by removing replicas rather than terminating the entire job, allowing training to continue at reduced capacity.&lt;/p&gt; 
&lt;p&gt;Across different scales, the system preserves the global batch size and adapts learning rates, preventing model convergence from being adversely impacted. This enables workloads to dynamically scale up or down to utilize available AI accelerators without any manual intervention.&lt;/p&gt; 
&lt;p&gt;You can start elastic training through the HyperPod recipes for publicly available foundation models (FMs) including Llama and GPT-OSS. Additionally, you can modify your PyTorch training scripts to add elastic event handlers, which enable the job to dynamically scale.&lt;/p&gt; 
&lt;p&gt;To learn more, visit the &lt;a href="https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-eks-elastic-training.html"&gt;HyperPod Elastic Training&lt;/a&gt; in the Amazon SageMaker AI Developer Guide. To get started, find the &lt;a href="https://github.com/aws/sagemaker-hyperpod-recipes"&gt;HyperPod recipes&lt;/a&gt; available in the AWS GitHub repository.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;u&gt;Now available&lt;/u&gt;&lt;/strong&gt;&lt;br&gt; Both features are available in all the Regions in which Amazon SageMaker HyperPod is available. You can use these training techniques without additional cost. To learn more, visit the &lt;a href="https://aws.amazon.com/sagemaker/hyperpod?trk=769a1a2b-8c19-4976-9c45-b6b1226c7d20&amp;amp;sc_channel=el"&gt;SageMaker HyperPod product page&lt;/a&gt; and &lt;a href="https://aws.amazon.com/sagemaker/pricing?trk=769a1a2b-8c19-4976-9c45-b6b1226c7d20&amp;amp;sc_channel=el"&gt;SageMaker AI pricing page&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Give it a try and send feedback to &lt;a href="https://repost.aws/tags/TAT80swPyVRPKPcA0rsJYPuA/amazon-sagemaker"&gt;AWS re:Post for SageMaker&lt;/a&gt; or through your usual AWS Support contacts.&lt;/p&gt; 
&lt;p&gt;— &lt;a href="https://linkedin.com/in/channy"&gt;Channy&lt;/a&gt;&lt;/p&gt;</content:encoded>
					
					
			
		
		
			</item>
		<item>
		<title>Announcing replication support and Intelligent-Tiering for Amazon S3 Tables</title>
		<link>https://aws.amazon.com/blogs/aws/announcing-replication-support-and-intelligent-tiering-for-amazon-s3-tables/</link>
					
		
		<dc:creator><![CDATA[Sébastien Stormacq]]></dc:creator>
		<pubDate>Tue, 02 Dec 2025 16:19:14 +0000</pubDate>
				<category><![CDATA[Amazon S3 Tables]]></category>
		<category><![CDATA[Analytics]]></category>
		<category><![CDATA[Announcements]]></category>
		<category><![CDATA[Launch]]></category>
		<category><![CDATA[News]]></category>
		<guid isPermaLink="false">9e5546dd6dd4473fe951c4c88c955b1d2fb3516f</guid>

					<description>New features enable automatic cost optimization through intelligent storage tiering and simplified table replication across AWS Regions and accounts.</description>
										<content:encoded>&lt;p&gt;Today, we’re announcing two new capabilities for &lt;a href="https://aws.amazon.com/s3/features/tables/"&gt;Amazon S3 Tables&lt;/a&gt;: support for the new Intelligent-Tiering storage class that automatically optimizes costs based on access patterns, and replication support to automatically maintain consistent &lt;a href="https://docs.aws.amazon.com/AmazonS3/latest/userguide/s3-tables.html"&gt;Apache Iceberg&lt;/a&gt; table replicas across &lt;a href="https://docs.aws.amazon.com/global-infrastructure/latest/regions/aws-regions.html"&gt;AWS Regions&lt;/a&gt; and &lt;a href="https://docs.aws.amazon.com/glossary/latest/reference/glos-chap.html#account"&gt;accounts&lt;/a&gt; without manual sync.&lt;/p&gt; 
&lt;p&gt;Organizations working with tabular data face two common challenges. First, they need to manually manage storage costs as their datasets grow and access patterns change over time. Second, when maintaining replicas of Iceberg tables across Regions or accounts, they must build and maintain complex architectures to track updates, manage object replication, and handle metadata transformations.&lt;/p&gt; 
&lt;p&gt;&lt;span style="text-decoration: underline"&gt;&lt;strong&gt;S3 Tables Intelligent-Tiering storage class&lt;br&gt; &lt;/strong&gt;&lt;/span&gt;With the S3 Tables Intelligent-Tiering storage class&lt;strong&gt;,&lt;/strong&gt; data is automatically tiered to the most cost-effective access tier based on access patterns. Data is stored in three low-latency tiers: Frequent Access, Infrequent Access (40% lower cost than Frequent Access), and Archive Instant Access (68% lower cost compared to Infrequent Access). After 30 days without access, data moves to Infrequent Access, and after 90 days, it moves to Archive Instant Access. This happens without changes to your applications or impact on performance.&lt;/p&gt; 
&lt;p&gt;Table maintenance activities, including compaction, snapshot expiration, and unreferenced file removal, operate without affecting the data’s access tiers. Compaction automatically processes only data in the Frequent Access tier, optimizing performance for actively queried data while reducing maintenance costs by skipping colder files in lower-cost tiers.&lt;/p&gt; 
&lt;p&gt;By default, all existing tables use the Standard storage class. When creating new tables, you can specify Intelligent-Tiering as the storage class, or you can rely on the default storage class configured at the table bucket level. You can set Intelligent-Tiering as the default storage class for your table bucket to automatically store tables in Intelligent-Tiering when no storage class is specified during creation.&lt;/p&gt; 
&lt;p&gt;&lt;span style="text-decoration: underline"&gt;&lt;strong&gt;Let me show you how it works&lt;br&gt; &lt;/strong&gt;&lt;/span&gt;You can use the &lt;a href="https://aws.amazon.com/cli/"&gt;AWS Command Line Interface (AWS CLI)&lt;/a&gt; and the &lt;code&gt;put-table-bucket-storage-class&lt;/code&gt; and &lt;code&gt;get-table-bucket-storage-class&lt;/code&gt; commands to change or verify the storage tier of your S3 table bucket.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="lang-sh"&gt;# Change the storage class
aws s3tables put-table-bucket-storage-class \
   --table-bucket-arn $TABLE_BUCKET_ARN  \
   --storage-class-configuration storageClass=INTELLIGENT_TIERING

# Verify the storage class
aws s3tables get-table-bucket-storage-class \
   --table-bucket-arn $TABLE_BUCKET_ARN  \

{ "storageClassConfiguration":
   { 
      "storageClass": "INTELLIGENT_TIERING"
   }
}&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;span style="text-decoration: underline"&gt;&lt;strong&gt;S3 Tables replication support&lt;br&gt; &lt;/strong&gt;&lt;/span&gt;The new S3 Tables replication support helps you maintain consistent read replicas of your tables across AWS Regions and accounts. You specify the destination table bucket and the service creates read-only replica tables. It replicates all updates chronologically while preserving parent-child snapshot relationships. Table replication helps you build global datasets to minimize query latency for geographically distributed teams, meet compliance requirements, and provide data protection.&lt;/p&gt; 
&lt;p&gt;You can now easily create replica tables that deliver similar query performance as their source tables. Replica tables are updated within minutes of source table updates and support independent encryption and retention policies from their source tables. Replica tables can be queried using &lt;a href="https://aws.amazon.com/sagemaker/unified-studio/"&gt;Amazon SageMaker Unified Studio&lt;/a&gt; or any Iceberg-compatible engine including &lt;a href="https://duckdb.org/"&gt;DuckDB&lt;/a&gt;, &lt;a href="https://py.iceberg.apache.org/"&gt;PyIceberg&lt;/a&gt;, &lt;a href="https://spark.apache.org/"&gt;Apache Spark&lt;/a&gt;, and &lt;a href="https://trino.io/"&gt;Trino&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;You can create and maintain replicas of your tables through the &lt;a href="https://console.aws.amazon.com"&gt;AWS Management Console&lt;/a&gt; or APIs and &lt;a href="https://aws.amazon.com/tools/"&gt;AWS SDKs&lt;/a&gt;. You specify one or more destination table buckets to replicate your source tables. When you turn on replication, S3 Tables automatically creates read-only replica tables in your destination table buckets, backfills them with the latest state of the source table, and continually monitors for new updates to keep replicas in sync. This helps you meet time-travel and audit requirements while maintaining multiple replicas of your data.&lt;/p&gt; 
&lt;p&gt;&lt;span style="text-decoration: underline"&gt;&lt;strong&gt;Let me show you how it works&lt;br&gt; &lt;/strong&gt;&lt;/span&gt;To show you how it works, I proceed in three steps. First, I create an S3 table bucket, create an Iceberg table, and populate it with data. Second, I configure the replication. Third, I connect to the replicated table and query the data to show you that changes are replicated.&lt;/p&gt; 
&lt;p&gt;For this demo, the S3 team kindly gave me access to an &lt;a href="https://aws.amazon.com/emr"&gt;Amazon EMR&lt;/a&gt; cluster already provisioned. You can follow &lt;a href="https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-gs.html"&gt;the Amazon EMR documentation to create your own cluster&lt;/a&gt;. They also created two S3 table buckets, a source and a destination for the replication. Again, &lt;a href="https://docs.aws.amazon.com/AmazonS3/latest/userguide/s3-tables-buckets-create.html"&gt;the S3 Tables documentation will help you to get started&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;I take a note of the two S3 Tables bucket Amazon Resource Names (ARNs). In this demo, I refer to these as the environment variables &lt;code&gt;SOURCE_TABLE_ARN&lt;/code&gt; and &lt;code&gt;DEST_TABLE_ARN&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;First step: Prepare the source database&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;I start a terminal, connect to the EMR cluster, start a Spark session, create a table, and insert a row of data. The commands I use in this demo are documented in &lt;a href="https://docs.aws.amazon.com/AmazonS3/latest/userguide/s3-tables-integrating-open-source.html"&gt;Accessing tables using the Amazon S3 Tables Iceberg REST endpoint&lt;/a&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="lang-spark"&gt;sudo spark-shell \
--packages "org.apache.iceberg:iceberg-spark-runtime-3.5_2.12:1.4.1,software.amazon.awssdk:bundle:2.20.160,software.amazon.awssdk:url-connection-client:2.20.160" \
--master "local[*]" \
--conf "spark.sql.extensions=org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions" \
--conf "spark.sql.defaultCatalog=spark_catalog" \
--conf "spark.sql.catalog.spark_catalog=org.apache.iceberg.spark.SparkCatalog" \
--conf "spark.sql.catalog.spark_catalog.type=rest" \
--conf "spark.sql.catalog.spark_catalog.uri=https://s3tables.us-east-1.amazonaws.com/iceberg" \
--conf "spark.sql.catalog.spark_catalog.warehouse=arn:aws:s3tables:us-east-1:012345678901:bucket/aws-news-blog-test" \
--conf "spark.sql.catalog.spark_catalog.rest.sigv4-enabled=true" \
--conf "spark.sql.catalog.spark_catalog.rest.signing-name=s3tables" \
--conf "spark.sql.catalog.spark_catalog.rest.signing-region=us-east-1" \
--conf "spark.sql.catalog.spark_catalog.io-impl=org.apache.iceberg.aws.s3.S3FileIO" \
--conf "spark.hadoop.fs.s3a.aws.credentials.provider=org.apache.hadoop.fs.s3a.SimpleAWSCredentialProvider" \
--conf "spark.sql.catalog.spark_catalog.rest-metrics-reporting-enabled=false"

spark.sql("""
CREATE TABLE s3tablesbucket.test.aws_news_blog (
customer_id STRING,
address STRING
) USING iceberg
""")

spark.sql("INSERT INTO s3tablesbucket.test.aws_news_blog VALUES ('cust1', 'val1')")

spark.sql("SELECT * FROM s3tablesbucket.test.aws_news_blog LIMIT 10").show()
+-----------+-------+
|customer_id|address|
+-----------+-------+
|      cust1|   val1|
+-----------+-------+&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;So far, so good.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Second step: Configure the replication for S3 Tables&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Now, I use the &lt;span title="AWS Command Line Interface (AWS CLI)"&gt;CLI&lt;/span&gt; on my laptop to configure the S3 table bucket replication.&lt;/p&gt; 
&lt;p&gt;Before doing so, I create an &lt;a href="https://aws.amazon.com/iam/"&gt;AWS Identity and Access Management (IAM)&lt;/a&gt; policy to authorize the replication service to access my S3 table bucket and encryption keys. &lt;a href="https://docs.aws.amazon.com/AmazonS3/latest/userguide/s3-tables-replication-tables.html"&gt;Refer to the S3 Tables replication documentation for the details&lt;/a&gt;. The permissions I used for this demo are:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="lang-json"&gt;{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Effect": "Allow",
            "Action": [
                "s3:*",
                "s3tables:*",
                "kms:DescribeKey",
                "kms:GenerateDataKey",
                "kms:Decrypt"
            ],
            "Resource": "*"
        }
    ]
}&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;After having created this IAM policy, I can now proceed and configure the replication:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="lang-sh"&gt;aws s3tables-replication put-table-replication \
--table-arn ${SOURCE_TABLE_ARN} \
--configuration  '{
    "role": "arn:aws:iam::&amp;lt;MY_ACCOUNT_NUMBER&amp;gt;:role/S3TableReplicationManualTestingRole", 
    "rules":[
        {
            "destinations": [
                {
                    "destinationTableBucketARN": "${DST_TABLE_ARN}"
                }]
        }
    ]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The replication starts automatically. Updates are typically replicated within minutes. The time it takes to complete depends on the volume of data in the source table.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Third step: Connect to the replicated table and query the data&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Now, I connect to the EMR cluster again, and I start a second Spark session. This time, I use the destination table.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/14/2025-11-14_13-59-13.png"&gt;&lt;img loading="lazy" class="aligncenter size-full wp-image-100986" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/14/2025-11-14_13-59-13.png" alt="S3 Tables replication - destination table" width="802" height="424"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;To verify the replication works, I insert a second row of data on the source table.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="lang-spark"&gt;spark.sql("INSERT INTO s3tablesbucket.test.aws_news_blog VALUES ('cust2', 'val2')")
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;I wait a few minutes for the replication to trigger. I follow the status of the replication with the &lt;code&gt;get-table-replication-status&lt;/code&gt; command.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="lang-sh"&gt;aws s3tables-replication get-table-replication-status \
--table-arn ${SOURCE_TABLE_ARN} \
{
    "sourceTableArn": "arn:aws:s3tables:us-east-1:012345678901:bucket/manual-test/table/e0fce724-b758-4ee6-85f7-ca8bce556b41",
    "destinations": [
        {
            "replicationStatus": "pending",
            "destinationTableBucketArn": "arn:aws:s3tables:us-east-1:012345678901:bucket/manual-test-dst",
            "destinationTableArn": "arn:aws:s3tables:us-east-1:012345678901:bucket/manual-test-dst/table/5e3fb799-10dc-470d-a380-1a16d6716db0",
            "lastSuccessfulReplicatedUpdate": {
                "metadataLocation": "s3://e0fce724-b758-4ee6-8-i9tkzok34kum8fy6jpex5jn68cwf4use1b-s3alias/e0fce724-b758-4ee6-85f7-ca8bce556b41/metadata/00001-40a15eb3-d72d-43fe-a1cf-84b4b3934e4c.metadata.json",
                "timestamp": "2025-11-14T12:58:18.140281+00:00"
            }
        }
    ]
}&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;When replication status shows &lt;code&gt;ready&lt;/code&gt;, I connect to the EMR cluster and I query the destination table. Without surprise, I see the new row of data.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/14/2025-11-14_14-44-40.png"&gt;&lt;img loading="lazy" class="aligncenter size-full wp-image-100987" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/14/2025-11-14_14-44-40.png" alt="S3 Tables replication - target table is up to date" width="778" height="126"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="text-decoration: underline"&gt;&lt;strong&gt;Additional things to know&lt;br&gt; &lt;/strong&gt;&lt;/span&gt;Here are a couple of additional points to pay attention to:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Replication for S3 Tables supports both Apache Iceberg V2 and V3 table formats, giving you flexibility in your table format choice.&lt;/li&gt; 
 &lt;li&gt;You can configure replication at the table bucket level, making it straightforward to replicate all tables under that bucket without individual table configurations.&lt;/li&gt; 
 &lt;li&gt;Your replica tables maintain the storage class you choose for your destination tables, which means you can optimize for your specific cost and performance needs.&lt;/li&gt; 
 &lt;li&gt;Any Iceberg-compatible catalog can directly query your replica tables without additional coordination—they only need to point to the replica table location. This gives you flexibility in choosing query engines and tools.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style="text-decoration: underline"&gt;&lt;strong&gt;Pricing and availability&lt;br&gt; &lt;/strong&gt;&lt;/span&gt;You can track your storage usage by access tier through &lt;a href="https://docs.aws.amazon.com/cur/latest/userguide/what-is-cur.html"&gt;AWS Cost and Usage Reports&lt;/a&gt; and &lt;a href="https://aws.amazon.com/cloudwatch/"&gt;Amazon CloudWatch&lt;/a&gt; metrics. For replication monitoring, &lt;a href="https://aws.amazon.com/cloudtrail/"&gt;AWS CloudTrail&lt;/a&gt; logs provide events for each replicated object.&lt;/p&gt; 
&lt;p&gt;There are no additional charges to configure Intelligent-Tiering. You only pay for storage costs in each tier. Your tables continue to work as before, with automatic cost optimization based on your access patterns.&lt;/p&gt; 
&lt;p&gt;For S3 Tables replication, you pay the S3 Tables charges for storage in the destination table, for replication PUT requests, for table updates (commits), and for object monitoring on the replicated data. For cross-Region table replication, you also pay for inter-Region data transfer out from Amazon S3 to the destination Region based on the Region pair.&lt;/p&gt; 
&lt;p&gt;As usual, refer to the &lt;a href="https://aws.amazon.com/s3/pricing/"&gt;Amazon S3 pricing page&lt;/a&gt; for the details.&lt;/p&gt; 
&lt;p&gt;Both capabilities are available today in all AWS Regions where &lt;a href="https://docs.aws.amazon.com/general/latest/gr/s3.html#s3_region"&gt;S3 Tables are supported&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;To learn more about these new capabilities, visit the &lt;a href="https://docs.aws.amazon.com/AmazonS3/latest/userguide/s3-tables.html"&gt;Amazon S3 Tables documentation&lt;/a&gt; or try them in the &lt;a href="https://console.aws.amazon.com/s3/table-buckets"&gt;Amazon S3 console&lt;/a&gt; today. Share your feedback through AWS re:Post for Amazon S3 or through your AWS Support contacts.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://linktr.ee/sebsto"&gt;— seb&lt;/a&gt;&lt;/p&gt;</content:encoded>
					
					
			
		
		
			</item>
		<item>
		<title>Amazon S3 Storage Lens adds performance metrics, support for billions of prefixes, and export to S3 Tables</title>
		<link>https://aws.amazon.com/blogs/aws/amazon-s3-storage-lens-adds-performance-metrics-support-for-billions-of-prefixes-and-export-to-s3-tables/</link>
					
		
		<dc:creator><![CDATA[Veliswa Boya]]></dc:creator>
		<pubDate>Tue, 02 Dec 2025 16:15:12 +0000</pubDate>
				<category><![CDATA[Amazon Athena]]></category>
		<category><![CDATA[Amazon CloudWatch]]></category>
		<category><![CDATA[Amazon EMR]]></category>
		<category><![CDATA[Amazon Quick Sight]]></category>
		<category><![CDATA[Amazon Redshift]]></category>
		<category><![CDATA[Amazon S3 Tables]]></category>
		<category><![CDATA[Amazon Simple Storage Service (S3)]]></category>
		<category><![CDATA[Analytics]]></category>
		<category><![CDATA[Storage]]></category>
		<guid isPermaLink="false">169f9b95f728c066443b9287bf5e95b5131fe24d</guid>

					<description>New capabilities help optimize application performance, analyze unlimited prefixes, and simplify metrics analysis through S3 Tables integration.</description>
										<content:encoded>&lt;p&gt;Today, we’re announcing three new capabilities for &lt;a href="https://aws.amazon.com/s3/storage-lens/"&gt;Amazon S3 Storage Lens&lt;/a&gt; that give you deeper insights into your storage performance and usage patterns. With the addition of performance metrics, support for analyzing billions of prefixes, and direct export to &lt;a href="https://aws.amazon.com/s3/features/tables/?trk=7c8639c6-87c6-47d6-9bd0-a5812eecb848&amp;amp;sc_channel=el"&gt;Amazon S3 Tables,&lt;/a&gt; you have the tools you need to optimize application performance, reduce costs, and make data-driven decisions about your Amazon S3&amp;nbsp;storage strategy.&lt;/p&gt; 
&lt;p&gt;&lt;span style="text-decoration: underline"&gt;&lt;strong&gt;New performance metric categories&lt;/strong&gt;&lt;/span&gt;&lt;br&gt; S3 Storage Lens now includes eight new performance metric categories that help identify and resolve performance constraints across your organization. These are available at organization, account, bucket, and prefix levels. For example, the service helps you identify small objects in a bucket or prefix that can&amp;nbsp; slow down application performance. This can be mitigated by batching small objects or using the &lt;a href="https://aws.amazon.com/s3/storage-classes/express-one-zone/?trk=7c8639c6-87c6-47d6-9bd0-a5812eecb848&amp;amp;sc_channel=el"&gt;Amazon S3 Express One Zone&lt;/a&gt; storage class for higher performance small object workloads.&lt;/p&gt; 
&lt;p&gt;To access the new performance metrics, you need to enable performance metrics in the S3 Storage Lens advanced tier when creating a new Storage Lens dashboard or editing an existing configuration.&lt;/p&gt; 
&lt;table style="border: 2px solid black;border-collapse: collapse;margin-left: auto;margin-right: auto"&gt; 
 &lt;tbody&gt; 
  &lt;tr style="border-bottom: 1px solid black;background-color: #e0e0e0"&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;&lt;strong&gt;Metric category&lt;/strong&gt;&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;&lt;strong&gt;Details&lt;/strong&gt;&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;&lt;strong&gt;Use case&lt;/strong&gt;&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;&lt;strong&gt;Mitigation&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr style="border-bottom: 1px solid black"&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;Read request size&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;Distribution of read request sizes (GET) by day&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;Identify dataset with small read request patterns that slow down performance&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;Small request: Batch small objects or use Amazon S3 Express One Zone for high-performance small object workloads&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr style="border-bottom: 1px solid black"&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;Write request size&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;Distribution of write request sizes (PUT, POST, COPY, and UploadPart) by day&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;Identify dataset with small write request patterns that slow down performance&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;Large request: Parallelize requests, use MPU or use AWS CRT&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr style="border-bottom: 1px solid black"&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;Storage size&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;Distribution of object sizes&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;Identify dataset with small small objects that slow down performance&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;Small object sizes: Consider bundling small objects&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr style="border-bottom: 1px solid black"&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;Concurrent PUT 503 errors&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;Number of 503s due to concurrent PUT operation on same object&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;Identify prefixes with concurrent PUT throttling that slow down performance&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;For single writer, modify retry behavior or use Amazon S3 Express One Zone. For multiple writers, use consensus mechanism or use Amazon S3 Express One Zone&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr style="border-bottom: 1px solid black"&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;Cross-Region data transfer&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;Bytes transferred and requests sent across Region, in Region&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;Identify potential performance and cost degradation due to cross-Region data access&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;Co-locate compute with data in the same AWS Region&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr style="border-bottom: 1px solid black"&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;Unique objects accessed&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;Number or percentage of unique objects accessed per day&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;Identify datasets where small subset of objects are being frequently accessed. These can be moved to higher performance storage tier for better performance&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;Consider moving active data to Amazon S3 Express One Zone or other caching solutions&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr style="border-bottom: 1px solid black"&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;FirstByteLatency (existing &lt;a href="https://aws.amazon.com/cloudwatch/?trk=7c8639c6-87c6-47d6-9bd0-a5812eecb848&amp;amp;sc_channel=el"&gt;Amazon CloudWatch&lt;/a&gt; metric)&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;Daily average of first byte latency metric&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;The daily average per-request time from the complete request being received to when the response starts to be returned&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr style="border-bottom: 1px solid black"&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;TotalRequestLatency (existing Amazon CloudWatch metric)&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;Daily average of Total Request Latency&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;The daily average elapsed per request time from the first byte received to the last byte sent&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;How it works&lt;br&gt; &lt;/strong&gt;On the &lt;a href="https://console.aws.amazon.com/s3/storage-analytics-insights/?trk=7c8639c6-87c6-47d6-9bd0-a5812eecb848&amp;amp;sc_channel=el"&gt;Amazon S3 console&lt;/a&gt; I choose &lt;strong&gt;Create Storage Lens dashboard&lt;/strong&gt; to create a new dashboard. You can also edit an existing dashboard configuration. I then configure general settings such as providing a &lt;strong&gt;Dashboard name&lt;/strong&gt;, &lt;strong&gt;Status&lt;/strong&gt;, and the optional &lt;strong&gt;Tags.&lt;/strong&gt; Then, I choose &lt;strong&gt;Next&lt;/strong&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/24/metricsdashboard1.png"&gt;&lt;img loading="lazy" class="aligncenter size-large wp-image-101722" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/24/metricsdashboard1-1024x283.png" alt="" width="1024" height="283"&gt;&lt;/a&gt;&lt;br&gt; Next, I define the scope of the dashboard by selecting &lt;strong&gt;Include all Regions and Include all buckets&lt;/strong&gt; and specifying the Regions and buckets to be included.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/24/metricsdashboard2.png"&gt;&lt;img loading="lazy" class="aligncenter size-large wp-image-101724" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/24/metricsdashboard2-1024x227.png" alt="" width="1024" height="227"&gt;&lt;/a&gt;&lt;br&gt; I opt in to the &lt;strong&gt;Advanced tier&lt;/strong&gt; in the Storage Lens dashboard configuration, select &lt;strong&gt;Performance metrics&lt;/strong&gt;, then choose &lt;strong&gt;Next&lt;/strong&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/24/metricsdashboard3.png"&gt;&lt;img loading="lazy" class="aligncenter size-large wp-image-101725" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/24/metricsdashboard3-1024x394.png" alt="" width="1024" height="394"&gt;&lt;/a&gt;&lt;br&gt; Next, I select &lt;strong&gt;Prefix aggregation&lt;/strong&gt; as an additional metrics aggregation, then leave the rest of the information as default before I choose &lt;strong&gt;Next&lt;/strong&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/25/Screenshot-2025-11-18-at-11.13.31-PM.png"&gt;&lt;img loading="lazy" class="aligncenter size-large wp-image-101833" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/25/Screenshot-2025-11-18-at-11.13.31-PM-1024x464.png" alt="" width="1024" height="464"&gt;&lt;/a&gt;&lt;br&gt; I select the &lt;strong&gt;Default metrics report&lt;/strong&gt;, then &lt;strong&gt;General purpose bucket&lt;/strong&gt; as the bucket type, and then select the Amazon S3 bucket in my AWS account as the &lt;strong&gt;Destination bucket&lt;/strong&gt;. I leave the rest of the information as default, then select &lt;strong&gt;Next&lt;/strong&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/25/Screenshot-2025-11-24-at-5.25.01-PM.png"&gt;&lt;img loading="lazy" class="aligncenter size-large wp-image-101834" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/25/Screenshot-2025-11-24-at-5.25.01-PM-1024x382.png" alt="" width="1024" height="382"&gt;&lt;/a&gt;&lt;br&gt; I review all the information before I choose &lt;strong&gt;Submit&lt;/strong&gt; to finalize the process.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/24/metricsdashboard6.png"&gt;&lt;img loading="lazy" class="aligncenter size-large wp-image-101728" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/24/metricsdashboard6-871x1024.png" alt="" width="871" height="1024"&gt;&lt;/a&gt;&lt;br&gt; After it’s enabled, I’ll receive daily performance metrics directly in the &lt;a href="https://console.aws.amazon.com/s3/?trk=7c8639c6-87c6-47d6-9bd0-a5812eecb848&amp;amp;sc_channel=el"&gt;Storage Lens console&lt;/a&gt; dashboard. You can also choose to export report in CSV or Parquet format to any bucket in your account or publish to Amazon CloudWatch. The performance metrics are aggregated and published daily and will be available at multiple levels: organization, account, bucket, and prefix. In this dropdown menu, I choose the % concurrent PUT 503 error for the &lt;strong&gt;Metric&lt;/strong&gt;, Last 30 days for the &lt;strong&gt;Date range&lt;/strong&gt;, and 10 for the &lt;strong&gt;Top N buckets&lt;/strong&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/24/Screenshot-2025-11-18-at-10.46.28-PM.png"&gt;&lt;img loading="lazy" class="aligncenter size-large wp-image-101738" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/24/Screenshot-2025-11-18-at-10.46.28-PM-1024x434.png" alt="" width="1024" height="434"&gt;&lt;/a&gt;&lt;br&gt; The Concurrent PUT 503 error count metric tracks the number of 503 errors generated by simultaneous PUT operations to the same object. Throttling errors can degrade application performance. For a single writer, modify retry behavior or use higher performance storage tier such as Amazon S3 Express One Zone to mitigate concurrent PUT 503 errors. For multiple writers scenario, use a consensus mechanism to avoid concurrent PUT 503 errors or use higher performance storage tier such as Amazon S3 Express One Zone.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/13/oasis_conc_PUT.png"&gt;&lt;img loading="lazy" class="aligncenter size-large wp-image-100904" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/13/oasis_conc_PUT-1024x730.png" alt="" width="1024" height="730"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="text-decoration: underline"&gt;&lt;strong&gt;Complete analytics for all prefixes in your S3 buckets&lt;/strong&gt;&lt;/span&gt;&lt;br&gt; S3 Storage Lens now supports analytics for all prefixes in your S3 buckets through a new &lt;strong&gt;Expanded prefixes metrics report&lt;/strong&gt;. This capability removes previous limitations that restricted analysis to prefixes meeting a 1% size threshold and a maximum depth of 10 levels. You can now track up to billions of prefixes per bucket for analysis at the most granular prefix level, regardless of size or depth.&lt;/p&gt; 
&lt;p&gt;The Expanded prefixes metrics report includes all existing S3 Storage Lens metric categories: storage usage, activity metrics (requests and bytes transferred), data protection metrics, and detailed status code metrics.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;How to get started&lt;/strong&gt;&lt;br&gt; I follow the same steps outlined in the &lt;strong&gt;How it works&lt;/strong&gt; section to create or update the Storage Lens dashboard. In Step 4 on the console, where you select export options, you can select the new &lt;strong&gt;Expanded prefixes metrics report&lt;/strong&gt;. Thereafter, I can export the expanded prefixes metrics report in CSV or Parquet format to any general purpose bucket in my account for efficient querying of my Storage Lens data.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/24/metricsdashboard5-1.png"&gt;&lt;img loading="lazy" class="aligncenter size-large wp-image-101729" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/24/metricsdashboard5-1-1024x350.png" alt="" width="1024" height="350"&gt;&lt;/a&gt;&lt;br&gt; &lt;strong&gt;Good to know&lt;br&gt; &lt;/strong&gt;This enhancement addresses scenarios where organizations need granular visibility across their entire prefix structure. For example, you can identify prefixes with incomplete multipart uploads to reduce costs, track compliance across your entire prefix structure for encryption and replication requirements, and detect performance issues at the most granular level.&lt;/p&gt; 
&lt;p&gt;&lt;span style="text-decoration: underline"&gt;&lt;strong&gt;Export S3 Storage Lens metrics to S3 Tables&lt;br&gt; &lt;/strong&gt;&lt;/span&gt;S3 Storage Lens metrics can now be automatically exported to S3 Tables, a fully managed feature on AWS with built-in Apache Iceberg support. This integration provides daily automatic delivery of metrics to AWS managed S3 Tables for immediate querying without requiring additional processing infrastructure.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;How to get started&lt;/strong&gt;&lt;br&gt; I start by following the process outlined in Step 5 on the console, where I choose the export destination. This time, I choose &lt;strong&gt;Expanded prefixes metrics report&lt;/strong&gt;. In addition to General purpose bucket, I choose &lt;strong&gt;Table bucket&lt;/strong&gt;.&lt;/p&gt; 
&lt;p&gt;The new Storage Lens metrics are exported to new tables in an &lt;a href="https://docs.aws.amazon.com/AmazonS3/latest/userguide/s3-tables-buckets.html"&gt;AWS managed bucket&lt;/a&gt; &lt;code&gt;aws-s3&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/18/seer1.png"&gt;&lt;img loading="lazy" class="aligncenter size-large wp-image-101352" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/18/seer1-1024x429.png" alt="" width="1024" height="429"&gt;&lt;/a&gt;&lt;br&gt; I select the &lt;strong&gt;expanded_prefixes_activity_metrics&lt;/strong&gt; table to view API usage metrics for expanded prefix reports.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/18/seer2.png"&gt;&lt;img loading="lazy" class="aligncenter size-large wp-image-101353" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/18/seer2-1024x446.png" alt="" width="1024" height="446"&gt;&lt;/a&gt;&lt;br&gt; I can preview the table on the Amazon S3 console or use &lt;a href="https://aws.amazon.com/athena"&gt;Amazon Athena&lt;/a&gt; to query the table.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/18/seer3.png"&gt;&lt;img loading="lazy" class="aligncenter size-large wp-image-101354" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/18/seer3-1024x323.png" alt="" width="1024" height="323"&gt;&lt;/a&gt;&lt;br&gt; &lt;strong&gt;Good to know&lt;br&gt; &lt;/strong&gt;S3 Tables integration with S3 Storage Lens simplifies metric analysis using familiar SQL tools and AWS analytics services such as Amazon Athena, &lt;a href="https://quicksight.aws"&gt;Amazon QuickSight&lt;/a&gt;, &lt;a href="https://aws.amazon.com/emr"&gt;Amazon EMR&lt;/a&gt;, and &lt;a href="https://aws.amazon.com/redshift/"&gt;Amazon Redshift&lt;/a&gt;, without requiring a data pipeline. The metrics are automatically organized for optimal querying, with custom retention and encryption options to suit your needs.&lt;/p&gt; 
&lt;p&gt;This integration enables cross-account and cross-Region analysis, custom dashboard creation, and data correlation with other AWS services. For example, you can combine Storage Lens metrics with S3 Metadata to analyze prefix-level activity patterns and identify objects in prefixes with cold data that are eligible for transition to lower-cost storage tiers.&lt;/p&gt; 
&lt;p&gt;For your agentic AI workflows, you can use natural language to query S3 Storage Lens metrics in S3 Tables with the &lt;a href="https://aws.amazon.com/about-aws/whats-new/2025/07/amazon-s3-tables-mcp-server/"&gt;S3 Tables MCP Server&lt;/a&gt;. Agents can ask questions such as ‘which buckets grew the most last month?’ or ‘show me storage costs by storage class’ and get instant insights from your observability data.&lt;/p&gt; 
&lt;p&gt;&lt;span style="text-decoration: underline"&gt;&lt;strong&gt;Now available&lt;br&gt; &lt;/strong&gt;&lt;/span&gt;All three enhancements are available in all &lt;a href="https://builder.aws.com/build/capabilities/explore?tab=service-feature"&gt;AWS Regions&lt;/a&gt; where S3 Storage Lens is currently offered (except the China Regions and AWS GovCloud (US)).&lt;/p&gt; 
&lt;p&gt;These features are included in the Amazon S3 Storage Lens Advanced tier at no additional charge beyond standard advanced tier pricing. For the S3 Tables export, you pay only for S3 Tables storage, maintenance, and queries. There is no additional charge for the export functionality itself.&lt;/p&gt; 
&lt;p&gt;To learn more about Amazon S3 Storage Lens performance metrics, support for billions of prefixes, and export to S3 Tables, refer to the &lt;a href="http://docs.aws.amazon.com/AmazonS3/latest/userguide/storage_lens.html"&gt;Amazon S3 user guide&lt;/a&gt;. For pricing details, visit the &lt;a href="https://aws.amazon.com/s3/pricing/"&gt;Amazon S3 pricing page&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://linkedin.com/in/veliswa-boya"&gt;Veliswa Boya&lt;/a&gt;.&lt;/p&gt;</content:encoded>
					
					
			
		
		
			</item>
		<item>
		<title>Amazon Bedrock AgentCore adds quality evaluations and policy controls for deploying trusted AI agents</title>
		<link>https://aws.amazon.com/blogs/aws/amazon-bedrock-agentcore-adds-quality-evaluations-and-policy-controls-for-deploying-trusted-ai-agents/</link>
					
		
		<dc:creator><![CDATA[Danilo Poccia]]></dc:creator>
		<pubDate>Tue, 02 Dec 2025 16:14:36 +0000</pubDate>
				<category><![CDATA[Amazon Bedrock]]></category>
		<category><![CDATA[Amazon Machine Learning]]></category>
		<category><![CDATA[Announcements]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[AWS re:Invent]]></category>
		<category><![CDATA[Generative AI]]></category>
		<category><![CDATA[Launch]]></category>
		<category><![CDATA[News]]></category>
		<guid isPermaLink="false">3870755b4dc5b85bc25b91b3e76720a4dab01f61</guid>

					<description>Deploy AI agents with confidence using new quality evaluations and policy controls—enabling precise boundaries on agent actions, continuous quality monitoring, and experience-based learning while maintaining natural conversation flows.</description>
										<content:encoded>&lt;p&gt;Today, we’re announcing new capabilities in &lt;a href="https://aws.amazon.com/bedrock/agentcore/"&gt;Amazon Bedrock AgentCore&lt;/a&gt; to further remove barriers holding AI agents back from production. Organizations across industries are already building on AgentCore, the most advanced agentic platform to build, deploy, and operate highly capable agents securely at any scale. In just 5 months since preview, the &lt;a href="https://github.com/aws/bedrock-agentcore-sdk-python"&gt;AgentCore SDK&lt;/a&gt; has been downloaded over 2 million times. For example:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;PGA TOUR, a pioneer and innovation leader in sports has built a multi-agent content generation system to create articles for their digital platforms. The new solution, built on AgentCore, enables the PGA TOUR to provide comprehensive coverage for every player in the field, by increasing content writing speed by 1,000 percent while achieving a 95 percent reduction in costs.&lt;/li&gt; 
 &lt;li&gt;Independent software vendors (ISVs) like Workday are building the software of the future on AgentCore. AgentCore Code Interpreter provides Workday Planning Agent with secure data protection and essential features for financial data exploration. Users can analyze financial and operational data through natural language queries, making financial planning intuitive and self-driven. This capability reduces time spent on routine planning analysis by 30 percent, saving approximately 100 hours per month.&lt;/li&gt; 
 &lt;li&gt;Grupo Elfa, a Brazilian distributor and retailer, relies on AgentCore Observability for complete audit traceability and real-time metrics of their agents, transforming their reactive processes into proactive operations. Using this unified platform, their sales team can handle thousands of daily price quotes while the organization maintains full visibility of agent decisions, helping achieve 100 percent traceability of agent decisions and interactions, and reduced problem resolution time by 50 percent.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;As organizations scale their agent deployments, they face challenges around implementing the right boundaries and quality checks to confidently deploy agents. The autonomy that makes agents powerful also makes them hard to confidently deploy at scale, as they might access sensitive data inappropriately, make unauthorized decisions, or take unexpected actions. Development teams must balance enabling agent autonomy while ensuring they operate within acceptable boundaries and with the quality you require to put them in front of customers and employees.&lt;/p&gt; 
&lt;p&gt;The new capabilities available today take the guesswork out of this process and help you build and deploy trusted AI agents with confidence:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Policy in AgentCore&lt;/strong&gt; (Preview) – Defines clear boundaries for agent actions by intercepting AgentCore Gateway tool calls before they run using policies with fine-grained permissions.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;AgentCore Evaluations&lt;/strong&gt; (Preview) – Monitors the quality of your agents based on real-world behavior using built-in evaluators for dimensions such as correctness and helpfulness, plus custom evaluators for business-specific requirements.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;We’re also introducing features that expand what agents can do:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Episodic functionality in AgentCore Memory&lt;/strong&gt; – A new long-term strategy that helps agents learn from experiences and adapt solutions across similar situations for improved consistency and performance in similar future tasks.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Bidirectional streaming in AgentCore Runtime&lt;/strong&gt; – Deploys voice agents where both users and agents can speak simultaneously following a natural conversation flow.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style="text-decoration: underline"&gt;&lt;strong&gt;Policy in AgentCore for precise agent control&lt;/strong&gt;&lt;/span&gt;&lt;br&gt; Policy gives you control over the actions agents can take and are applied outside of the agent’s reasoning loop, treating agents as autonomous actors whose decisions require verification before reaching tools, systems, or data. It integrates with AgentCore Gateway to intercept tool calls as they happen, processing requests while maintaining operational speed, so workflows remain fast and responsive.&lt;/p&gt; 
&lt;p&gt;You can create policies using natural language or directly use &lt;a href="https://www.cedarpolicy.com/"&gt;Cedar&lt;/a&gt;—an open source policy language for fine-grained permissions—simplifying the process to set up, understand, and audit rules without writing custom code. This approach makes policy creation accessible to development, security, and compliance teams who can create, understand, and audit rules without specialized coding knowledge.&lt;/p&gt; 
&lt;p&gt;The policies operate independently of how the agent was built or which model it uses. You can define which tools and data agents can access—whether they are APIs, &lt;a href="https://aws.amazon.com/lambda/"&gt;AWS Lambda&lt;/a&gt; functions, &lt;a href="https://modelcontextprotocol.io/"&gt;Model Context Protocol (MCP)&lt;/a&gt; servers, or third-party services—what actions they can perform, and under what conditions.&lt;/p&gt; 
&lt;p&gt;Teams can define clear policies once and apply them consistently across their organization. With policies in place, developers gain the freedom to create innovative agentic experiences, and organizations can deploy their agents to act autonomously while knowing they’ll stay within defined boundaries and compliance requirements.&lt;/p&gt; 
&lt;p&gt;&lt;span style="text-decoration: underline"&gt;&lt;strong&gt;Using Policy in AgentCore&lt;br&gt; &lt;/strong&gt;&lt;/span&gt;You can start by creating a policy engine in the new &lt;strong&gt;Policy&lt;/strong&gt; section of the &lt;a href="https://console.aws.amazon.com/bedrock-agentcore"&gt;AgentCore console&lt;/a&gt; and associate it with one or more AgentCore gateways.&lt;/p&gt; 
&lt;p&gt;A policy engine is a collection of policies that are evaluated at the gateway endpoint. When associating a gateway with a policy engine, you can choose whether to enforce the result of the policy—effectively permitting or denying access to a tool call—or to only emit logs. Using logs helps you test and validate a policy before enabling it in production.&lt;/p&gt; 
&lt;p&gt;Then, you can define the policies to apply to have granular control over access to the tools offered by the associated AgentCore gateways.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/25/agentcore-policy-console.png"&gt;&lt;img loading="lazy" class="aligncenter size-full wp-image-101864" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/25/agentcore-policy-console.png" alt="Amazon Bedrock AgentCore Policy console" width="995" height="791"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;To create a policy, you can start with a natural language description (that should include information of the authentication claims to use) or directly edit Cedar code.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/25/agentcore-policy-add.png"&gt;&lt;img loading="lazy" class="aligncenter size-full wp-image-101868" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/25/agentcore-policy-add.png" alt="Amazon Bedrock AgentCore Policy add" width="1251" height="1007"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Natural language-based policy authoring provides a more accessible way for you to create fine-grained policies. Instead of writing formal policy code, you can describe rules in plain English. The system interprets your intent, generates candidate policies, validates them against the tool schema, and uses automated reasoning to check safety conditions—identifying prompts that are overly permissive, overly restrictive, or contain conditions that can never be satisfied.&lt;/p&gt; 
&lt;p&gt;Unlike generic &lt;a href="https://aws.amazon.com/what-is/large-language-model/"&gt;large language model (LLM)&lt;/a&gt; translations, this feature understands the structure of your tools and generates policies that are both syntactically correct and semantically aligned with your intent, while flagging rules that cannot be enforced. It is also available as a &lt;a href="https://modelcontextprotocol.io/"&gt;Model Context Protocol (MCP)&lt;/a&gt; server, so you can author and validate policies directly in your preferred AI-assisted coding environment as part of your normal development workflow. This approach reduces onboarding time and helps you write high-quality authorization rules without needing Cedar expertise.&lt;/p&gt; 
&lt;p&gt;The following sample policy uses information from the OAuth claims in the JWT token used to authenticate to an AgentCore gateway (for the &lt;code&gt;role&lt;/code&gt;) and the arguments passed to the tool call (&lt;code&gt;context.input&lt;/code&gt;) to validate access to the tool processing a refund. Only an authenticated user with the &lt;code&gt;refund-agent&lt;/code&gt; role can access the tool but for amounts (&lt;code&gt;context.input.amount&lt;/code&gt;) lower than $200 USD.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="lang-cedar"&gt;permit(
  principal is AgentCore::OAuthUser,
  action == AgentCore::Action::"RefundTool__process_refund",
  resource == AgentCore::Gateway::"&amp;lt;GATEWAY_ARN&amp;gt;"
)
when {
  principal.hasTag("role") &amp;amp;&amp;amp;
  principal.getTag("role") == "refund-agent" &amp;amp;&amp;amp;
  context.input.amount &amp;lt; 200
};&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;span style="text-decoration: underline"&gt;&lt;strong&gt;AgentCore Evaluations for continuous, real-time quality intelligence&lt;/strong&gt;&lt;/span&gt;&lt;br&gt; AgentCore Evaluations is a fully managed service that helps you continuously monitor and analyze agent performance based on real-world behavior. With AgentCore Evaluations, you can use built-in evaluators for common quality dimensions such as correctness, helpfulness, tool selection accuracy, safety, goal success rate, and context relevance. You can also create custom model-based scoring systems configured with your choice of prompt and model for business-tailored scoring while the service samples live agent interactions and scores them continuously.&lt;/p&gt; 
&lt;p&gt;All results from AgentCore Evaluations are visualized in &lt;a href="https://aws.amazon.com/cloudwatch/"&gt;Amazon CloudWatch&lt;/a&gt; alongside AgentCore Observability insights, providing one place for unified monitoring. You can also set up alerts and alarms on the evaluation scores to proactively monitor agent quality and respond when metrics fall outside acceptable thresholds.&lt;/p&gt; 
&lt;p&gt;You can use AgentCore Evaluations during the testing phase where you can check an agent against the baseline before deployment to stop faulty versions from reaching users, and in production for continuous improvement of your agents. When quality metrics drop below defined thresholds—such as a customer service agent satisfaction declining or politeness scores dropping by more than 10 percent over an 8-hour period—the system triggers immediate alerts, helping to detect and address quality issues faster.&lt;/p&gt; 
&lt;p&gt;&lt;span style="text-decoration: underline"&gt;&lt;strong&gt;Using AgentCore Evaluations&lt;br&gt; &lt;/strong&gt;&lt;/span&gt;You can create an online evaluation in the new &lt;strong&gt;Evaluations&lt;/strong&gt; section of the &lt;a href="https://console.aws.amazon.com/bedrock-agentcore"&gt;AgentCore console&lt;/a&gt;. You can use as data source an AgentCore agent endpoint or a CloudWatch log group used by an external agent. For example, I use here the same sample customer support agent I shared when we &lt;a href="https://aws.amazon.com/blogs/aws/introducing-amazon-bedrock-agentcore-securely-deploy-and-operate-ai-agents-at-any-scale/"&gt;introduced AgentCore in preview&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/25/agentcore-evaluations-source.png"&gt;&lt;img loading="lazy" class="aligncenter size-full wp-image-101865" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/25/agentcore-evaluations-source.png" alt="Amazon Bedrock AgentCore Evaluations source" width="982" height="813"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Then, you can select the evaluators to use, including custom evaluators that you can define starting from the existing templates or build from scratch.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/25/agentcore-evaluations-evaluators.png"&gt;&lt;img loading="lazy" class="aligncenter size-full wp-image-101866" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/25/agentcore-evaluations-evaluators.png" alt="Amazon Bedrock AgentCore Evaluations source" width="980" height="991"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;For example, for a customer support agent, you can select metrics such as:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Correctness&lt;/strong&gt; – Evaluates whether the information in the agent’s response is factually accurate&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Faithfulness&lt;/strong&gt; – Evaluates whether information in the response is supported by provided context/sources&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Helpfulness&lt;/strong&gt; – Evaluates from user’s perspective how useful and valuable the agent’s response is&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Harmfulness&lt;/strong&gt; – Evaluates whether the response contains harmful content&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Stereotyping&lt;/strong&gt; – Detects content that makes generalizations about individuals or groups&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The evaluators for tool selection and tool parameter accuracy can help you understand if an agent is choosing the right tool for a task and extracting the correct parameters from the user queries.&lt;/p&gt; 
&lt;p&gt;To complete the creation of the evaluation, you can choose the sampling rate and optional filters. For permissions, you can create a new &lt;a href="https://aws.amazon.com/iam/"&gt;AWS Identity and Access Management (IAM)&lt;/a&gt; service role or pass an existing one.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/25/agentcore-evaluations-filters-permissions.png"&gt;&lt;img loading="lazy" class="aligncenter size-full wp-image-101867" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/25/agentcore-evaluations-filters-permissions.png" alt="Amazon Bedrock AgentCore Evaluations create" width="983" height="643"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;The results are published, as they are evaluated, on &lt;a href="https://aws.amazon.com/cloudwatch/"&gt;Amazon CloudWatch&lt;/a&gt; in the AgentCore Observability dashboard. You can choose any of the bar chart sections to see the corresponding traces and gain deeper insight into the requests and responses behind that specific evaluation.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/27/agentcore-evaluations-results.png"&gt;&lt;img loading="lazy" class="aligncenter size-full wp-image-102185" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/27/agentcore-evaluations-results.png" alt="Amazon AgentCore Evaluations results" width="2360" height="1652"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Because the results are in CloudWatch, you can use all of its feature to create, for example, alarms and automations.&lt;/p&gt; 
&lt;p&gt;&lt;span style="text-decoration: underline"&gt;&lt;strong&gt;Creating custom evaluators in AgentCore Evaluations&lt;br&gt; &lt;/strong&gt;&lt;/span&gt;Custom evaluators allow you to define business-specific quality metrics tailored to your agent’s unique requirements. To create a custom evaluator, you provide the model to use as a judge, including inference parameters such as temperature and max output tokens, and a tailored prompt with the judging instructions. You can start from the prompt used by one of the built-in evaluators or enter a new one.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/26/agentcore-policy-custom-evaluator.png"&gt;&lt;img loading="lazy" class="aligncenter size-full wp-image-102068" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/26/agentcore-policy-custom-evaluator.png" alt="AgentCore Evaluations create custom evaluator" width="1183" height="954"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Then, you define the scale to produce in output. It can be either numeric values or custom text labels that you define. Finally, you configure whether the evaluation is computed by the model on single traces, full sessions, or for each tool call.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/26/agentcore-policy-custom-evaluator-scale.png"&gt;&lt;img loading="lazy" class="aligncenter size-full wp-image-102069" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/26/agentcore-policy-custom-evaluator-scale.png" alt="AgentCore Evaluations custom evaluator scale" width="1183" height="699"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="text-decoration: underline"&gt;&lt;strong&gt;AgentCore Memory episodic functionality for experience-based learning&lt;br&gt; &lt;/strong&gt;&lt;/span&gt;AgentCore Memory, a fully managed service that gives AI agents the ability to remember past interactions, now includes a new &lt;a href="https://docs.aws.amazon.com/bedrock-agentcore/latest/devguide/long-term-memory-long-term.html"&gt;long-term memory&lt;/a&gt; strategy that gives agents the ability to learn from past experiences and apply those lessons to provide more helpful assistance in future interactions.&lt;/p&gt; 
&lt;p&gt;Consider booking travel with an agent: over time, the agent learns from your booking patterns—such as the fact that you often need to move flights to later times when traveling for work due to client meetings. When you start your next booking involving client meetings, the agent proactively suggests flexible return options based on these learned patterns. Just like an experienced assistant who learns your specific travel habits, agents with episodic memory can now recognize and adapt to your individual needs.&lt;/p&gt; 
&lt;p&gt;When you enable the new episodic functionality, AgentCore Memory captures structured episodes that record the context, reasoning process, actions taken, and outcomes of agent interactions, while a reflection agent analyzes these episodes to extract broader insights and patterns. When facing similar tasks, agents can retrieve these learnings to improve decision-making consistency and reduce processing time. This reduces the need for custom instructions by including in the agent context only the specific learnings an agent needs to complete a task instead of a long list of all possible suggestions.&lt;/p&gt; 
&lt;p&gt;&lt;span style="text-decoration: underline"&gt;&lt;strong&gt;AgentCore Runtime bidirectional streaming for more natural conversations&lt;/strong&gt;&lt;/span&gt;&lt;br&gt; With AgentCore Runtime, you can deploy agentic applications with few lines of code. To simplify deploying conversational experiences that feel natural and responsive, AgentCore Runtime now supports bidirectional streaming. This capability enables voice agents to listen and adapt while users speak, so that people can interrupt agents mid-response and have the agent immediately adjust to the new context—without waiting for the agent to finish its current output. Rather than traditional turn-based interaction where users must wait for complete responses, bidirectional streaming creates flowing, natural conversations where agents dynamically change their response based on what the user is saying.&lt;/p&gt; 
&lt;p&gt;Building these conversational experiences from the ground up requires significant engineering effort to handle the complex flow of simultaneous communication. Bidirectional streaming simplifies this by managing the infrastructure needed for agents to process input while generating output, handling interruptions gracefully, and maintaining context throughout dynamic conversation shifts. You can now deploy agents that naturally adapt to the fluid nature of human conversation—supporting mid-thought interruptions, context switches, and clarifications without losing the thread of the interaction.&lt;/p&gt; 
&lt;p&gt;&lt;span style="text-decoration: underline"&gt;&lt;strong&gt;Things to know&lt;/strong&gt;&lt;/span&gt;&lt;br&gt; &lt;a href="https://aws.amazon.com/bedrock/agentcore/"&gt;Amazon Bedrock AgentCore&lt;/a&gt;, including the preview of Policy, is available in the US East (Ohio, N. Virginia), US West (Oregon), Asia Pacific (Mumbai, Singapore, Sydney, Tokyo), and Europe (Frankfurt, Ireland) &lt;a href="https://aws.amazon.com/about-aws/global-infrastructure/regions_az/"&gt;AWS Regions&lt;/a&gt; . The preview of AgentCore Evaluations is available in the US East (Ohio, N. Virginia), US West (Oregon), Asia Pacific (Sydney), and Europe (Frankfurt) Regions. For Regional availability and future roadmap, visit &lt;a href="https://builder.aws.com/capabilities/"&gt;AWS Capabilities by Region&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;With AgentCore, you pay for what you use with no upfront commitments. For detailed pricing information, visit the &lt;a href="https://aws.amazon.com/bedrock/pricing/"&gt;Amazon Bedrock pricing page&lt;/a&gt;. AgentCore is also a part of the &lt;a href="https://aws.amazon.com/free"&gt;AWS Free Tier&lt;/a&gt;&amp;nbsp;that new AWS customers can use to get started at no cost and explore key AWS services.&lt;/p&gt; 
&lt;p&gt;These new features work with any open source framework such as &lt;a href="https://www.crewai.com/"&gt;CrewAI&lt;/a&gt;, &lt;a href="https://www.langchain.com/langgraph"&gt;LangGraph&lt;/a&gt;, &lt;a href="https://www.llamaindex.ai/"&gt;LlamaIndex&lt;/a&gt;, and &lt;a href="https://strandsagents.com/"&gt;Strands Agents&lt;/a&gt;, and with any foundation model. AgentCore services can be used together or independently, and you can get started using your favorite AI-assisted development environment with the &lt;a href="https://awslabs.github.io/mcp/servers/amazon-bedrock-agentcore-mcp-server"&gt;AgentCore open source MCP server&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;To learn more and get started quickly, visit the &lt;a href="https://docs.aws.amazon.com/bedrock-agentcore/latest/devguide/what-is-bedrock-agentcore.html"&gt;AgentCore Developer Guide&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;— &lt;a href="https://x.com/danilop"&gt;Danilo&lt;/a&gt;&lt;/p&gt;</content:encoded>
					
					
			
		
		
			</item>
		<item>
		<title>Build multi-step applications and AI workflows with AWS Lambda durable functions</title>
		<link>https://aws.amazon.com/blogs/aws/build-multi-step-applications-and-ai-workflows-with-aws-lambda-durable-functions/</link>
					
		
		<dc:creator><![CDATA[Donnie Prakoso]]></dc:creator>
		<pubDate>Tue, 02 Dec 2025 16:12:19 +0000</pubDate>
				<category><![CDATA[AWS Lambda]]></category>
		<category><![CDATA[AWS re:Invent]]></category>
		<category><![CDATA[Compute]]></category>
		<category><![CDATA[Launch]]></category>
		<category><![CDATA[News]]></category>
		<guid isPermaLink="false">ded717d9c4eebbe5f07189f19a241835cf588271</guid>

					<description>New Lambda capability lets you build applications that coordinate multiple steps reliably over extended periods—from seconds to up to one year—without paying for idle compute time when waiting for external events or human decisions.</description>
										<content:encoded>&lt;p&gt;Modern applications increasingly require complex and long-running coordination between services, such as multi-step payment processing, AI agent orchestration, or approval processes awaiting human decisions. Building these traditionally required significant effort to implement state management, handle failures, and integrate multiple infrastructure services.&lt;/p&gt; 
&lt;p&gt;Starting today, you can use &lt;a href="https://aws.amazon.com/lambda/lambda-durable-functions/"&gt;AWS Lambda durable functions&lt;/a&gt; to build reliable multi-step applications directly within the familiar AWS Lambda experience. Durable functions are regular Lambda functions with the same event handler and integrations you already know. You write sequential code in your preferred programming language, and durable functions track progress, automatically retry on failures, and suspend execution for up to one year at defined points,&amp;nbsp;without paying for idle compute during waits.&lt;/p&gt; 
&lt;p&gt;AWS Lambda durable functions use a checkpoint and replay mechanism, known as durable execution, to deliver these capabilities. After enabling a function for durable execution, you add the new open source durable execution SDK to your function code. You then use SDK primitives like “steps” to add automatic checkpointing and retries to your business logic and “waits” to efficiently suspend execution without compute charges. When execution terminates unexpectedly, Lambda resumes from the last checkpoint, replaying your event handler from the beginning while skipping completed operations.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;span style="text-decoration: underline"&gt;Getting started with AWS Lambda durable functions&lt;br&gt; &lt;/span&gt;&lt;/strong&gt;Let me walk you through how to use durable functions.&lt;/p&gt; 
&lt;p&gt;First, I create a new &lt;a href="https://console.aws.amazon.com/lambda?trk=c4ea046f-18ad-4d23-a1ac-cdd1267f942c&amp;amp;sc_channel=el"&gt;Lambda function in the console&lt;/a&gt; and select &lt;strong&gt;Author from scratch&lt;/strong&gt;. In the &lt;strong&gt;Durable execution&lt;/strong&gt; section, I select &lt;strong&gt;Enable&lt;/strong&gt;. Note that, durable function setting can only be set during function creation and currently can’t be modified for existing Lambda functions.&lt;/p&gt; 
&lt;p&gt;&lt;img loading="lazy" class="aligncenter size-full wp-image-101851" style="border: 1px solid black;padding: 3px" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/25/2025-news-durable-function-4.png" alt="" width="1066" height="889"&gt;&lt;/p&gt; 
&lt;p&gt;After I create my Lambda durable function, I can get started with the provided code.&lt;/p&gt; 
&lt;p&gt;&lt;img loading="lazy" class="aligncenter size-full wp-image-101860" style="border: 1px solid black;padding: 3px" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/25/2025-news-durable-function-5.png" alt="" width="1311" height="1405"&gt;&lt;/p&gt; 
&lt;p&gt;Lambda durable functions introduces two core primitives that handle state management and recovery:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Steps&lt;/strong&gt;—The &lt;code&gt;context.step()&lt;/code&gt; method adds automatic retries and checkpointing to your business logic. After a step is completed, it will be skipped during replay.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Wait&lt;/strong&gt;—The &lt;code&gt;context.wait()&lt;/code&gt; method pauses execution for a specified duration, terminating the function, suspending and resuming execution without compute charges.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Additionally, Lambda durable functions provides other operations for more complex patterns: &lt;code&gt;create_callback()&lt;/code&gt; creates a callback that you can use to await results for external events like API responses or human approvals, &lt;code&gt;wait_for_condition()&lt;/code&gt; pauses until a specific condition is met like polling a REST API for process completion, and &lt;code&gt;parallel()&lt;/code&gt; or &lt;code&gt;map()&lt;/code&gt; operations for advanced concurrency use cases.&lt;/p&gt; 
&lt;p&gt;&lt;span style="text-decoration: underline"&gt;&lt;strong&gt;Building a production-ready order processing workflow&lt;br&gt; &lt;/strong&gt;&lt;/span&gt;Now let’s expand the default example to build a production-ready order processing workflow. This demonstrates how to use callbacks for external approvals, handle errors properly, and configure retry strategies. I keep the code intentionally concise to focus on these core concepts. In a full implementation, you could enhance the validation step with &lt;a href="https://console.aws.amazon.com/bedrock?trk=c4ea046f-18ad-4d23-a1ac-cdd1267f942c&amp;amp;sc_channel=el"&gt;Amazon Bedrock&lt;/a&gt; to add AI-powered order analysis.&lt;/p&gt; 
&lt;p&gt;Here’s how the order processing workflow works:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;First, &lt;code&gt;validate_order()&lt;/code&gt; checks order data to ensure all required fields are present.&lt;/li&gt; 
 &lt;li&gt;Next, &lt;code&gt;send_for_approval()&lt;/code&gt; sends the order for external human approval and waits for a callback response, suspending execution without compute charges.&lt;/li&gt; 
 &lt;li&gt;Then, &lt;code&gt;process_order()&lt;/code&gt; completes order processing.&lt;/li&gt; 
 &lt;li&gt;Throughout the workflow, try-catch error handling distinguishes between terminal errors that stop execution immediately and recoverable errors inside steps that trigger automatic retries.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Here’s the complete order processing workflow with step definitions and the main handler:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import random
from aws_durable_execution_sdk_python import (
    DurableContext,
    StepContext,
    durable_execution,
    durable_step,
)
from aws_durable_execution_sdk_python.config import (
    Duration,
    StepConfig,
    CallbackConfig,
)
from aws_durable_execution_sdk_python.retries import (
    RetryStrategyConfig,
    create_retry_strategy,
)


@durable_step
def validate_order(step_context: StepContext, order_id: str) -&amp;gt; dict:
    """Validates order data using AI."""
    step_context.logger.info(f"Validating order: {order_id}")
    # In production: calls Amazon Bedrock to validate order completeness and accuracy
    return {"order_id": order_id, "status": "validated"}


@durable_step
def send_for_approval(step_context: StepContext, callback_id: str, order_id: str) -&amp;gt; dict:
    """Sends order for approval using the provided callback token."""
    step_context.logger.info(f"Sending order {order_id} for approval with callback_id: {callback_id}")
    
    # In production: send callback_id to external approval system
    # The external system will call Lambda SendDurableExecutionCallbackSuccess or
    # SendDurableExecutionCallbackFailure APIs with this callback_id when approval is complete
    
    return {
        "order_id": order_id,
        "callback_id": callback_id,
        "status": "sent_for_approval"
    }


@durable_step
def process_order(step_context: StepContext, order_id: str) -&amp;gt; dict:
    """Processes the order with retry logic for transient failures."""
    step_context.logger.info(f"Processing order: {order_id}")
    # Simulate flaky API that sometimes fails
    if random.random() &amp;gt; 0.4:
        step_context.logger.info("Processing failed, will retry")
        raise Exception("Processing failed")
    return {
        "order_id": order_id,
        "status": "processed",
        "timestamp": "2025-11-27T10:00:00Z",
    }


@durable_execution
def lambda_handler(event: dict, context: DurableContext) -&amp;gt; dict:
    try:
        order_id = event.get("order_id")
        
        # Step 1: Validate the order
        validated = context.step(validate_order(order_id))
        if validated["status"] != "validated":
            raise Exception("Validation failed")  # Terminal error - stops execution
        context.logger.info(f"Order validated: {validated}")
        
        # Step 2: Create callback
        callback = context.create_callback(
            name="awaiting-approval",
            config=CallbackConfig(timeout=Duration.from_minutes(3))
        )
        context.logger.info(f"Created callback with id: {callback.callback_id}")
        
        # Step 3: Send for approval with the callback_id
        approval_request = context.step(send_for_approval(callback.callback_id, order_id))
        context.logger.info(f"Approval request sent: {approval_request}")
        
        # Step 4: Wait for the callback result
        # This blocks until external system calls SendDurableExecutionCallbackSuccess or SendDurableExecutionCallbackFailure
        approval_result = callback.result()
        context.logger.info(f"Approval received: {approval_result}")
        
        # Step 5: Process the order with custom retry strategy
        retry_config = RetryStrategyConfig(max_attempts=3, backoff_rate=2.0)
        processed = context.step(
            process_order(order_id),
            config=StepConfig(retry_strategy=create_retry_strategy(retry_config)),
        )
        if processed["status"] != "processed":
            raise Exception("Processing failed")  # Terminal error
        
        context.logger.info(f"Order successfully processed: {processed}")
        return processed
        
    except Exception as error:
        context.logger.error(f"Error processing order: {error}")
        raise error  # Re-raise to fail the execution
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This code demonstrates several important concepts:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Error handling&lt;/strong&gt;—The try-catch block handles terminal errors. When an unhandled exception is thrown outside of a step (like the validation check), it terminates the execution immediately. This is useful when there’s no point in retrying, such as invalid order data.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Step retries&lt;/strong&gt;—Inside the &lt;code&gt;process_order&lt;/code&gt; step, exceptions trigger automatic retries based on the default (step 1) or configured &lt;code&gt;RetryStrategy&lt;/code&gt; (step 5). This handles transient failures like temporary API unavailability.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Logging&lt;/strong&gt;—I use &lt;code&gt;context.logger&lt;/code&gt; for the main handler and &lt;code&gt;step_context.logger&lt;/code&gt; inside steps. The context logger suppresses duplicate logs during replay.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Now I create a test event with &lt;code&gt;order_id&lt;/code&gt; and invoke the function asynchronously to start the order workflow. I navigate to the &lt;strong&gt;Test&lt;/strong&gt; tab and fill in the optional &lt;strong&gt;Durable execution name&lt;/strong&gt; to identify this execution. Note that, durable functions provides built-in idempotency. If I invoke the function twice with the same execution name, the second invocation returns the existing execution result instead of creating a duplicate.&lt;/p&gt; 
&lt;p&gt;&lt;img loading="lazy" class="aligncenter size-full wp-image-102269" style="border: 1px solid black;padding: 3px" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/28/2025-news-durable-function-rev-8-2.png" alt="" width="1297" height="1257"&gt;&lt;/p&gt; 
&lt;p&gt;I can monitor the execution by navigating to the &lt;strong&gt;Durable executions&lt;/strong&gt; tab in the Lambda console:&lt;/p&gt; 
&lt;p&gt;&lt;img loading="lazy" class="aligncenter wp-image-102325 size-full" style="border: 1px solid black;padding: 3px" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/29/2025-news-durable-function-rev-9-1.png" alt="" width="693" height="624"&gt;&lt;/p&gt; 
&lt;p&gt;Here I can see each step’s status and timing. The execution shows &lt;code&gt;CallbackStarted&lt;/code&gt; followed by &lt;code&gt;InvocationCompleted&lt;/code&gt;, which indicates the function has terminated and execution is suspended to avoid idle charges while waiting for the approval callback.&lt;/p&gt; 
&lt;p&gt;&lt;img loading="lazy" class="aligncenter size-full wp-image-102314" style="border: 1px solid black;padding: 3px" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/29/2025-news-durable-function-rev-3-1-1.png" alt="" width="1397" height="419"&gt;&lt;/p&gt; 
&lt;p&gt;I can now complete the callback directly from the console by choosing &lt;strong&gt;Send success&lt;/strong&gt; or &lt;strong&gt;Send failure&lt;/strong&gt;, or programmatically using the Lambda API.&lt;/p&gt; 
&lt;p&gt;&lt;img loading="lazy" class="aligncenter size-full wp-image-102315" style="border: 1px solid black;padding: 3px" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/29/2025-news-durable-function-rev-3-2.png" alt="" width="1645" height="725"&gt;&lt;/p&gt; 
&lt;p&gt;I choose &lt;strong&gt;Send success&lt;/strong&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;img loading="lazy" class="aligncenter size-full wp-image-102195" style="border: 1px solid black;padding: 3px" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/27/2025-news-durable-function-rev-6.png" alt="" width="1342" height="967"&gt;&lt;/p&gt; 
&lt;p&gt;After the callback completes, the execution resumes and processes the order. If the &lt;code&gt;process_order&lt;/code&gt; step fails due to the simulated flaky API, it automatically retries based on the configured strategy. Once all retries succeed, the execution completes successfully.&lt;/p&gt; 
&lt;p&gt;&lt;img loading="lazy" class="aligncenter size-full wp-image-102316" style="border: 1px solid black;padding: 3px" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/29/2025-news-durable-function-rev-3-3.png" alt="" width="1387" height="834"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="text-decoration: underline"&gt;&lt;strong&gt;Monitoring executions with Amazon EventBridge&lt;br&gt; &lt;/strong&gt;&lt;/span&gt;You can also monitor durable function executions using Amazon EventBridge. Lambda automatically sends execution status change events to the default event bus, allowing you to build downstream workflows, send notifications, or integrate with other AWS services.&lt;/p&gt; 
&lt;p&gt;To receive these events, create an EventBridge rule on the default event bus with this pattern:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "source": ["aws.lambda"],
  "detail-type": ["Durable Execution Status Change"]
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;&lt;span style="text-decoration: underline"&gt;Things to know&lt;br&gt; &lt;/span&gt;&lt;/strong&gt;Here are key points to note:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Availability&lt;/strong&gt;—Lambda durable functions are now available in US East (Ohio) AWS Region. For the latest Region availability, visit the &lt;a href="https://builder.aws.com/build/capabilities/explore?trk=c4ea046f-18ad-4d23-a1ac-cdd1267f942c&amp;amp;sc_channel=el"&gt;AWS Capabilities by Region&lt;/a&gt; page.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Programming language support&lt;/strong&gt;—At launch, AWS Lambda durable functions supports JavaScript/TypeScript (Node.js 22/24) and Python (3.13/3.14). We recommend bundling the durable execution SDK with your function code using your preferred package manager. The SDKs are fast-moving, so you can easily update dependencies as new features become available.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Using Lambda versions&lt;/strong&gt;—When deploying durable functions to production, use Lambda versions to ensure replay always happens on the same code version. If you update your function code while an execution is suspended, replay will use the version that started the execution, preventing inconsistencies from code changes during long-running workflows.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Testing your durable functions&lt;/strong&gt;—You can test durable functions locally without AWS credentials using the separate testing SDK with pytest integration and the &lt;a href="https://aws.amazon.com/serverless/sam/?trk=c4ea046f-18ad-4d23-a1ac-cdd1267f942c&amp;amp;sc_channel=el"&gt;AWS Serverless Application Model (AWS SAM) command line interface (CLI)&lt;/a&gt; for more complex integration testing.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Open source SDKs&lt;/strong&gt;—The durable execution SDKs are open source for &lt;a href="https://github.com/aws/aws-durable-execution-sdk-js"&gt;JavaScript/TypeScript&lt;/a&gt; and &lt;a href="https://github.com/aws/aws-durable-execution-sdk-python"&gt;Python&lt;/a&gt;. You can review the source code, contribute improvements, and stay updated with the latest features.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Pricing&lt;/strong&gt;—To learn more on AWS Lambda durable functions pricing, refer to the &lt;a href="https://aws.amazon.com/lambda/pricing/?trk=c4ea046f-18ad-4d23-a1ac-cdd1267f942c&amp;amp;sc_channel=el"&gt;AWS Lambda pricing&lt;/a&gt; page.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Get started with AWS Lambda durable functions by visiting the &lt;a href="https://console.aws.amazon.com/lambda?trk=c4ea046f-18ad-4d23-a1ac-cdd1267f942c&amp;amp;sc_channel=el"&gt;AWS Lambda console&lt;/a&gt;. To learn more, refer to &lt;a href="https://docs.aws.amazon.com/lambda/latest/dg/durable-functions.html?trk=c4ea046f-18ad-4d23-a1ac-cdd1267f942c&amp;amp;sc_channel=el"&gt;AWS Lambda durable functions&lt;/a&gt; documentation page.&lt;/p&gt; 
&lt;p&gt;Happy building!&lt;/p&gt; 
&lt;p&gt;— &lt;a href="https://www.linkedin.com/in/donnieprakoso"&gt;Donnie&lt;/a&gt;&lt;/p&gt;</content:encoded>
					
					
			
		
		
			</item>
		<item>
		<title>New capabilities to optimize costs and improve scalability on Amazon RDS for SQL Server and Oracle</title>
		<link>https://aws.amazon.com/blogs/aws/amazon-rds-for-oracle-and-rds-for-sql-server-add-new-capabilities-to-enhance-performance-and-optimize-costs/</link>
					
		
		<dc:creator><![CDATA[Matheus Guimaraes]]></dc:creator>
		<pubDate>Tue, 02 Dec 2025 16:09:29 +0000</pubDate>
				<category><![CDATA[Amazon RDS]]></category>
		<category><![CDATA[AWS re:Invent]]></category>
		<category><![CDATA[Database]]></category>
		<category><![CDATA[Launch]]></category>
		<category><![CDATA[RDS for SQL Server]]></category>
		<guid isPermaLink="false">80bde854a021762f63ed56a4e300407c0c0acb72</guid>

					<description>Manage development, testing, and production database workloads more efficiently with new features including Developer Edition support for SQL Server, M7i/R7i instance support with optimize CPU, and expanded storage options up to 256 TiB.</description>
										<content:encoded>&lt;p&gt;Managing database environments demands a balance of resource efficiency and scalability. Organizations need flexible options across their entire database lifecycle, spanning development, testing, and production workloads with diverse storage and compute requirements.&lt;/p&gt; 
&lt;p&gt;To address these needs, we’re announcing four new capabilities for &lt;a href="https://aws.amazon.com/rds/?trk=ac97e39c-d115-4d4a-b3fe-c695e0c9a7ee&amp;amp;sc_channel=el"&gt;Amazon Relational Database Service (Amazon RDS)&lt;/a&gt; to help customers optimize their costs as well as improve efficiency and scalability for their &lt;a href="https://aws.amazon.com/rds/oracle/"&gt;Amazon RDS for Oracle&lt;/a&gt; and &lt;a href="https://aws.amazon.com/rds/sqlserver?trk=ac97e39c-d115-4d4a-b3fe-c695e0c9a7ee&amp;amp;sc_channel=el"&gt;Amazon RDS for SQL Server&lt;/a&gt; databases. These enhancements include SQL Server Developer Edition support and expanded storage capabilities for both RDS for Oracle and RDS for SQL Server. Additionally, you can have CPU optimization options for RDS for SQL Server on M7i and R7i instances, which offer price reductions from previous generation instances and separately billed licensing fees.&lt;/p&gt; 
&lt;p&gt;Let’s explore what’s new.&lt;/p&gt; 
&lt;p&gt;&lt;span style="text-decoration: underline"&gt;&lt;strong&gt;SQL Server Developer Edition support&lt;br&gt; &lt;/strong&gt;&lt;/span&gt;SQL Server Developer Edition is now available on RDS for SQL Server, offering a free SQL Server edition that includes all the Enterprise Edition functionalities. Developer Edition is licensed specifically for non-production workloads, so you can build and test applications without incurring SQL Server licensing costs in your development and testing environments.&lt;/p&gt; 
&lt;p&gt;This release brings significant cost savings to your development and testing environments, while maintaining consistency with your production configurations. You’ll have access to all Enterprise Edition features in your development environment, making it easier to test and validate your applications. Additionally, you’ll benefit from the full suite of Amazon RDS features, including automated backups, software updates, monitoring, and encryption capabilities throughout your development process.&lt;/p&gt; 
&lt;p&gt;To get started, upload your SQL Server binary files to &lt;a href="https://aws.amazon.com/s3?trk=ac97e39c-d115-4d4a-b3fe-c695e0c9a7ee&amp;amp;sc_channel=el"&gt;Amazon Simple Storage Service (Amazon S3)&lt;/a&gt; and use them to create your Developer Edition instance. You can migrate existing data from your Enterprise or Standard Edition instances to Developer Edition instances using built-in SQL Server backup and restore operations.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/28/image-22-5.png"&gt;&lt;img loading="lazy" class="aligncenter size-full wp-image-102267" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/28/image-22-5.png" alt="" width="1069" height="679"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="text-decoration: underline"&gt;&lt;strong&gt;M7i/R7i instances on RDS for SQL Server with support for optimize CPU&lt;br&gt; &lt;/strong&gt;&lt;/span&gt;You can now use M7i and R7i instances on Amazon RDS for SQL Server to achieve several key benefits. These instances offer significant cost savings over previous generation instances. You also get improved transparency over your database costs with licensing fees and Amazon RDS DB instances costs billed separately.&lt;/p&gt; 
&lt;p&gt;RDS for SQL Server M7i/R7i instances offer up to 55% lower costs compared to previous generation instances. &lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/29/Screenshot-2025-11-26-at-20.17.37-1.png"&gt;&lt;img loading="lazy" class="aligncenter size-full wp-image-102340" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/29/Screenshot-2025-11-26-at-20.17.37-1.png" alt="" width="805" height="148"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/29/Screenshot-2025-11-26-at-20.17.44-1.png"&gt;&lt;img loading="lazy" class="aligncenter size-full wp-image-102339" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/29/Screenshot-2025-11-26-at-20.17.44-1.png" alt="" width="804" height="146"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Using the optimize CPU capability on these instances, you can customize the number of vCPUs on license-included RDS for SQL Server instances. This enhancement is particularly valuable for database workloads that require high memory and input/output operations per second (IOPS), but lower vCPU counts&lt;/p&gt; 
&lt;p&gt;This feature provides substantial benefits for your database operations. You can significantly reduce vCPU-based licensing costs while maintaining the same memory and IOPS performance levels your applications require. The capability supports higher memory-to-vCPU ratios and automatically disables hyperthreading while maintaining instance performance. Most importantly, you can fine-tune your CPU settings to precisely match your specific workload requirements, providing optimal resource utilization.&lt;/p&gt; 
&lt;p&gt;To get started, select SQL Server with an M7i or R7i instance type when creating a new database instance. Under &lt;strong&gt;Optimize CPU&lt;/strong&gt; select &lt;strong&gt;Configure the number of vCPUs&lt;/strong&gt; and set your desired vCPU count.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/26/image-42-1.png"&gt;&lt;img loading="lazy" class="aligncenter size-full wp-image-102110" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/26/image-42-1.png" alt="" width="2184" height="572"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="text-decoration: underline"&gt;&lt;strong&gt;Additional storage volumes for RDS for Oracle and SQL Server&lt;br&gt; &lt;/strong&gt;&lt;/span&gt;Amazon RDS for Oracle and Amazon RDS for SQL Server now support up to 256 TiB storage size, a fourfold increase in storage size per database instance, through the addition of up to three additional storage volumes.&lt;/p&gt; 
&lt;p&gt;The additional storage volumes provide extensive flexibility in managing your database storage needs. You can configure your volumes using both io2 and gp3 volumes to create an optimal storage strategy. You can store frequently accessed data on high-performance Provisioned IOPS SSD (io2) volumes while keeping historical data on cost-effective General Purpose SSD (gp3) volumes, which balances performance and cost. For temporary storage needs, such as month-end processing or data imports, you can add storage volumes as needed. After these operations are complete, you can empty the volumes and then remove them to reduce unnecessary storage costs.&lt;/p&gt; 
&lt;p&gt;These storage volumes offer operational flexibility with zero downtime and you can add or remove additional storage volumes without interrupting your database operations. You can also scale up multiple volumes in parallel to quickly meet growing storage demands. For Multi-AZ deployments, all additional storage volumes are automatically replicated to maintain high availability.&lt;/p&gt; 
&lt;p&gt;You can add storage volumes to new or existing database instances through the &lt;a href="https://console.aws.amazon.com/?trk=ac97e39c-d115-4d4a-b3fe-c695e0c9a7ee&amp;amp;sc_channel=el"&gt;AWS Management Console&lt;/a&gt;, &lt;a href="https://aws.amazon.com/cli?trk=ac97e39c-d115-4d4a-b3fe-c695e0c9a7ee&amp;amp;sc_channel=el"&gt;AWS Command Line Interface (AWS CLI)&lt;/a&gt;, or &lt;a href="https://builder.aws.com/build/tools?trk=ac97e39c-d115-4d4a-b3fe-c695e0c9a7ee&amp;amp;sc_channel=el"&gt;AWS SDKs&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Let me show you a quick example. I’ll add a storage volume to an existing RDS for Oracle database instance.&lt;/p&gt; 
&lt;p&gt;First, I navigate to the RDS console, then to my RDS for Oracle database instance detail page. I look under Configuration and I find the &lt;strong&gt;Additional storage volumes &lt;/strong&gt;section.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/25/image-22-4.png"&gt;&lt;img loading="lazy" class="aligncenter size-full wp-image-101915" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/25/image-22-4.png" alt="" width="2266" height="556"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;You can add up to three additional storage volumes and each must be named according to a naming convention. Storage volumes can’t have the same name and you must choose between rdsdbdata2, rdsdbdata3, and rdsdbdata4. For RDS for Oracle database instances, I can add additional storage volumes to the database instance with the primary storage volume size of 200 GiB or higher.&lt;/p&gt; 
&lt;p&gt;I’m going to add two volumes, so I choose &lt;strong&gt;Add additional storage volume&lt;/strong&gt; and then fill in all the required information. I choose &lt;code&gt;rdsdbdata2&lt;/code&gt; as the volume name and give it 12000 GiB of allocated storage with 60000 provisioned IOPS on an io2 storage type. For my second additional storage volume, &lt;code&gt;rdsdbdata3&lt;/code&gt;, I choose to have 2000 GiB on gp3 with 15000 provisioned IOPS.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/25/image-23-3.png"&gt;&lt;img loading="lazy" class="aligncenter size-full wp-image-101934" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/25/image-23-3.png" alt="" width="2712" height="1550"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;After confirmation, I wait for Amazon RDS to process my request and then my additional volumes are available.&lt;/p&gt; 
&lt;p&gt;You can also use the AWS CLI to add volumes during creation of database instances or when modifying them.&lt;/p&gt; 
&lt;p&gt;&lt;span style="text-decoration: underline"&gt;&lt;strong&gt;Things to know&lt;br&gt; &lt;/strong&gt;&lt;/span&gt;These capabilities are now available in all commercial AWS Regions and the &lt;a href="https://aws.amazon.com/govcloud-us?trk=ac97e39c-d115-4d4a-b3fe-c695e0c9a7ee&amp;amp;sc_channel=el"&gt;AWS GovCloud (US)&lt;/a&gt; Regions where Amazon RDS for Oracle and Amazon RDS for SQL Server are offered.&lt;/p&gt; 
&lt;p&gt;You can learn more about each of these capabilities in the Amazon RDS documentation for &lt;a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Welcome.html?trk=ac97e39c-d115-4d4a-b3fe-c695e0c9a7ee&amp;amp;sc_channel=el"&gt;Developer Edition&lt;/a&gt;, &lt;a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/SQLServer.Concepts.General.OptimizeCPU.html"&gt;optimize CPU&lt;/a&gt;, &lt;a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/User_Oracle_AdditionalStorage.html?trk=ac97e39c-d115-4d4a-b3fe-c695e0c9a7ee&amp;amp;sc_channel=el"&gt;additional storage volumes for RDS for Oracle&lt;/a&gt; and &lt;a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Appendix.SQLServer.CommonDBATasks.DatabaseStorage.html?trk=ac97e39c-d115-4d4a-b3fe-c695e0c9a7ee&amp;amp;sc_channel=el"&gt;additional storage volumes for RDS for SQL Server&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;To learn more about the unbundled pricing structure for M7i and R7i instances on RDS for SQL Server, visit the &lt;a href="https://aws.amazon.com/rds/sqlserver/pricing/?trk=ac97e39c-d115-4d4a-b3fe-c695e0c9a7ee&amp;amp;sc_channel=el"&gt;Amazon RDS for SQL Server pricing page&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;To get started with any of these capabilities, go to the &lt;a href="https://console.aws.com/rds?trk=ac97e39c-d115-4d4a-b3fe-c695e0c9a7ee&amp;amp;sc_channel=el"&gt;Amazon RDS console&lt;/a&gt; or learn more by visiting the &lt;a href="https://docs.aws.amazon.com/rds?trk=ac97e39c-d115-4d4a-b3fe-c695e0c9a7ee&amp;amp;sc_channel=el"&gt;Amazon RDS documentation&lt;/a&gt;.&lt;/p&gt;</content:encoded>
					
					
			
		
		
			</item>
		<item>
		<title>Introducing Database Savings Plans for AWS Databases</title>
		<link>https://aws.amazon.com/blogs/aws/introducing-database-savings-plans-for-aws-databases/</link>
					
		
		<dc:creator><![CDATA[Betty Zheng (郑予彬)]]></dc:creator>
		<pubDate>Tue, 02 Dec 2025 16:09:26 +0000</pubDate>
				<category><![CDATA[Announcements]]></category>
		<category><![CDATA[AWS re:Invent]]></category>
		<category><![CDATA[Database]]></category>
		<category><![CDATA[Launch]]></category>
		<category><![CDATA[News]]></category>
		<guid isPermaLink="false">9b15658e48fa13242a4e3943c56d7e286fbe4581</guid>

					<description>New pricing model helps maintain cost efficiency while providing flexibility with database services and deployment options.</description>
										<content:encoded>&lt;p&gt;Since &lt;a href="https://aws.amazon.com/?nc2=h_home"&gt;Amazon Web Services (AWS)&lt;/a&gt; introduced &lt;a href="https://aws.amazon.com/savingsplans/"&gt;Savings Plans&lt;/a&gt;, customers have been able to lower the cost of running sustained workloads while maintaining the flexibility to manage usage across accounts, resource types, and &lt;a href="https://docs.aws.amazon.com/glossary/latest/reference/glos-chap.html#region"&gt;AWS Regions&lt;/a&gt;. Today, we’re extending this flexible pricing model to AWS managed database services with the launch of Database Savings Plans, which help customers reduce database costs by up to 35% when they commit to a consistent amount of usage ($/hour) over a &lt;strong&gt;1-year&lt;/strong&gt; term. Savings automatically apply each hour to eligible usage across supported database services, and any additional usage beyond the commitment is billed at on-demand rates.&lt;/p&gt; 
&lt;p&gt;As organizations build and manage data-driven and AI applications, they often use different database services, engines and deployment types, including instance-based and serverless options, to meet evolving business needs. Database Savings Plans provide the flexibility to choose how workloads run while maintaining cost efficiency. If customers are in the middle of a migration or modernization effort, they can switch database engines and adjust deployment types, such as from provisioned to serverless as part of ongoing cost optimization, while continuing to receive discounted rates. If a customer’s business expands globally, they can also shift usage across AWS Regions and continue to benefit from the same commitment. By applying a consistent hourly commitment, customers can maintain predictable spend even as usage patterns evolve and analyze coverage and utilization using familiar cost management tools.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;u&gt;New Savings Plans&lt;br&gt; &lt;/u&gt;&lt;/strong&gt;Each plan defines where pricing applies, the range of available discounts, and the level of flexibility provided across supported database engines, instance families, sizes, deployment options, or AWS Regions.&lt;/p&gt; 
&lt;p&gt;The hourly commitment automatically applies to all eligible usage regardless of Region, with support for &lt;a href="https://aws.amazon.com/rds/aurora/?nc2=type_a"&gt;Amazon Aurora&lt;/a&gt;, &lt;a href="https://aws.amazon.com/rds/?nc2=type_a"&gt;Amazon Relational Database Service (Amazon RDS)&lt;/a&gt;, &lt;a href="https://aws.amazon.com/dynamodb/?nc2=type_a"&gt;Amazon DynamoDB&lt;/a&gt;, &lt;a href="https://aws.amazon.com/elasticache/?nc2=type_a"&gt;Amazon ElastiCache&lt;/a&gt;, &lt;a href="https://aws.amazon.com/documentdb/?nc2=type_a"&gt;Amazon DocumentDB (with MongoDB compatibility)&lt;/a&gt;, &lt;a href="https://aws.amazon.com/neptune/?nc2=type_a"&gt;Amazon Neptune&lt;/a&gt;, &lt;a href="https://aws.amazon.com/keyspaces/?nc2=type_a"&gt;Amazon Keyspaces (for Apache Cassandra)&lt;/a&gt;, &lt;a href="https://aws.amazon.com/timestream/?nc2=type_a"&gt;Amazon Timestream&lt;/a&gt;, and &lt;a href="https://aws.amazon.com/dms/?nc2=type_a"&gt;AWS Database Migration Service (AWS DMS)&lt;/a&gt;. As new eligible database offerings, instance types, or Regions become available, Savings Plans will automatically apply to that usage.&lt;/p&gt; 
&lt;p&gt;Discounts vary by deployment model and service type. Serverless deployments provide up to 35% savings compared to on-demand rates. Provisioned instances across supported database services deliver up to 20% savings. For Amazon DynamoDB and Amazon Keyspaces, on-demand throughput workloads receive up to 18% savings, and provisioned capacity offers up to 12%. Together, these savings help customers optimize costs while maintaining consistent coverage for database usage. To learn more about the pricing and eligible usage, visit the &lt;a href="https://aws.amazon.com/savingsplans/database-pricing/"&gt;Database Savings Plans pricing page&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;u&gt;Purchasing Database Savings Plans&lt;br&gt; &lt;/u&gt;&lt;/strong&gt;&lt;a href="https://aws.amazon.com/aws-cost-management/aws-cost-explorer/?nc2=type_a"&gt;AWS Billing and Cost Management Console&lt;/a&gt; helps you choose Savings Plans and guides you through the purchase process. You can get started from the &lt;a href="https://aws.amazon.com/console/?nc2=type_a"&gt;AWS Management Console&lt;/a&gt; or use the &lt;a href="https://aws.amazon.com/cli/"&gt;AWS Command Line Interface (AWS CLI)&lt;/a&gt; and the API. There are two ways to evaluate Database Savings Plans purchases, in the Recommendations view and in the Purchase Analyzer.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Recommendations&lt;/strong&gt; – are automatically generated from your recent on-demand usage. To reach the Recommendations view in the &lt;a href="https://console.aws.amazon.com/cost-reports/home?region=us-east-1#/dashboard"&gt;&lt;strong&gt;Billing and Cost Management console&lt;/strong&gt;&lt;/a&gt;, choose &lt;strong&gt;Savings and Commitments&lt;/strong&gt;, &lt;strong&gt;Savings Plans&lt;/strong&gt;, and &lt;strong&gt;Recommendations &lt;/strong&gt;in the navigation pane. In the &lt;strong&gt;Recommendations&lt;/strong&gt; view, select &lt;strong&gt;Database Savings Plans &lt;/strong&gt;and configure the &lt;strong&gt;Recommendation options&lt;/strong&gt;. AWS Savings Plans recommendations analyze your historical on-demand usage to identify the hourly commitment that delivers the highest overall savings.&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/15/recommendation-1.png"&gt;&lt;img loading="lazy" class="aligncenter size-full wp-image-101049" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/15/recommendation-1.png" alt="" width="3006" height="990"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;The Purchase Analyzer &lt;/strong&gt;– is designed for modeling custom commitment levels. If you want to purchase a different amount than the recommended commitment on the&lt;strong&gt; Purchase Analyzer &lt;/strong&gt;page, select &lt;strong&gt;Database Savings Plans&lt;/strong&gt; and configure &lt;strong&gt;Lookback period&lt;/strong&gt; and &lt;strong&gt;Hourly commitment&lt;/strong&gt; to simulate alternative commitment levels and see the projected impact on &lt;strong&gt;Cost&lt;/strong&gt;, &lt;strong&gt;Coverage&lt;/strong&gt;, and &lt;strong&gt;Utilization&lt;/strong&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/20/image-1-17.png"&gt;&lt;img loading="lazy" class="aligncenter size-full wp-image-101457" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/20/image-1-17.png" alt="" width="1206" height="970"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;This way is preferred if your purchasing strategy includes smaller, incremental commitments over time or if you expect future usage changes that could affect your ideal purchase amount.&lt;/p&gt; 
&lt;p&gt;After reviewing the recommendations or running simulations in Savings Plans Recommendations or Savings Plans Purchase Analyzer, choose &lt;strong&gt;Add to cart&lt;/strong&gt; to proceed with your chosen commitment. If you prefer to purchase directly, you can also navigate to the &lt;strong&gt;Purchase Savings Plans &lt;/strong&gt;page. The console updates estimated discounts and coverage in real time as you adjust each setting, so you can evaluate the impact before completing your order.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/20/purchase-savings-plans.png"&gt;&lt;img loading="lazy" class="aligncenter size-full wp-image-101459" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/20/purchase-savings-plans.png" alt="" width="2876" height="1222"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;You can learn more about how to choose and purchase Database Saving Plans by visiting the &lt;a href="https://docs.aws.amazon.com/savingsplans/latest/userguide/what-is-savings-plans.html"&gt;Savings Plans User Guide&lt;/a&gt; documents.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;u&gt;Now available&lt;br&gt; &lt;/u&gt;&lt;/strong&gt;Database Savings Plans are available in all AWS Regions outside of China. Give them a try and start shaping your database strategy with more flexibility and predictable costs.&lt;/p&gt; 
&lt;p&gt;–&amp;nbsp;&lt;a href="https://www.linkedin.com/in/zhengyubin714/"&gt;Betty&lt;/a&gt;&lt;/p&gt;</content:encoded>
					
					
			
		
		
			</item>
		<item>
		<title>Amazon CloudWatch introduces unified data management and analytics for operations, security, and compliance</title>
		<link>https://aws.amazon.com/blogs/aws/amazon-cloudwatch-introduces-unified-data-management-and-analytics-for-operations-security-and-compliance/</link>
					
		
		<dc:creator><![CDATA[Channy Yun (윤석찬)]]></dc:creator>
		<pubDate>Tue, 02 Dec 2025 16:07:11 +0000</pubDate>
				<category><![CDATA[Amazon CloudWatch]]></category>
		<category><![CDATA[AWS re:Invent]]></category>
		<category><![CDATA[Events]]></category>
		<category><![CDATA[Launch]]></category>
		<category><![CDATA[Management Tools]]></category>
		<category><![CDATA[News]]></category>
		<guid isPermaLink="false">9ecd3d21b2fbf221f45a766e4cfddc11f2f0c46c</guid>

					<description>Reduce data management complexity and costs with automatic normalization across sources, native analytics integration, and built-in support for industry-standard formats like OCSF and Apache Iceberg.</description>
										<content:encoded>&lt;p&gt;Today we’re expanding &lt;a href="https://aws.amazon.com/cloudwatch/"&gt;Amazon CloudWatch&lt;/a&gt; capabilities to unify and manage log data across operational, security, and compliance use cases with flexible and powerful analytics in one place and with reduced data duplication and costs.&lt;/p&gt; 
&lt;p&gt;This enhancement means that CloudWatch can automatically normalize and process data to offer consistency across sources with built-in support for &lt;a href="https://docs.aws.amazon.com/security-lake/latest/userguide/open-cybersecurity-schema-framework.html"&gt;Open Cybersecurity Schema Framework (OCSF)&lt;/a&gt; and &lt;a href="https://opentelemetry.io/"&gt;Open Telemetry (OTel)&lt;/a&gt; formats, so you can focus on analytics and insights. CloudWatch also introduces Apache Iceberg compatible access to your data through &lt;a href="https://aws.amazon.com/s3/features/tables/"&gt;Amazon Simple Storage Service (Amazon S3) Tables&lt;/a&gt;, so that you can run analytics, not only locally but also using &lt;a href="https://aws.amazon.com/athena"&gt;Amazon Athena&lt;/a&gt;, &lt;a href="https://aws.amazon.com/sagemaker/unified-studio/"&gt;Amazon SageMaker Unified Studio&lt;/a&gt;, or any other Iceberg-compatible tool.&lt;/p&gt; 
&lt;p&gt;You can also correlate your operational data in CloudWatch with other business data from your preferred tools to correlate with other data. This unified approach streamlines management and provides comprehensive correlation across security, operational, and business use cases.&lt;/p&gt; 
&lt;p&gt;Here are the detailed enhancements:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Streamline data ingestion and normalization&lt;/strong&gt; – CloudWatch automatically collects AWS vended logs across accounts and AWS Regions, integrating with &lt;a href="https://aws.amazon.com/organizations/"&gt;AWS Organizations&lt;/a&gt; from AWS services including &lt;a href="https://aws.amazon.com/cloudtrail/"&gt;AWS CloudTrail,&lt;/a&gt; &lt;a href="https://aws.amazon.com/vpc/"&gt;Amazon Virtual Private Cloud (Amazon VPC)&lt;/a&gt; Flow Logs, &lt;a href="https://aws.amazon.com/waf"&gt;AWS WAF&lt;/a&gt; access logs, &lt;a href="https://aws.amazon.com/route53"&gt;Amazon Route 53&lt;/a&gt; resolver logs, and pre-built connectors for third-party sources such as endpoint (CrowdStrike, SentinelOne), identity (Okta, Entra ID), cloud security (Wiz), network security (Zscaler, Palo Alto Networks), productivity and collaboration (Microsoft Office 365, Windows Event Logs, and GitHub), along with IT service manager with ServiceNow CMDB. To normalize and process your data as they are being ingested, CloudWatch offers managed OCSF conversion for various AWS and third-party data sources and other processors such as Grok for custom parsing, field-level operations, and string manipulations.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Reduce costly log data management&lt;/strong&gt; – CloudWatch consolidates log management into a single service with built-in governance capabilities without storing and maintaining multiple copies of the same data across different tools and data stores. The unified data store of CloudWatch eliminates the need for complex ETL pipelines and reduces your operational costs and management overhead needed to maintain multiple separate data stores and tools.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Discover business insights from log data&lt;/strong&gt; – You can run queries in CloudWatch using natural language queries and popular query languages such as LogsQL, PPL, and SQL through a single interface, or query your data using your preferred analytics tools through Apache Iceberg-compatible tables. The new Facets interface gives you intuitive filtering by source, application, account, region, and log type, which you can use to run queries across log groups of multiple AWS accounts and Regions with intelligent parameter inference.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;In the next sections we explore the new log management and analytics features of the CloudWatch Logs!&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;1. Data discovery and management by data sources and types&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;You can see a high-level overview of logs and all data sources with a new Logs Management View in the CloudWatch console. To get started, go to the &lt;a href="https://console.aws.amazon.com/cloudwatch/home"&gt;CloudWatch console&lt;/a&gt; and choose &lt;strong&gt;Log Management&lt;/strong&gt; under the &lt;strong&gt;Logs&lt;/strong&gt; menu in the left navigation pane. In the &lt;strong&gt;Summary&lt;/strong&gt; tab, you can observe your logs data sources and types, insights into how your log groups are doing across ingestion, and anomalies.&lt;/p&gt; 
&lt;p&gt;&lt;img loading="lazy" class="aligncenter wp-image-101615 size-full" style="border: solid 1px #ccc" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/21/2025-cloudwatch-log-1-data-management-overview-1-1.png" alt="" width="2554" height="1833"&gt;&lt;/p&gt; 
&lt;p&gt;Choose the &lt;strong&gt;Data sources&lt;/strong&gt; tab to find and manage your log data by data sources, types, and fields. CloudWatch ingests and automatically categorizes data sources by AWS services, third-party, or custom sources such as application logs.&lt;/p&gt; 
&lt;p&gt;&lt;img loading="lazy" class="aligncenter wp-image-102561 size-full" style="border: solid 1px #ccc" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/12/02/2025-cloudwatch-log-management-2-data-sources-2-1.png" alt="" width="2428" height="1675"&gt;&lt;/p&gt; 
&lt;p&gt;Choose the &lt;strong&gt;Data source actions&lt;/strong&gt; to integrate S3 Tables to make future logs for selected data sources. You have the flexibility to analyze the logs through Athena and Amazon Redshift and other query engines such as Spark using Iceberg compatible access patterns. With this integration, logs from CloudWatch are available in a read-only &lt;code&gt;aws-cloudwatch&lt;/code&gt; S3 Tables bucket.&lt;/p&gt; 
&lt;p&gt;When you choose a specific data source such as CloudTrail data, you can view the details of the data source that includes information regarding data format, pipeline, facets/field indexes, S3 Tables association, and the number of logs with that data source. You can observe all log groups included in this data source and type and edit a source/type field index policy using the new schema support.&lt;/p&gt; 
&lt;p&gt;&lt;img loading="lazy" class="aligncenter wp-image-102254 size-full" style="border: solid 1px #ccc" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/28/2025-cloudwatch-log-management-3-data-sources-detail-2.png" alt="" width="2294" height="1370"&gt;&lt;/p&gt; 
&lt;p&gt;To learn more about how to manage your data sources and index policy, visit &lt;a href="https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/data-sources.html?trk=769a1a2b-8c19-4976-9c45-b6b1226c7d20&amp;amp;sc_channel=el"&gt;Data sources&lt;/a&gt; in the Amazon CloudWatch Logs User Guide.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2. Ingestion and transformation using CloudWatch pipelines&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;You can create pipelines to streamline collecting, transforming, and routing telemetry and security data while standardizing data formats to optimize observability and security data management. The new pipeline feature of CloudWatch connects data from a catalogue of data sources, so that you can add and configure pipeline processors from a library to parse, enrich, and standardize data.&lt;/p&gt; 
&lt;p&gt;&lt;img loading="lazy" class="aligncenter wp-image-102253 size-full" style="border: solid 1px #ccc" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/28/2025-cloudwatch-log-management-4-pipeline-list-1.jpg" alt="" width="2064" height="466"&gt;&lt;/p&gt; 
&lt;p&gt;In the &lt;strong&gt;Pipeline&lt;/strong&gt; tab, choose &lt;strong&gt;Add pipeline&lt;/strong&gt;. It shows you the pipeline configuration wizard. This wizard guides you through five steps where you can choose the data source and other source details such as log source types, configure destination, configure up to 19 processors to perform an action on your data (such as filtering, transforming, or enriching), and finally review and deploy the pipeline.&lt;/p&gt; 
&lt;p&gt;&lt;img loading="lazy" class="aligncenter wp-image-101618 size-full" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/21/2025-cloudwatch-log-management-4-pipeline-wizards.jpg" alt="" width="2560" height="1022"&gt;&lt;/p&gt; 
&lt;p&gt;You also have the option to create pipelines through the new &lt;strong&gt;Ingestion&lt;/strong&gt; experience in CloudWatch. To learn more about how to set up and manage the pipelines, visit &lt;a href="https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/cloudwatch-pipelines.html?trk=769a1a2b-8c19-4976-9c45-b6b1226c7d20&amp;amp;sc_channel=el"&gt;Pipelines&lt;/a&gt; in the Amazon CloudWatch Logs User Guide.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;3. Enhanced analytics and querying based on data sources&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;You can enhance analytics with support for Facets and querying based on data sources. Facets enable interactive exploration and drill-down into logs and their values are automatically extracted based on the selected time period.&lt;/p&gt; 
&lt;p&gt;Choose the &lt;strong&gt;Facets&lt;/strong&gt; tab in the&amp;nbsp;&lt;strong&gt;Log Insights&lt;/strong&gt; under the &lt;strong&gt;Logs&lt;/strong&gt; menu in the left navigation pane. You can view available facets and values that appear in the panel. Choose one or more facets and values to interactively explore your data. I choose Facets regarding a VPC Flow Logs group and action, query to list the five most frequent patterns in my VPC Flow Logs through the AI query generator, and get the result patterns.&lt;/p&gt; 
&lt;p&gt;&lt;img loading="lazy" class="aligncenter size-full wp-image-100830" style="border: solid 1px #ccc" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/12/2025-cloudwatch-log-management-5-log-insights.png" alt="" width="2854" height="2287"&gt;&lt;/p&gt; 
&lt;p&gt;You can save your query with the selected Facets and values that you have specified. When you next choose your saved query, the logs to be queried have the pre-specified facets and values. To learn more about Facet management, visit &lt;a href="https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/CloudWatchLogs-Facets.html?trk=769a1a2b-8c19-4976-9c45-b6b1226c7d20&amp;amp;sc_channel=el"&gt;Facets&lt;/a&gt; in the CloudWatch Logs User Guide.&lt;/p&gt; 
&lt;p&gt;As I previously noted, you can integrate data sources into S3 Tables and query together. For example, using a Query Editor in Athena, you can query correlates network traffic with AWS API activity from a specific IP range (&lt;code&gt;174.163.137.*&lt;/code&gt;) by joining VPC Flow Logs with CloudTrail logs based on matching source IP addresses.&lt;/p&gt; 
&lt;p&gt;&lt;img loading="lazy" class="aligncenter size-full wp-image-101642" style="border: solid 1px #ccc" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/22/2025-cloudwatch-log-management-5-log-insights-athena.png" alt="" width="2514" height="2234"&gt;&lt;/p&gt; 
&lt;p&gt;This type of integrated search is particularly valuable for security monitoring, incident investigation, and suspicious behavior detection. You can view if an IP that’s making network connections is also performing sensitive AWS operations such as creating users, modifying security groups, or accessing data.&lt;/p&gt; 
&lt;p&gt;To learn more, visit &lt;a href="https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/s3-tables-integration.html?trk=769a1a2b-8c19-4976-9c45-b6b1226c7d20&amp;amp;sc_channel=el"&gt;S3 Tables integration with CloudWatch&lt;/a&gt; in the CloudWatch Logs User Guide.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;u&gt;Now available&lt;/u&gt;&lt;/strong&gt;&lt;br&gt; New log management features of Amazon CloudWatch are available today in all AWS Regions except the AWS GovCloud (US) Regions and China Regions. For Regional availability and future roadmap, visit the &lt;a class="c-link" href="https://builder.aws.com/capabilities/?trk=769a1a2b-8c19-4976-9c45-b6b1226c7d20&amp;amp;sc_channel=el" target="_blank" rel="noopener noreferrer" data-stringify-link="https://builder.aws.com/capabilities/" data-sk="tooltip_parent"&gt;AWS Capabilities by Region&lt;/a&gt;. There are no upfront commitments or minimum fees, and you pay for the usage of existing CloudWatch Logs for data ingestion, storage, and queries. To learn more, visit the &lt;a href="https://aws.amazon.com/cloudwatch/pricing/?trk=769a1a2b-8c19-4976-9c45-b6b1226c7d20&amp;amp;sc_channel=el"&gt;CloudWatch pricing page&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Give it a try in the &lt;a href="https://console.aws.amazon.com/cloudwatch/?trk=769a1a2b-8c19-4976-9c45-b6b1226c7d20&amp;amp;sc_channel=el"&gt;CloudWatch console&lt;/a&gt;. To learn more, visit the &lt;a href="https://aws.amazon.com/cloudwatch/features/unified-data-and-telemetry/"&gt;CloudWatch product page&lt;/a&gt; and send feedback to &lt;a href="https://repost.aws/tags/TAK9UOZOiFRI2NrXQ-VpOPfQ/amazon-cloudwatch-logs?trk=769a1a2b-8c19-4976-9c45-b6b1226c7d20&amp;amp;sc_channel=el"&gt;AWS re:Post for CloudWatch Logs&lt;/a&gt; or through your usual AWS Support contacts.&lt;/p&gt; 
&lt;p&gt;— &lt;a href="https://linkedin.com/in/channy/"&gt;Channy&lt;/a&gt;&lt;/p&gt;</content:encoded>
					
					
			
		
		
			</item>
		<item>
		<title>New and enhanced AWS Support plans add AI capabilities to expert guidance</title>
		<link>https://aws.amazon.com/blogs/aws/new-and-enhanced-aws-support-plans-add-ai-capabilities-to-expert-guidance/</link>
					
		
		<dc:creator><![CDATA[Matheus Guimaraes]]></dc:creator>
		<pubDate>Tue, 02 Dec 2025 16:07:03 +0000</pubDate>
				<category><![CDATA[AWS re:Invent]]></category>
		<category><![CDATA[AWS Support]]></category>
		<category><![CDATA[News]]></category>
		<guid isPermaLink="false">3a33abdc4b936ac0aa0676f95f0e7b5293edecc7</guid>

					<description>Prevent cloud infrastructure issues before they impact your business with AWS Support plans that combine AI-powered insights with expert guidance, offering faster response times and proactive monitoring across performance, security, and cost dimensions.</description>
										<content:encoded>&lt;p&gt;Today, we’re announcing a fundamental shift in how &lt;a href="https://aws.amazon.com/premiumsupport/?trk=ac97e39c-d115-4d4a-b3fe-c695e0c9a7ee&amp;amp;sc_channel=el"&gt;AWS Support&lt;/a&gt; helps customers move from reactive problem-solving to proactive issue prevention. This evolution introduces new Support plans that combine AI-powered capabilities with &lt;a href="https://aws.amazon.com/?trk=ac97e39c-d115-4d4a-b3fe-c695e0c9a7ee&amp;amp;sc_channel=el"&gt;Amazon Web Services (AWS)&lt;/a&gt; expertise. The new and enhanced plans help you identify and address potential issues before they impact your business operations, helping you to operate and optimize your cloud workloads more effectively.&lt;/p&gt; 
&lt;p&gt;The portfolio includes three plans designed to match different operational needs. Each plan offers distinct capabilities, with higher tiers including all the capabilities of lower tiers plus additional features and enhanced service levels. Let’s have a look at them.&lt;/p&gt; 
&lt;p&gt;&lt;span style="text-decoration: underline"&gt;&lt;strong&gt;New and enhanced AWS Support paid plans&lt;br&gt; &lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;Business Support+ &lt;/strong&gt;transforms the developer, startup, and small business experience by providing intelligent assistance powered by AI. You can choose to engage directly with AWS experts or start with AI-powered contextual recommendations that seamlessly transition to AWS experts when needed. AWS experts respond within 30 minutes for critical cases (twice as fast as before), maintaining previous context and saving you from having to repeat yourself.&lt;/p&gt; 
&lt;p&gt;With a low-cost monthly subscription, this plan delivers advanced operational capabilities through a combination of AI-powered tools and AWS expertise. The plan provides personalized recommendations to help optimize your workloads based on your specific environment, while maintaining seamless access to AWS experts for technical support when needed.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Enterprise Support &lt;/strong&gt;builds on our established support model, this tier accelerates innovation and cloud operations success through intelligent operations and AI-powered trusted human guidance. Your designated technical account manager (TAM) combines deep AWS knowledge with data-driven insights from your environment to help identify optimization opportunities and potential risks before they impact your operations. The plan also offers access to AWS Security Incident Response at no additional fee, a comprehensive service that centralizes tracking, storage, and management of security events while providing automated monitoring and investigation capabilities to strengthen your security posture.&lt;/p&gt; 
&lt;p&gt;Through AI-powered assistance and continuous monitoring of your AWS environment, this tier helps you achieve new levels of scale in your operations. With up to 15-minute response times for production-critical issues and support engineers who receive personalized context delivered by AI agents, this tier enables faster and more personalized resolution while maintaining operational excellence. Additionally, you also get access to interactive programs and hands-on workshops to foster continuous technical growth.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Unified Operations Support &lt;/strong&gt;delivers our highest level of context-aware Support through an expanded team of AWS experts. Your core team comprised of a Technical Account Manager, a Domain Engineer, and a designated Senior Billing and Account Specialist is complemented by on-demand experts in migration, incident management, and security. These designated experts understand your unique environment and operational history, providing guidance through your preferred collaboration channels while combining their architectural knowledge with AI-powered insights.&lt;/p&gt; 
&lt;p&gt;Through comprehensive around-the-clock monitoring and AI-powered automation, this tier strengthens your mission-critical operations with proactive risk identification and contextual guidance. When critical incidents occur, you receive 5-minute response times with technical recommendations provided by Support engineers who understand your workloads. The team conducts systematic application reviews, helps validate operational readiness, and supports business-critical events, which means you can focus on innovation while maintaining the highest levels of operational excellence.&lt;/p&gt; 
&lt;p&gt;&lt;span style="text-decoration: underline"&gt;&lt;strong&gt;Transforming your cloud operations&lt;/strong&gt;&lt;/span&gt;&lt;br&gt; AWS Support is evolving to help you build, operate, and optimize your cloud infrastructure more effectively. We maintain context of your account’s support history, configuration, and previous cases, so our AI-powered capabilities and AWS experts can deliver more relevant and effective solutions tailored to your specific environment.&lt;/p&gt; 
&lt;p&gt;Support plan capabilities will continuously evolve to add comprehensive visibility into your infrastructure, delivering actionable insights across performance, security, and cost dimensions with clear evaluation of business impact and cost benefits. This combination of AI-powered tools and AWS expertise represents a fundamental shift from reactive to proactive operations, helping you prevent issues before they impact your business.&lt;/p&gt; 
&lt;p&gt;Subscribers of AWS Developer Support, AWS Business Support (classic), and AWS Enterprise On-Ramp Support plans can continue to receive their current level of support through January 1, 2027. You can transition to one of the new and enhanced plans at any time before then by visiting the AWS Management Console or by reaching out to your AWS account team. Customers subscribed to AWS Enterprise Support can begin using the new features of this plan at any time.&lt;/p&gt; 
&lt;p&gt;&lt;span style="text-decoration: underline"&gt;&lt;strong&gt;Things to know&lt;br&gt; &lt;/strong&gt;&lt;/span&gt;Business Support+, Enterprise Support, and Unified Operations are available in all commercial AWS Regions. Existing customers can continue their current plans or explore the new offerings for enhanced performance and efficiency.&lt;/p&gt; 
&lt;p&gt;Business Support+ starts at $29 per month, a 71% savings over the previous Business Support monthly minimum. Enterprise Support starts at $5,000 per month, a 67% savings over the previous Enterprise Support minimum price. Unified Operations, designed for organizations with mission-critical workloads and including a designated team of AWS experts, starts at $50,000 a month. All new Support plans use pricing tiers, which rewards higher usage with lower marginal prices for Support.&lt;/p&gt; 
&lt;p&gt;For critical cases, AWS Support provides different target response times across the plans. Business Support+ offers a 30-minute response time, Enterprise Support responds within 15 minutes, and Unified Operations Support delivers the fastest response time at 5 minutes.&lt;/p&gt; 
&lt;p&gt;To learn more about AWS Support plans and features, visit the &lt;a href="https://aws.amazon.com/premiumsupport?trk=ac97e39c-d115-4d4a-b3fe-c695e0c9a7ee&amp;amp;sc_channel=el"&gt;AWS Support page&lt;/a&gt; or sign in to the &lt;a href="https://console.aws.amazon.com?trk=ac97e39c-d115-4d4a-b3fe-c695e0c9a7ee&amp;amp;sc_channel=el"&gt;AWS Management Console&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;For hands-on guidance with AWS Support features, schedule a consultation with your account team.&lt;/p&gt;</content:encoded>
					
					
			
		
		
			</item>
		<item>
		<title>Amazon OpenSearch Service improves vector database performance and cost with GPU acceleration and auto-optimization</title>
		<link>https://aws.amazon.com/blogs/aws/amazon-opensearch-service-improves-vector-database-performance-and-cost-with-gpu-acceleration-and-auto-optimization/</link>
					
		
		<dc:creator><![CDATA[Channy Yun (윤석찬)]]></dc:creator>
		<pubDate>Tue, 02 Dec 2025 16:06:41 +0000</pubDate>
				<category><![CDATA[Amazon OpenSearch Service]]></category>
		<category><![CDATA[Analytics]]></category>
		<category><![CDATA[AWS re:Invent]]></category>
		<category><![CDATA[Launch]]></category>
		<category><![CDATA[News]]></category>
		<guid isPermaLink="false">7d16b5a9bfc90793652375d019f63b6ef02ccd65</guid>

					<description>Build and optimize large-scale vector databases up to 10 times faster and at a quarter of the cost with new GPU acceleration and auto-optimization capabilities that automatically balance search quality, speed, and resource usage.</description>
										<content:encoded>&lt;p&gt;Today we’re announcing serverless GPU acceleration and auto-optimization for vector index in &lt;a href="https://aws.amazon.com/opensearch-service/"&gt;Amazon OpenSearch Service&lt;/a&gt; that helps you build large-scale vector databases faster with lower costs and automatically optimize vector indexes for optimal trade-offs between search quality, speed, and cost.&lt;/p&gt; 
&lt;p&gt;Here are the new capabilities introduced today:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;GPU acceleration&lt;/strong&gt; – You can build vector databases up to 10 times faster at a quarter of the indexing cost when compared to non-GPU acceleration, and you can create billion-scale vector databases in under an hour.&amp;nbsp;With significant gains in cost saving and speed, you get an advantage in time-to-market, innovation velocity, and adoption of vector search at scale.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Auto-optimization&lt;/strong&gt; – You can find the best balance between search latency, quality, and memory requirements for your vector field without needing vector expertise. This optimization helps you achieve better cost-savings and recall rates when compared to default index configurations, while manual index tuning can take weeks to complete.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p data-pm-slice="1 1 []"&gt;You can use these capabilities to build vector databases faster and more cost-effectively on OpenSearch Service. You can use them to power generative AI applications, search product catalogs and knowledge bases, and more. You can enable GPU acceleration and auto-optimization when you create a new OpenSearch domain or collection, as well as update an existing domain or collection.&lt;/p&gt; 
&lt;p&gt;Let’s go through how it works!&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;u&gt;GPU acceleration for vector index&lt;/u&gt;&lt;/strong&gt;&lt;br&gt; When you enable GPU acceleration on your OpenSearch Service domain or Serverless collection, OpenSearch Service automatically detects opportunities to accelerate your vector indexing workloads. This acceleration helps build the vector data structures in your OpenSearch Service domain or Serverless collection.&lt;/p&gt; 
&lt;p&gt;You don’t need to provision the GPU instances, manage their usage or pay for idle time. OpenSearch Service securely isolates your accelerated workloads to your domain’s or collection’s &lt;a href="https://aws.amazon.com/vpc"&gt;Amazon Virtual Private Cloud (Amazon VPC)&lt;/a&gt; within your account. You pay only for useful processing through the OpenSearch Compute Units (OCU) – Vector Acceleration pricing.&lt;/p&gt; 
&lt;p&gt;To enable GPU acceleration, go to the &lt;a href="https://console.aws.amazon.com/aos/home"&gt;OpenSearch Service console&lt;/a&gt; and choose &lt;strong&gt;Enable GPU Acceleration&lt;/strong&gt; in the &lt;strong&gt;Advanced features&lt;/strong&gt; section when you create or update your OpenSearch Service domain or Serverless collection.&lt;/p&gt; 
&lt;p&gt;&lt;img loading="lazy" class="aligncenter size-full wp-image-100952" style="border: solid 1px #ccc" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/14/2025-opensearch-gpu-accel-auto-tune-1-gpu-setting.jpg" alt="" width="2238" height="960"&gt;&lt;/p&gt; 
&lt;p&gt;You can use the following &lt;a href="https://aws.amazon.com/cli"&gt;AWS Command Line Interface (AWS CLI)&lt;/a&gt; command to enable GPU acceleration for an existing OpenSearch Service domain.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="lang-bash"&gt;$ aws opensearch update-domain-config \
    --domain-name my-domain \
    --aiml-options '{"ServerlessVectorAcceleration": {"Enabled": true}}'
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can create a vector index optimized for GPU processing. This example index stores 768-dimensional vectors for text embeddings by enabling &lt;code&gt;index.knn.remote_index_build.enabled&lt;/code&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="lang-json"&gt;PUT my-vector-index
{
    "settings": {
        "index.knn": true,
        "index.knn.remote_index_build.enabled": true
    },
    "mappings": {
        "properties": {
        "vector_field": {
        "type": "knn_vector",
        "dimension": 768,
      },
      "text": {
        "type": "text"
      }
    }
  }
}&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Now you can add vector data and optimize your index using standard OpenSearch Service operations using the bulk API. The GPU acceleration is automatically applied to indexing and force-merge operations.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="lang-json"&gt;POST my-vector-index/_bulk
{"index": {"_id": "1"}}
{"vector_field": [0.1, 0.2, 0.3, ...], "text": "Sample document 1"}
{"index": {"_id": "2"}}
{"vector_field": [0.4, 0.5, 0.6, ...], "text": "Sample document 2"}&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;We ran index build benchmarks and observed speed gains from GPU acceleration ranging between 6.4 to 13.8 times. Stay tuned for more benchmarks and further details in upcoming posts.&lt;/p&gt; 
&lt;p&gt;&lt;img loading="lazy" class="aligncenter size-full wp-image-101751" style="width: 80%" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/24/2025-opensearchservice-gpu-acceralation-benchmark.png" alt="" width="1000" height="600"&gt;&lt;/p&gt; 
&lt;p&gt;To learn more, visit &lt;a href="https://docs.aws.amazon.com/opensearch-service/latest/developerguide/gpu-acceleration-vector-index.html"&gt;GPU acceleration for vector indexing&lt;/a&gt; in the Amazon OpenSearch Service Developer Guide.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;u&gt;Auto-optimizing vector databases&lt;/u&gt;&lt;/strong&gt;&lt;br&gt; You can use the new vector ingestion feature to ingest documents from &lt;a href="https://aws.amazon.com/s3"&gt;Amazon Simple Storage Service (Amazon S3)&lt;/a&gt;, generate vector embeddings, optimize indexes automatically, and build large-scale vector indexes in minutes. During the ingestion, auto-optimization generates recommendations based on your vector fields and indexes of your OpenSearch Service domain or Serverless collection. You can choose one of these recommendations to quickly ingest and index your vector dataset instead of manually configuring these mappings.&lt;/p&gt; 
&lt;p&gt;To get started, choose &lt;strong&gt;Vector ingestion&lt;/strong&gt; under the &lt;strong&gt;Ingestion&lt;/strong&gt; menu in the left navigation pane of &lt;a href="https://console.aws.amazon.com/aos/home"&gt;OpenSearch Service console&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;img loading="lazy" class="aligncenter size-full wp-image-101470" style="border: solid 1px #ccc" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/20/2025-opensearch-service-auto-optimize-1.png" alt="" width="2342" height="1286"&gt;&lt;/p&gt; 
&lt;p&gt;You can create a new vector ingestion job with the following steps:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Prepare dataset&lt;/strong&gt; – Prepare OpenSearch Service parquet documents in an S3 bucket and choose a domain or collection for your destination.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Configure index and automate optimizations&lt;/strong&gt; – Auto-optimize your vector fields or manually configure them.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Ingest and accelerate indexing&lt;/strong&gt; – Use OpenSearch ingestion pipelines to load data from Amazon S3 into OpenSearch Service. Build large vector indexes up to 10 times faster at a quarter of the cost.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;In &lt;strong&gt;Step 2&lt;/strong&gt;, configure your vector index with auto-optimize vector field. Auto-optimize is currently limited to one vector field. Further index mappings can be input after the auto-optimization job has completed.&lt;/p&gt; 
&lt;p&gt;&lt;img loading="lazy" class="aligncenter wp-image-101471 size-full" style="border: solid 1px #ccc" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/20/2025-opensearch-service-auto-optimize-3.png" alt="" width="2266" height="1679"&gt;&lt;/p&gt; 
&lt;p&gt;Your vector field optimization settings depend on your use case. For example, if you need high search quality (recall rate) and don’t need faster responses, then choose &lt;strong&gt;Modest&lt;/strong&gt; for the &lt;strong&gt;Latency requirements (p90)&lt;/strong&gt; and more than or equal to &lt;strong&gt;0.9&lt;/strong&gt; for the &lt;strong&gt;Acceptable search quality (recall)&lt;/strong&gt;. When you create a job, it starts to ingest vector data and auto-optimize vector index. The processing time depends on the vector dimensionality.&lt;/p&gt; 
&lt;p&gt;To learn more, visit &lt;a href="https://docs.aws.amazon.com/opensearch-service/latest/developerguide/serverless-auto-optimize.html"&gt;Auto-optimize vector index&lt;/a&gt; in the OpenSearch Service Developer Guide.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;u&gt;Now available&lt;/u&gt;&lt;/strong&gt;&lt;br&gt; GPU acceleration in Amazon OpenSearch Service is now available in the US East (N. Virginia), US West (Oregon), Asia Pacific (Sydney), Asia Pacific (Tokyo), and Europe (Ireland) Regions. Auto-optimization in OpenSearch Service is now available in the US East (Ohio), US East (N. Virginia), US West (Oregon), Asia Pacific (Mumbai), Asia Pacific (Singapore), Asia Paciﬁc (Sydney), Asia Pacific (Tokyo), Europe (Frankfurt), and Europe (Ireland) Regions.&lt;/p&gt; 
&lt;p&gt;OpenSearch Service separately charges for used OCU – Vector Acceleration only to index your vector databases. For more information, visit&lt;a href="https://aws.amazon.com/opensearch-service/pricing/"&gt;OpenSearch Service pricing page&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Give it a try and send feedback to the &lt;a href="https://repost.aws/tags/TA6VFzFFY6QQa_KlHRKR-WsA/amazon-opensearch-service"&gt;AWS re:Post for Amazon OpenSearch Service&lt;/a&gt; or through your usual AWS Support contacts.&lt;/p&gt; 
&lt;p&gt;— &lt;a href="https://linkedin.com/in/channyun"&gt;Channy&lt;/a&gt;&lt;/p&gt;</content:encoded>
					
					
			
		
		
			</item>
		<item>
		<title>Amazon S3 Vectors now generally available with increased scale and performance</title>
		<link>https://aws.amazon.com/blogs/aws/amazon-s3-vectors-now-generally-available-with-increased-scale-and-performance/</link>
					
		
		<dc:creator><![CDATA[Sébastien Stormacq]]></dc:creator>
		<pubDate>Tue, 02 Dec 2025 16:06:11 +0000</pubDate>
				<category><![CDATA[Amazon Simple Storage Service (S3)]]></category>
		<category><![CDATA[Announcements]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[AWS re:Invent]]></category>
		<category><![CDATA[Generative AI]]></category>
		<category><![CDATA[Launch]]></category>
		<category><![CDATA[News]]></category>
		<guid isPermaLink="false">48db219ae3f1846b114aff45f04253245c9ed13f</guid>

					<description>Scale vector storage and querying to new heights with S3 Vectors' general availability—now supporting up to 1 billion vectors per index, 100ms query latencies, and expanded regional availability, while reducing costs up to 90% compared to specialized databases.</description>
										<content:encoded>&lt;p&gt;Today, I’m excited to announce that &lt;a href="https://aws.amazon.com/s3/features/vectors/"&gt;Amazon S3 Vectors&lt;/a&gt; is now generally available with significantly increased scale and production-grade performance capabilities. S3 Vectors is the first cloud object storage with native support to store and query vector data. You can use it to help you reduce the total cost of storing and querying vectors by up to 90% when compared to specialized vector database solutions.&lt;/p&gt; 
&lt;p&gt;Since &lt;a href="https://aws.amazon.com/blogs/aws/introducing-amazon-s3-vectors-first-cloud-storage-with-native-vector-support-at-scale/"&gt;we announced the preview of S3 Vectors in July&lt;/a&gt;, I’ve been impressed by how quickly you adopted this new capability to store and query vector data. In just over four months, you created over 250,000 vector indexes and ingested more than 40 billion vectors, performing over 1 billion queries (as of November 28th).&lt;/p&gt; 
&lt;p&gt;You can now store and search across up to 2 billion vectors in a single index, that’s up to 20 trillion vectors in a vector bucket and a 40x increase from 50 million per index during preview. This means that you can consolidate your entire vector dataset into one index, removing the need to shard across multiple smaller indexes or implement complex query federation logic.&lt;/p&gt; 
&lt;p&gt;Query performance has been optimized. Infrequent queries continue to return results in under one second, with more frequent queries now resulting in latencies around 100ms or less, making it well-suited for interactive applications such as conversational AI and multi-agent workflows. You can also retrieve up to 100 search results per query, up from 30 previously, providing more comprehensive context for retrieval augmented generation (RAG) applications.&lt;/p&gt; 
&lt;p&gt;The write performance has also improved substantially, with support for up to 1,000 PUT transactions per second when streaming single-vector updates into your indexes, delivering significantly higher write throughput for small batch sizes. This higher throughput supports workloads where new data must be immediately searchable, helping you ingest small data corpora quickly or handle many concurrent sources writing simultaneously to the same index.&lt;/p&gt; 
&lt;p&gt;The fully serverless architecture removes infrastructure overhead—there’s no infrastructure to set up or resources to provision. You pay for what you use as you store and query vectors. This AI-ready storage provides you with quick access to any amount of vector data to support your complete AI development lifecycle, from initial experimentation and prototyping through to large-scale production deployments. S3 Vectors now provides the scale and performance needed for production workloads across AI agents, inference, semantic search, and RAG applications.&lt;/p&gt; 
&lt;p&gt;Two key integrations that were launched in preview are now generally available. &lt;a href="https://docs.aws.amazon.com/AmazonS3/latest/userguide/s3-vectors-bedrock-kb.html"&gt;You can use S3 Vectors as a vector storage engine for Amazon Bedrock Knowledge Base&lt;/a&gt;. In particular, you can use it to build RAG applications with production-grade scale and performance. Moreover, &lt;a href="https://docs.aws.amazon.com/AmazonS3/latest/userguide/s3-vectors-opensearch.html"&gt;S3 Vectors integration with Amazon OpenSearch is now generally available&lt;/a&gt;, so that you can use S3 Vectors as your vector storage layer while using OpenSearch for search and analytics capabilities.&lt;/p&gt; 
&lt;p&gt;You can now use S3 Vectors in 14 AWS Regions, expanding from five AWS Regions during the preview.&lt;/p&gt; 
&lt;p&gt;&lt;span style="text-decoration: underline"&gt;&lt;strong&gt;Let’s see how it works&lt;br&gt; &lt;/strong&gt;&lt;/span&gt;In this post, I demonstrate how to use S3 Vectors through the AWS Console and CLI.&lt;/p&gt; 
&lt;p&gt;First, I create an S3 Vector bucket and an index.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="lang-sh"&gt;echo "Creating S3 Vector bucket..."
aws s3vectors create-vector-bucket \
    --vector-bucket-name "$BUCKET_NAME"

echo "Creating vector index..."
aws s3vectors create-index \
    --vector-bucket-name "$BUCKET_NAME" \
    --index-name "$INDEX_NAME" \
    --data-type "float32" \
    --dimension "$DIMENSIONS" \
    --distance-metric "$DISTANCE_METRIC" \
    --metadata-configuration "nonFilterableMetadataKeys=AMAZON_BEDROCK_TEXT,AMAZON_BEDROCK_METADATA"&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The dimension metric must match the dimension of the model used to compute the vectors. The distance metric indicates to the algorithm to compute the distance between vectors. S3 Vectors supports &lt;a href="https://en.wikipedia.org/wiki/Cosine_similarity"&gt;cosine&lt;/a&gt; and &lt;a href="https://en.wikipedia.org/wiki/Euclidean_distance"&gt;euclidian&lt;/a&gt; distances.&lt;/p&gt; 
&lt;p&gt;I can also use the console to create the bucket. We’ve added the capability to configure encryption parameters at creation time. By default, indexes use the bucket-level encryption, but I can override bucket-level encryption at the index level with a custom &lt;a href="https://aws.amazon.com/kms/"&gt;AWS Key Management Service (AWS KMS)&lt;/a&gt; key.&lt;/p&gt; 
&lt;p&gt;I also can add tags for the vector bucket and vector index. Tags at the vector index help with access control and cost allocation.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/18/2025-11-18_13-59-12.png"&gt;&lt;img loading="lazy" class="aligncenter size-large wp-image-101282" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/18/2025-11-18_13-59-12-1024x613.png" alt="S3 Vector console - create" width="1024" height="613"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;And I can now manage &lt;strong&gt;Properties&lt;/strong&gt; and &lt;strong&gt;Permissions&lt;/strong&gt; directly in the console.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/18/2025-11-18_14-00-11.png"&gt;&lt;img loading="lazy" class="aligncenter size-large wp-image-101281" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/18/2025-11-18_14-00-11-1024x645.png" alt="S3 Vector console - properties" width="1024" height="645"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/18/2025-11-18_14-05-11.png"&gt;&lt;img loading="lazy" class="aligncenter size-large wp-image-101280" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/18/2025-11-18_14-05-11-1024x584.png" alt="S3 Vector console - create" width="1024" height="584"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Similarly, I define &lt;strong&gt;Non-filterable metadata&lt;/strong&gt; and I configure &lt;strong&gt;Encryption&lt;/strong&gt; parameters for the vector index.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/18/2025-11-18_14-06-58.png"&gt;&lt;img loading="lazy" class="aligncenter size-large wp-image-101283" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/18/2025-11-18_14-06-58-1024x649.png" alt="S3 Vector console - create index" width="1024" height="649"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Next, I create and store the embeddings (vectors). For this demo, I ingest my constant companion: the AWS Style Guide. This is an 800-page document that describes how to write posts, technical documentation, and articles at AWS.&lt;/p&gt; 
&lt;p&gt;I use &lt;a href="https://docs.aws.amazon.com/bedrock/latest/userguide/knowledge-base.html"&gt;Amazon Bedrock Knowledge Bases&lt;/a&gt; to ingest the PDF document stored on a general purpose S3 bucket. Amazon Bedrock Knowledge Bases reads the document and splits it in pieces called chunks. Then, it computes the embeddings for each chunk with the &lt;a href="https://docs.aws.amazon.com/bedrock/latest/userguide/titan-embedding-models.html"&gt;Amazon Titan Text Embeddings&lt;/a&gt; model and it stores the vectors and their metadata on my newly created vector bucket. The detailed steps for that process are out of the scope of this post, but you can read &lt;a href="https://docs.aws.amazon.com/AmazonS3/latest/userguide/s3-vectors-bedrock-kb.html"&gt;the instructions in the documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;When querying vectors, you can store up to 50 metadata keys per vector, with up to 10 marked as non-filterable. You can use the filterable metadata keys to filter query results based on specific attributes. Therefore, you can combine vector similarity search with metadata conditions to narrow down results. You can also store more non-filterable metadata for larger contextual information. Amazon Bedrock Knowledge Bases computes and stores the vectors. It also adds large metadata (the chunk of the original text). I exclude this metadata from the searchable index.&lt;/p&gt; 
&lt;p&gt;There are other methods to ingest your vectors. You can try the &lt;a href="https://github.com/awslabs/s3vectors-embed-cli"&gt;S3 Vectors Embed CLI&lt;/a&gt;, a command line tool that helps you generate embeddings using Amazon Bedrock and store them in S3 Vectors through direct commands. You can also use S3 Vectors &lt;a href="https://docs.aws.amazon.com/AmazonS3/latest/userguide/s3-vectors-opensearch.html"&gt;as a vector storage engine for OpenSearch&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Now I’m ready to query my vector index. Let’s imagine I wonder how to write “open source”. Is it “open-source”, with a hyphen, or “open source” without a hyphen? Should I use uppercase or not? I want to search the relevant sections of the AWS Style Guide relative to “open source.”&lt;/p&gt; 
&lt;pre&gt;&lt;code class="lang-sh"&gt;# 1. Create embedding request
echo '{"inputText":"Should I write open source or open-source"}' | base64 | tr -d '\n' &amp;gt; body_encoded.txt

# 2. Compute the embeddings with Amazon Titan Embed model
aws bedrock-runtime invoke-model \
  --model-id amazon.titan-embed-text-v2:0 \
  --body "$(cat body_encoded.txt)" \
  embedding.json

# Search the S3 Vectors index for similar chunks
vector_array=$(cat embedding.json | jq '.embedding') &amp;amp;&amp;amp; \
aws s3vectors query-vectors \
  --index-arn "$S3_VECTOR_INDEX_ARN" \
  --query-vector "{\"float32\": $vector_array}" \
  --top-k 3 \
  --return-metadata \
  --return-distance | jq -r '.vectors[] | "Distance: \(.distance) | Source: \(.metadata."x-amz-bedrock-kb-source-uri" | split("/")[-1]) | Text: \(.metadata.AMAZON_BEDROCK_TEXT[0:100])..."'&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The first result shows this JSON:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="lang-json"&gt;        {
            "key": "348e0113-4521-4982-aecd-0ee786fa4d1d",
            "metadata": {
                "x-amz-bedrock-kb-data-source-id": "0SZY6GYPVS",
                "x-amz-bedrock-kb-source-uri": "s3://sst-aws-docs/awsstyleguide.pdf",
                "AMAZON_BEDROCK_METADATA": "{\"createDate\":\"2025-10-21T07:49:38Z\",\"modifiedDate\":\"2025-10-23T17:41:58Z\",\"source\":{\"sourceLocation\":\"s3://sst-aws-docs/awsstyleguide.pdf\"",
                "AMAZON_BEDROCK_TEXT": "[redacted] open source (adj., n.) Two words. Use open source as an adjective (for example, open source software), or as a noun (for example, the code throughout this tutorial is open source). Don't use open-source, opensource, or OpenSource. [redacted]",
                "x-amz-bedrock-kb-document-page-number": 98.0
            },
            "distance": 0.63120436668396
        }&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;It finds the relevant section in the AWS Style Guide. I must write “open source” without a hyphen. It even retrieved the page number in the original document to help me cross-check the suggestion with the relevant paragraph in the source document.&lt;/p&gt; 
&lt;p&gt;&lt;span style="text-decoration: underline"&gt;&lt;strong&gt;One more thing&lt;br&gt; &lt;/strong&gt;&lt;/span&gt;S3 Vectors has also expanded its integration capabilities. You can now use &lt;a href="https://aws.amazon.com/cloudformation/"&gt;AWS CloudFormation&lt;/a&gt; to deploy and manage your vector resources, &lt;a href="https://aws.amazon.com/privatelink/"&gt;AWS PrivateLink&lt;/a&gt; for private network connectivity, and resource tagging for cost allocation and access control.&lt;/p&gt; 
&lt;p&gt;&lt;span style="text-decoration: underline"&gt;&lt;strong&gt;Pricing and availability&lt;br&gt; &lt;/strong&gt;&lt;/span&gt;S3 Vectors is now available in 14 AWS Regions, adding Asia Pacific (Mumbai, Seoul, Singapore, Tokyo), Canada (Central), and Europe (Ireland, London, Paris, Stockholm) to the existing five Regions from preview (US East (Ohio, N. Virginia), US West (Oregon), Asia Pacific (Sydney), and Europe (Frankfurt))&lt;/p&gt; 
&lt;p&gt;Amazon S3 Vectors pricing is based on three dimensions. &lt;strong&gt;PUT pricing&lt;/strong&gt; is calculated based on the logical GB of vectors you upload, where each vector includes its logical vector data, metadata, and key. &lt;strong&gt;Storage costs&lt;/strong&gt; are determined by the total logical storage across your indexes. &lt;strong&gt;Query charges&lt;/strong&gt; include a per-API charge plus a $/TB charge based on your index size (excluding non-filterable metadata). As your index scales beyond 100,000 vectors, you benefit from lower $/TB pricing. &lt;a href="https://aws.amazon.com/s3/pricing/"&gt;As usual, the Amazon S3 pricing page has the details&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;To get started with S3 Vectors, visit the &lt;a href="https://console.aws.amazon.com/s3/vector-buckets"&gt;Amazon S3 console&lt;/a&gt;. You can create vector indexes, start storing your embeddings, and begin building scalable AI applications. For more information, check out the &lt;a href="https://docs.aws.amazon.com/AmazonS3/latest/userguide/s3-vectors.html"&gt;Amazon S3 User Guide&lt;/a&gt; or the &lt;a href="https://docs.aws.amazon.com/cli/latest/reference/s3vectors/"&gt;AWS CLI Command Reference&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;I look forward to seeing what you build with these new capabilities. Please share your feedback through &lt;a href="https://repost.aws/"&gt;AWS re:Post&lt;/a&gt; or your usual &lt;a href="https://aws.amazon.com/contact-us/"&gt;AWS Support contacts.&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://linktr.ee/sebsto"&gt;— seb&lt;/a&gt;&lt;/p&gt;</content:encoded>
					
					
			
		
		
			</item>
		<item>
		<title>Amazon Bedrock adds 18 fully managed open weight models, including the new Mistral Large 3 and Ministral 3 models</title>
		<link>https://aws.amazon.com/blogs/aws/amazon-bedrock-adds-fully-managed-open-weight-models/</link>
					
		
		<dc:creator><![CDATA[Channy Yun (윤석찬)]]></dc:creator>
		<pubDate>Tue, 02 Dec 2025 16:05:57 +0000</pubDate>
				<category><![CDATA[Amazon Bedrock]]></category>
		<category><![CDATA[Amazon Machine Learning]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[AWS re:Invent]]></category>
		<category><![CDATA[Launch]]></category>
		<category><![CDATA[News]]></category>
		<category><![CDATA[Serverless]]></category>
		<guid isPermaLink="false">c396cd44e5a6ee8301334276c427113b366280ad</guid>

					<description>Access fully managed foundation models from leading providers like Google, Kimi AI, MiniMax AI, Mistral AI, NVIDIA, OpenAI, and Qwen, including the new Mistral Large 3 and Ministral 3 3B, 8B, and 14B models through Amazon Bedrock.</description>
										<content:encoded>&lt;p&gt;Today, we’re announcing the general availability of an additional 18 fully managed open weight models in &lt;a href="https://aws.amazon.com/bedrock/?trk=769a1a2b-8c19-4976-9c45-b6b1226c7d20&amp;amp;sc_channel=el"&gt;Amazon Bedrock&lt;/a&gt; from Google, MiniMax AI, &lt;a href="https://aws.amazon.com/bedrock/mistral/?trk=769a1a2b-8c19-4976-9c45-b6b1226c7d20&amp;amp;sc_channel=el"&gt;Mistral AI&lt;/a&gt;, Moonshot AI, NVIDIA, &lt;a href="https://aws.amazon.com/bedrock/openai/?trk=769a1a2b-8c19-4976-9c45-b6b1226c7d20&amp;amp;sc_channel=el"&gt;OpenAI&lt;/a&gt;, and &lt;a href="https://aws.amazon.com/bedrock/qwen/?trk=769a1a2b-8c19-4976-9c45-b6b1226c7d20&amp;amp;sc_channel=el"&gt;Qwen&lt;/a&gt;, including the new Mistral Large 3 and Ministral 3 3B, 8B, and 14B models.&lt;/p&gt; 
&lt;p&gt;With this launch, Amazon Bedrock now provides nearly 100 serverless models, offering a broad and deep range of models from leading AI companies, so customers can choose the precise capabilities that best serve their unique needs. By closely monitoring both customer needs and technological advancements, we regularly expand &lt;a href="https://aws.amazon.com/bedrock/model-choice/?trk=769a1a2b-8c19-4976-9c45-b6b1226c7d20&amp;amp;sc_channel=el"&gt;our curated selection of models&lt;/a&gt; based on customer needs and technological advancements to include promising new models alongside established industry favorites.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/12/02/Amazon-Bedrock-Model-Provider-Portfolio-reInvent-2025.png"&gt;&lt;img loading="lazy" class="alignnone wp-image-102511 size-full" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/12/02/Amazon-Bedrock-Model-Provider-Portfolio-reInvent-2025.png" alt="" width="1370" height="572"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;This ongoing expansion of high-performing and differentiated model offerings helps customers stay at the forefront of AI innovation. You can access these models on Amazon Bedrock through the unified API, evaluate, switch, and adopt new models without rewriting applications or changing infrastructure.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;u&gt;New Mistral AI models&lt;/u&gt;&lt;/strong&gt;&lt;br&gt; These four Mistral AI models are now available first on Amazon Bedrock, each optimized for different performance and cost requirements:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Mistral Large 3&lt;/strong&gt; – This open weight model is optimized for long-context, multimodal, and instruction reliability. It excels in long document understanding, agentic and tool use workflows, enterprise knowledge work, coding assistance, advanced workloads such as math and coding tasks, multilingual analysis and processing, and multimodal reasoning with vision.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Ministral 3 3B&lt;/strong&gt; – The smallest in the Ministral 3 family is edge-optimized for single GPU deployment with strong language and vision capabilities. It shows robust performance in image captioning, text classification, real-time translation, data extraction, short content generation, and lightweight real-time applications on edge or low-resource devices.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Ministral 3 8B&lt;/strong&gt; – The best-in-class Ministral 3 model for text and vision is edge-optimized for single GPU deployment with high performance and minimal footprint. This model is ideal for chat interfaces in constrained environments, image and document description and understanding, specialized agentic use cases, and balanced performance for local or embedded systems.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Ministral 3 14B&lt;/strong&gt; – The most capable Ministral 3 model delivers state-of the-art text and vision performance optimized for single GPU deployment. You can use advanced local agentic use cases and private AI deployments where advanced capabilities meet practical hardware constraints.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;&lt;u&gt;More open weight model options&lt;/u&gt;&lt;/strong&gt;&lt;br&gt; You can use these open weight models for a wide range of use cases across industries:&lt;/p&gt; 
&lt;table style="border: 2px solid black;border-collapse: collapse;margin-left: auto;margin-right: auto"&gt; 
 &lt;tbody&gt; 
  &lt;tr style="border-bottom: 1px solid black;background-color: #e0e0e0"&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;&lt;strong&gt;Model provider&lt;/strong&gt;&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;&lt;strong&gt;Model name&lt;/strong&gt;&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;&lt;strong&gt;Description&lt;/strong&gt;&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;&lt;strong&gt;Use cases&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr style="border-bottom: 1px solid black"&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px" rowspan="3"&gt;&lt;strong&gt;Google&lt;/strong&gt;&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px"&gt;&lt;a href="https://huggingface.co/google/gemma-3-4b-it"&gt;Gemma 3 4B&lt;/a&gt;&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px"&gt;Efficient text and image model that runs locally on laptops. Multilingual support for on-device AI applications.&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px"&gt;On-device AI for mobile and edge applications, privacy-sensitive local inference, multilingual chat assistants, image captioning and description, and lightweight content generation.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr style="border-bottom: 1px solid black"&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px"&gt;&lt;a href="https://huggingface.co/google/gemma-3-12b-it"&gt;Gemma 3 12B&lt;/a&gt;&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px"&gt;Balanced text and image model for workstations. Multi-language understanding with local deployment for privacy-sensitive applications.&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px"&gt;Workstation-based AI applications; local deployment for enterprises; multilingual document processing, image analysis and Q&amp;amp;A; and privacy-compliant AI assistants.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr style="border-bottom: 1px solid black"&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px"&gt;&lt;a href="https://huggingface.co/collections/google/gemma-3-release"&gt;Gemma 3 27B&lt;/a&gt;&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px"&gt;Powerful text and image model for enterprise applications. Multi-language support with local deployment for privacy and control.&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px"&gt;Enterprise local deployment, high-performance multimodal applications, advanced image understanding, multilingual customer service, and data-sensitive AI workflows.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr style="border-bottom: 1px solid black"&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px"&gt;&lt;strong&gt;Moonshot&amp;nbsp;AI&lt;/strong&gt;&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px"&gt;&lt;a href="https://huggingface.co/moonshotai/Kimi-K2-Thinking"&gt;Kimi K2 Thinking&lt;/a&gt;&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px"&gt;Deep reasoning model that thinks while using tools. Handles research, coding and complex workflows requiring hundreds of sequential actions.&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px"&gt;Complex coding projects requiring planning, multistep workflows, data analysis and computation, and long-form content creation with research.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr style="border-bottom: 1px solid black"&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;width: 90px"&gt;&lt;strong&gt;MiniMax AI&lt;/strong&gt;&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px"&gt;&lt;a href="https://huggingface.co/MiniMaxAI/MiniMax-M2"&gt;MiniMax M2&lt;/a&gt;&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px"&gt;Built for coding agents and automation. Excels at multi-file edits, terminal operations and executing long tool-calling chains efficiently.&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px"&gt;Coding agents and integrated development environment (IDE) integration, multi-file code editing, terminal automation and DevOps, long-chain tool orchestration, and agentic software development.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr style="border-bottom: 1px solid black"&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px" rowspan="3"&gt;&lt;strong&gt;Mistral AI&lt;/strong&gt;&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px"&gt;&lt;a href="https://huggingface.co/mistralai/Magistral-Small-2509"&gt;Magistral Small 1.2&lt;/a&gt;&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px"&gt;Excels at math, coding, multilingual tasks, and multimodal reasoning with vision capabilities for efficient local deployment.&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px"&gt;Math and coding tasks, multilingual analysis and processing, and multimodal reasoning with vision.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr style="border-bottom: 1px solid black"&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px"&gt;&lt;a href="https://huggingface.co/mistralai/Voxtral-Mini-3B-2507"&gt;Voxtral Mini 1.0&lt;/a&gt;&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px"&gt;Advanced audio understanding model with transcription, multilingual support, Q&amp;amp;A, and summarization.&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px"&gt;Voice-controlled applications, fast speech-to-text conversion, and offline voice assistants.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr style="border-bottom: 1px solid black"&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px"&gt;&lt;a href="https://huggingface.co/mistralai/Voxtral-Small-24B-2507"&gt;Voxtral Small 1.0&lt;/a&gt;&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px"&gt;Features state-of-the-art audio input with best-in-class text performance; excels at speech transcription, translation, and understanding.&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px"&gt;Enterprise speech transcription, multilingual customer service, and audio content summarization.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr style="border-bottom: 1px solid black"&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px" rowspan="2"&gt;&lt;strong&gt;NVIDIA&lt;/strong&gt;&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px"&gt;&lt;a href="https://huggingface.co/nvidia/NVIDIA-Nemotron-Nano-9B-v2"&gt;NVIDIA Nemotron Nano 2 9B&lt;/a&gt;&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px"&gt;High efficiency LLM with hybrid transformer Mamba design, excelling in reasoning and agentic tasks.&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px"&gt;Reasoning, tool calling, math, coding, and instruction following.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr style="border-bottom: 1px solid black"&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px"&gt;&lt;a href="https://huggingface.co/nvidia/NVIDIA-Nemotron-Nano-12B-v2-VL-BF16"&gt;NVIDIA Nemotron Nano 2 VL 12B&lt;/a&gt;&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px"&gt;Advanced multimodal reasoning model for video understanding and document intelligence, powering Retrieval-Augmented Generation (RAG) and multimodal agentic applications.&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px"&gt;Multi-image and video understanding, visual Q&amp;amp;A, and summarization.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr style="border-bottom: 1px solid black"&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px" rowspan="2"&gt;&lt;strong&gt;OpenAI&lt;/strong&gt;&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px"&gt;&lt;a href="https://huggingface.co/openai/gpt-oss-safeguard-20b"&gt;gpt-oss-safeguard-20b&lt;/a&gt;&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px"&gt;Content safety model that applies your custom policies. Classifies harmful content with explanations for trust and safety workflows.&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px"&gt;Content moderation and safety classification, custom policy enforcement, user-generated content filtering, trust and safety workflows, and automated content triage.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr style="border-bottom: 1px solid black"&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px"&gt;&lt;a href="https://huggingface.co/openai/gpt-oss-safeguard-120b"&gt;gpt-oss-safeguard-120b&lt;/a&gt;&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px"&gt;Larger content safety model for complex moderation. Applies custom policies with detailed reasoning for enterprise trust and safety teams.&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px"&gt;Enterprise content moderation at scale, complex policy interpretation, multilayered safety classification, regulatory compliance checking, high-stakes content review.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr style="border-bottom: 1px solid black"&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px" rowspan="2"&gt;&lt;strong&gt;Qwen&lt;/strong&gt;&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px"&gt;&lt;a href="https://huggingface.co/Qwen/Qwen3-Next-80B-A3B-Instruct"&gt;Qwen3-Next-80B-A3B&lt;/a&gt;&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px"&gt;Fast inference with hybrid attention for ultra-long documents. Optimized for RAG pipelines, tool use &amp;amp; agentic workflows with quick responses.&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px"&gt;RAG pipelines with long documents, agentic workflows with tool calling, code generation and software development, multi-turn conversations with extended context, multilingual content generation.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr style="border-bottom: 1px solid black"&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px"&gt;&lt;a href="https://huggingface.co/Qwen/Qwen3-VL-235B-A22B-Instruct"&gt;Qwen3-VL-235B-A22B&lt;/a&gt;&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px"&gt;Understands images and video. Extracts text from documents, converts screenshots to working code, and automates clicking through interfaces.&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px"&gt;Extracting text from images and PDFs, converting UI designs or screenshots to working code, automating clicks and navigation in applications, video analysis and understanding, reading charts and diagrams.&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;When implementing publicly available models, give careful consideration to data privacy requirements in your production environments, check for bias in output, and monitor your results for data security, &lt;a href="https://aws.amazon.com/ai/responsible-ai/?trk=769a1a2b-8c19-4976-9c45-b6b1226c7d20&amp;amp;sc_channel=el"&gt;responsible AI&lt;/a&gt;, and &lt;a href="https://aws.amazon.com/bedrock/evaluations/?trk=769a1a2b-8c19-4976-9c45-b6b1226c7d20&amp;amp;sc_channel=el"&gt;model evaluation&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;You can access the &lt;a href="https://aws.amazon.com/bedrock/security-compliance/?trk=769a1a2b-8c19-4976-9c45-b6b1226c7d20&amp;amp;sc_channel=el"&gt;enterprise-grade security features&lt;/a&gt; of Amazon Bedrock and implement safeguards customized to your application requirements and responsible AI policies with &lt;a href="https://aws.amazon.com/bedrock/guardrails/?trk=769a1a2b-8c19-4976-9c45-b6b1226c7d20&amp;amp;sc_channel=el"&gt;Amazon Bedrock Guardrails&lt;/a&gt;. You can also evaluate and compare models to identify the optimal models for your use cases by using &lt;a href="https://aws.amazon.com/blogs/aws/amazon-bedrock-model-evaluation-is-now-generally-available/?trk=769a1a2b-8c19-4976-9c45-b6b1226c7d20&amp;amp;sc_channel=el"&gt;Amazon Bedrock model evaluation tools&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;To get started, you can quickly test these models with a few prompts in the playground of the &lt;a href="https://console.aws.amazon.com/bedrock/?trk=769a1a2b-8c19-4976-9c45-b6b1226c7d20&amp;amp;sc_channel=el"&gt;Amazon Bedrock console&lt;/a&gt; or&amp;nbsp;use any &lt;a href="https://aws.amazon.com/tools/?trk=769a1a2b-8c19-4976-9c45-b6b1226c7d20&amp;amp;sc_channel=el"&gt;AWS SDKs&lt;/a&gt; to include access to the Bedrock &lt;a href="https://docs.aws.amazon.com/bedrock/latest/APIReference/API_runtime_InvokeModel.html?trk=769a1a2b-8c19-4976-9c45-b6b1226c7d20&amp;amp;sc_channel=el"&gt;InvokeModel&lt;/a&gt; and &lt;a href="https://docs.aws.amazon.com/bedrock/latest/APIReference/API_runtime_Converse.html?trk=769a1a2b-8c19-4976-9c45-b6b1226c7d20&amp;amp;sc_channel=el"&gt;Converse&lt;/a&gt; APIs. You can also use these models with any agentic framework that supports Amazon Bedrock and deploy the agents using &lt;a href="https://aws.amazon.com/bedrock/agentcore/?trk=769a1a2b-8c19-4976-9c45-b6b1226c7d20&amp;amp;sc_channel=el"&gt;Amazon Bedrock AgentCore&lt;/a&gt; and &lt;a href="https://strandsagents.com/?trk=769a1a2b-8c19-4976-9c45-b6b1226c7d20&amp;amp;sc_channel=el"&gt;Strands Agents&lt;/a&gt;. To learn more, visit &lt;a href="https://docs.aws.amazon.com/bedrock/latest/userguide/service_code_examples.html?trk=769a1a2b-8c19-4976-9c45-b6b1226c7d20&amp;amp;sc_channel=el"&gt;Code examples for Amazon Bedrock using AWS SDKs&lt;/a&gt; in the Amazon Bedrock User Guide.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;u&gt;Now available&lt;/u&gt;&lt;/strong&gt;&lt;br&gt; Check the &lt;a href="https://docs.aws.amazon.com/bedrock/latest/userguide/models-regions.html?trk=769a1a2b-8c19-4976-9c45-b6b1226c7d20&amp;amp;sc_channel=el"&gt;full Region list&lt;/a&gt; for availability and future updates of new models or search your model name in the &lt;a href="https://aws.amazon.com/cloudformation/?trk=769a1a2b-8c19-4976-9c45-b6b1226c7d20&amp;amp;sc_channel=el"&gt;AWS CloudFormation&lt;/a&gt; resources tab of &lt;a href="https://builder.aws.com/build/capabilities/explore?tab=cfn-resources&amp;amp;trk=769a1a2b-8c19-4976-9c45-b6b1226c7d20&amp;amp;sc_channel=el"&gt;AWS Capabilities by Region&lt;/a&gt;. To learn more, check out the &lt;a href="https://aws.amazon.com/bedrock/?trk=769a1a2b-8c19-4976-9c45-b6b1226c7d20&amp;amp;sc_channel=el"&gt;Amazon Bedrock product page&lt;/a&gt; and the &lt;a href="https://aws.amazon.com/bedrock/pricing/?trk=769a1a2b-8c19-4976-9c45-b6b1226c7d20&amp;amp;sc_channel=el"&gt;Amazon Bedrock pricing page&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Give these models a try in the &lt;a href="https://console.aws.amazon.com/bedrock?trk=769a1a2b-8c19-4976-9c45-b6b1226c7d20&amp;amp;sc_channel=el"&gt;Amazon Bedrock console&lt;/a&gt; today and send feedback to &lt;a href="https://repost.aws/tags/TAQeKlaPaNRQ2tWB6P7KrMag/amazon-bedrock?trk=769a1a2b-8c19-4976-9c45-b6b1226c7d20&amp;amp;sc_channel=el"&gt;AWS re:Post for Amazon Bedrock&lt;/a&gt; or through your usual AWS Support contacts.&lt;/p&gt; 
&lt;p&gt;— &lt;a href="https://linkedin.com/in/channy/"&gt;Channy&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Updated on 4 December&lt;/strong&gt; — Amazon Bedrock now supports Responses API on new OpenAI API-compatible service endpoints for GPT OSS 20B and 120B models. To learn more, visit &lt;a href="https://docs.aws.amazon.com/bedrock/latest/userguide/bedrock-mantle.html"&gt;Generate responses using OpenAI APIs&lt;/a&gt;.&lt;/p&gt;</content:encoded>
					
					
			
		
		
			</item>
		<item>
		<title>Introducing Amazon EC2 X8aedz instances powered by 5th Gen AMD EPYC processors for memory-intensive workloads</title>
		<link>https://aws.amazon.com/blogs/aws/introducing-amazon-ec2-x8aedz-instances-powered-by-5th-gen-amd-epyc-processors-for-memory-intensive-workloads/</link>
					
		
		<dc:creator><![CDATA[Channy Yun (윤석찬)]]></dc:creator>
		<pubDate>Tue, 02 Dec 2025 16:05:44 +0000</pubDate>
				<category><![CDATA[Amazon EC2]]></category>
		<category><![CDATA[AWS re:Invent]]></category>
		<category><![CDATA[Compute]]></category>
		<category><![CDATA[Events]]></category>
		<category><![CDATA[Launch]]></category>
		<category><![CDATA[News]]></category>
		<guid isPermaLink="false">3137206c1861610424e12f242392d19ba05c4ad1</guid>

					<description>New memory-optimized instances deliver up to 5 GHz processor speeds and 3 TiB of memory—ideal for electronic design automation workloads and memory-intensive databases requiring high single-threaded performance.</description>
										<content:encoded>&lt;p&gt;Today, we’re announcing the availability of new memory-optimized, high-frequency &lt;a href="https://aws.amazon.com/ec2/"&gt;Amazon Elastic Compute Cloud (Amazon EC2)&lt;/a&gt; X8aedz instances powered by a 5th Gen AMD EPYC processor. These instances offer the highest CPU frequency, 5GHz in the cloud. They deliver up to two times higher compute performance compared to previous generation X2iezn instances.&lt;/p&gt; 
&lt;p&gt;X8aedz instances are ideal for electronic design automation (EDA) workloads, such as physical layout and physical verification jobs, and relational databases that benefit from high single-threaded processor performance and a large memory footprint. The combination of 5 GHz processors and local NVMe storage enables faster processing of memory-intensive backend EDA workloads such as floor planning, logic placement, clock tree synthesis (CTS), routing, and power/signal integrity analysis. The high memory-to-vCPU ratio of 32:1 makes these instances particularly effective for applications with vCPU-based licensing models.&lt;/p&gt; 
&lt;p&gt;Let me explain the instance type naming: The “a” suffix indicates an AMD processor, “e” denotes extended memory in the memory-optimized instance family, “d” represents local NVMe-based SSDs physically connected to the host server, and “z” indicates high-frequency processors.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;u&gt;X8aedz instances&lt;/u&gt;&lt;/strong&gt;&lt;br&gt; X8aedz instances are available in eight sizes ranging from 2–96 vCPUs with 64–3,072 GiB of memory, including two bare metal sizes. X8aedz instances feature up to 75 Gbps of network bandwidth with support for the &lt;a href="https://aws.amazon.com/hpc/efa/?trk=769a1a2b-8c19-4976-9c45-b6b1226c7d20&amp;amp;sc_channel=el"&gt;Elastic Fabric Adapter (EFA)&lt;/a&gt;, up to 60 Gbps of throughput to the &lt;a href="https://aws.amazon.com/ebs/"&gt;Amazon Elastic Block Store (Amazon EBS)&lt;/a&gt;, and up to 8 TB of local NVMe SSD storage.&lt;/p&gt; 
&lt;p&gt;Here are the specs for X8aedz instances:&lt;/p&gt; 
&lt;table style="border: 2px solid black;border-collapse: collapse;margin-left: auto;margin-right: auto"&gt; 
 &lt;tbody&gt; 
  &lt;tr style="border-bottom: 1px solid black;background-color: #e0e0e0"&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;&lt;strong&gt;Instance name&lt;/strong&gt;&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;&lt;strong&gt;vCPUs&lt;/strong&gt;&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;&lt;strong&gt;Memory&lt;br&gt; &lt;/strong&gt;&lt;strong&gt;(GiB)&lt;/strong&gt;&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;&lt;strong&gt;NVMe SSD storage (GB)&lt;/strong&gt;&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;&lt;strong&gt;Network bandwidth (Gbps)&lt;/strong&gt;&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;&lt;strong&gt;EBS bandwidth (Gbps)&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr style="border-bottom: 1px solid black"&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;&lt;strong&gt;x8aedz.large&lt;/strong&gt;&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;2&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;64&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;158&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;Up to 18.75&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;Up to 15&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr style="border-bottom: 1px solid black"&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;&lt;strong&gt;x8aedz.xlarge&lt;/strong&gt;&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;4&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;128&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;316&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;Up to 18.75&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;Up to 15&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr style="border-bottom: 1px solid black"&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;&lt;strong&gt;x8aedz.3xlarge&lt;/strong&gt;&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;12&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;384&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;950&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;Up to 18.75&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;Up to 15&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr style="border-bottom: 1px solid black"&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;&lt;strong&gt;x8aedz.6xlarge&lt;/strong&gt;&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;24&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;768&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;1,900&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;18.75&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;15&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr style="border-bottom: 1px solid black"&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;&lt;strong&gt;x8aedz.12xlarge&lt;/strong&gt;&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;48&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;1,536&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;3,800&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;37.5&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;30&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr style="border-bottom: 1px solid black"&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;&lt;strong&gt;x8aedz.24xlarge&lt;/strong&gt;&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;96&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;3,072&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;7,600&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;75&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;60&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr style="border-bottom: 1px solid black"&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;&lt;strong&gt;x8aedz.metal-12xl&lt;/strong&gt;&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;48&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;1,536&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;3,800&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;37.5&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;30&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr style="border-bottom: 1px solid black"&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;&lt;strong&gt;x8aedz.metal-24xl&lt;/strong&gt;&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;96&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;3,072&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;7,600&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;75&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;60&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;With the 60 Gbps Amazon EBS bandwidth and up to 8 TB of local NVMe SSD storage, you can achieve faster database response times and reduced latency for EDA operations, ultimately accelerating time-to-market for chip designs. These instances also support the instance bandwidth configuration feature that offers flexibility in allocating resources between network and EBS bandwidth. You can scale network or EBS bandwidth by 25% and improve database (read and write) performance, query processing, and logging speeds.&lt;/p&gt; 
&lt;p&gt;X8aedz instances use sixth-generation &lt;a href="https://aws.amazon.com/ec2/nitro/"&gt;AWS Nitro&lt;/a&gt; cards, which offload CPU virtualization, storage, and networking functions to dedicated hardware and software, enhancing performance and security for your workloads.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;u&gt;Now available&lt;/u&gt;&lt;/strong&gt;&lt;br&gt; Amazon EC2 X8aedz instances are now available in US West (Oregon) and Asia Pacific (Tokyo) &lt;a href="https://docs.aws.amazon.com/glossary/latest/reference/glos-chap.html#region?trk=769a1a2b-8c19-4976-9c45-b6b1226c7d20&amp;amp;sc_channel=el"&gt;AWS Regions&lt;/a&gt;, and additional Regions will be coming soon. For Regional availability and future roadmap, search the instance type in the &lt;a href="https://aws.amazon.com/cloudformation/?trk=769a1a2b-8c19-4976-9c45-b6b1226c7d20&amp;amp;sc_channel=el"&gt;AWS CloudFormation&lt;/a&gt; resources tab of the &lt;a href="https://builder.aws.com/build/capabilities/explore?tab=cfn-resources&amp;amp;trk=769a1a2b-8c19-4976-9c45-b6b1226c7d20&amp;amp;sc_channel=el"&gt;AWS Capabilities by Region&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;You can purchase these instances as &lt;a href="https://aws.amazon.com/ec2/pricing/on-demand/?trk=cf96f8ec-de40-4ee0-8b64-3f7cf7660da2&amp;amp;sc_channel=el"&gt;On-Demand&lt;/a&gt;, &lt;a href="https://aws.amazon.com/savingsplans/?trk=cc9e0036-98c5-4fa8-8df0-5281f75284ca&amp;amp;sc_channel=el"&gt;Savings Plan&lt;/a&gt;, &lt;a href="https://aws.amazon.com/ec2/spot/pricing/?trk=307341f6-3463-47d5-ba81-0957847a9b73&amp;amp;sc_channel=el"&gt;Spot Instances&lt;/a&gt;, and &lt;a href="https://aws.amazon.com/ec2/pricing/dedicated-instances/"&gt;Dedicated Instances&lt;/a&gt;. To learn more, visit the &lt;a href="https://aws.amazon.com/ec2/pricing/?trk=769a1a2b-8c19-4976-9c45-b6b1226c7d20&amp;amp;sc_channel=el"&gt;Amazon EC2 Pricing page&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Give X8aedz instances a try in the &lt;a href="https://console.aws.amazon.com/ec2/?trk=769a1a2b-8c19-4976-9c45-b6b1226c7d20&amp;amp;sc_channel=el"&gt;Amazon EC2 console&lt;/a&gt;. To learn more, visit the &lt;a href="https://aws.amazon.com/ec2/instance-types/x8aedz/?trk=769a1a2b-8c19-4976-9c45-b6b1226c7d20&amp;amp;sc_channel=el"&gt;Amazon EC2 X8aedz instances page&lt;/a&gt; and send feedback to &lt;a href="https://repost.aws/tags/TAO-wqN9fYRoyrpdULLa5y7g/amazon-ec-2?trk=769a1a2b-8c19-4976-9c45-b6b1226c7d20&amp;amp;sc_channel=el"&gt;AWS re:Post for EC2&lt;/a&gt; or through your usual AWS Support contacts.&lt;/p&gt; 
&lt;p&gt;— &lt;a href="https://linkedin.com/in/channy/"&gt;Channy&lt;/a&gt;&lt;/p&gt;</content:encoded>
					
					
			
		
		
			</item>
		<item>
		<title>AWS DevOps Agent helps you accelerate incident response and improve system reliability (preview)</title>
		<link>https://aws.amazon.com/blogs/aws/aws-devops-agent-helps-you-accelerate-incident-response-and-improve-system-reliability-preview/</link>
					
		
		<dc:creator><![CDATA[Sébastien Stormacq]]></dc:creator>
		<pubDate>Tue, 02 Dec 2025 16:05:42 +0000</pubDate>
				<category><![CDATA[Announcements]]></category>
		<category><![CDATA[DevOps]]></category>
		<category><![CDATA[Launch]]></category>
		<category><![CDATA[News]]></category>
		<guid isPermaLink="false">d7d202e7e519cb35dfd1d682677c6f1f018b5f7b</guid>

					<description>New service acts as an always-on DevOps engineer, helping you respond to incidents, identify root causes, and prevent future issues through systematic analysis of incidents and operational patterns.</description>
										<content:encoded>&lt;p&gt;Today, we’re announcing the public preview of AWS DevOps Agent, a &lt;a href="https://aws.amazon.com/ai/frontier-agents"&gt;frontier agent&lt;/a&gt; that helps you respond to incidents, identify root causes, and prevent future issues through systematic analysis of past incidents and operational patterns.&lt;/p&gt; 
&lt;p&gt;Frontier agents represent a new class of AI agents that are autonomous, massively scalable, and work for hours or days without constant intervention.&lt;/p&gt; 
&lt;p&gt;When production incidents occur, on-call engineers face significant pressure to quickly identify root causes while managing stakeholder communications. They must analyze data across multiple monitoring tools, review recent deployments, and coordinate response teams. After service restoration, teams often lack bandwidth to transform incident learnings into systematic improvements.&lt;/p&gt; 
&lt;p&gt;AWS DevOps Agent is your always-on, autonomous on-call engineer. When issues arise, it automatically correlates data across your operational toolchain, from metrics and logs to recent code deployments in GitHub or GitLab. It identifies probable root causes and recommends targeted mitigations, helping reduce mean time to resolution. The agent also manages incident coordination, using Slack channels for stakeholder updates and maintaining detailed investigation timelines.&lt;/p&gt; 
&lt;p&gt;To get started, you connect AWS DevOps Agent to your existing tools through the &lt;a href="https://console.aws.amazon.com"&gt;AWS Management Console&lt;/a&gt;. The agent works with popular services such as &lt;a href="https://aws.amazon.com/cloudwatch/"&gt;Amazon CloudWatch&lt;/a&gt;, &lt;a href="https://www.datadoghq.com/"&gt;Datadog&lt;/a&gt;, &lt;a href="https://www.dynatrace.com/"&gt;Dynatrace&lt;/a&gt;, &lt;a href="https://newrelic.com/"&gt;New Relic&lt;/a&gt;, and &lt;a href="https://www.splunk.com/"&gt;Splunk&lt;/a&gt; for observability data, while integrating with GitHub Actions and GitLab CI/CD to track deployments and their impact on your cloud resources. Through the bring your own (BYO) &lt;a href="https://modelcontextprotocol.io/docs/getting-started/intro"&gt;Model Context Protocol (MCP)&lt;/a&gt; server capability, you can also integrate additional tools such as your organization’s custom tools, specialized platforms or open source observability solutions, such as &lt;a href="https://grafana.com/"&gt;Grafana&lt;/a&gt; and &lt;a href="https://prometheus.io/"&gt;Prometheus&lt;/a&gt; into your investigations.&lt;/p&gt; 
&lt;p&gt;The agent acts as a virtual team member and can be configured to automatically respond to incidents from your ticketing systems. It includes built-in support for &lt;a href="https://www.servicenow.com/"&gt;ServiceNow&lt;/a&gt;, and through configurable &lt;a href="https://en.wikipedia.org/wiki/Webhook"&gt;webhooks&lt;/a&gt;, can respond to events from other incident management tools like &lt;a href="https://www.pagerduty.com/"&gt;PagerDuty&lt;/a&gt;. As investigations progress, the agent updates tickets and relevant Slack channels with its findings. All of this is powered by an intelligent application topology the agent builds—a comprehensive map of your system components and their interactions, including deployment history that helps identify potential deployment-related causes during investigations.&lt;/p&gt; 
&lt;p&gt;&lt;span style="text-decoration: underline"&gt;&lt;strong&gt;Let me show you how it works&lt;br&gt; &lt;/strong&gt;&lt;/span&gt;To show you how it works, I deployed a straigthforward &lt;a href="https://aws.amazon.com/lambda/"&gt;AWS Lambda&lt;/a&gt; function that intentionally generates errors when invoked. I deployed it in an &lt;a href="https://aws.amazon.com/cloudformation/"&gt;AWS CloudFormation&lt;/a&gt; stack.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Step 1: Create an Agent Space&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;An Agent Space defines the scope of what AWS DevOps Agent can access as it performs tasks.&lt;/p&gt; 
&lt;p&gt;You can organize Agent Spaces based on your operational model. Some teams align an Agent Space with a single application, others create one per on-call team managing multiple services, and some organizations use a centralized approach. For this demonstration, I’ll show you how to create an Agent Space for a single application. This setup helps isolate investigations and resources for that specific application, making it easier to track and analyze incidents within its context.&lt;/p&gt; 
&lt;p&gt;In the AWS DevOps Agent section of the &lt;a href="https://console.aws.amazon.com"&gt;AWS Management Console&lt;/a&gt;, I select &lt;strong&gt;Create Agent Space&lt;/strong&gt;, enter a name for this space and create the &lt;a href="https://aws.amazon.com/iam/"&gt;AWS Identity and Access Management (IAM)&lt;/a&gt; roles it uses to introspect AWS resources in my or others’ AWS accounts.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/21/2025-11-21_08-15-01.png"&gt;&lt;img loading="lazy" class="aligncenter size-large wp-image-101546" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/21/2025-11-21_08-15-01-1024x570.png" alt="AWS DevOps Agent - Create an Agent Space" width="1024" height="570"&gt;&lt;/a&gt;For this demo, I choose to enable the AWS DevOps Agent web app; more about this later. This can be done at a later stage.&lt;/p&gt; 
&lt;p&gt;When ready, I choose &lt;strong&gt;Create&lt;/strong&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/21/2025-11-21_08-15-07.png"&gt;&lt;img loading="lazy" class="aligncenter size-large wp-image-101547" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/21/2025-11-21_08-15-07-1024x472.png" alt="AWS DevOps Agent - Enable Web App" width="1024" height="472"&gt;&lt;/a&gt;After it has been created, I choose the &lt;strong&gt;Topology&lt;/strong&gt; tab.&lt;/p&gt; 
&lt;p&gt;This view shows the key resources, entities, and relationships AWS DevOps Agent has selected as a foundation for performing its tasks efficiently. It doesn’t represent everything AWS DevOps Agent can access or see, only what the Agent considers most relevant right now. By default, the Topology includes the AWS resources that are contained in my account. As your agent completes more tasks, it will discover and add new resources to this list.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/21/2025-11-21_08-19-12.png"&gt;&lt;img loading="lazy" class="aligncenter size-large wp-image-101548" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/21/2025-11-21_08-19-12-1024x650.png" alt="AWS DevOps Agent - Topology" width="1024" height="650"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Step 2: Configure the AWS DevOps web app for the operators&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;The AWS DevOps Agent web app provides a web interface for on-call engineers to manually trigger investigations, view investigation details including relevant topology elements, steer investigations, and ask questions about an investigation.&lt;/p&gt; 
&lt;p&gt;I can access the web app directly from my Agent Space in the AWS console by choosing the &lt;strong&gt;Operator access&lt;/strong&gt; link. Alternatively, I can use &lt;a href="https://aws.amazon.com/iam/identity-center/"&gt;AWS IAM Identity Center&lt;/a&gt; to configure user access for my team. IAM Identity Center lets me manage users and groups directly or connect to an identity provider (IdP), providing a centralized way to control who can access the AWS DevOps Agent web app.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/28/2025-11-28_19-52-39.png"&gt;&lt;img loading="lazy" class="aligncenter size-large wp-image-102290" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/28/2025-11-28_19-52-39-1024x545.png" alt="AWS DevOps Agent - web app access" width="1024" height="545"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;At this stage, I have an Agent Space all set up to focus investigations and resources for this speciﬁc application, and I’ve enabled the DevOps team to initiate investigations using the web app.&lt;/p&gt; 
&lt;p&gt;Now that the one-time setup for this application is done, I start invoking the faulty Lambda function. It generates errors at each invocation. The CloudWatch alarm associated with the Lambda errors count turns on to &lt;strong&gt;ALARM&lt;/strong&gt; state. In real life, you might receive an alert from external services, such as ServiceNow. You can configure AWS DevOps Agent to automatically start investigations when receiving such alerts.&lt;/p&gt; 
&lt;p&gt;For this demo, I manually start the investigation by selecting &lt;strong&gt;Start Investigation&lt;/strong&gt;.&lt;/p&gt; 
&lt;p&gt;You can also choose from several preconfigured starting points to quickly begin your investigation: Latest alarm to investigate your most recent triggered alarm and analyze the underlying metrics and logs to determine the root cause, High CPU usage to investigate high CPU utilization metrics across your compute resources and identify which processes or services are consuming excessive resources, or Error rate spike to investigate the recent increase in application error rates by analyzing metrics, application logs, and identifying the source of failures.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/28/2025-11-28_19-55-05.png"&gt;&lt;img loading="lazy" class="aligncenter size-large wp-image-102291" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/28/2025-11-28_19-55-05-1024x528.png" alt="AWS DevOps Agent - web app" width="1024" height="528"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;I enter some information, such as &lt;strong&gt;Investigation details&lt;/strong&gt;, &lt;strong&gt;Investigation starting point&lt;/strong&gt;, the &lt;strong&gt;Date and time of the incident&lt;/strong&gt;, the &lt;strong&gt;AWS Account ID for the incident.&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/21/2025-11-21_08-39-07-v3.png"&gt;&lt;img loading="lazy" class="aligncenter size-large wp-image-101554" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/21/2025-11-21_08-39-07-v3-601x1024.png" alt="- web app - start investigation" width="601" height="1024"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;In the AWS DevOps Agent web app, you can watch the investigation unfold in real time. The agent identifies the application stack. It correlates metrics from CloudWatch, examines logs from CloudWatch Logs or external sources, such as Splunk, reviews recent code changes from GitHub, and analyzes traces from &lt;a href="https://aws.amazon.com/x-ray/"&gt;AWS X-Ray&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/21/2025-11-21_08-45-49.png"&gt;&lt;img loading="lazy" class="aligncenter size-large wp-image-101555" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/21/2025-11-21_08-45-49-1024x900.png" alt="- web app - application stack" width="1024" height="900"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;It identifies the error patterns and provides a detailed investigation summary. In the context of this demo, the investigation reveals that these are intentional test exceptions, shows the timeline of function invocations leading to the alarm, and even suggests monitoring improvements for error handling.&lt;/p&gt; 
&lt;p&gt;The agent uses a dedicated incident channel in Slack, notifies on-call teams if needed, and provides real-time status updates to stakeholders. Through the investigation chat interface, you can interact directly with the agent by asking clarifying questions such as “which logs did you analyze?” or steering the investigation by providing additional context, such as “focus on these specific log groups and rerun your analysis.” If you need expert assistance, you can create an AWS Support case with a single click, automatically populating it with the agent’s findings, and engage with AWS Support experts directly through the investigation chat window.&lt;/p&gt; 
&lt;p&gt;For this demo, the AWS DevOps Agent correctly identified manual activities in the Lambda console to invoke a function that intentionally triggers errors &lt;img src="https://s.w.org/images/core/emoji/14.0.0/72x72/1f607.png" alt="&#128519;" class="wp-smiley" style="height: 1em; max-height: 1em;"&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/21/2025-11-21_08-50-57.png"&gt;&lt;img loading="lazy" class="aligncenter size-large wp-image-101556" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/21/2025-11-21_08-50-57-1024x697.png" alt="- web app - root cause" width="1024" height="697"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Beyond incident response, AWS DevOps Agent analyzes my recent incidents to identify high-impact improvements that prevent future issues.&lt;/p&gt; 
&lt;p&gt;During active incidents, the agent offers immediate mitigation plans through its incident mitigations tab to help restore service quickly. Mitigation plans consist of specs that provide detailed implementation guidance for developers and agentic development tools like &lt;a href="https://kiro.dev/"&gt;Kiro&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;For longer-term resilience, it identifies potential enhancements by examining gaps in observability, infrastructure configurations, and deployment pipeline. My straightforward demo that triggered intentional errors was not enough to generate relevant recommendations though.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/21/2025-11-21_09-08-36.png"&gt;&lt;img loading="lazy" class="aligncenter size-large wp-image-101560" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/21/2025-11-21_09-08-36-1024x390.png" alt="AWS DevOps Agent - web app - recommendations" width="1024" height="390"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;For example, it might detect that a critical service lacks multi-AZ deployment and comprehensive monitoring. The agent then creates detailed recommendations with implementation guidance, considering factors like operational impact and implementation complexity. In an upcoming quick follow-up release, the agent will expand its analysis to include code bugs and testing coverage improvements.&lt;/p&gt; 
&lt;p&gt;&lt;span style="text-decoration: underline"&gt;&lt;strong&gt;Availability&lt;br&gt; &lt;/strong&gt;&lt;/span&gt;You can try AWS DevOps Agent today in the US East (N. Virginia) Region. Although the agent itself runs in US East (N. Virginia) (&lt;code&gt;us-east-1&lt;/code&gt;), it can monitor applications deployed in any Region, across multiple AWS accounts.&lt;/p&gt; 
&lt;p&gt;During the preview period, you can use AWS DevOps Agent at no charge, but there will be a limit on the number of agent task hours per month.&lt;/p&gt; 
&lt;p&gt;As someone who has spent countless nights debugging production issues, I’m particularly excited about how AWS DevOps Agent combines deep operational insights with practical, actionable recommendations. The service helps teams move from reactive firefighting to proactive system improvement.&lt;/p&gt; 
&lt;p&gt;To learn more and sign up for the preview, visit &lt;a href="https://aws.amazon.com/devops-agent"&gt;AWS DevOps Agent&lt;/a&gt;.&amp;nbsp;I look forward to hearing how AWS DevOps Agent helps improve your operational efficiency.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://linktr.ee/sebsto"&gt;— seb&lt;/a&gt;&lt;/p&gt;</content:encoded>
					
					
			
		
		
			</item>
		<item>
		<title>Accelerate AI development using Amazon SageMaker AI with serverless MLflow</title>
		<link>https://aws.amazon.com/blogs/aws/accelerate-ai-development-using-amazon-sagemaker-ai-with-serverless-mlflow/</link>
					
		
		<dc:creator><![CDATA[Donnie Prakoso]]></dc:creator>
		<pubDate>Tue, 02 Dec 2025 16:02:56 +0000</pubDate>
				<category><![CDATA[Amazon SageMaker]]></category>
		<category><![CDATA[Amazon SageMaker Unified Studio]]></category>
		<category><![CDATA[Announcements]]></category>
		<category><![CDATA[AWS re:Invent]]></category>
		<category><![CDATA[Launch]]></category>
		<category><![CDATA[News]]></category>
		<guid isPermaLink="false">ee605f669a451e2017fbcb9b69e2a94fb47c736d</guid>

					<description>Simplify AI experimentation with zero-infrastructure MLflow that launches in minutes, scales automatically, and seamlessly integrates with SageMaker's model customization and pipeline capabilities.</description>
										<content:encoded>&lt;p&gt;Since we &lt;a href="https://aws.amazon.com/blogs/aws/manage-ml-and-generative-ai-experiments-using-amazon-sagemaker-with-mlflow/?trk=c4ea046f-18ad-4d23-a1ac-cdd1267f942c&amp;amp;sc_channel=el"&gt;announced Amazon SageMaker AI with MLflow in June 2024&lt;/a&gt;, our customers have been using MLflow tracking servers to manage their &lt;a href="https://aws.amazon.com/ai/machine-learning/"&gt;machine learning (ML)&lt;/a&gt; and AI experimentation workflows. Building on this foundation, we’re continuing to evolve the MLflow experience to make experimentation even more accessible.&lt;/p&gt; 
&lt;p&gt;Today, I’m excited to announce that &lt;a href="https://aws.amazon.com/sagemaker/ai/experiments/?trk=c4ea046f-18ad-4d23-a1ac-cdd1267f942c&amp;amp;sc_channel=el"&gt;Amazon SageMaker AI with MLflow&lt;/a&gt; now includes a serverless capability that eliminates infrastructure management. This new MLflow capability transforms experiment tracking into an immediate, on-demand experience with automatic scaling that removes the need for capacity planning.&lt;/p&gt; 
&lt;p&gt;The shift to zero-infrastructure management fundamentally changes how teams approach AI experimentation—ideas can be tested immediately without infrastructure planning, enabling more iterative and exploratory development workflows.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;span style="text-decoration: underline"&gt;Getting started with Amazon SageMaker AI and MLflow&lt;/span&gt;&lt;br&gt; &lt;/strong&gt;Let me walk you through creating your first serverless MLflow instance.&lt;/p&gt; 
&lt;p&gt;I navigate to &lt;a href="https://console.aws.amazon.com/sagemaker?trk=c4ea046f-18ad-4d23-a1ac-cdd1267f942c&amp;amp;sc_channel=el"&gt;Amazon SageMaker AI Studio console&lt;/a&gt; and select the &lt;strong&gt;MLflow&lt;/strong&gt; application. The term &lt;strong&gt;MLflow Apps&lt;/strong&gt; replaces the previous &lt;strong&gt;MLflow tracking servers&lt;/strong&gt;&amp;nbsp;terminology, reflecting the simplified, application-focused approach.&lt;/p&gt; 
&lt;p&gt;&lt;img loading="lazy" class="aligncenter size-full wp-image-101811" style="border: 1px solid black;padding: 3px" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/25/news-2025-11-sagemaker-mlflow-rev1-2.png" alt="" width="1675" height="954"&gt;&lt;/p&gt; 
&lt;p&gt;Here, I can see there’s already a default MLflow App created. This simplified MLflow experience makes it more straightforward for me to start doing experiments.&lt;/p&gt; 
&lt;p&gt;I choose &lt;strong&gt;Create MLflow App&lt;/strong&gt;, and enter a name. Here, I have both an &lt;a href="https://aws.amazon.com/iam/"&gt;AWS Identity and Access Management (IAM) role&lt;/a&gt; and &lt;a href="https://aws.amazon.com/s3/"&gt;Amazon Simple Service (Amazon S3)&lt;/a&gt; bucket are already been configured. I only need to modify them in &lt;strong&gt;Advanced settings&lt;/strong&gt; if needed.&lt;br&gt; &lt;img loading="lazy" class="aligncenter size-full wp-image-100710" style="border: 1px solid black;padding: 3px" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/11/news-2025-11-sagemaker-mlflow-1.png" alt="" width="1580" height="754"&gt;&lt;/p&gt; 
&lt;p&gt;Here’s where the first major improvement becomes apparent—the creation process completes in approximately 2 minutes. This immediate availability enables rapid experimentation without infrastructure planning delays, eliminating the wait time that previously interrupted experimentation workflows.&lt;/p&gt; 
&lt;p&gt;&lt;img loading="lazy" class="aligncenter size-full wp-image-100711" style="border: 1px solid black;padding: 3px" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/11/news-2025-11-sagemaker-mlflow-2.png" alt="" width="1156" height="721"&gt;&lt;/p&gt; 
&lt;p&gt;After it’s created, I receive an MLflow &lt;a href="https://docs.aws.amazon.com/IAM/latest/UserGuide/reference-arns.html"&gt;Amazon Resource Name (ARN)&lt;/a&gt; for connecting from notebooks. The simplified management means no server sizing decisions or capacity planning required. I no longer need to choose between different configurations or manage infrastructure capacity, which means I can focus entirely on experimentation. You can learn how to use MLflow SDK at &lt;a href="https://docs.aws.amazon.com/sagemaker/latest/dg/mlflow-track-experiments.html"&gt;Integrate MLflow with your environment in the Amazon SageMaker Developer Guide&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;img loading="lazy" class="aligncenter size-full wp-image-101027" style="border: 1px solid black;padding: 3px" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/15/news-2025-11-sagemaker-mlflow-6.png" alt="" width="2424" height="917"&gt;&lt;/p&gt; 
&lt;p&gt;With MLflow 3.4 support, I can now access new capabilities for &lt;a href="https://aws.amazon.com/generative-ai/"&gt;generative AI&lt;/a&gt; development. MLflow Tracing captures detailed execution paths, inputs, outputs, and metadata throughout the development lifecycle, enabling efficient debugging across distributed AI systems.&lt;/p&gt; 
&lt;p&gt;&lt;img loading="lazy" class="aligncenter size-full wp-image-100713" style="border: 1px solid black;padding: 3px" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/11/news-2025-11-sagemaker-mlflow-4.png" alt="" width="1920" height="734"&gt;&lt;/p&gt; 
&lt;p&gt;This new capability also introduces cross-domain access and cross-account access through &lt;a href="https://aws.amazon.com/ram/?trk=c4ea046f-18ad-4d23-a1ac-cdd1267f942c&amp;amp;sc_channel=el"&gt;AWS Resource Access Manager (AWS RAM)&lt;/a&gt; share. This enhanced collaboration means that teams across different AWS domains and accounts can share MLflow instances securely, breaking down organizational silos.&lt;img loading="lazy" class="aligncenter size-full wp-image-100714" style="border: 1px solid black;padding: 3px" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/11/news-2025-11-sagemaker-mlflow-5.png" alt="" width="1177" height="770"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="text-decoration: underline"&gt;&lt;strong&gt;Better together: Pipelines integration&lt;br&gt; &lt;/strong&gt;&lt;/span&gt;&lt;a href="https://aws.amazon.com/sagemaker/ai/pipelines/"&gt;Amazon SageMaker Pipelines&lt;/a&gt; is integrated with MLflow. SageMaker Pipelines is a serverless workflow orchestration service purpose-built for &lt;a href="https://aws.amazon.com/sagemaker/ai/mlops/?trk=c4ea046f-18ad-4d23-a1ac-cdd1267f942c&amp;amp;sc_channel=el"&gt;machine learning operations (MLOps) and large language model operations (LLMOps) automation&lt;/a&gt;—the practices of deploying, monitoring, and managing ML and LLM models in production. You can easily build, execute, and monitor repeatable end-to-end AI workflows with an intuitive drag-and-drop UI or the Python SDK.&lt;/p&gt; 
&lt;p&gt;&lt;img loading="lazy" class="aligncenter size-full wp-image-101647" style="border: 1px solid black;padding: 3px" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/23/news-2025-11-sagemaker-mlflow-rev1-0.jpg" alt="" width="1737" height="1006"&gt;&lt;/p&gt; 
&lt;p&gt;From a pipeline, a default MLflow App will be created if one doesn’t already exist. The experiment name can be defined and metrics, parameters, and artifacts are logged to the MLflow App as defined in your code. SageMaker AI with MLflow is also integrated with familiar SageMaker AI model development capabilities like &lt;a href="https://aws.amazon.com/sagemaker/ai/jumpstart/"&gt;SageMaker AI JumpStart&lt;/a&gt; and &lt;a href="https://docs.aws.amazon.com/sagemaker/latest/dg/model-registry.html"&gt;Model Registry&lt;/a&gt;, enabling end-to-end workflow automation from data preparation through model fine-tuning.&lt;/p&gt; 
&lt;p&gt;&lt;span style="text-decoration: underline"&gt;&lt;strong&gt;Things to know&lt;br&gt; &lt;/strong&gt;&lt;/span&gt;Here are key points to note:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Pricing&lt;/strong&gt; – The new serverless MLflow capability is offered at no additional cost. Note there are service limits that apply.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Availability&lt;/strong&gt; – This capability is available in the following AWS Regions: US East (N. Virginia, Ohio), US West (N.California, Oregon), Asia Pacific (Mumbai, Seoul, Singapore, Sydney, Tokyo), Canada (Central), Europe (Frankfurt, Ireland, London, Paris, Stockholm), South America (São Paulo).&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Automatic upgrades:&lt;/strong&gt; MLflow in-place version upgrades happen automatically, providing access to the latest features without manual migration work or compatibility concerns. The service currently supports MLflow 3.4, providing access to the latest capabilities including enhanced tracing features.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Migration support&lt;/strong&gt; – You can use the open source MLflow export-import tool available at &lt;a href="https://github.com/mlflow/mlflow-export-import"&gt;mlflow-export-import&lt;/a&gt; to help migrate from existing Tracking Servers, whether they’re from SageMaker AI, self-hosted, or otherwise to serverless MLflow (MLflow Apps).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Get started with serverless MLflow by visiting &lt;a href="https://aws.amazon.com/sagemaker/ai/studio/"&gt;Amazon SageMaker AI Studio&lt;/a&gt; and creating your first MLflow App. Serverless MLflow is also supported in SageMaker Unified Studio for additional workflow flexibility.&lt;/p&gt; 
&lt;p&gt;Happy experimenting!&lt;br&gt; — &lt;a href="https://www.linkedin.com/in/donnieprakoso"&gt;Donnie&lt;/a&gt;&lt;/p&gt;</content:encoded>
					
					
			
		
		
			</item>
		<item>
		<title>Amazon FSx for NetApp ONTAP now integrates with Amazon S3 for seamless data access</title>
		<link>https://aws.amazon.com/blogs/aws/amazon-fsx-for-netapp-ontap-now-integrates-with-amazon-s3-for-seamless-data-access/</link>
					
		
		<dc:creator><![CDATA[Veliswa Boya]]></dc:creator>
		<pubDate>Tue, 02 Dec 2025 15:59:54 +0000</pubDate>
				<category><![CDATA[Amazon Athena]]></category>
		<category><![CDATA[Amazon Bedrock Knowledge Bases]]></category>
		<category><![CDATA[Amazon FSx for NetApp ONTAP]]></category>
		<category><![CDATA[Amazon Kinesis]]></category>
		<category><![CDATA[Amazon SageMaker]]></category>
		<category><![CDATA[Amazon Simple Storage Service (S3)]]></category>
		<category><![CDATA[Analytics]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[AWS Glue]]></category>
		<category><![CDATA[Compute]]></category>
		<category><![CDATA[Serverless]]></category>
		<category><![CDATA[Storage]]></category>
		<guid isPermaLink="false">532a4418828b71483888792b050ac43ee8ddc4d1</guid>

					<description>Access FSx for NetApp ONTAP file data through S3 to enable AI/ML workloads and analytics—letting you use enterprise file data with Bedrock, SageMaker, and analytics services while it remains in your file system.</description>
										<content:encoded>&lt;p&gt;Today, we’re announcing the ability to access your data in &lt;a href="https://aws.amazon.com/fsx/netapp-ontap/?https://aws.amazon.com/fsx/netapp-ontap/"&gt;Amazon FSx for NetApp ONTAP&lt;/a&gt; file systems using &lt;a href="https://aws.amazon.com/pm/serv-s3/?trk=7c8639c6-87c6-47d6-9bd0-a5812eecb848&amp;amp;sc_channel=el"&gt;Amazon Simple Storage Service (Amazon S3)&lt;/a&gt;. With this capability, you can use your enterprise file data to augment generative AI applications with &lt;a href="https://aws.amazon.com/bedrock/knowledge-bases/?trk=7c8639c6-87c6-47d6-9bd0-a5812eecb848&amp;amp;sc_channel=el"&gt;Amazon Bedrock Knowledge Bases for Retrieval Augmented Generation (RAG)&lt;/a&gt;, train &lt;a href="https://aws.amazon.com/ai/machine-learning/?trk=7c8639c6-87c6-47d6-9bd0-a5812eecb848&amp;amp;sc_channel=el"&gt;machine learning (ML)&lt;/a&gt; models with &lt;a href="https://aws.amazon.com/sagemaker/?https://aws.amazon.com/sagemaker/"&gt;Amazon SageMaker&lt;/a&gt;, generate insights with Amazon S3 integrated third-party services, use comprehensive research capabilities in AI-powered business intelligence (BI) tools such as &lt;a href="https://aws.amazon.com/quicksuite/?trk=7c8639c6-87c6-47d6-9bd0-a5812eecb848&amp;amp;sc_channel=el"&gt;Amazon Quick Suite&lt;/a&gt;, and run analyses using Amazon S3 based cloud-native applications, all while your file data continues to reside in your FSx for NetApp ONTAP file system.&lt;/p&gt; 
&lt;p&gt;Amazon FSx for NetApp ONTAP is the first and only fully AWS managed NetApp ONTAP file system in the cloud to migrate on-premises applications that rely on NetApp ONTAP or other &lt;a href="https://aws.amazon.com/what-is/nas/?trk=7c8639c6-87c6-47d6-9bd0-a5812eecb848&amp;amp;sc_channel=el"&gt;network-attached storage (NAS) &lt;/a&gt;appliances to AWS without having to change how you manage your data. FSx for NetApp ONTAP provides the popular capabilities, high performance, and data management APIs of ONTAP file systems with the added benefits of the AWS Cloud, such as simpliﬁed management, on-demand scaling, and seamless integration with other AWS services.&lt;/p&gt; 
&lt;p&gt;Over the years, AWS has developed a broad range of industry-leading AI, ML, and analytics services and applications that work with data in Amazon S3 that organizations use to innovate faster, discover new insights, and make even better data-driven decisions. However, some organizations want to use these services with their enterprise file data stored in NetApp ONTAP or other NAS appliances.&lt;/p&gt; 
&lt;p&gt;&lt;span style="text-decoration: underline"&gt;&lt;strong&gt;How to get started&lt;br&gt; &lt;/strong&gt;&lt;/span&gt;You can create and attach an S3 Access Point to your FSx for ONTAP file system using the &lt;a href="https://console.aws.amazon.com/fsx/?https://console.aws.amazon.com/fsx/?trk=7c8639c6-87c6-47d6-9bd0-a5812eecb848&amp;amp;sc_channel=el"&gt;Amazon FSx console&lt;/a&gt;, the &lt;a href="https://aws.amazon.com/cli/"&gt;AWS Command Line Interface (AWS CLI)&lt;/a&gt;, or the &lt;a href="https://aws.amazon.com/developer/tools/?trk=7c8639c6-87c6-47d6-9bd0-a5812eecb848&amp;amp;sc_channel=el"&gt;AWS SDK&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;I have an existing FSx for ONTAP file system &lt;code&gt;demo-create-s3access&lt;/code&gt; which I created by following the steps in the &lt;a href="https://docs.aws.amazon.com/fsx/latest/ONTAPGuide/creating-file-systems.html?trk=7c8639c6-87c6-47d6-9bd0-a5812eecb848&amp;amp;sc_channel=el"&gt;Creating file systems in the FSx for ONTAP documentation&lt;/a&gt;. Using the Amazon FSx console I now choose the file system ID &lt;code&gt;fs-0c45b011a7f071d70&lt;/code&gt; to access the full details of the file system.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/17/s3access1.png"&gt;&lt;img loading="lazy" class="aligncenter size-large wp-image-101213" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/17/s3access1-1024x241.png" alt="" width="1024" height="241"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;I’ll attach the access point to the volume of the file system. I choose the volume &lt;code&gt;vol1&lt;/code&gt; and then select &lt;strong&gt;Create S3 Access Point&lt;/strong&gt; from the &lt;strong&gt;Actions&lt;/strong&gt; dropdown menu.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/17/s3access2.png"&gt;&lt;img loading="lazy" class="aligncenter size-large wp-image-101215" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/17/s3access2-1024x422.png" alt="" width="1024" height="422"&gt;&lt;/a&gt;&lt;br&gt; I enter details such as the &lt;strong&gt;access point name&lt;/strong&gt;, the type of &lt;strong&gt;file system user identity &lt;/strong&gt;and the &lt;strong&gt;network configuration&lt;/strong&gt;, then choose &lt;strong&gt;Create s3 Access Point&lt;/strong&gt; to finalize the process.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/17/s3access3.png"&gt;&lt;img loading="lazy" class="aligncenter size-full wp-image-101216" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/17/s3access3.png" alt="" width="889" height="946"&gt;&lt;/a&gt;&lt;br&gt; After it’s created, the access point &lt;code&gt;my-s3-accesspoint&lt;/code&gt; is ready to allow access to the file data stored in my file system &lt;code&gt;demo-create-s3access&lt;/code&gt; from Amazon S3. &lt;a href="https://aws.amazon.com/s3/features/access-points/?trk=7c8639c6-87c6-47d6-9bd0-a5812eecb848&amp;amp;sc_channel=el"&gt;Amazon Access Points&lt;/a&gt; are S3 endpoints that can be attached to Amazon FSx volumes and used to perform Amazon S3 object operations.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/26/s3access5-3.png"&gt;&lt;img loading="lazy" class="aligncenter size-large wp-image-102059" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/26/s3access5-3-1024x378.png" alt="" width="1024" height="378"&gt;&lt;/a&gt;&lt;br&gt; I can now bring proprietary data stored in the file system &lt;code&gt;demo-create-s3access&lt;/code&gt; to Amazon S3 for use in applications that work with Amazon S3 while my file data continues to reside in the FSx for NetApp ONTAP file system using the access point &lt;code&gt;my-s3-accesspoint&lt;/code&gt; (this data remains accessible through the file protocols).&lt;/p&gt; 
&lt;p&gt;For the walkthrough in this post, I’ll integrate with Quick Suite.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Integrating decades of enterprise file data with the latest AI powered BI tools on AWS&lt;/strong&gt;&lt;span style="text-decoration: underline"&gt;&lt;strong&gt;&lt;br&gt; &lt;/strong&gt;&lt;/span&gt;In the &lt;a href="https://docs.aws.amazon.com/quicksuite/latest/userguide/signing-in.html"&gt;Quick Suite Console&lt;/a&gt;, in the left navigation pane, I choose &lt;strong&gt;Connections&lt;/strong&gt;, then select &lt;strong&gt;Integrations&lt;/strong&gt;. Before you begin, make sure that you have the correct permissions to the Amazon S3 AWS resource. You can control the AWS resources that Quick Suite can access by &lt;a href="https://docs.aws.amazon.com/quicksuite/latest/userguide/accessing-data-sources.html"&gt;following the Amazon Quick Suite user guide&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/20/qsuite1.png"&gt;&lt;img loading="lazy" class="aligncenter size-large wp-image-101484" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/20/qsuite1-1024x506.png" alt="" width="1024" height="506"&gt;&lt;/a&gt;&lt;br&gt; After I’ve selected the &lt;strong&gt;Amazon S3 integration&lt;/strong&gt; I enter my Amazon S3 Access Point alias as the &lt;strong&gt;S3 bucket URL&lt;/strong&gt;, leave the rest of the information as default, then choose &lt;strong&gt;Create and continue&lt;/strong&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/26/qsuite2-1.png"&gt;&lt;img loading="lazy" class="aligncenter size-large wp-image-102058" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/26/qsuite2-1-1024x481.png" alt="" width="1024" height="481"&gt;&lt;/a&gt;&lt;br&gt; I finalize the process by providing the &lt;strong&gt;Name&lt;/strong&gt; of the knowledge base, the &lt;strong&gt;Description&lt;/strong&gt;, then choose &lt;strong&gt;Create&lt;/strong&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/20/qsuite3.png"&gt;&lt;img loading="lazy" class="aligncenter size-large wp-image-101489" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/20/qsuite3-1024x472.png" alt="" width="1024" height="472"&gt;&lt;/a&gt;&lt;br&gt; After the knowledge base has been created it’s automatically synchronized, it’s now available for interaction.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/20/qsuite4.png"&gt;&lt;img loading="lazy" class="aligncenter size-large wp-image-101490" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/20/qsuite4-1024x224.png" alt="" width="1024" height="224"&gt;&lt;/a&gt;&lt;br&gt; I want to learn more about the &lt;a href="https://aws.eu/"&gt;AWS European Sovereign Cloud&lt;/a&gt; so I’ve updated the file system (accessed through the S3 Access Point &lt;code&gt;my-s3-accesspoin-iyytkgz83djdjj7abn3u711supfgkuse1b-ext-s3alias&lt;/code&gt;) with the AWS whitepaper on this topic. In the chat in Amazon Quick Suite. I start asking the first question “&lt;em&gt;do we have any documentation on the europe sovereignty cloud?&lt;/em&gt;“. To answer my question, &lt;a href="https://docs.aws.amazon.com/quicksuite/latest/userguide/use-agents.html"&gt;the chat agent accesses and analyzes various types of data sources I have permission to use&lt;/a&gt;, including uploaded files in my current conversation, spaces I have access to, knowledge bases from my integrations, and more.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/20/qsuite6.png"&gt;&lt;img loading="lazy" class="aligncenter size-full wp-image-101493" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/20/qsuite6.png" alt="" width="544" height="748"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;When I verify the source, I see that the document I uploaded to my file system is listed as one of the sources.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/20/qsuite7.png"&gt;&lt;img loading="lazy" class="aligncenter size-full wp-image-101494" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/20/qsuite7.png" alt="" width="552" height="466"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="text-decoration: underline"&gt;&lt;strong&gt;Other use cases of Amazon S3 Access Points for Amazon FSx for NetApp ONTAP&lt;/strong&gt;&lt;/span&gt;&lt;br&gt; Earlier, we looked at use cases such as connecting an organization’s proprietary file data to Amazon Quick Suite for advanced business intelligence. Additionally, Amazon S3 Access Points for Amazon FSx for NetApp ONTAP can be used to seamlessly integrate enterprise file data with comprehensive analytics services, such as &lt;a href="https://aws.amazon.com/athena/?trk=7c8639c6-87c6-47d6-9bd0-a5812eecb848&amp;amp;sc_channel=el"&gt;Amazon Athena for serverless SQL queries&lt;/a&gt; or &lt;a href="https://aws.amazon.com/glue/?trk=7c8639c6-87c6-47d6-9bd0-a5812eecb848&amp;amp;sc_channel=el"&gt;AWS Glue for ETL processing&lt;/a&gt;, to name a few.&lt;/p&gt; 
&lt;p&gt;Amazon S3 Access Points for Amazon FSx for NetApp ONTAP are also suitable for data access from &lt;a href="https://aws.amazon.com/serverless/?trk=7c8639c6-87c6-47d6-9bd0-a5812eecb848&amp;amp;sc_channel=el"&gt;serverless&lt;/a&gt; compute workloads that are cloud-native with containerized microservices that require flexible access to shared enterprise datasets, such as configuration files, reference data, content libraries, model artifacts, and application assets.&lt;/p&gt; 
&lt;p&gt;&lt;span style="text-decoration: underline"&gt;&lt;strong&gt;Now available&lt;/strong&gt;&lt;/span&gt;&lt;br&gt; You can get started today using the Amazon FSx console, AWS CLI, or AWS SDK to attach Amazon S3 Access Points to your Amazon FSx for NetApp ONTAP file systems. The feature is available in the following &lt;a href="https://aws.amazon.com/about-aws/global-infrastructure/regions_az/?trk=7c8639c6-87c6-47d6-9bd0-a5812eecb848&amp;amp;sc_channel=el"&gt;AWS Regions&lt;/a&gt;: Africa (Cape Town), Asia Pacific (Hong Kong, Hyderabad, Jakarta, Melbourne, Mumbai, Osaka, Seoul, Singapore, Sydney, Tokyo), Canada (Central, Calgary), Europe (Frankfurt, Ireland, London, Milan, Paris, Spain, Stockholm, Zurich), Israel (Tel Aviv), Middle East (Bahrain, UAE), South America (Sao Paulo), US East (N. Virginia, Ohio), and US West (N. California Oregon). You’re billed by Amazon S3 for the requests and data transfer costs through your S3 Access Point, in addition to your standard Amazon FSx charges. Learn more on the &lt;a href="https://aws.amazon.com/fsx/netapp-ontap/pricing/?trk=7c8639c6-87c6-47d6-9bd0-a5812eecb848&amp;amp;sc_channel=el"&gt;Amazon FSx for NetApp ONTAP pricing page&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;PS: Writing a blog post at AWS is always a team effort, even when you see only one name under the post title. In this case, I want to thank &lt;a href="https://www.linkedin.com/in/luke-miller-1a937a66/"&gt;Luke Miller&lt;/a&gt;, for his expertise and generous help with technical guidance, which made this overview possible and comprehensive.&lt;/p&gt; 
&lt;p&gt;– &lt;a href="https://linkedin.com/in/veliswa-boya"&gt;Veliswa Boya&lt;/a&gt;.&lt;/p&gt;</content:encoded>
					
					
			
		
		
			</item>
	</channel>
</rss>